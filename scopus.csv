"Authors","Author full names","Author(s) ID","Title","Year","Source title","Volume","Issue","Art. No.","Page start","Page end","Page count","Cited by","DOI","Link","Affiliations","Authors with affiliations","Abstract","Author Keywords","Index Keywords","Editors","Publisher","Language of Original Document","Document Type","Publication Stage","Open Access","Source","EID"
"Chandrasekhar A.; Chan J.; Ogoke F.; Ajenifujah O.; Barati Farimani A.","Chandrasekhar, Achuth (59193602900); Chan, Jonathan (59193322900); Ogoke, Francis (57221686064); Ajenifujah, Olabode (55123178400); Barati Farimani, Amir (37067199500)","59193602900; 59193322900; 57221686064; 55123178400; 37067199500","AMGPT: A large language model for contextual querying in additive manufacturing","2024","Additive Manufacturing Letters","11","","100232","","","","0","10.1016/j.addlet.2024.100232","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202690158&doi=10.1016%2fj.addlet.2024.100232&partnerID=40&md5=d8b80a489b6fc34f4a884dad482652fb","Materials Science and Engineering, Carnegie Mellon University, Pittsburgh, 15213, PA, United States; Mechanical Engineering, Carnegie Mellon University, Pittsburgh, 15213, PA, United States; Biomedical Engineering, Carnegie Mellon University, Pittsburgh, 15213, PA, United States; Chemical Engineering, Carnegie Mellon University, Pittsburgh, 15213, PA, United States; Machine Learning Department, Carnegie Mellon University, Pittsburgh, 15213, PA, United States","Chandrasekhar A., Materials Science and Engineering, Carnegie Mellon University, Pittsburgh, 15213, PA, United States; Chan J., Mechanical Engineering, Carnegie Mellon University, Pittsburgh, 15213, PA, United States; Ogoke F., Mechanical Engineering, Carnegie Mellon University, Pittsburgh, 15213, PA, United States; Ajenifujah O., Mechanical Engineering, Carnegie Mellon University, Pittsburgh, 15213, PA, United States; Barati Farimani A., Mechanical Engineering, Carnegie Mellon University, Pittsburgh, 15213, PA, United States, Biomedical Engineering, Carnegie Mellon University, Pittsburgh, 15213, PA, United States, Chemical Engineering, Carnegie Mellon University, Pittsburgh, 15213, PA, United States, Machine Learning Department, Carnegie Mellon University, Pittsburgh, 15213, PA, United States","Generalized large language models (LLMs) such as GPT-4 may not provide specific answers to queries formulated by materials science researchers. These models may produce a high-level outline but lack the capacity to return detailed instructions on manufacturing and material properties of novel alloys. We introduce “AMGPT”, a specialized LLM text generator designed for metal AM queries. The goal of AMGPT is to assist researchers and users in navigating a curated corpus of literature. Instead of training from scratch, we employ a pre-trained Llama2-7B model from Hugging Face in a Retrieval-Augmented Generation (RAG) setup, utilizing it to dynamically incorporate information from ∼50 AM papers and textbooks in PDF format. Mathpix is used to convert these PDF documents into TeX format, facilitating their integration into the RAG pipeline managed by LlamaIndex. A query retrieval function has also been added, enabling the system to fetch relevant literature from Elsevier journals based on the context of the query. Expert evaluations of this project highlight that specific embeddings from the RAG setup accelerate response times and maintain coherence in the generated text. © 2024 The Authors","Contextual querying; Large language models; Laser powder bed fusion; Machine learning; Retrieval-augmented generation","","","Elsevier B.V.","English","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85202690158"
"Toslali M.; Snible E.; Chen J.; Cha A.; Singh S.; Kalantar M.; Parthasarathy S.","Toslali, Mert (57219230376); Snible, Edward (6507254062); Chen, Jing (59225825800); Cha, Alan (57202355346); Singh, Sandeep (59225989200); Kalantar, Michael (6602000730); Parthasarathy, Srinivasan (58808222100)","57219230376; 6507254062; 59225825800; 57202355346; 59225989200; 6602000730; 58808222100","AgraBOT: Accelerating Third-Party Security Risk Management in Enterprise Setting through Generative AI","2024","FSE Companion - Companion Proceedings of the 32nd ACM International Conference on the Foundations of Software Engineering","","","","74","79","5","0","10.1145/3663529.3663829","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199019160&doi=10.1145%2f3663529.3663829&partnerID=40&md5=19433821b2ca4168fd3b3c33f47aea2d","IBM Research, Cambridge, United States; IBM Research, Yorktown Heights, United States; IBM, Bengaluru, India","Toslali M., IBM Research, Cambridge, United States; Snible E., IBM Research, Yorktown Heights, United States; Chen J., IBM Research, Yorktown Heights, United States; Cha A., IBM Research, Yorktown Heights, United States; Singh S., IBM, Bengaluru, India; Kalantar M., IBM Research, Yorktown Heights, United States; Parthasarathy S., IBM Research, Yorktown Heights, United States","In the contemporary business landscape, organizations often rely on third-party services for many functions, including IT services, cloud computing, and business processes. To identify potential security risks, organizations conduct rigorous assessments before engaging with third-party vendors, referred to as Third-Party Security Risk Management (TPSRM). Traditionally, TPSRM assessments are executed manually by human experts and involve scrutinizing various third-party documents such as System and Organization Controls Type 2 (SOC 2) reports and reviewing comprehensive questionnaires along with the security policy and procedures of vendors—a process that is time-intensive and inherently lacks scalability. AgraBOT, a Retrieval Augmented Generation (RAG) framework, can assist TPSRM assessors by expediting TPSRM assessments and reducing the time required from days to minutes. AgraBOT utilizes AI techniques, including information retrieval (IR), large language models (LLMs), multi-stage ranking, prompt engineering, and in-context learning to accurately generate relevant answers from third-party documents to conduct assessments. We evaluate AgraBOT on seven real TPSRM assessments, consisting of 373 question-answer pairs, and attain an F1 score of 0.85. © 2024 Copyright held by the owner/author(s).","AI; Document Understanding; LLM; RAG; TPSRM","Document understanding; IT services; Language model; Large language model; Management assessment; Retrieval augmented generation; Security risk managements; Third parties; Third party services; Third-party security risk management; Risk management","d�Amorim M.","Association for Computing Machinery, Inc","English","Conference paper","Final","","Scopus","2-s2.0-85199019160"
"Kreimeyer K.; Canzoniero J.V.; Fatteh M.; Anagnostou V.; Botsis T.","Kreimeyer, Kory (36450954100); Canzoniero, Jenna V. (57214142995); Fatteh, Maria (57732298400); Anagnostou, Valsamo (6503916207); Botsis, Taxiarchis (57202845066)","36450954100; 57214142995; 57732298400; 6503916207; 57202845066","Using Retrieval-Augmented Generation to Capture Molecularly-Driven Treatment Relationships for Precision Oncology","2024","Studies in Health Technology and Informatics","316","","","983","987","4","0","10.3233/SHTI240575","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202004674&doi=10.3233%2fSHTI240575&partnerID=40&md5=73ab64dbe5f498edcb90fedca177ca93","Sidney Kimmel Comprehensive Cancer Center, Johns Hopkins School of Medicine, Baltimore, MD, United States; The Johns Hopkins Molecular Tumor Board, Johns Hopkins School of Medicine, Baltimore, MD, United States","Kreimeyer K., Sidney Kimmel Comprehensive Cancer Center, Johns Hopkins School of Medicine, Baltimore, MD, United States; Canzoniero J.V., Sidney Kimmel Comprehensive Cancer Center, Johns Hopkins School of Medicine, Baltimore, MD, United States, The Johns Hopkins Molecular Tumor Board, Johns Hopkins School of Medicine, Baltimore, MD, United States; Fatteh M., Sidney Kimmel Comprehensive Cancer Center, Johns Hopkins School of Medicine, Baltimore, MD, United States, The Johns Hopkins Molecular Tumor Board, Johns Hopkins School of Medicine, Baltimore, MD, United States; Anagnostou V., Sidney Kimmel Comprehensive Cancer Center, Johns Hopkins School of Medicine, Baltimore, MD, United States, The Johns Hopkins Molecular Tumor Board, Johns Hopkins School of Medicine, Baltimore, MD, United States; Botsis T., Sidney Kimmel Comprehensive Cancer Center, Johns Hopkins School of Medicine, Baltimore, MD, United States","Modern generative artificial intelligence techniques like retrieval-augmented generation (RAG) may be applied in support of precision oncology treatment discussions. Experts routinely review published literature for evidence and recommendations of treatments in a labor-intensive process. A RAG pipeline may help reduce this effort by providing chunks of text from these publications to an off-the-shelf large language model (LLM), allowing it to answer related questions without any fine-tuning. This potential application is demonstrated by retrieving treatment relationships from a trusted data source (OncoKB) and reproducing over 80% of them by asking simple questions to an untrained Llama 2 model with access to relevant abstracts. © 2024 The Authors.","Large Language Models; Precision Oncology; Retrieval-Augmented Generation","Artificial Intelligence; Data Mining; Humans; Information Storage and Retrieval; Medical Oncology; Natural Language Processing; Neoplasms; Precision Medicine; Artificial intelligence techniques; Data-source; Fine tuning; Labor intensive process; Language model; Large language model; Precision oncology; Retrieval-augmented generation; Simple++; artificial intelligence; data mining; human; information retrieval; natural language processing; neoplasm; oncology; personalized medicine; procedures; therapy; Modeling languages","Mantas J.; Hasman A.; Demiris G.; Saranto K.; Marschollek M.; Arvanitis T.N.; Ognjanovic I.; Benis A.; Gallos P.; Zoulias E.; Andrikopoulou E.","IOS Press BV","English","Conference paper","Final","All Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85202004674"
"Jang D.-S.; Cho D.-H.; Lee W.-C.; Ryu S.-K.; Jeong B.; Hong M.; Jung M.; Kim M.; Lee M.; Lee S.; Choi H.-L.","Jang, Dae-Sung (54941965700); Cho, Doo-Hyun (57199755160); Lee, Woo-Cheol (57193274836); Ryu, Seung-Keol (58160850500); Jeong, Byeongmin (55882237300); Hong, Minji (59246007100); Jung, Minjo (59246007200); Kim, Minchae (59245183000); Lee, Minjoon (57373537700); Lee, SeungJae (59246007300); Choi, Han-Lim (7404339098)","54941965700; 57199755160; 57193274836; 58160850500; 55882237300; 59246007100; 59246007200; 59245183000; 57373537700; 59246007300; 7404339098","Unlocking Robotic Autonomy: A Survey on the Applications of Foundation Models","2024","International Journal of Control, Automation and Systems","22","8","","2341","2384","43","0","10.1007/s12555-024-0438-7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200332581&doi=10.1007%2fs12555-024-0438-7&partnerID=40&md5=e59db2e8be707b8362ac54cf3a856d86","Department of Aeronautical and Astronautical Engineering, Korea Aerospace University, 76 Hanggongdaehak-ro, Deogyang-gu, Goyang-si, Gyeonggi-do, 10540, South Korea; AI Team, D.Notitia Inc, 1 Gangnam-daero 51-gil, Seocho-gu, Seoul, 06628, South Korea; Extreme Robotics Team, Korea Atomic Energy Research Institute, 111 Daedeok-daero 989 beon-gil, Yuseong-gu, Daejeon, 34057, South Korea; Department of Aerospace Engineering, KAIST, 291 Daehak-ro, Yuseong-gu, Daejeon, 34141, South Korea; Space Systems Team, Defense Agency for Technology and Quality, 70 Saneopdanji-ro, Daedeok-gu, Daejeon, South Korea","Jang D.-S., Department of Aeronautical and Astronautical Engineering, Korea Aerospace University, 76 Hanggongdaehak-ro, Deogyang-gu, Goyang-si, Gyeonggi-do, 10540, South Korea; Cho D.-H., AI Team, D.Notitia Inc, 1 Gangnam-daero 51-gil, Seocho-gu, Seoul, 06628, South Korea; Lee W.-C., Extreme Robotics Team, Korea Atomic Energy Research Institute, 111 Daedeok-daero 989 beon-gil, Yuseong-gu, Daejeon, 34057, South Korea; Ryu S.-K., Department of Aerospace Engineering, KAIST, 291 Daehak-ro, Yuseong-gu, Daejeon, 34141, South Korea; Jeong B., Department of Aerospace Engineering, KAIST, 291 Daehak-ro, Yuseong-gu, Daejeon, 34141, South Korea; Hong M., Department of Aerospace Engineering, KAIST, 291 Daehak-ro, Yuseong-gu, Daejeon, 34141, South Korea; Jung M., Department of Aerospace Engineering, KAIST, 291 Daehak-ro, Yuseong-gu, Daejeon, 34141, South Korea; Kim M., Department of Aerospace Engineering, KAIST, 291 Daehak-ro, Yuseong-gu, Daejeon, 34141, South Korea; Lee M., Space Systems Team, Defense Agency for Technology and Quality, 70 Saneopdanji-ro, Daedeok-gu, Daejeon, South Korea; Lee S., AI Team, D.Notitia Inc, 1 Gangnam-daero 51-gil, Seocho-gu, Seoul, 06628, South Korea; Choi H.-L., Department of Aerospace Engineering, KAIST, 291 Daehak-ro, Yuseong-gu, Daejeon, 34141, South Korea","The advancement of foundation models, such as large language models (LLMs), vision-language models (VLMs), diffusion models, and robotics foundation models (RFMs), has become a new paradigm in robotics by offering innovative approaches to the long-standing challenge of building robot autonomy. These models enable the development of robotic agents that can independently understand and reason about semantic contexts, plan actions, physically interact with surroundings, and adapt to new environments and untrained tasks. This paper presents a comprehensive and systematic survey of recent advancements in applying foundation models to robot perception, planning, and control. It introduces the key concepts and terminology associated with foundation models, providing a clear understanding for researchers in robotics and control engineering. The relevant studies are categorized based on how foundation models are utilized in various elements of robotic autonomy, focusing on 1) perception and situational awareness: object detection and classification, semantic understanding, mapping, and navigation; 2) decision making and task planning: mission understanding, task decomposition and coordination, planning with symbolic and learning-based approaches, plan validation and correction, and LLM-robot interaction; 3) motion planning and control: motion planning, control command and reward generation, and trajectory generation and optimization with diffusion models. Furthermore, the survey covers essential environmental setups, including real-world and simulation datasets and platforms used in training and validating these models. It concludes with a discussion on current challenges such as robustness, explainability, data scarcity, and real-time performance, and highlights promising future directions, including retrieval augmented generation, on-device foundation models, and explainability. This survey aims to systematically summarize the latest research trends in applying foundation models to robotics, bridging the gap between the state-of-the-art in artificial intelligence and robotics. By sharing knowledge and resources, this survey is expected to foster the introduction of a new research paradigm for building generalized and autonomous robots. © ICROS, KIEE and Springer 2024.","Decision making; foundation models; large language models (LLMs); motion planning; perception; robotic autonomy; task planning; vision-language models (VLMs)","Autonomous agents; Control theory; Diffusion; Intelligent robots; Motion planning; Robot programming; Semantics; Simulation platform; Decisions makings; Diffusion model; Foundation models; Language model; Large language model; Motion-planning; Robotic autonomy; Task planning; Vision-language model; Decision making","","Institute of Control, Robotics and Systems","English","Article","Final","","Scopus","2-s2.0-85200332581"
"Gong E.J.; Bang C.S.","Gong, Eun Jeong (56107863900); Bang, Chang Seok (57991522300)","56107863900; 57991522300","Evaluating the role of large language models in inflammatory bowel disease patient information","2024","World Journal of Gastroenterology","30","29","","3538","3540","2","1","10.3748/wjg.v30.i29.3538","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199874702&doi=10.3748%2fwjg.v30.i29.3538&partnerID=40&md5=1e52bf55e2df32a35c66b72e90eaba78","Department of Internal Medicine, Hallym University College of Medicine, Gangwon-do, Chuncheon, 24253, South Korea","Gong E.J., Department of Internal Medicine, Hallym University College of Medicine, Gangwon-do, Chuncheon, 24253, South Korea; Bang C.S., Department of Internal Medicine, Hallym University College of Medicine, Gangwon-do, Chuncheon, 24253, South Korea","This letter evaluates the article by Gravina et al on ChatGPT’s potential in providing medical information for inflammatory bowel disease patients. While promising, it highlights the need for advanced techniques like reasoning + action and retrieval-augmented generation to improve accuracy and reliability. Emphasizing that simple question and answer testing is insufficient, it calls for more nuanced evaluation methods to truly gauge large language models’ capabilities in clinical applications. ©The Author(s) 2024. Published by Baishideng Publishing Group Inc. All rights reserved.","Artificial intelligence; Chat generative pre-trained transformer; Crohn’s disease; Inflammatory bowel disease; Large language model; Ulcerative colitis","Humans; Inflammatory Bowel Diseases; Language; Patient Education as Topic; Reproducibility of Results; Article; artificial intelligence; ChatGPT; chronic disease; doctor patient relationship; empathy; health care personnel; human; inflammatory bowel disease; information retrieval; large language model; medical information; patient information; quality of life; questionnaire; diagnosis; language; patient education; reproducibility; therapy","","Baishideng Publishing Group Inc","English","Article","Final","","Scopus","2-s2.0-85199874702"
"Benzinho J.; Ferreira J.; Batista J.; Pereira L.; Maximiano M.; Távora V.; Gomes R.; Remédios O.","Benzinho, José (59370201600); Ferreira, João (59369845700); Batista, Joel (59370025400); Pereira, Leandro (56890359100); Maximiano, Marisa (57203750906); Távora, Vítor (57201127535); Gomes, Ricardo (57413754100); Remédios, Orlando (57188984597)","59370201600; 59369845700; 59370025400; 56890359100; 57203750906; 57201127535; 57413754100; 57188984597","LLM Based Chatbot for Farm-to-Fork Blockchain Traceability Platform","2024","Applied Sciences (Switzerland)","14","19","8856","","","","0","10.3390/app14198856","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206560782&doi=10.3390%2fapp14198856&partnerID=40&md5=2fe7418f0352f6383d2ddc20af5c2831","School of Technology and Management, Polytechnic of Leiria, Leiria, 2411-901, Portugal; Computer Science and Communication Research Centre (CIIC), Leiria, 2411-901, Portugal; Sensefinity, Lisboa, 1749-016, Portugal","Benzinho J., School of Technology and Management, Polytechnic of Leiria, Leiria, 2411-901, Portugal; Ferreira J., School of Technology and Management, Polytechnic of Leiria, Leiria, 2411-901, Portugal; Batista J., School of Technology and Management, Polytechnic of Leiria, Leiria, 2411-901, Portugal; Pereira L., School of Technology and Management, Polytechnic of Leiria, Leiria, 2411-901, Portugal; Maximiano M., School of Technology and Management, Polytechnic of Leiria, Leiria, 2411-901, Portugal, Computer Science and Communication Research Centre (CIIC), Leiria, 2411-901, Portugal; Távora V., School of Technology and Management, Polytechnic of Leiria, Leiria, 2411-901, Portugal; Gomes R., School of Technology and Management, Polytechnic of Leiria, Leiria, 2411-901, Portugal; Remédios O., Sensefinity, Lisboa, 1749-016, Portugal","Blockchain technology has been used with great effect in farm-to-fork traceability projects. However, this technology has a steep learning curve when it comes to its user interface. To minimize this difficulty, we created a solution based on a Large Language Model (LLM) conversational agent. Our implementation, starting with an existing knowledge base that is prepared and processed with an embedding model to be stored in a vector database, follows a Retrieval-Augmented Generation (RAG) approach. Other non-textual media like images and videos are aggregated with the embeddings to enrich the user experience. User queries are combined with a proximity search in the vector database and feed into an LLM that considers the conversation history with the user in its replies. Given the asynchronous nature of these models, we implemented a similarly asynchronous scheme using Server-Sent Events that deliver the models’ replies to a UI that supports multimodal media types such as images and videos by providing the visualization of these resources. The end solution allows users to interact with advanced technologies using a natural language interface; this in turn empowers food traceability projects to overcome their natural difficulty in engaging early adopters. © 2024 by the authors.","chatbot; large language model; RAG; user support; vector databases","Bot (Internet); Database systems; Block-chain; Chatbots; Embeddings; Language model; Large language model; Model-based OPC; Retrieval-augmented generation; Steep learning curve; User support; Vector database; Chatbots","","Multidisciplinary Digital Publishing Institute (MDPI)","English","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85206560782"
"Ji X.; Wang X.; Zhang H.; Meng Z.; Zhang J.; Zhuang P.; Jia Y.; Xu D.","Ji, Xiangyu (59368869700); Wang, Xin (59157656000); Zhang, Heyi (59369171000); Meng, Zhaopeng (7201894900); Zhang, Junhua (55720332300); Zhuang, Pengwei (26032475900); Jia, Yongzhe (57212389595); Xu, Dawei (57212379937)","59368869700; 59157656000; 59369171000; 7201894900; 55720332300; 26032475900; 57212389595; 57212379937","Knowledge Augmentation on Traditional Chinese Medicine Language Model; [面向中医药大模型的知识增强方法研究]","2024","Journal of Frontiers of Computer Science and Technology","18","10","","2616","2629","13","0","10.3778/j.issn.1673-9418.2407082","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206536429&doi=10.3778%2fj.issn.1673-9418.2407082&partnerID=40&md5=427400fe20f40c6fb77890db963f88c7","College of Intelligence and Computing, Tianjin University, Tianjin, 300350, China; Tianjin University of Traditional Chinese Medicine, Tianjin, 300193, China; National Clinical Research Center for Chinese Medicine Acupuncture and Moxibustion, First Teaching Hospital of Tianjin University of Traditional Chinese Medicine, Tianjin, 300193, China; Tiandazhitu(Tianjin) Technology Co., Ltd., Tianjin, 300192, China","Ji X., College of Intelligence and Computing, Tianjin University, Tianjin, 300350, China; Wang X., College of Intelligence and Computing, Tianjin University, Tianjin, 300350, China; Zhang H., College of Intelligence and Computing, Tianjin University, Tianjin, 300350, China; Meng Z., Tianjin University of Traditional Chinese Medicine, Tianjin, 300193, China; Zhang J., Tianjin University of Traditional Chinese Medicine, Tianjin, 300193, China; Zhuang P., National Clinical Research Center for Chinese Medicine Acupuncture and Moxibustion, First Teaching Hospital of Tianjin University of Traditional Chinese Medicine, Tianjin, 300193, China; Jia Y., College of Intelligence and Computing, Tianjin University, Tianjin, 300350, China, Tiandazhitu(Tianjin) Technology Co., Ltd., Tianjin, 300192, China; Xu D., Tiandazhitu(Tianjin) Technology Co., Ltd., Tianjin, 300192, China","Recently, large language models (LLM) have made significant achievements in various fields. However, due to lack of specialized knowledge and the gap between modern medicine and traditional Chinese medicine (TCM), it is still a challenge to deploy LLM in TCM. Existing methods fail to maintain the structure of TCM prescription. To address the problems, a pattern of knowledge augmentation is proposed. The method includes model training, knowledge graph construction and knowledge augmentation. In the training phase, TCM language model is trained on TCM corpus, by a two-stage method combining pre-training and fine-tuning. In the knowledge graph construction phase, prescription knowledge graph is constructed from nearly 100000 preprocessed classical TCM prescriptions and those from ancient books. In the knowledge augmentation phase, enhanced by the above pattern, outputs are generated from computation of knowledge graph, according to the schema of knowledge graph from searching result, which preserves the structure of prescriptions. A set of evaluations specific to prescription optimizations is proposed, including objective and subjective indicators, to evaluate the performance of the model for the task. Experiment shows that the model improves greatly on both subjective and objective evaluations compared with baselines. BLEU-1 is increased by up to 0.09, while ROUGE-1 is increased by up to 0.21. Ablation study shows that, it is of vital importance for the model performance to be knowledge-augmented. BLEU-1 of augmentation-free model is decreased by about 37% compared with that of the augmented model. © 2024 Journal of Computer Engineering and Applications Beijing Co., Ltd.; Science Press. All rights reserved.","large language model (LLM); prescription optimization; retrieval augmented generation; traditional Chinese medicine","","","Journal of Computer Engineering and Applications Beijing Co., Ltd.; Science Press","Chinese","Article","Final","","Scopus","2-s2.0-85206536429"
"Soman K.; Rose P.W.; Morris J.H.; Akbas R.E.; Smith B.; Peetoom B.; Villouta-Reyes C.; Cerono G.; Shi Y.; Rizk-Jackson A.; Israni S.; Nelson C.A.; Huang S.; Baranzini S.E.","Soman, Karthik (57203998162); Rose, Peter W. (7201669132); Morris, John H. (8278371800); Akbas, Rabia E. (58110121800); Smith, Brett (59114478600); Peetoom, Braian (58754087500); Villouta-Reyes, Catalina (58754153400); Cerono, Gabriel (57918698800); Shi, Yongmei (57374782600); Rizk-Jackson, Angela (12345286100); Israni, Sharat (57197752356); Nelson, Charlotte A. (57195939920); Huang, Sui (58808317700); Baranzini, Sergio E. (6601933310)","57203998162; 7201669132; 8278371800; 58110121800; 59114478600; 58754087500; 58754153400; 57918698800; 57374782600; 12345286100; 57197752356; 57195939920; 58808317700; 6601933310","Biomedical knowledge graph-optimized prompt generation for large language models","2024","Bioinformatics","40","9","btae560","","","","0","10.1093/bioinformatics/btae560","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205402312&doi=10.1093%2fbioinformatics%2fbtae560&partnerID=40&md5=4a86e921811e77ed9e411bb8fcd611d0","Department of Neurology, Weill Institute for Neurosciences, University of California, San Francisco, San Francisco, 94158, CA, United States; San Diego Supercomputer Center, University of California, San Diego, 92093, CA, United States; Department of Pharmaceutical Chemistry, School of Pharmacy, University of California, San Francisco, 94158, CA, United States; Institute for Systems Biology, Seattle, 98109, WA, United States; Bakar Computational Health Sciences Institute, University of California, San Francisco, 94158, CA, United States; Mate Bioservices, Inc. Swallowtail Ct., Brisbane, 94005, CA, United States","Soman K., Department of Neurology, Weill Institute for Neurosciences, University of California, San Francisco, San Francisco, 94158, CA, United States; Rose P.W., San Diego Supercomputer Center, University of California, San Diego, 92093, CA, United States; Morris J.H., Department of Pharmaceutical Chemistry, School of Pharmacy, University of California, San Francisco, 94158, CA, United States; Akbas R.E., Department of Neurology, Weill Institute for Neurosciences, University of California, San Francisco, San Francisco, 94158, CA, United States; Smith B., Institute for Systems Biology, Seattle, 98109, WA, United States; Peetoom B., Department of Neurology, Weill Institute for Neurosciences, University of California, San Francisco, San Francisco, 94158, CA, United States; Villouta-Reyes C., Department of Neurology, Weill Institute for Neurosciences, University of California, San Francisco, San Francisco, 94158, CA, United States; Cerono G., Department of Neurology, Weill Institute for Neurosciences, University of California, San Francisco, San Francisco, 94158, CA, United States; Shi Y., Bakar Computational Health Sciences Institute, University of California, San Francisco, 94158, CA, United States; Rizk-Jackson A., Bakar Computational Health Sciences Institute, University of California, San Francisco, 94158, CA, United States; Israni S., Bakar Computational Health Sciences Institute, University of California, San Francisco, 94158, CA, United States; Nelson C.A., Mate Bioservices, Inc. Swallowtail Ct., Brisbane, 94005, CA, United States; Huang S., Institute for Systems Biology, Seattle, 98109, WA, United States; Baranzini S.E., Department of Neurology, Weill Institute for Neurosciences, University of California, San Francisco, San Francisco, 94158, CA, United States","Motivation: Large language models (LLMs) are being adopted at an unprecedented rate, yet still face challenges in knowledge-intensive domains such as biomedicine. Solutions such as pretraining and domain-specific fine-tuning add substantial computational overhead, requiring further domain-expertise. Here, we introduce a token-optimized and robust Knowledge Graph-based Retrieval Augmented Generation (KG-RAG) framework by leveraging a massive biomedical KG (SPOKE) with LLMs such as Llama-2-13b, GPT-3.5-Turbo, and GPT-4, to generate meaningful biomedical text rooted in established knowledge. Results: Compared to the existing RAG technique for Knowledge Graphs, the proposed method utilizes minimal graph schema for context extraction and uses embedding methods for context pruning. This optimization in context extraction results in more than 50% reduction in token consumption without compromising the accuracy, making a cost-effective and robust RAG implementation on proprietary LLMs. KG-RAG consistently enhanced the performance of LLMs across diverse biomedical prompts by generating responses rooted in established knowledge, accompanied by accurate provenance and statistical evidence (if available) to substantiate the claims. Further benchmarking on human curated datasets, such as biomedical true/false and multiple-choice questions (MCQ), showed a remarkable 71% boost in the performance of the Llama-2 model on the challenging MCQ dataset, demonstrating the framework’s capacity to empower open-source models with fewer parameters for domain-specific questions. Furthermore, KG-RAG enhanced the performance of proprietary GPT models, such as GPT-3.5 and GPT-4. In summary, the proposed framework combines explicit and implicit knowledge of KG and LLM in a token optimized fashion, thus enhancing the adaptability of general-purpose LLMs to tackle domain-specific questions in a cost-effective fashion. © The Author(s) 2024. Published by Oxford University Press.","","Algorithms; Computational Biology; Humans; Natural Language Processing; algorithm; bioinformatics; human; natural language processing; procedures","","Oxford University Press","English","Article","Final","","Scopus","2-s2.0-85205402312"
"Tarabanis C.; Zahid S.; Mamalis M.; Zhang K.; Kalampokis E.; Jankelson L.","Tarabanis, Constantine (55960009800); Zahid, Sohail (56425934700); Mamalis, Marios (58510212300); Zhang, Kevin (58632890100); Kalampokis, Evangelos (24766142200); Jankelson, Lior (57208337124)","55960009800; 56425934700; 58510212300; 58632890100; 24766142200; 57208337124","Performance of Publicly Available Large Language Models on Internal Medicine Board-style Questions","2024","PLOS Digital Health","3","9","e0000604","","","","0","10.1371/journal.pdig.0000604","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204309804&doi=10.1371%2fjournal.pdig.0000604&partnerID=40&md5=1e97c7f7f162bef2ab5d9eb480e3bbdc","Leon H. Charney Division of Cardiology, NYU Langone Health, New York University, School of Medicine, New York, NY, United States; Information Systems Laboratory, University of Macedonia, Thessaloniki, Greece; Department of Internal Medicine, NYU Langone Health, New York University, School of Medicine, New York, NY, United States","Tarabanis C., Leon H. Charney Division of Cardiology, NYU Langone Health, New York University, School of Medicine, New York, NY, United States; Zahid S., Leon H. Charney Division of Cardiology, NYU Langone Health, New York University, School of Medicine, New York, NY, United States; Mamalis M., Information Systems Laboratory, University of Macedonia, Thessaloniki, Greece; Zhang K., Department of Internal Medicine, NYU Langone Health, New York University, School of Medicine, New York, NY, United States; Kalampokis E., Information Systems Laboratory, University of Macedonia, Thessaloniki, Greece; Jankelson L., Leon H. Charney Division of Cardiology, NYU Langone Health, New York University, School of Medicine, New York, NY, United States","Ongoing research attempts to benchmark large language models (LLM) against physicians’ fund of knowledge by assessing LLM performance on medical examinations. No prior study has assessed LLM performance on internal medicine (IM) board examination questions. Limited data exists on how knowledge supplied to the models, derived from medical texts improves LLM performance. The performance of GPT-3.5, GPT-4.0, LaMDA and Llama 2, with and without additional model input augmentation, was assessed on 240 randomly selected IM board-style questions. Questions were sourced from the Medical Knowledge Self-Assessment Program released by the American College of Physicians with each question serving as part of the LLM prompt. When available, LLMs were accessed both through their application programming interface (API) and their corresponding chatbot. Mode inputs were augmented with Harrison’s Principles of Internal Medicine using the method of Retrieval Augmented Generation. LLM-generated explanations to 25 correctly answered questions were presented in a blinded fashion alongside the MKSAP explanation to an IM board-certified physician tasked with selecting the human generated response. GPT-4.0, accessed either through Bing Chat or its API, scored 77.5–80.7% outperforming GPT-3.5, human respondents, LaMDA and Llama 2 in that order. GPT-4.0 outperformed human MKSAP users on every tested IM subject with its highest and lowest percentile scores in Infectious Disease (80th) and Rheumatology (99.7th), respectively. There is a 3.2–5.3% decrease in performance of both GPT-3.5 and GPT-4.0 when accessing the LLM through its API instead of its online chatbot. There is 4.5–7.5% increase in performance of both GPT-3.5 and GPT-4.0 accessed through their APIs after additional input augmentation. The blinded reviewer correctly identified the human generated MKSAP response in 72% of the 25-question sample set. GPT-4.0 performed best on IM board-style questions outperforming human respondents. Augmenting with domain-specific information improved performance rendering Retrieval Augmented Generation a possible technique for improving accuracy in medical examination LLM responses. © 2024 Public Library of Science. All rights reserved.","","","","Public Library of Science","English","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85204309804"
"Du X.; Novoa-Laurentiev J.; Plasek J.M.; Chuang Y.-W.; Wang L.; Marshall G.A.; Mueller S.K.; Chang F.; Datta S.; Paek H.; Lin B.; Wei Q.; Wang X.; Wang J.; Ding H.; Manion F.J.; Du J.; Bates D.W.; Zhou L.","Du, Xinsong (57200046456); Novoa-Laurentiev, John (59144662300); Plasek, Joseph M. (56723809300); Chuang, Ya-Wen (8537704300); Wang, Liqin (57155540700); Marshall, Gad A. (11940855100); Mueller, Stephanie K. (54793411100); Chang, Frank (15055402800); Datta, Surabhi (57211502829); Paek, Hunki (58823453800); Lin, Bin (59196017900); Wei, Qiang (59196647100); Wang, Xiaoyan (58822222700); Wang, Jingqi (56580826200); Ding, Hao (59195418100); Manion, Frank J. (57190321588); Du, Jingcheng (56463293100); Bates, David W. (57113031900); Zhou, Li (56518549100)","57200046456; 59144662300; 56723809300; 8537704300; 57155540700; 11940855100; 54793411100; 15055402800; 57211502829; 58823453800; 59196017900; 59196647100; 58822222700; 56580826200; 59195418100; 57190321588; 56463293100; 57113031900; 56518549100","Enhancing early detection of cognitive decline in the elderly: a comparative study utilizing large language models in clinical notes","2024","eBioMedicine","109","","105401","","","","0","10.1016/j.ebiom.2024.105401","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206108844&doi=10.1016%2fj.ebiom.2024.105401&partnerID=40&md5=2865ebfdc5494cb834083fb9309dd3fb","Division of General Internal Medicine and Primary Care, Brigham and Women's Hospital, Boston, 02115, MA, United States; Department of Medicine, Harvard Medical School, Boston, 02115, MA, United States; Division of Nephrology, Taichung Veterans General Hospital, Taichung, 407219, Taiwan; Department of Post-Baccalaureate Medicine, College of Medicine, National Chung Hsing University, Taichung, 402202, Taiwan; School of Medicine, College of Medicine, China Medical University, Taichung, 406040, Taiwan; Department of Neurology, Brigham and Women's Hospital, Boston, 02115, MA, United States; Intelligent Medical Objects, Rosemont, 60018, IL, United States","Du X., Division of General Internal Medicine and Primary Care, Brigham and Women's Hospital, Boston, 02115, MA, United States, Department of Medicine, Harvard Medical School, Boston, 02115, MA, United States; Novoa-Laurentiev J., Division of General Internal Medicine and Primary Care, Brigham and Women's Hospital, Boston, 02115, MA, United States; Plasek J.M., Division of General Internal Medicine and Primary Care, Brigham and Women's Hospital, Boston, 02115, MA, United States, Department of Medicine, Harvard Medical School, Boston, 02115, MA, United States; Chuang Y.-W., Division of General Internal Medicine and Primary Care, Brigham and Women's Hospital, Boston, 02115, MA, United States, Department of Medicine, Harvard Medical School, Boston, 02115, MA, United States, Division of Nephrology, Taichung Veterans General Hospital, Taichung, 407219, Taiwan, Department of Post-Baccalaureate Medicine, College of Medicine, National Chung Hsing University, Taichung, 402202, Taiwan, School of Medicine, College of Medicine, China Medical University, Taichung, 406040, Taiwan; Wang L., Division of General Internal Medicine and Primary Care, Brigham and Women's Hospital, Boston, 02115, MA, United States, Department of Medicine, Harvard Medical School, Boston, 02115, MA, United States; Marshall G.A., Department of Medicine, Harvard Medical School, Boston, 02115, MA, United States, Department of Neurology, Brigham and Women's Hospital, Boston, 02115, MA, United States; Mueller S.K., Division of General Internal Medicine and Primary Care, Brigham and Women's Hospital, Boston, 02115, MA, United States, Department of Medicine, Harvard Medical School, Boston, 02115, MA, United States; Chang F., Division of General Internal Medicine and Primary Care, Brigham and Women's Hospital, Boston, 02115, MA, United States; Datta S., Intelligent Medical Objects, Rosemont, 60018, IL, United States; Paek H., Intelligent Medical Objects, Rosemont, 60018, IL, United States; Lin B., Intelligent Medical Objects, Rosemont, 60018, IL, United States; Wei Q., Intelligent Medical Objects, Rosemont, 60018, IL, United States; Wang X., Intelligent Medical Objects, Rosemont, 60018, IL, United States; Wang J., Intelligent Medical Objects, Rosemont, 60018, IL, United States; Ding H., Intelligent Medical Objects, Rosemont, 60018, IL, United States; Manion F.J., Intelligent Medical Objects, Rosemont, 60018, IL, United States; Du J., Intelligent Medical Objects, Rosemont, 60018, IL, United States; Bates D.W., Division of General Internal Medicine and Primary Care, Brigham and Women's Hospital, Boston, 02115, MA, United States, Department of Medicine, Harvard Medical School, Boston, 02115, MA, United States; Zhou L., Division of General Internal Medicine and Primary Care, Brigham and Women's Hospital, Boston, 02115, MA, United States, Department of Medicine, Harvard Medical School, Boston, 02115, MA, United States","Background: Large language models (LLMs) have shown promising performance in various healthcare domains, but their effectiveness in identifying specific clinical conditions in real medical records is less explored. This study evaluates LLMs for detecting signs of cognitive decline in real electronic health record (EHR) clinical notes, comparing their error profiles with traditional models. The insights gained will inform strategies for performance enhancement. Methods: This study, conducted at Mass General Brigham in Boston, MA, analysed clinical notes from the four years prior to a 2019 diagnosis of mild cognitive impairment in patients aged 50 and older. We developed prompts for two LLMs, Llama 2 and GPT-4, on Health Insurance Portability and Accountability Act (HIPAA)-compliant cloud-computing platforms using multiple approaches (e.g., hard prompting, retrieval augmented generation, and error analysis-based instructions) to select the optimal LLM-based method. Baseline models included a hierarchical attention-based neural network and XGBoost. Subsequently, we constructed an ensemble of the three models using a majority vote approach. Confusion-matrix-based scores were used for model evaluation. Findings: We used a randomly annotated sample of 4949 note sections from 1969 patients (women: 1046 [53.1%]; age: mean, 76.0 [SD, 13.3] years), filtered with keywords related to cognitive functions, for model development. For testing, a random annotated sample of 1996 note sections from 1161 patients (women: 619 [53.3%]; age: mean, 76.5 [SD, 10.2] years) without keyword filtering was utilised. GPT-4 demonstrated superior accuracy and efficiency compared to Llama 2, but did not outperform traditional models. The ensemble model outperformed the individual models in terms of all evaluation metrics with statistical significance (p < 0.01), achieving a precision of 90.2% [95% CI: 81.9%–96.8%], a recall of 94.2% [95% CI: 87.9%–98.7%], and an F1-score of 92.1% [95% CI: 86.8%–96.4%]. Notably, the ensemble model showed a significant improvement in precision, increasing from a range of 70%–79% to above 90%, compared to the best-performing single model. Error analysis revealed that 63 samples were incorrectly predicted by at least one model; however, only 2 cases (3.2%) were mutual errors across all models, indicating diverse error profiles among them. Interpretation: LLMs and traditional machine learning models trained using local EHR data exhibited diverse error profiles. The ensemble of these models was found to be complementary, enhancing diagnostic performance. Future research should investigate integrating LLMs with smaller, localised models and incorporating medical data and domain knowledge to enhance performance on specific tasks. Funding: This research was supported by the National Institute on Aging grants (R44AG081006, R01AG080429) and National Library of Medicine grant (R01LM014239). © 2024 The Author(s)","Alzheimer disease; Cognitive dysfunction; Dementia; Early diagnosis; Electronic health records; Natural language processing; Neurobehavioral manifestations","aged; Article; artificial intelligence; artificial neural network; cognition; cognitive defect; comparative study; computer model; deep neural network; deterioration; diagnostic accuracy; electronic health record; health care system; human; k nearest neighbor; language model; long short term memory network; machine learning; Mini Mental State Examination; Montreal cognitive assessment; neuropsychological assessment; sensitivity and specificity; working memory","","Elsevier B.V.","English","Article","Final","","Scopus","2-s2.0-85206108844"
"Byun J.; Kim B.; Cha K.-A.; Lee E.","Byun, Jaeyeon (59322592000); Kim, Bokyeong (59322797300); Cha, Kyung-Ae (54972498500); Lee, Eunhyung (59322695200)","59322592000; 59322797300; 54972498500; 59322695200","Design and Implementation of an Interactive Question-Answering System with Retrieval-Augmented Generation for Personalized Databases","2024","Applied Sciences (Switzerland)","14","17","7995","","","","0","10.3390/app14177995","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203625391&doi=10.3390%2fapp14177995&partnerID=40&md5=7080eefdde3205ba8135c5ce33f7e806","Department of Artificial Intelligence, Daegu University, Gyeongsan, 38453, South Korea; Textway Inc., A02 Unicorn Lab, 5th Fl, 111, Oksan-ro, Buk-gu, Daegu, 41593, South Korea","Byun J., Department of Artificial Intelligence, Daegu University, Gyeongsan, 38453, South Korea; Kim B., Department of Artificial Intelligence, Daegu University, Gyeongsan, 38453, South Korea; Cha K.-A., Department of Artificial Intelligence, Daegu University, Gyeongsan, 38453, South Korea; Lee E., Textway Inc., A02 Unicorn Lab, 5th Fl, 111, Oksan-ro, Buk-gu, Daegu, 41593, South Korea","This study introduces a novel approach to personalized information retrieval by integrating retrieval augmentation generation (RAG) with a personalized database system. Recent advancements in large language models (LLMs) have shown impressive text generation capabilities but face limitations in knowledge accuracy and hallucinations. Our research addresses these challenges by combining LLMs with structured, personalized data to enhance search precision and relevance. By tagging keywords within personal documents and organizing information into context-based categories, users can conduct efficient searches within their data repositories. We conducted experiments using the GPT-3.5 and text-embedding-ada-002 models and evaluated the RAG assessment framework with five different language models and two embedding models. Our results indicate that the combination of GPT-3.5 and text-embedding-ada-002 is effective for a personalized database question-answering system, with potential for various language models depending on the application. Our approach offers improved accuracy, real-time data updates, and enhanced user experience, making a significant contribution to information retrieval by LLMs and impacting various artificial intelligence applications. © 2024 by the authors.","GPT; large language model (LLM); personalized knowledge database; retrieval-augmented generation (RAG)","Ada (programming language); Data accuracy; Database systems; Information retrieval; Structured Query Language; Design and implementations; Embeddings; GPT; Knowledge database; Language model; Large language model; Personalized information retrieval; Personalized knowledge database; Question answering systems; Retrieval-augmented generation; Question answering","","Multidisciplinary Digital Publishing Institute (MDPI)","English","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85203625391"
"Kakalou C.; Karamanidou C.; Dalamagas T.; Koubarakis M.","Kakalou, Christine (57197859712); Karamanidou, Christina (57225243304); Dalamagas, Theodore (10044926600); Koubarakis, Manolis (55872674100)","57197859712; 57225243304; 10044926600; 55872674100","Enhancing Patient Empowerment and Health Literacy: Integrating Knowledge Graphs with Language Models for Personalized Health Content Delivery","2024","Studies in Health Technology and Informatics","316","","","1018","1022","4","0","10.3233/SHTI240582","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202005489&doi=10.3233%2fSHTI240582&partnerID=40&md5=daf616dedaa143d3fdb973042d46fb0d","Department of Informatics and Telecommunications, National and Kapodistrian University of Athens, Athens, Greece; Psychology Lab, Institute of Applied Biosciences, Centre for Research & Technology Hellas, Thessaloniki, Greece; Information Management Systems Institute, ATHENA Research Center, Marousi, Greece","Kakalou C., Department of Informatics and Telecommunications, National and Kapodistrian University of Athens, Athens, Greece, Psychology Lab, Institute of Applied Biosciences, Centre for Research & Technology Hellas, Thessaloniki, Greece; Karamanidou C., Psychology Lab, Institute of Applied Biosciences, Centre for Research & Technology Hellas, Thessaloniki, Greece; Dalamagas T., Information Management Systems Institute, ATHENA Research Center, Marousi, Greece; Koubarakis M., Department of Informatics and Telecommunications, National and Kapodistrian University of Athens, Athens, Greece","Health literacy empowers people to access, understand and apply health information to effectively manage their own health and to be an active participant in healthcare decisions. In this paper we propose a conceptual model for cognitive factors affecting health literacy and related socioeconomic aspects. Then we develop the HEALIE Knowledge Graph to represent the model, drawing from various medical ontologies, resources, and insights from domain experts. Finally, we combine the Knowledge Graph with a Large Language Model to generate personalised medical content and showcase the results through an example. © 2024 The Authors.","Health Literacy; Knowledge Graphs; Natural Language Generation; Patient Empowerment; Retrieval Augmented Generation","Empowerment; Health Literacy; Humans; Natural Language Processing; Patient Participation; Precision Medicine; Electronic health record; Contents deliveries; Health informations; Health literacy; Knowledge graphs; Language model; Natural language generation; Patient empowerments; Patient health; Personalized healths; Retrieval augmented generation; empowerment; health literacy; human; natural language processing; patient participation; personalized medicine; Knowledge graph","Mantas J.; Hasman A.; Demiris G.; Saranto K.; Marschollek M.; Arvanitis T.N.; Ognjanovic I.; Benis A.; Gallos P.; Zoulias E.; Andrikopoulou E.","IOS Press BV","English","Conference paper","Final","All Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85202005489"
"Fung S.C.E.; Wong M.F.; Tan C.W.","Fung, Sze Ching Evelyn (59165301000); Wong, Man Fai (57223141367); Tan, Chee Wei (58856511000)","59165301000; 57223141367; 58856511000","Automatic Feedback Generation on K-12 Students' Data Science Education by Prompting Cloud-based Large Language Models","2024","L@S 2024 - Proceedings of the 11th ACM Conference on Learning @ Scale","","","","255","258","3","0","10.1145/3657604.3664673","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199910179&doi=10.1145%2f3657604.3664673&partnerID=40&md5=06cffdf862f4e79f7a85cbb581d82008","Diocesan Girls' School, Hong Kong, Hong Kong; City University of Hong Kong, Hong Kong, Hong Kong; Nanyang Technological University, Singapore, Singapore","Fung S.C.E., Diocesan Girls' School, Hong Kong, Hong Kong; Wong M.F., City University of Hong Kong, Hong Kong, Hong Kong; Tan C.W., Nanyang Technological University, Singapore, Singapore","Since data science is traditionally an advanced field taught at the college or university level, introducing its concepts to K-12 students can present unique learning challenges. As educational environments increasingly adopt data science curricula for K-12 students, the need for scalable, personalized teaching tools becomes critical. While the integration of large language models (LLMs) in educational environments offers significant potential for scalability and automation, it is important to note that the generated language output may not always be highly suitable for K-12 students. In this paper, we introduce the DSRAG, a novel educational automatic feedback generation framework that leverages Retrieval-Augmented Generation (RAG) and cloud-based LLMs to provide automated and personalized feedback for K-12 students engaged in data science education. DSRAG employs Langchain question-answering and RAG systems to manage educational content and generate feedback on the top of GPT-4. We also demonstrate the framework's capability to simplify complex concepts and align its responses to be pedagogically appropriate and understandable for K-12 students. © 2024 ACM.","large language models; learning technologies; prompt engineering; retrieval-augmented generation","Computational linguistics; Data Science; Education computing; Engineering education; Learning systems; Automatic feedback; Cloud-based; Educational environment; Language model; Large language model; Learning technology; Prompt engineering; Retrieval-augmented generation; Science education; University levels; Students","","Association for Computing Machinery, Inc","English","Conference paper","Final","","Scopus","2-s2.0-85199910179"
"Alonso I.; Oronoz M.; Agerri R.","Alonso, Iñigo (58358273400); Oronoz, Maite (59330935900); Agerri, Rodrigo (6508050065)","58358273400; 59330935900; 6508050065","MedExpQA: Multilingual benchmarking of Large Language Models for Medical Question Answering","2024","Artificial Intelligence in Medicine","155","","102938","","","","0","10.1016/j.artmed.2024.102938","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200647612&doi=10.1016%2fj.artmed.2024.102938&partnerID=40&md5=faa781fa8e7dadbfc3cb30a461f305d3","HiTZ Center - Ixa, University of the Basque Country UPV/EHU, Spain","Alonso I., HiTZ Center - Ixa, University of the Basque Country UPV/EHU, Spain; Oronoz M., HiTZ Center - Ixa, University of the Basque Country UPV/EHU, Spain; Agerri R., HiTZ Center - Ixa, University of the Basque Country UPV/EHU, Spain","Large Language Models (LLMs) have the potential of facilitating the development of Artificial Intelligence technology to assist medical experts for interactive decision support. This potential has been illustrated by the state-of-the-art performance obtained by LLMs in Medical Question Answering, with striking results such as passing marks in licensing medical exams. However, while impressive, the required quality bar for medical applications remains far from being achieved. Currently, LLMs remain challenged by outdated knowledge and by their tendency to generate hallucinated content. Furthermore, most benchmarks to assess medical knowledge lack reference gold explanations which means that it is not possible to evaluate the reasoning of LLMs predictions. Finally, the situation is particularly grim if we consider benchmarking LLMs for languages other than English which remains, as far as we know, a totally neglected topic. In order to address these shortcomings, in this paper we present MedExpQA, the first multilingual benchmark based on medical exams to evaluate LLMs in Medical Question Answering. To the best of our knowledge, MedExpQA includes for the first time reference gold explanations, written by medical doctors, of the correct and incorrect options in the exams. Comprehensive multilingual experimentation using both the gold reference explanations and Retrieval Augmented Generation (RAG) approaches show that performance of LLMs, with best results around 75 accuracy for English, still has large room for improvement, especially for languages other than English, for which accuracy drops 10 points. Therefore, despite using state-of-the-art RAG methods, our results also demonstrate the difficulty of obtaining and integrating readily available medical knowledge that may positively impact results on downstream evaluations for Medical Question Answering. Data, code, and fine-tuned models will be made publicly available.1 © 2024 The Author(s)","Large Language Models; Medical Question Answering; Multilinguality; Natural Language Processing; Retrieval Augmented Generation","Artificial Intelligence; Benchmarking; Humans; Multilingualism; Natural Language Processing; Computational linguistics; Decision support systems; Gold; Medical applications; Natural language processing systems; Artificial intelligence technologies; Language model; Language processing; Large language model; Medical knowledge; Medical question answering; Multilinguality; Natural language processing; Natural languages; Retrieval augmented generation; Article; benchmarking; controlled study; data accuracy; English (language); French (language); information retrieval; Italian (language); knowledge; large language model; medical examination; multilingualism; physician; Spanish (language); artificial intelligence; human; natural language processing; Benchmarking","","Elsevier B.V.","English","Article","Final","All Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85200647612"
"Yang D.; Rao J.; Chen K.; Guo X.; Zhang Y.; Yang J.; Zhang Y.","Yang, Diji (57207102600); Rao, Jinmeng (57214601755); Chen, Kezhen (57205545957); Guo, Xiaoyuan (58411095000); Zhang, Yawen (57207478380); Yang, Jie (58604665700); Zhang, Yi (56018366600)","57207102600; 57214601755; 57205545957; 58411095000; 57207478380; 58604665700; 56018366600","IM-RAG: Multi-Round Retrieval-Augmented Generation Through Learning Inner Monologues","2024","SIGIR 2024 - Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval","","","","730","740","10","0","10.1145/3626772.3657760","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200609115&doi=10.1145%2f3626772.3657760&partnerID=40&md5=8a0ffb59cf04bb33a2ea47bfa524cc4e","University of California Santa Cruz, Santa Cruz, CA, United States; Mineral.ai, Mountain View, CA, United States; Together Ai, San Francisco, CA, United States; Google, Mountain View, CA, United States; Cybever, Mountain View, CA, United States","Yang D., University of California Santa Cruz, Santa Cruz, CA, United States; Rao J., Mineral.ai, Mountain View, CA, United States; Chen K., Together Ai, San Francisco, CA, United States; Guo X., Google, Mountain View, CA, United States; Zhang Y., Mineral.ai, Mountain View, CA, United States; Yang J., Cybever, Mountain View, CA, United States; Zhang Y., University of California Santa Cruz, Santa Cruz, CA, United States","Although the Retrieval-Augmented Generation (RAG) paradigms can use external knowledge to enhance and ground the outputs of Large Language Models (LLMs) to mitigate generative hallucinations and static knowledge base problems, they still suffer from limited flexibility in adopting Information Retrieval (IR) systems with varying capabilities, constrained interpretability during the multi-round retrieval process, and a lack of end-to-end optimization. To address these challenges, we propose a novel LLM-centric approach, IM-RAG, that integrates IR systems with LLMs to support multi-round RAG through learning Inner Monologues (IM, i.e., the human inner voice that narrates one's thoughts). During the IM process, the LLM serves as the core reasoning model (i.e., Reasoner ) to either propose queries to collect more information via the Retriever or to provide a final answer based on the conversational context. We also introduce a Refiner that improves the outputs from the Retriever, effectively bridging the gap between the Reasoner and IR modules with varying capabilities and fostering multi-round communications. The entire IM process is optimized via Reinforcement Learning (RL) where a Progress Tracker is incorporated to provide mid-step rewards, and the answer prediction is further separately optimized via Supervised Fine-Tuning (SFT). We conduct extensive experiments with the HotPotQA dataset, a popular benchmark for retrieval-based, multi-step question-answering. The results show that our approach achieves state-of-the-art (SOTA) performance while providing high flexibility in integrating IR modules as well as strong interpretability exhibited in the learned inner monologue. © 2024 Owner/Author.","inner monologue; large language models; multi-round retrieval; question answering; retrieval augmented generation","Computational linguistics; Information retrieval; Knowledge based systems; Query processing; Reinforcement learning; Search engines; External knowledge; Information-retrieval systems; Inner monolog; Interpretability; Language model; Large language model; Multi-round retrieval; Question Answering; Reasoners; Retrieval augmented generation; Constrained optimization","","Association for Computing Machinery, Inc","English","Conference paper","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85200609115"
"Diaz-Pace J.A.; Tommasel A.; Vazquez H.C.","Diaz-Pace, J. Andrés (14017872900); Tommasel, Antonela (56341290400); Vazquez, Hernan C. (56905291600)","14017872900; 56341290400; 56905291600","The JavaScript Package Selection Task: A Comparative Experiment Using an LLM-based Approach","2024","CLEI Eletronic Journal (CLEIej)","27","2","","","","","0","10.19153/cleiej.27.2.4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200607578&doi=10.19153%2fcleiej.27.2.4&partnerID=40&md5=de47f9f789048a7d60acfd877bbf7598","ISISTAN Research Institute, CONICET & UNICEN University, Buenos Aires, Tandil, Argentina; Faculty of Sciences, UNICEN University, Buenos Aires, Tandil, Argentina","Diaz-Pace J.A., ISISTAN Research Institute, CONICET & UNICEN University, Buenos Aires, Tandil, Argentina; Tommasel A., ISISTAN Research Institute, CONICET & UNICEN University, Buenos Aires, Tandil, Argentina; Vazquez H.C., Faculty of Sciences, UNICEN University, Buenos Aires, Tandil, Argentina","When developing JavaScript (JS) applications, the assessment and selection of JS packages becomes challenging for developers due to the growing number of technology options available. Given a technology-related task, a common developers’ strategy is to query Web repositories (e.g., from GitHub) via a search engine (e.g., NPM, Google) and then shortlist candidate JS packages. However, this search might return a long list of results and not all of them might be relevant. Thus, these results often need to be (re-)ordered according to the developer’s criteria. To address these problems, in prior work, we developed a recommender system called AIDT that assists developers in the package selection task. AIDT relies on meta-search and machine learning techniques to infer the relevant packages for a query. An initial evaluation of AIDT showed good search effectiveness, but the tool was unable to explain its choices to the developer. Research on Large Language Models (LLMs) has recently opened new opportunities for this kind of recommender systems. Anyway, human developers should judge whether the recommendations (e.g., JS packages) of these tools (either AIDT or LLMs) are fit to purpose. In this paper, we propose a Retrieval Augmented Generation (RAG) architecture for using LLMs in the domain of technology selection that enhances the AIDT original design. Furthermore, we report on a user study using both AIDT and different LLM-based variants (ChatGPT, Cohere, Llama2) on a sample of JS-related queries, in which we compared their results and also validated them against developers’ criteria for the task. Our findings show that, although the ranking capabilities of LLMs are not yet on par with AIDT or human efforts, the RAG architecture can achieve a decent performance and is good at providing explanations for the package choices in the rankings. The latter feature makes it more transparent than AIDT and, thus, potentially more flexible to support developers’ tasks. © 2024 Latin American Center for Informatics Studies. All rights reserved.","JavaScript; LLMs; Package Selection; RAG Architecture; User Study","","","Latin American Center for Informatics Studies","English","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85200607578"
"Landschaft A.; Antweiler D.; Mackay S.; Kugler S.; Rüping S.; Wrobel S.; Höres T.; Allende-Cid H.","Landschaft, Assaf (56156105200); Antweiler, Dario (57226515296); Mackay, Sina (57209588307); Kugler, Sabine (57828199100); Rüping, Stefan (55904110500); Wrobel, Stefan (7005162181); Höres, Timm (58991261100); Allende-Cid, Hector (57208732887)","56156105200; 57226515296; 57209588307; 57828199100; 55904110500; 7005162181; 58991261100; 57208732887","Implementation and evaluation of an additional GPT-4-based reviewer in PRISMA-based medical systematic literature reviews","2024","International Journal of Medical Informatics","189","","105531","","","","1","10.1016/j.ijmedinf.2024.105531","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197350356&doi=10.1016%2fj.ijmedinf.2024.105531&partnerID=40&md5=a80157c78e7460f85a8d0dc46fb08f45","Boston Children's Hospital, 300 Longwood Avenue, Boston, 02115, MA, United States; Fraunhofer-Institut für Intelligente Analyse- und Informationssysteme (IAIS), Sankt Augustin, Germany; Fraunhofer-Institut für Translationale Medizin und Pharmakologie (ITMP), Frankfurt am Main, Germany","Landschaft A., Boston Children's Hospital, 300 Longwood Avenue, Boston, 02115, MA, United States, Fraunhofer-Institut für Intelligente Analyse- und Informationssysteme (IAIS), Sankt Augustin, Germany; Antweiler D., Fraunhofer-Institut für Intelligente Analyse- und Informationssysteme (IAIS), Sankt Augustin, Germany; Mackay S., Fraunhofer-Institut für Intelligente Analyse- und Informationssysteme (IAIS), Sankt Augustin, Germany; Kugler S., Fraunhofer-Institut für Intelligente Analyse- und Informationssysteme (IAIS), Sankt Augustin, Germany; Rüping S., Fraunhofer-Institut für Intelligente Analyse- und Informationssysteme (IAIS), Sankt Augustin, Germany; Wrobel S., Fraunhofer-Institut für Intelligente Analyse- und Informationssysteme (IAIS), Sankt Augustin, Germany; Höres T., Fraunhofer-Institut für Translationale Medizin und Pharmakologie (ITMP), Frankfurt am Main, Germany; Allende-Cid H., Fraunhofer-Institut für Intelligente Analyse- und Informationssysteme (IAIS), Sankt Augustin, Germany","Background: PRISMA-based literature reviews require meticulous scrutiny of extensive textual data by multiple reviewers, which is associated with considerable human effort. Objective: To evaluate feasibility and reliability of using GPT-4 API as a complementary reviewer in systematic literature reviews based on the PRISMA framework. Methodology: A systematic literature review on the role of natural language processing and Large Language Models (LLMs) in automatic patient-trial matching was conducted using human reviewers and an AI-based reviewer (GPT-4 API). A RAG methodology with LangChain integration was used to process full-text articles. Agreement levels between two human reviewers and GPT-4 API for abstract screening and between a single reviewer and GPT-4 API for full-text parameter extraction were evaluated. Results: An almost perfect GPT–human reviewer agreement in the abstract screening process (Cohen's kappa > 0.9) and a lower agreement in the full-text parameter extraction were observed. Conclusion: As GPT-4 has performed on a par with human reviewers in abstract screening, we conclude that GPT-4 has an exciting potential of being used as a main screening tool for systematic literature reviews, replacing at least one of the human reviewers. © 2024 The Author(s)","AI-based reviewer; GPT-4 API; PRISMA; Systematic literature review","Artificial Intelligence; Humans; Natural Language Processing; Reproducibility of Results; Systematic Reviews as Topic; Abstracting; Diagnosis; Extraction; Natural language processing systems; AI-based reviewer; GPT-4 API; Language model; Language processing; Literature reviews; Natural languages; Parameters extraction; PRISMA; Systematic literature review; Textual data; Article; artificial intelligence; confidence interval; controlled study; data extraction; evaluation study; GPT 4; human; information science; interrater reliability; kappa statistics; large language model; medical literature; natural language processing; Preferred Reporting Items for Systematic Reviews and Meta-Analyses; probability; screening; systematic review; artificial intelligence; natural language processing; reproducibility; systematic review (topic); Parameter extraction","","Elsevier Ireland Ltd","English","Article","Final","","Scopus","2-s2.0-85197350356"
"Deldari S.; Goudarzi M.; Joshi A.; Shaghaghi A.; Finn S.; Salim F.D.; Jha S.","Deldari, Shohreh (57219371495); Goudarzi, Mohammad (57197131768); Joshi, Aditya (55437053100); Shaghaghi, Arash (56469553900); Finn, Simon (59254974300); Salim, Flora D. (7801420000); Jha, Sanjay (55658382400)","57219371495; 57197131768; 55437053100; 56469553900; 59254974300; 7801420000; 55658382400","AuditNet: A Conversational AI-based Security Assistant","2024","MobileHCI 2024 Adjunct Proceedings - Publication of the 26th International Conference on Mobile Human-Computer Interaction","","","20","","","","0","10.1145/3640471.3680444","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206186510&doi=10.1145%2f3640471.3680444&partnerID=40&md5=f58d3dc28b9dc3d3fad3ddf9a3222eda","University of New South Wales (UNSW), CSCRC, Australia; Cisco, Australia","Deldari S., University of New South Wales (UNSW), CSCRC, Australia; Goudarzi M., University of New South Wales (UNSW), CSCRC, Australia; Joshi A., University of New South Wales (UNSW), CSCRC, Australia; Shaghaghi A., University of New South Wales (UNSW), CSCRC, Australia; Finn S., Cisco, Australia; Salim F.D., University of New South Wales (UNSW), CSCRC, Australia; Jha S., University of New South Wales (UNSW), CSCRC, Australia","In the age of information overload, professionals across various fields face the challenge of navigating vast amounts of documentation and ever-evolving standards. Ensuring compliance with standards, regulations, and contractual obligations is a critical yet complex task across various professional fields. We propose a versatile conversational AI assistant framework designed to facilitate compliance checking on the go, in diverse domains, including but not limited to network infrastructure, legal contracts, educational standards, environmental regulations, and government policies. By leveraging retrieval-augmented generation using large language models, our framework automates the review, indexing, and retrieval of relevant, context-aware information, streamlining the process of verifying adherence to established guidelines and requirements. This AI assistant not only reduces the manual effort involved in compliance checks but also enhances accuracy and efficiency, supporting professionals in maintaining high standards of practice and ensuring regulatory compliance in their respective fields. We propose and demonstrate AuditNet, the first conversational AI security assistant designed to assist IoT network security experts by providing instant access to security standards, policies, and regulations. © 2024 Copyright held by the owner/author(s).","Prompt Engineering; Question Answering; Retrieval-Augmented Generation","Behavioral research; Indexing (of information); Complex task; Compliance checking; Contractual obligations; Diverse domains; Information overloads; On The Go; Professional fields; Prompt engineering; Question Answering; Retrieval-augmented generation; Regulatory compliance","","Association for Computing Machinery, Inc","English","Conference paper","Final","","Scopus","2-s2.0-85206186510"
"Thomo A.","Thomo, Alex (15124825100)","15124825100","PubMed Retrieval with RAG Techniques","2024","Studies in Health Technology and Informatics","316","","","652","653","1","0","10.3233/SHTI240498","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201999863&doi=10.3233%2fSHTI240498&partnerID=40&md5=a3580feac338b8b05b1d9cd70424a8f9","University of Victoria, United States","Thomo A., University of Victoria, United States","This study explores the application of Retriever-Augmented Generation (RAG) in enhancing medical information retrieval from the PubMed database. By integrating RAG with Large Language Models (LLMs), we aim to improve the accuracy and relevance of medical information provided to healthcare professionals. Our evaluation on a labeled dataset of 1,000 queries demonstrates promising results in answer relevance, while highlighting areas for improvement in groundedness and context relevance. © 2024 The Authors.","LLM; PubMed; Retriever-Augmented Generation (RAG)","Humans; Information Storage and Retrieval; Natural Language Processing; PubMed; Information retrieval; Modeling languages; Generation techniques; Health care professionals; Labeled dataset; Language model; Large language model; Medical information; Pubmed; Retriever-augmented generation; human; information retrieval; Medline; natural language processing; procedures; Labeled data","Mantas J.; Hasman A.; Demiris G.; Saranto K.; Marschollek M.; Arvanitis T.N.; Ognjanovic I.; Benis A.; Gallos P.; Zoulias E.; Andrikopoulou E.","IOS Press BV","English","Conference paper","Final","All Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85201999863"
"Farzi N.; Dietz L.","Farzi, Naghmeh (58904296500); Dietz, Laura (57223416572)","58904296500; 57223416572","Pencils Down! Automatic Rubric-based Evaluation of Retrieve/Generate Systems","2024","ICTIR 2024 - Proceedings of the 2024 ACM SIGIR International Conference on the Theory of Information Retrieval","","","","175","184","9","1","10.1145/3664190.3672511","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202430249&doi=10.1145%2f3664190.3672511&partnerID=40&md5=57ca9a0bcc89a33109e7647332a6f11d","University of New Hampshire, Durham, NH, United States","Farzi N., University of New Hampshire, Durham, NH, United States; Dietz L., University of New Hampshire, Durham, NH, United States","Current IR evaluation paradigms are challenged by large language models (LLMs) and retrieval-augmented generation (RAG) methods. Furthermore, evaluation either resorts to expensive human judgments or lead to an over-reliance on LLMs. To remedy this situation, we introduce the RUBRIC metric, which puts information retrieval systems to the proverbial test. This metric leverages a bank of query-related test questions to quantify relevant information content that is contained in the systems' responses. The process involves (1) decomposing the query into detailed questions, and (2) checking each for answerability using passages in the system response. Using three TREC benchmarks, we demonstrate that our LLM-based RUBRIC approach works successfully. Unlike previous LLM-based evaluation measures, our paradigm lends itself for incorporating a human-in-the-loop while avoiding some pitfalls of over-reliance on AI or resorting to expensive manual passage-level judgments. Moreover, our evaluation is repeatable and extensible and can be scored with existing evaluation tools. Data and code at https://github.com/TREMA-UNH/rubric-evaluation/ © 2024 Owner/Author.","information retrieval evaluation; large language models","Benchmarking; Content based retrieval; Metadata; Nonbibliographic retrieval systems; Online searching; Query languages; Query processing; Structured Query Language; 'current; Generation method; Human judgments; Information retrieval evaluation; Information-retrieval systems; Language model; Large language model; Over reliance; Retrieval evaluation; System response; Search engines","","Association for Computing Machinery, Inc","English","Conference paper","Final","All Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85202430249"
"Michailidis K.; Tsouros D.; Guns T.","Michailidis, Kostis (59324286500); Tsouros, Dimos (57200227357); Guns, Tias (26534198800)","59324286500; 57200227357; 26534198800","Constraint Modelling with LLMs Using In-Context Learning","2024","Leibniz International Proceedings in Informatics, LIPIcs","307","","20","","","","1","10.4230/LIPIcs.CP.2024.20","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203704444&doi=10.4230%2fLIPIcs.CP.2024.20&partnerID=40&md5=de71f7281c04cf569677e2ffb5f8cd57","DTAI, KU Leuven, Belgium","Michailidis K., DTAI, KU Leuven, Belgium; Tsouros D., DTAI, KU Leuven, Belgium; Guns T., DTAI, KU Leuven, Belgium","Constraint Programming (CP) allows for the modelling and solving of a wide range of combinatorial problems. However, modelling such problems using constraints over decision variables still requires significant expertise, both in conceptual thinking and syntactic use of modelling languages. In this work, we explore the potential of using pre-trained Large Language Models (LLMs) as coding assistants, to transform textual problem descriptions into concrete and executable CP specifications. We present different transformation pipelines with explicit intermediate representations, and we investigate the potential benefit of various retrieval-augmented example selection strategies for in-context learning. We evaluate our approach on 2 datasets from the literature, namely NL4Opt (optimisation) and Logic Grid Puzzles (satisfaction), and a heterogeneous set of exercises from a CP course. The results show that pre-trained LLMs have promising potential for initialising the modelling process, with retrieval-augmented in-context learning significantly enhancing their modelling capabilities.  © Kostis Michailidis, Dimos Tsouros, and Tias Guns.","Constraint Acquisition; Constraint Modelling; Constraint Programming; In-Context Learning; Large Language Models; Named Entity Recognition; Natural Language Processing; Optimisation; Retrieval-Augmented Generation","Adversarial machine learning; Constraint programming; Constraint theory; Contrastive Learning; Natural language processing systems; Pipeline codes; Problem oriented languages; Specification languages; Constraint acquisition; Constraint programming; Constraints models; Context learning; In contexts; In-context learning; Language model; Language processing; Large language model; Named entity recognition; Natural language processing; Natural languages; Optimisations; Retrieval-augmented generation; Modeling languages","Shaw P.","Schloss Dagstuhl- Leibniz-Zentrum fur Informatik GmbH, Dagstuhl Publishing","English","Conference paper","Final","","Scopus","2-s2.0-85203704444"
"Hu Z.; Wang C.; Shu Y.; Paik H.-Y.; Zhu L.","Hu, Zhibo (58902580800); Wang, Chen (55890923700); Shu, Yanfeng (34882194100); Paik, Hye-Young (57226387254); Zhu, Liming (7404202229)","58902580800; 55890923700; 34882194100; 57226387254; 7404202229","Prompt Perturbation in Retrieval-Augmented Generation based Large Language Models","2024","Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining","","","","1119","1130","11","0","10.1145/3637528.3671932","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203681487&doi=10.1145%2f3637528.3671932&partnerID=40&md5=f2d55542a581a2c0ef1a5084464e1a5e","The University of New South Wales, Sydney, NSW, Australia; CSIRO Data61, Sydney, NSW, Australia; CSIRO Data61, Hobart, TAS, Australia","Hu Z., The University of New South Wales, Sydney, NSW, Australia, CSIRO Data61, Sydney, NSW, Australia; Wang C., The University of New South Wales, Sydney, NSW, Australia, CSIRO Data61, Sydney, NSW, Australia; Shu Y., CSIRO Data61, Hobart, TAS, Australia; Paik H.-Y., The University of New South Wales, Sydney, NSW, Australia; Zhu L., The University of New South Wales, Sydney, NSW, Australia, CSIRO Data61, Sydney, NSW, Australia","The robustness of large language models (LLMs) becomes increasingly important as their use rapidly grows in a wide range of domains. Retrieval-Augmented Generation (RAG) is considered as a means to improve the trustworthiness of text generation from LLMs. However, how the outputs from RAG-based LLMs are affected by slightly different inputs is not well studied. In this work, we find that the insertion of even a short prefix to the prompt leads to the generation of outputs far away from factually correct answers. We systematically evaluate the effect of such prefixes on RAG by introducing a novel optimization technique called Gradient Guided Prompt Perturbation (GGPP). GGPP achieves a high success rate in steering outputs of RAG-based LLMs to targeted wrong answers. It can also cope with instructions in the prompts requesting to ignore irrelevant context. We also exploit LLMs' neuron activation difference between prompts with and without GGPP perturbations to give a method that improves the robustness of RAG-based LLMs through a highly effective detector trained on neuron activation triggered by GGPP generated prompts. Our evaluation on open-sourced LLMs demonstrates the effectiveness of our methods.  © 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.","LLM; prompt attack; retrieval-augmented generation; robustness","Problem oriented languages; Language model; Large language model; Optimization techniques; Prompt attack; Retrieval-augmented generation; Robustness; Text generations; Wrong answers; Neurons","","Association for Computing Machinery","English","Conference paper","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85203681487"
"Sudhi V.; Bhat S.R.; Rudat M.; Teucher R.","Sudhi, Viju (57226695685); Bhat, Sinchana Ramakanth (58668982200); Rudat, Max (57868673400); Teucher, Roman (57803401500)","57226695685; 58668982200; 57868673400; 57803401500","RAG-Ex: A Generic Framework for Explaining Retrieval Augmented Generation","2024","SIGIR 2024 - Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval","","","","2776","2780","4","0","10.1145/3626772.3657660","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200595421&doi=10.1145%2f3626772.3657660&partnerID=40&md5=f859f3df85f71024e42630ab030a43fe","Fraunhofer Iais, Dresden, Germany","Sudhi V., Fraunhofer Iais, Dresden, Germany; Bhat S.R., Fraunhofer Iais, Dresden, Germany; Rudat M., Fraunhofer Iais, Dresden, Germany; Teucher R., Fraunhofer Iais, Dresden, Germany","Owing to their size and complexity, large language models (LLMs) hardly explain why they generate a response. This effectively reduces the trust and confidence of end users in LLM-based applications, including Retrieval Augmented Generation (RAG) for Question Answering (QA) tasks. In this work, we introduce RAG-Ex, a model- and language-agnostic explanation framework that presents approximate explanations to the users revealing why the LLMs possibly generated a piece of text as a response, given the user input. Our framework is compatible with both open-source and proprietary LLMs. We report the significance scores of the approximated explanations from our generic explainer in both English and German QA tasks and also study their correlation with the downstream performance of LLMs. In the extensive user studies, our explainer yields an F1-score of 76.9% against the end user annotations and attains almost on-par performance with model-intrinsic approaches. © 2024 Owner/Author.","explainability; large language models; retrieval augmented generation","Information retrieval; End-users; Explainability; Generic frameworks; Language model; Large language model; Model-based OPC; Performance; Question Answering Task; Retrieval augmented generation; User input; Computational linguistics","","Association for Computing Machinery, Inc","English","Conference paper","Final","","Scopus","2-s2.0-85200595421"
"Li X.; Dou Z.; Zhou Y.; Liu F.","Li, Xiaoxi (58784375200); Dou, Zhicheng (24722777200); Zhou, Yujia (57214938039); Liu, Fangchao (59279491100)","58784375200; 24722777200; 57214938039; 59279491100","CorpusLM: Towards a Unified Language Model on Corpus for Knowledge-Intensive Tasks","2024","SIGIR 2024 - Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval","","","","26","37","11","0","10.1145/3626772.3657778","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200584508&doi=10.1145%2f3626772.3657778&partnerID=40&md5=d01bbe3cb6d69e65d80c9e2b65831278","Gaoling School of Artificial Intelligence, Renmin University of China, Beijing, China; Huawei Poisson Lab, Beijing, China","Li X., Gaoling School of Artificial Intelligence, Renmin University of China, Beijing, China; Dou Z., Gaoling School of Artificial Intelligence, Renmin University of China, Beijing, China; Zhou Y., Gaoling School of Artificial Intelligence, Renmin University of China, Beijing, China; Liu F., Huawei Poisson Lab, Beijing, China","Large language models (LLMs) have gained significant attention in various fields but prone to hallucination, especially in knowledge-intensive (KI) tasks. To address this, retrieval-augmented generation (RAG) has emerged as a popular solution to enhance factual accuracy. However, traditional retrieval modules often rely on large document index and disconnect with generative tasks. With the advent of generative retrieval (GR), language models can retrieve by directly generating document identifiers (DocIDs), offering superior performance in retrieval tasks. However, the potential relationship between GR and downstream tasks remains unexplored. In this paper, we propose CorpusLM, a unified language model that leverages external corpus to tackle various knowledge-intensive tasks by integrating generative retrieval, closed-book generation, and RAG through a unified greedy decoding process. We design the following mechanisms to facilitate effective retrieval and generation, and improve the end-to-end effectiveness of KI tasks: (1) We develop a ranking-oriented DocID list generation strategy, which refines GR by directly learning from a DocID ranking list, to improve retrieval quality. (2) We design a continuous DocIDs-References-Answer generation strategy, which facilitates effective and efficient RAG. (3) We employ well-designed unsupervised DocID understanding tasks, to comprehend DocID semantics and their relevance to downstream tasks. We evaluate our approach on the widely used KILT benchmark with two variants of backbone models, i.e., T5 and Llama2. Experimental results demonstrate the superior performance of our models in both retrieval and downstream tasks. © 2024 ACM.","generative retrieval; knowledge-intensive language tasks; rag","Computational linguistics; Information retrieval; Document identifiers; Down-stream; Generative retrieval; Knowledge intensive tasks; Knowledge-intensive language task; Language model; Performance; Rag; Retrieval languages; Unified language; Semantics","","Association for Computing Machinery, Inc","English","Conference paper","Final","","Scopus","2-s2.0-85200584508"
"Han B.; Susnjak T.; Mathrani A.","Han, Binglan (57222239441); Susnjak, Teo (57211327278); Mathrani, Anuradha (35242743800)","57222239441; 57211327278; 35242743800","Automating Systematic Literature Reviews with Retrieval-Augmented Generation: A Comprehensive Overview","2024","Applied Sciences (Switzerland)","14","19","9103","","","","0","10.3390/app14199103","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206333493&doi=10.3390%2fapp14199103&partnerID=40&md5=0b38c7be5626368e4a837722cff6b2d5","School of Mathematical and Computational Sciences, Massey University, Auckland, 0632, New Zealand","Han B., School of Mathematical and Computational Sciences, Massey University, Auckland, 0632, New Zealand; Susnjak T., School of Mathematical and Computational Sciences, Massey University, Auckland, 0632, New Zealand; Mathrani A., School of Mathematical and Computational Sciences, Massey University, Auckland, 0632, New Zealand","This study examines Retrieval-Augmented Generation (RAG) in large language models (LLMs) and their significant application for undertaking systematic literature reviews (SLRs). RAG-based LLMs can potentially automate tasks like data extraction, summarization, and trend identification. However, while LLMs are exceptionally proficient in generating human-like text and interpreting complex linguistic nuances, their dependence on static, pre-trained knowledge can result in inaccuracies and hallucinations. RAG mitigates these limitations by integrating LLMs’ generative capabilities with the precision of real-time information retrieval. We review in detail the three key processes of the RAG framework—retrieval, augmentation, and generation. We then discuss applications of RAG-based LLMs to SLR automation and highlight future research topics, including integration of domain-specific LLMs, multimodal data processing and generation, and utilization of multiple retrieval sources. We propose a framework of RAG-based LLMs for automating SRLs, which covers four stages of SLR process: literature search, literature screening, data extraction, and information synthesis. Future research aims to optimize the interaction between LLM selection, training strategies, RAG techniques, and prompt engineering to implement the proposed framework, with particular emphasis on the retrieval of information from individual scientific papers and the integration of these data to produce outputs addressing various aspects such as current status, existing gaps, and emerging trends. © 2024 by the authors.","large language models; retrieval-augmented generation; systematic literature review","Content based retrieval; Data assimilation; Data reduction; Linguistics; Metadata; Modeling languages; Network security; Data extraction; Data summarizations; Data trend; Human like; Key process; Language model; Large language model; Real-time information; Retrieval-augmented generation; Systematic literature review; Data integration","","Multidisciplinary Digital Publishing Institute (MDPI)","English","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85206333493"
"Yao S.; Ke Q.; Li K.; Wang Q.; Hu J.","Yao, Shunyu (57217295494); Ke, Qingqing (59362530900); Li, Kangtong (59362926200); Wang, Qiwei (58670775200); Hu, Jie (57226187628)","57217295494; 59362530900; 59362926200; 58670775200; 57226187628","News GPT: A Large Language Model for Reliable and Hallucination-Controlled News Generation","2024","ACM International Conference Proceeding Series","","","","113","119","6","0","10.1145/3689299.3689320","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206089335&doi=10.1145%2f3689299.3689320&partnerID=40&md5=121754fe5f82fc69c933d88ba42a8742","Big Data and Artificial Intelligence Institute, China Telecom Research Institute, Beijing, China; China Telecom, Beijing, China; Beijing University of Posts and Telecommunications, Beijing, China","Yao S., Big Data and Artificial Intelligence Institute, China Telecom Research Institute, Beijing, China; Ke Q., China Telecom, Beijing, China; Li K., Beijing University of Posts and Telecommunications, Beijing, China; Wang Q., Beijing University of Posts and Telecommunications, Beijing, China; Hu J., Big Data and Artificial Intelligence Institute, China Telecom Research Institute, Beijing, China","With the continuous development of natural language processing (NLP) technology, large models have become essential tools for handling natural language tasks. In the news domain, large models can be used for automating news generation, thereby enhancing the productivity and quality of news production. As a result, we introduce a new large model-News GPT-which utilizes an external knowledge retrieval module to inject real information, providing authentic and reliable news generation services. By combining Chinese and English news data with general domain data, we have constructed a high-quality, multi-domain news dataset consisting of 1.4B tokens. In the pre-training phase, we expand the Chinese vocabulary for the Llama2-70B model, and in the fine-tuning phase, we design expert prompts to help the model understand downstream tasks better. We have tested News GPT in various aspects, and the experimental results show that News GPT, as an intelligent news assistant, can effectively complete tasks using retrieval tools in different application scenarios. It possesses excellent natural language understanding, knowledge, and logical reasoning abilities, and effectively controls the hallucinations in the generation process. News GPT demonstrates high accuracy and reliability in news generation and can provide substantial support for the news industry. © 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.","Autonomous Agents; Large Language Models; News Generation; Retrieval-augmented Generation","Large datasets; Metadata; Modeling languages; Natural language processing systems; Continuous development; Language model; Language processing; Large language model; Large models; Natural languages; News domain; News generation; Processing technologies; Retrieval-augmented generation; Autonomous agents","","Association for Computing Machinery","English","Conference paper","Final","","Scopus","2-s2.0-85206089335"
"Alkhalaf M.; Yu P.; Yin M.; Deng C.","Alkhalaf, Mohammad (57572229700); Yu, Ping (57226078770); Yin, Mengyang (57219893979); Deng, Chao (26424514600)","57572229700; 57226078770; 57219893979; 26424514600","Applying generative AI with retrieval augmented generation to summarize and extract key clinical information from electronic health records","2024","Journal of Biomedical Informatics","156","","104662","","","","2","10.1016/j.jbi.2024.104662","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196401422&doi=10.1016%2fj.jbi.2024.104662&partnerID=40&md5=10730aa6849d77e7ddb65a5c408364e8","School of Computing and Information Technology, University of Wollongong, Wollongong, 2522, NSW, Australia; School of Computer Science, Qassim University, Qassim, 51452, Saudi Arabia; Opal Healthcare, Level 11/420 George St, Sydney, 2000, NSW, Australia; School of Medical, Indigenous and Health Sciences, University of Wollongong, Wollongong, 2522, NSW, Australia","Alkhalaf M., School of Computing and Information Technology, University of Wollongong, Wollongong, 2522, NSW, Australia, School of Computer Science, Qassim University, Qassim, 51452, Saudi Arabia; Yu P., School of Computing and Information Technology, University of Wollongong, Wollongong, 2522, NSW, Australia; Yin M., Opal Healthcare, Level 11/420 George St, Sydney, 2000, NSW, Australia; Deng C., School of Medical, Indigenous and Health Sciences, University of Wollongong, Wollongong, 2522, NSW, Australia","Background: Malnutrition is a prevalent issue in aged care facilities (RACFs), leading to adverse health outcomes. The ability to efficiently extract key clinical information from a large volume of data in electronic health records (EHR) can improve understanding about the extent of the problem and developing effective interventions. This research aimed to test the efficacy of zero-shot prompt engineering applied to generative artificial intelligence (AI) models on their own and in combination with retrieval augmented generation (RAG), for the automating tasks of summarizing both structured and unstructured data in EHR and extracting important malnutrition information. Methodology: We utilized Llama 2 13B model with zero-shot prompting. The dataset comprises unstructured and structured EHRs related to malnutrition management in 40 Australian RACFs. We employed zero-shot learning to the model alone first, then combined it with RAG to accomplish two tasks: generate structured summaries about the nutritional status of a client and extract key information about malnutrition risk factors. We utilized 25 notes in the first task and 1,399 in the second task. We evaluated the model's output of each task manually against a gold standard dataset. Result: The evaluation outcomes indicated that zero-shot learning applied to generative AI model is highly effective in summarizing and extracting information about nutritional status of RACFs’ clients. The generated summaries provided concise and accurate representation of the original data with an overall accuracy of 93.25%. The addition of RAG improved the summarization process, leading to a 6% increase and achieving an accuracy of 99.25%. The model also proved its capability in extracting risk factors with an accuracy of 90%. However, adding RAG did not further improve accuracy in this task. Overall, the model has shown a robust performance when information was explicitly stated in the notes; however, it could encounter hallucination limitations, particularly when details were not explicitly provided. Conclusion: This study demonstrates the high performance and limitations of applying zero-shot learning to generative AI models to automatic generation of structured summarization of EHRs data and extracting key clinical information. The inclusion of the RAG approach improved the model performance and mitigated the hallucination problem. © 2024 The Author(s)","Generative AI; LLAMA; Malnutrition; Nursing notes; RAG; Summarization","Algorithms; Artificial Intelligence; Australia; Electronic Health Records; Humans; Information Storage and Retrieval; Malnutrition; Data mining; Learning systems; Records management; Zero-shot learning; Clinical information; Electronic health; Generative artificial intelligence; Health records; Intelligence models; LLAMA; Malnutrition; Nursing note; Retrieval augmented generation; Summarization; adult; Article; Australian; automation; controlled study; data extraction; electronic health record; generative artificial intelligence; gold standard; human; information retrieval; large language model; machine learning; malnutrition; medical information; middle aged; mitigation; nursing home; nutritional status; patient care; pilot study; risk factor; zero shot learning; algorithm; artificial intelligence; Australia; information retrieval; procedures; Nutrition","","Academic Press Inc.","English","Article","Final","All Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85196401422"
"Hara T.; Maeda H.; Komatsubara S.","Hara, Takenori (36023690900); Maeda, Haruka (57210706067); Komatsubara, Shigeru (35770976000)","36023690900; 57210706067; 35770976000","Enhancing VR Customer Service Training: A System for Generating Customer Queries and Evaluating Trainee Responses","2024","Proceedings - SIGGRAPH 2024 Posters","","","25","","","","0","10.1145/3641234.3671058","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200735643&doi=10.1145%2f3641234.3671058&partnerID=40&md5=a7ee051c5149fa8916bfac360aaec3da","Dai Nippon Printing Co., Ltd., Shinjuku, Tokyo, Japan","Hara T., Dai Nippon Printing Co., Ltd., Shinjuku, Tokyo, Japan; Maeda H., Dai Nippon Printing Co., Ltd., Shinjuku, Tokyo, Japan; Komatsubara S., Dai Nippon Printing Co., Ltd., Shinjuku, Tokyo, Japan","Virtual customer service training using avatars eliminates the need for physical facilities, reducing costs and enabling remote participation. However, the challenge lies in the authoring cost of preparing service specific question and the necessity of experienced instructors. To address this, we employ LLM technology to generate service specific question and evaluate trainee's answer mitigating authoring costs. Despite LLMs having general knowledge limitations, we integrate RAG to imbue them with specific service knowledge. This innovation facilitates the generation of service specific questions. Furthermore, we are developing a self-training system where RAG assesses the correctness of trainee answers, enabling independent learning (without an instructor). This paper discusses the issues faced and insights gained during the development of our system.  © 2024 Owner/Author.","AI; avatar; large-scale language model; LLM; RAG; Retrieval Augmented Generation; VR training","Avatar; Customer queries; Customer-service; Language model; Large-scale language model; Large-scales; LLM; RAG; Retrieval augmented generation; VR training; Sales","Spencer S.N.","Association for Computing Machinery, Inc","English","Conference paper","Final","All Open Access; Bronze Open Access","Scopus","2-s2.0-85200735643"
"Salemi A.; Zamani H.","Salemi, Alireza (57223748391); Zamani, Hamed (56342230300)","57223748391; 56342230300","Evaluating Retrieval Quality in Retrieval-Augmented Generation","2024","SIGIR 2024 - Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval","","","","2395","2400","5","4","10.1145/3626772.3657957","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194438628&doi=10.1145%2f3626772.3657957&partnerID=40&md5=096220ab2a293460d8d1995178326256","University of Massachusetts Amherst, Amherst, MA, United States","Salemi A., University of Massachusetts Amherst, Amherst, MA, United States; Zamani H., University of Massachusetts Amherst, Amherst, MA, United States","Evaluating retrieval-augmented generation (RAG) presents challenges, particularly for retrieval models within these systems. Traditional end-to-end evaluation methods are computationally expensive. Furthermore, evaluation of the retrieval model's performance based on query-document relevance labels shows a small correlation with the RAG system's downstream performance. We propose a novel evaluation approach, eRAG, where each document in the retrieval list is individually utilized by the large language model within the RAG system. The output generated for each document is then evaluated based on the downstream task ground truth labels. In this manner, the downstream performance for each document serves as its relevance label. We employ various downstream task metrics to obtain document-level annotations and aggregate them using set-based or ranking metrics. Extensive experiments on a wide range of datasets demonstrate that eRAG achieves a higher correlation with downstream RAG performance compared to baseline methods, with improvements in Kendall's tau correlation ranging from 0.168 to 0.494. Additionally, eRAG offers significant computational advantages, improving runtime and consuming up to 50 times less GPU memory than end-to-end evaluation. © 2024 Owner/Author.","evaluation; retrieval quality; retrieval-augmented generation","Information retrieval; Down-stream; End to end; Evaluation; Evaluation methods; Generation systems; Modeling performance; Performance; Retrieval models; Retrieval quality; Retrieval-augmented generation; Quality control","","Association for Computing Machinery, Inc","English","Conference paper","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85194438628"
"Zeghouani O.; Ali Z.; van Dijkhuizen W.S.; Hong J.W.; Clos J.","Zeghouani, Omar (59350070200); Ali, Zawar (59350070300); van Dijkhuizen, William Simson (59349611000); Hong, Jia Wei (59349842300); Clos, Jeremie (57194087104)","59350070200; 59350070300; 59349611000; 59349842300; 57194087104","AI in the Classroom: Examining the Feasibility of AI-Generated Questions in Educational Settings","2024","ACM International Conference Proceeding Series","","","36","","","","0","10.1145/3686038.3686652","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205352111&doi=10.1145%2f3686038.3686652&partnerID=40&md5=d59897951744cc6ed8c7bb79017ae766","University of Nottingham, Nottingham, United Kingdom","Zeghouani O., University of Nottingham, Nottingham, United Kingdom; Ali Z., University of Nottingham, Nottingham, United Kingdom; van Dijkhuizen W.S., University of Nottingham, Nottingham, United Kingdom; Hong J.W., University of Nottingham, Nottingham, United Kingdom; Clos J., University of Nottingham, Nottingham, United Kingdom","Educators face ever-growing time constraints, leading to poor work-life balance and a negative impact on work quality. Through their language generation capabilities, large language models offer an interesting avenue to ease this academic workload, allowing both students and lecturers to generate educational content. In this work, we leverage the latest developments in automatic speech recognition, natural language generation, retrieval-augmented generation, and multimodal models to design the Augmented Lecture Integration Network (ALINet), a system capable of producing a diverse range of high-quality assessment questions from lecture content. We inform the design of our system through a series of automated experiments using public datasets and evaluate it with a user study conducted on students and educators. Our results indicate a generally positive perception of the system's performance, particularly in generating natural and clear questions relevant to the taught content, demonstrating its potential as a valuable resource in educational settings. This project lays the foundation for future research in multimodal educational question generation and is available for reuse in our public repository. © 2024 Copyright held by the owner/author(s).","Educational Question Generation; Generative AI; Large Language Models","Adversarial machine learning; Generative adversarial networks; Speech recognition; Teaching; Educational contents; Educational question generation; Educational settings; Generative AI; Language generation; Language model; Large language model; Time constraints; Work quality; Work-life balance; Students","","Association for Computing Machinery","English","Conference paper","Final","","Scopus","2-s2.0-85205352111"
"Yan M.; Wang Y.; Pang K.; Xie M.; Li J.","Yan, Mengyi (57219732694); Wang, Yaoshu (55801094000); Pang, Kehan (58963835600); Xie, Min (56272894700); Li, Jianxin (55720560100)","57219732694; 55801094000; 58963835600; 56272894700; 55720560100","Efficient Mixture of Experts based on Large Language Models for Low-Resource Data Preprocessing","2024","Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining","","","","3690","3701","11","0","10.1145/3637528.3671873","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203686489&doi=10.1145%2f3637528.3671873&partnerID=40&md5=e64840fea83d3ac38bf5f87256c4c1e7","Beihang University, Beijing, China; Shenzhen Institute of Computing Sciences, Shenzhen, China","Yan M., Beihang University, Beijing, China; Wang Y., Shenzhen Institute of Computing Sciences, Shenzhen, China; Pang K., Beihang University, Beijing, China; Xie M., Shenzhen Institute of Computing Sciences, Shenzhen, China; Li J., Beihang University, Beijing, China","Data preprocessing (DP) that transforms erroneous and raw data to a clean version is a cornerstone of the data mining pipeline. Due to the diverse requirements of downstream tasks, data scientists and domain experts have to handcraft domain-specific rules or train ML models with annotated examples, which is costly/time-consuming. In this paper, we present MELD (<u>Mixture of <u>Experts on <u>Large Language Models for <u>Data Preprocessing), a universal solver for low-resource DP. MELD adopts a Mixture-of-Experts (MoE) architecture that enables the amalgamation and enhancement of domain-specific experts trained on limited annotated examples. To fine-tune MELD, we develop a suite of expert-tuning and MoE-tuning techniques, including a retrieval augmented generation (RAG) system, meta-path search for data augmentation, expert refinement and router network training based on information bottleneck. To further verify the effectiveness of MELD, we theoretically prove that MoE in MELD is superior than a single expert and the router network is able to dispatch data to the right experts. Finally, we conducted extensive experiments on 19 datasets over 10 DP tasks to show that MELD outperforms the state-of-the-art methods in both effectiveness and efficiency. More importantly, MELD is able to be fine-tuned in a low-resource environment, e.g. a local, single and low-priced 3090 GPU.  © 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.","data preprocessing; LLMs; low-resource; mixture of expert","Expert systems; Natural language processing systems; Problem oriented languages; Data preprocessing; Domain experts; Domain specific; Down-stream; Generation systems; Language model; LLM; Low-resource; Mixture of experts; Router networks; Metadata","","Association for Computing Machinery","English","Conference paper","Final","","Scopus","2-s2.0-85203686489"
"Huly O.; Pogrebinsky I.; Carmel D.; Kurland O.; Maarek Y.","Huly, Oz (59249176900); Pogrebinsky, Idan (59248874400); Carmel, David (7003995138); Kurland, Oren (23012253900); Maarek, Yoelle (55903308800)","59249176900; 59248874400; 7003995138; 23012253900; 55903308800","Old IR Methods Meet RAG","2024","SIGIR 2024 - Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval","","","","2559","2563","4","0","10.1145/3626772.3657935","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200558695&doi=10.1145%2f3626772.3657935&partnerID=40&md5=f0517818054058c54ac7db693e5d2e22","Technion, Haifa, Israel; Technion & Technology Innovation Institute, Haifa, Israel","Huly O., Technion, Haifa, Israel; Pogrebinsky I., Technion, Haifa, Israel; Carmel D., Technion & Technology Innovation Institute, Haifa, Israel; Kurland O., Technion, Haifa, Israel; Maarek Y., Technion & Technology Innovation Institute, Haifa, Israel","Retrieval augmented generation (RAG) is an important approach to provide large language models (LLMs) with context pertaining to the text generation task: given a prompt, passages are retrieved from external corpora to ground the generation with more relevant and/or fresher data. Most previous studies used dense retrieval methods for applying RAG in question answering scenarios. However, recent work showed that traditional information retrieval methods (a.k.a. sparse methods) can do as well as or even better than dense retrieval ones. In particular, it was shown that Okapi BM25 outperforms dense retrieval methods, in terms of perplexity, for the fundamental text completion task in LLMs. We extend this study and show, using two popular LLMs, that a broad set of sparse retrieval methods achieve better results than all the dense retrieval methods we experimented with, for varying lengths of queries induced from the prompt. Furthermore, we found that Okapi BM25 is substantially outperformed by a term-proximity retrieval method (MRF), which is in turn outperformed by a pseudo-feedback-based bag-of-terms approach (relevance model). Additional exploration sheds some light on the effectiveness of lexical retrieval methods for RAG. Our findings call for further study of classical retrieval methods for RAG. © 2024 Owner/Author.","retrieval augmented generation","Natural language processing systems; Feed-back based; IR methods; Language model; Question Answering; Relevance models; Retrieval augmented generation; Retrieval methods; Sparse methods; Text generations; Information retrieval","","Association for Computing Machinery, Inc","English","Conference paper","Final","","Scopus","2-s2.0-85200558695"
"Toro S.; Anagnostopoulos A.V.; Bello S.M.; Blumberg K.; Cameron R.; Carmody L.; Diehl A.D.; Dooley D.M.; Duncan W.D.; Fey P.; Gaudet P.; Harris N.L.; Joachimiak M.P.; Kiani L.; Lubiana T.; Munoz-Torres M.C.; O‘Neil S.; Osumi-Sutherland D.; Puig-Barbe A.; Reese J.T.; Reiser L.; Robb S.M.C.; Ruemping T.; Seager J.; Sid E.; Stefancsik R.; Weber M.; Wood V.; Haendel M.A.; Mungall C.J.","Toro, Sabrina (6603093413); Anagnostopoulos, Anna V. (7005821953); Bello, Susan M. (7004458522); Blumberg, Kai (57221544265); Cameron, Rhiannon (57454524400); Carmody, Leigh (6603002819); Diehl, Alexander D. (35774295100); Dooley, Damion M. (57189233849); Duncan, William D. (57201461830); Fey, Petra (7003555000); Gaudet, Pascale (6602633077); Harris, Nomi L. (57188535624); Joachimiak, Marcin P. (6508039734); Kiani, Leila (58792947600); Lubiana, Tiago (57200940340); Munoz-Torres, Monica C. (21934921800); O‘Neil, Shawn (59369990200); Osumi-Sutherland, David (6506419854); Puig-Barbe, Aleix (57219786544); Reese, Justin T. (15048513900); Reiser, Leonore (6701412452); Robb, Sofia MC. (59303866000); Ruemping, Troy (58792963200); Seager, James (57213184555); Sid, Eric (57144485200); Stefancsik, Ray (6506725443); Weber, Magalie (57222043470); Wood, Valerie (7102296936); Haendel, Melissa A. (6602819027); Mungall, Christopher J. (6602880619)","6603093413; 7005821953; 7004458522; 57221544265; 57454524400; 6603002819; 35774295100; 57189233849; 57201461830; 7003555000; 6602633077; 57188535624; 6508039734; 58792947600; 57200940340; 21934921800; 59369990200; 6506419854; 57219786544; 15048513900; 6701412452; 59303866000; 58792963200; 57213184555; 57144485200; 6506725443; 57222043470; 7102296936; 6602819027; 6602880619","Dynamic Retrieval Augmented Generation of Ontologies using Artificial Intelligence (DRAGON-AI)","2024","Journal of Biomedical Semantics","15","1","19","","","","0","10.1186/s13326-024-00320-3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206568005&doi=10.1186%2fs13326-024-00320-3&partnerID=40&md5=22bc17dbc78786d7aa562484bd258d12","University of North Carolina at Chapel Hill, Chapel Hill, NC, United States; The Jackson Laboratory, Bar Harbor, ME, United States; Department of Agriculture, Beltsville Human Nutrition Research Center, Beltsville, MD, United States; Simon Fraser University, Burnaby, BC, Canada; The Jackson Laboratory for Genomic Medicine, Farmington, CT, United States; University at Buffalo, Buffalo, NY, United States; University of Florida, Gainesville, FL, United States; Northwestern University, Evanston, IL, United States; SIB Swiss Institute of Bioinformatics, Geneva, Switzerland; Lawrence Berkeley National Laboratory, Berkeley, CA, United States; Independent Scientific Information Analyst, Philadelphia, United States; University of São Paulo, São Paulo, Brazil; University of Colorado Anschutz Medical Campus, Aurora, CO, United States; Sanger Institute, Hinxton, United Kingdom; European Bioinformatics Institute (EMBL-EBI), Hinxton, United Kingdom; Phoenix Bioinformatics, Newark, CA, United States; Stowers Institute for Medical Research, Kansas City, MO, United States; IC-FOODS, Austin, TX, United States; Rothamsted Research, Harpenden, United Kingdom; National Center for Advancing Translational Sciences, Bethesda, MD, United States; INRAE, French National Research Institute for Agriculture, Food and Environment, UR BIA, Nantes, France; University of Cambridge, Cambridge, United Kingdom","Toro S., University of North Carolina at Chapel Hill, Chapel Hill, NC, United States; Anagnostopoulos A.V., The Jackson Laboratory, Bar Harbor, ME, United States; Bello S.M., The Jackson Laboratory, Bar Harbor, ME, United States; Blumberg K., Department of Agriculture, Beltsville Human Nutrition Research Center, Beltsville, MD, United States; Cameron R., Simon Fraser University, Burnaby, BC, Canada; Carmody L., The Jackson Laboratory for Genomic Medicine, Farmington, CT, United States; Diehl A.D., University at Buffalo, Buffalo, NY, United States; Dooley D.M., Simon Fraser University, Burnaby, BC, Canada; Duncan W.D., University of Florida, Gainesville, FL, United States; Fey P., Northwestern University, Evanston, IL, United States; Gaudet P., SIB Swiss Institute of Bioinformatics, Geneva, Switzerland; Harris N.L., Lawrence Berkeley National Laboratory, Berkeley, CA, United States; Joachimiak M.P., Lawrence Berkeley National Laboratory, Berkeley, CA, United States; Kiani L., Independent Scientific Information Analyst, Philadelphia, United States; Lubiana T., University of São Paulo, São Paulo, Brazil; Munoz-Torres M.C., University of Colorado Anschutz Medical Campus, Aurora, CO, United States; O‘Neil S., University of North Carolina at Chapel Hill, Chapel Hill, NC, United States; Osumi-Sutherland D., Sanger Institute, Hinxton, United Kingdom; Puig-Barbe A., European Bioinformatics Institute (EMBL-EBI), Hinxton, United Kingdom; Reese J.T., Lawrence Berkeley National Laboratory, Berkeley, CA, United States; Reiser L., Phoenix Bioinformatics, Newark, CA, United States; Robb S.M.C., Stowers Institute for Medical Research, Kansas City, MO, United States; Ruemping T., IC-FOODS, Austin, TX, United States; Seager J., Rothamsted Research, Harpenden, United Kingdom; Sid E., National Center for Advancing Translational Sciences, Bethesda, MD, United States; Stefancsik R., European Bioinformatics Institute (EMBL-EBI), Hinxton, United Kingdom; Weber M., INRAE, French National Research Institute for Agriculture, Food and Environment, UR BIA, Nantes, France; Wood V., University of Cambridge, Cambridge, United Kingdom; Haendel M.A., University of North Carolina at Chapel Hill, Chapel Hill, NC, United States; Mungall C.J., Lawrence Berkeley National Laboratory, Berkeley, CA, United States","Background: Ontologies are fundamental components of informatics infrastructure in domains such as biomedical, environmental, and food sciences, representing consensus knowledge in an accurate and computable form. However, their construction and maintenance demand substantial resources and necessitate substantial collaboration between domain experts, curators, and ontology experts. We present Dynamic Retrieval Augmented Generation of Ontologies using AI (DRAGON-AI), an ontology generation method employing Large Language Models (LLMs) and Retrieval Augmented Generation (RAG). DRAGON-AI can generate textual and logical ontology components, drawing from existing knowledge in multiple ontologies and unstructured text sources. Results: We assessed performance of DRAGON-AI on de novo term construction across ten diverse ontologies, making use of extensive manual evaluation of results. Our method has high precision for relationship generation, but has slightly lower precision than from logic-based reasoning. Our method is also able to generate definitions deemed acceptable by expert evaluators, but these scored worse than human-authored definitions. Notably, evaluators with the highest level of confidence in a domain were better able to discern flaws in AI-generated definitions. We also demonstrated the ability of DRAGON-AI to incorporate natural language instructions in the form of GitHub issues. Conclusions: These findings suggest DRAGON-AI's potential to substantially aid the manual ontology construction process. However, our results also underscore the importance of having expert curators and ontology editors drive the ontology generation process. © The Author(s) 2024.","Artificial intelligence; Biocuration; Knowledge graphs; Large language models; Ontologies; Ontology engineering","Artificial Intelligence; Biological Ontologies; Information Storage and Retrieval; Natural Language Processing; artificial intelligence; biological ontology; information retrieval; natural language processing; procedures","","BioMed Central Ltd","English","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85206568005"
"Kresevic S.; Giuffrè M.; Ajcevic M.; Accardo A.; Crocè L.S.; Shung D.L.","Kresevic, Simone (58189580900); Giuffrè, Mauro (57210704630); Ajcevic, Milos (55647508100); Accardo, Agostino (6603688769); Crocè, Lory S. (7004111132); Shung, Dennis L. (56447050200)","58189580900; 57210704630; 55647508100; 6603688769; 7004111132; 56447050200","Optimization of hepatological clinical guidelines interpretation by large language models: a retrieval augmented generation-based framework","2024","npj Digital Medicine","7","1","102","","","","7","10.1038/s41746-024-01091-y","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191075594&doi=10.1038%2fs41746-024-01091-y&partnerID=40&md5=6d44109de8d3a3997cf2069604d69bed","Department of Engineering and Architecture, University of Trieste, Trieste, Italy; Department of Medicine (Digestive Diseases), Yale School of Medicine, Yale University, New Haven, CT, United States; Department of Medical, Surgical, and Health Sciences, University of Trieste, Trieste, Italy","Kresevic S., Department of Engineering and Architecture, University of Trieste, Trieste, Italy, Department of Medicine (Digestive Diseases), Yale School of Medicine, Yale University, New Haven, CT, United States; Giuffrè M., Department of Medicine (Digestive Diseases), Yale School of Medicine, Yale University, New Haven, CT, United States; Ajcevic M., Department of Engineering and Architecture, University of Trieste, Trieste, Italy; Accardo A., Department of Engineering and Architecture, University of Trieste, Trieste, Italy; Crocè L.S., Department of Medical, Surgical, and Health Sciences, University of Trieste, Trieste, Italy; Shung D.L., Department of Medicine (Digestive Diseases), Yale School of Medicine, Yale University, New Haven, CT, United States","Large language models (LLMs) can potentially transform healthcare, particularly in providing the right information to the right provider at the right time in the hospital workflow. This study investigates the integration of LLMs into healthcare, specifically focusing on improving clinical decision support systems (CDSSs) through accurate interpretation of medical guidelines for chronic Hepatitis C Virus infection management. Utilizing OpenAI’s GPT-4 Turbo model, we developed a customized LLM framework that incorporates retrieval augmented generation (RAG) and prompt engineering. Our framework involved guideline conversion into the best-structured format that can be efficiently processed by LLMs to provide the most accurate output. An ablation study was conducted to evaluate the impact of different formatting and learning strategies on the LLM’s answer generation accuracy. The baseline GPT-4 Turbo model’s performance was compared against five experimental setups with increasing levels of complexity: inclusion of in-context guidelines, guideline reformatting, and implementation of few-shot learning. Our primary outcome was the qualitative assessment of accuracy based on expert review, while secondary outcomes included the quantitative measurement of similarity of LLM-generated responses to expert-provided answers using text-similarity scores. The results showed a significant improvement in accuracy from 43 to 99% (p < 0.001), when guidelines were provided as context in a coherent corpus of text and non-text sources were converted into text. In addition, few-shot learning did not seem to improve overall accuracy. The study highlights that structured guideline reformatting and advanced prompt engineering (data quality vs. data quantity) can enhance the efficacy of LLM integrations to CDSSs for guideline delivery. © The Author(s) 2024.","","Artificial intelligence; Computational linguistics; Health care; Learning systems; Viruses; Chronic hepatitis; Clinical decision support systems; Clinical guideline; Hepatitis C virus; Language model; Medical guidelines; Modelling framework; Optimisations; Virus infection; Work-flows; accuracy; Article; chronic hepatitis C; clinical decision support system; data quality; hallucination; human; information retrieval; large language model; practice guideline; source text; workflow; Decision support systems","","Nature Research","English","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85191075594"
"Bronzini M.; Nicolini C.; Lepri B.; Passerini A.; Staiano J.","Bronzini, Marco (24757915300); Nicolini, Carlo (58709992200); Lepri, Bruno (14008023300); Passerini, Andrea (7006983227); Staiano, Jacopo (14832068200)","24757915300; 58709992200; 14008023300; 7006983227; 14832068200","Glitter or gold? Deriving structured insights from sustainability reports via large language models","2024","EPJ Data Science","13","1","41","","","","2","10.1140/epjds/s13688-024-00481-2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195597218&doi=10.1140%2fepjds%2fs13688-024-00481-2&partnerID=40&md5=8f15a5c870c193ef56585deb0716e421","University of Trento, Trento, Italy; Ipazia S.p.A., Milan, Italy; Fondazione Bruno Kessler (FBK), Trento, Italy","Bronzini M., University of Trento, Trento, Italy, Ipazia S.p.A., Milan, Italy; Nicolini C., Ipazia S.p.A., Milan, Italy; Lepri B., Ipazia S.p.A., Milan, Italy, Fondazione Bruno Kessler (FBK), Trento, Italy; Passerini A., University of Trento, Trento, Italy; Staiano J., University of Trento, Trento, Italy","Over the last decade, several regulatory bodies have started requiring the disclosure of non-financial information from publicly listed companies, in light of the investors’ increasing attention to Environmental, Social, and Governance (ESG) issues. Publicly released information on sustainability practices is often disclosed in diverse, unstructured, and multi-modal documentation. This poses a challenge in efficiently gathering and aligning the data into a unified framework to derive insights related to Corporate Social Responsibility (CSR). Thus, using Information Extraction (IE) methods becomes an intuitive choice for delivering insightful and actionable data to stakeholders. In this study, we employ Large Language Models (LLMs), In-Context Learning, and the Retrieval-Augmented Generation (RAG) paradigm to extract structured insights related to ESG aspects from companies’ sustainability reports. We then leverage graph-based representations to conduct statistical analyses concerning the extracted insights. These analyses revealed that ESG criteria cover a wide range of topics, exceeding 500, often beyond those considered in existing categorizations, and are addressed by companies through a variety of initiatives. Moreover, disclosure similarities emerged among companies from the same region or sector, validating ongoing hypotheses in the ESG literature. Lastly, by incorporating additional company attributes into our analyses, we investigated which factors impact the most on companies’ ESG ratings, showing that ESG disclosure affects the obtained ratings more than other financial or company data. © The Author(s) 2024.","Bipartite graph analyses; ESG dimensions; In-context learning; Interpretability; Knowledge graphs; Large language models; Non-financial disclosures","Computational linguistics; Data mining; Finance; Gold; Knowledge graph; Learning systems; Sustainable development; Bipartite graph analyze; Bipartite graphs; Context learning; Environmental, social, and governance dimension; Financial disclosure; Graph analysis; In contexts; In-context learning; Interpretability; Knowledge graphs; Language model; Large language model; Non-financial disclosure; Graphic methods","","Springer Science and Business Media Deutschland GmbH","English","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85195597218"
"Dos Santos Junior J.C.; Hu R.; Song R.; Bai Y.","Dos Santos Junior, José Cassio (59323603900); Hu, Rachel (59323760600); Song, Richard (59324079100); Bai, Yunfei (59323604000)","59323603900; 59323760600; 59324079100; 59323604000","Domain-Driven LLM Development: Insights into RAG and Fine-Tuning Practices","2024","Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining","","","","6416","6417","1","0","10.1145/3637528.3671445","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203696688&doi=10.1145%2f3637528.3671445&partnerID=40&md5=704f0b37252163ce658572f7ae4b4133","Amazon Web Services, Seattle, WA, United States; CambioML Corp, San Jose, CA, United States; Epsilla, Jersey City, NJ, United States","Dos Santos Junior J.C., Amazon Web Services, Seattle, WA, United States; Hu R., CambioML Corp, San Jose, CA, United States; Song R., Epsilla, Jersey City, NJ, United States; Bai Y., Amazon Web Services, Seattle, WA, United States","To improve Large Language Model (LLM) performance on domain specific applications, ML developers often leverage Retrieval Augmented Generation (RAG) and LLM Fine-Tuning. RAG extends the capabilities of LLMs to specific domains or an organization's internal knowledge base, without the need to retrain the model. On the other hand, Fine-Tuning approach updates LLM weights with domain-specific data to improve performance on specific tasks. The fine-tuned model is particularly effective to systematically learn new comprehensive knowledge in a specific domain that is not covered by the LLM pre-training. This tutorial walks through the RAG and Fine-Tuning techniques, discusses the insights of their advantages and limitations, and provides best practices of adopting the methodologies for the LLM tasks and use cases. The hands-on labs demonstrate the advanced techniques to optimize the RAG and fine-tuned LLM architecture that handles domain specific LLM tasks. The labs in the tutorial are designed by using a set of open-source python libraries to implement the RAG and fine-tuned LLM architecture.  © 2024 Copyright held by the owner/author(s).","fine tuning; generative artificial intelligence; large language model; retrieval augmented generation","Domain Knowledge; Open source software; Search engines; Domain specific; Fine tuning; Generative artificial intelligence; Language model; Large language model; Model development; Modeling architecture; Modeling performance; Modeling task; Retrieval augmented generation; Open systems","","Association for Computing Machinery","English","Conference paper","Final","","Scopus","2-s2.0-85203696688"
"Xu Z.; Cruz M.J.; Guevara M.; Wang T.; Deshpande M.; Wang X.; Li Z.","Xu, Zhentao (58476763100); Cruz, Mark Jerome (59144407800); Guevara, Matthew (59144531700); Wang, Tie (57214938423); Deshpande, Manasi (59144664100); Wang, Xiaofeng (59144664200); Li, Zheng (59144448000)","58476763100; 59144407800; 59144531700; 57214938423; 59144664100; 59144664200; 59144448000","Retrieval-Augmented Generation with Knowledge Graphs for Customer Service Question Answering","2024","SIGIR 2024 - Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval","","","","2905","2909","4","1","10.1145/3626772.3661370","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200563752&doi=10.1145%2f3626772.3661370&partnerID=40&md5=5f5b45dc025223e99da508241e8bc034","LinkedIn Corporation, Sunnyvale, CA, United States","Xu Z., LinkedIn Corporation, Sunnyvale, CA, United States; Cruz M.J., LinkedIn Corporation, Sunnyvale, CA, United States; Guevara M., LinkedIn Corporation, Sunnyvale, CA, United States; Wang T., LinkedIn Corporation, Sunnyvale, CA, United States; Deshpande M., LinkedIn Corporation, Sunnyvale, CA, United States; Wang X., LinkedIn Corporation, Sunnyvale, CA, United States; Li Z., LinkedIn Corporation, Sunnyvale, CA, United States","In customer service technical support, swiftly and accurately retrieving relevant past issues is critical for efficiently resolving customer inquiries. The conventional retrieval methods in retrieval-augmented generation (RAG) for large language models (LLMs) treat a large corpus of past issue tracking tickets as plain text, ignoring the crucial intra-issue structure and inter-issue relations, which limits performance. We introduce a novel customer service question-answering method that amalgamates RAG with a knowledge graph (KG). Our method constructs a KG from historical issues for use in retrieval, retaining the intra-issue structure and inter-issue relations. During the question-answering phase, our method parses consumer queries and retrieves related sub-graphs from the KG to generate answers. This integration of a KG not only improves retrieval accuracy by preserving customer service structure information but also enhances answering quality by mitigating the effects of text segmentation. Empirical assessments on our benchmark datasets, utilizing key retrieval (MRR, Recall@K, NDCG@K) and text generation (BLEU, ROUGE, METEOR) metrics, reveal that our method outperforms the baseline by 77.6% in MRR and by 0.32 in BLEU. Our method has been deployed within LinkedIn's customer service team for approximately six months and has reduced the median per-issue resolution time by 28.6%. © 2024 ACM.","knowledge graph; large language model; question answering; retrieval-augmented generation","Computational linguistics; Information retrieval; Sales; Customer inquiry; Customer-service; Knowledge graphs; Language model; Large corpora; Large language model; Question Answering; Retrieval methods; Retrieval-augmented generation; Technical support; Knowledge graph","","Association for Computing Machinery, Inc","English","Conference paper","Final","","Scopus","2-s2.0-85200563752"
"Lacasa L.A.; Dévora-Pajares M.; Zbib R.; Fabregat H.","Lacasa, Lucas Alvarez (57892049100); Dévora-Pajares, Martín (57223824721); Zbib, Rabih (6507259855); Fabregat, Hermenegildo (57195674110)","57892049100; 57223824721; 6507259855; 57195674110","Intent Classification Methods for Human Resources Chatbots; [Métodos para Clasificación de Intenciones en Chatbots de Recursos Humanos]","2024","Procesamiento del Lenguaje Natural","","73","","109","124","15","0","10.26342/2024-73-8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206551565&doi=10.26342%2f2024-73-8&partnerID=40&md5=84971c8a16972afe9ce0bb7cc9004825","Avature Machine Learning","Lacasa L.A., Avature Machine Learning; Dévora-Pajares M., Avature Machine Learning; Zbib R., Avature Machine Learning; Fabregat H., Avature Machine Learning","With the rapid development of artificial intelligence, conversational agents have become prevalent in most mainstream platforms. To accomplish the user’s goal, the system needs to determine their intention, detect emotions and extract key entities from the conversational utterances. This paper presents a comprehensive analysis of intent classification techniques applied to Human Resources chatbots. First, unsupervised learning methods are explored, using pre-trained encoders and Zero-Shot Classification pipelines. Then, we investigate supervised approaches and Large Language Models using Retrieval Augmented Generation. Finally, we propose a two-stage retrieval pipeline that trains a coarse-grained classifier and uses its prediction to retrieve the fine-grained intent with Approximate Nearest Neighbor search. Results reveal that while fully supervised methods yield superior models, unsupervised approaches demonstrate competitive performance, but have the advantage of allowing new intents to be added without requiring model retraining. Our proposed two-stage approach combines the benefits of better performance with the added flexibility. © 2024 Sociedad Española para el Procesamiento del Lenguaje Natural.","Dialog Systems; Intent Classification; LLM; RAG","","","Sociedad Espanola para el Procesamiento del Lenguaje Natural","English","Article","Final","","Scopus","2-s2.0-85206551565"
"Qi S.; Hu H.; Li H.; Li Q.; Xiao B.","Qi, Siyang (59327037100); Hu, Huiyun (59326969800); Li, Hongbing (57203122172); Li, Qi (59326900700); Xiao, Bo (35729594700)","59327037100; 59326969800; 57203122172; 59326900700; 35729594700","Domain-Specific Question Answering System Construction Approach Integrated with Large Language Model; [融合大语言模型的领域问答系统构建方法]","2024","Beijing Youdian Daxue Xuebao/Journal of Beijing University of Posts and Telecommunications","47","4","","50","56","6","0","10.13190/j.jbupt.2023-279","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203880563&doi=10.13190%2fj.jbupt.2023-279&partnerID=40&md5=583db63369b85a62a895bbda3a556b04","School of Artificial Intelligence, Beijing University of Posts and Telecommunications, Beijing, 100876, China","Qi S., School of Artificial Intelligence, Beijing University of Posts and Telecommunications, Beijing, 100876, China; Hu H., School of Artificial Intelligence, Beijing University of Posts and Telecommunications, Beijing, 100876, China; Li H., School of Artificial Intelligence, Beijing University of Posts and Telecommunications, Beijing, 100876, China; Li Q., School of Artificial Intelligence, Beijing University of Posts and Telecommunications, Beijing, 100876, China; Xiao B., School of Artificial Intelligence, Beijing University of Posts and Telecommunications, Beijing, 100876, China","The construction of domain-specific question answering system frequently encounters challenges, including substantial data costs, intricate knowledge construction, and the significant differences among datasets from various domains. To address these challenges, an approach that integrates large language models and domain specific knowledge for question answering system construction is proposed. Most of the existing methods directly store and match local knowledge corpus in segments. When performing retrieval-augmented generation, the semantic matching between the query and the corpus is insufficient, thus reducing the quality of text generation. Therefore, the prompt aligned retrieval generation approach is proposed to unify the semantic space of user queries and corpus by generating pseudo question and answer pairs, thereby improving the retrieval efficiency of domain knowledge and the accuracy of answers. Experiments show that the proposed approach overcomes challenges related to high model training costs, enabling rapid deployment across various vertical domains and outperforming other methods. © 2024 Beijing University of Posts and Telecommunications. All rights reserved.","knowledge base; large language model; question answering system; vertical domain","Domain Knowledge; Semantics; Structured Query Language; Construction approaches; Data costs; Domain specific; Knowledge base; Knowledge construction; Language model; Large language model; Question answering systems; System construction; Vertical domain; Question answering","","Beijing University of Posts and Telecommunications","Chinese","Article","Final","","Scopus","2-s2.0-85203880563"
"Church K.W.; Sun J.; Yue R.; Vickers P.; Saba W.; Chandrasekar R.","Church, Kenneth Ward (54790587800); Sun, Jiameng (59255181200); Yue, Richard (58609547100); Vickers, Peter (59255083200); Saba, Walid (59340098100); Chandrasekar, Raman (57222730876)","54790587800; 59255181200; 58609547100; 59255083200; 59340098100; 57222730876","Emerging trends: A gentle introduction to RAG","2024","Natural Language Engineering","30","4","","870","881","11","0","10.1017/S1351324924000044","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204963402&doi=10.1017%2fS1351324924000044&partnerID=40&md5=fe35bf341a51c3ee8be859f02a560dd7","Northeastern University, Boston, MA, United States","Church K.W., Northeastern University, Boston, MA, United States; Sun J., Northeastern University, Boston, MA, United States; Yue R., Northeastern University, Boston, MA, United States; Vickers P., Northeastern University, Boston, MA, United States; Saba W., Northeastern University, Boston, MA, United States; Chandrasekar R., Northeastern University, Boston, MA, United States","Retrieval-augmented generation (RAG) adds a simple but powerful feature to chatbots, the ability to upload files just-in-time. Chatbots are trained on large quantities of public data. The ability to upload files just-in-time makes it possible to reduce hallucinations by filling in gaps in the knowledge base that go beyond the public training data such as private data and recent events. For example, in a customer service scenario, with RAG, we can upload your private bill and then the bot can discuss questions about your bill as opposed to generic FAQ questions about bills in general. This tutorial will show how to upload files and generate responses to prompts; see https://github.com/kwchurch/RAG for multiple solutions based on tools from OpenAI, LangChain, HuggingFace transformers and VecML.  © The Author(s), 2024.","chatbots; hallucinations; LLMs; RAG; uploading files just-in-time","Bot (Internet); Mendelevium; Metadata; Chatbots; Emerging trends; Filling in; Hallucination; Just-in-time; LLM; Public data; Retrieval-augmented generation; Simple++; Uploading file just-in-time; Just in time production","","Cambridge University Press","English","Article","Final","","Scopus","2-s2.0-85204963402"
"Tu S.; Wang Y.; Yu J.; Xie Y.; Shi Y.; Wang X.; Zhang J.; Hou L.; Li J.","Tu, Shangqing (57225899353); Wang, Yuanchun (58489286600); Yu, Jifan (57205103754); Xie, Yuyang (57219458881); Shi, Yaran (59215248800); Wang, Xiaozhi (57216696467); Zhang, Jing (57216205138); Hou, Lei (56622056400); Li, Juanzi (8304332600)","57225899353; 58489286600; 57205103754; 57219458881; 59215248800; 57216696467; 57216205138; 56622056400; 8304332600","R-Eval: A Unified Toolkit for Evaluating Domain Knowledge of Retrieval Augmented Large Language Models","2024","Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining","","","","5813","5824","11","0","10.1145/3637528.3671564","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203674705&doi=10.1145%2f3637528.3671564&partnerID=40&md5=b93a5c228edb9c71ee3768ec75fa222e","DCST, Tsinghua University, Beijing, China; SoI, Renmin University of China, Beijing, China; SIOE, Beihang University, Beijing, China; BNRist, DCST, Tsinghua University, Beijing, China","Tu S., DCST, Tsinghua University, Beijing, China; Wang Y., SoI, Renmin University of China, Beijing, China; Yu J., DCST, Tsinghua University, Beijing, China; Xie Y., DCST, Tsinghua University, Beijing, China; Shi Y., SIOE, Beihang University, Beijing, China; Wang X., DCST, Tsinghua University, Beijing, China; Zhang J., SoI, Renmin University of China, Beijing, China; Hou L., BNRist, DCST, Tsinghua University, Beijing, China; Li J., BNRist, DCST, Tsinghua University, Beijing, China","Large language models have achieved remarkable success on general NLP tasks, but they may fall short for domain-specific problems. Recently, various Retrieval-Augmented Large Language Models (RALLMs) are proposed to address this shortcoming. However, existing evaluation tools only provide a few baselines and evaluate them on various domains without mining the depth of domain knowledge. In this paper, we address the challenges of evaluating RALLMs by introducing the R-Eval toolkit, a Python toolkit designed to streamline the evaluation of different RAG workflows in conjunction with LLMs. Our toolkit, which supports popular built-in RAG workflows and allows for the incorporation of customized testing data on the specific domain, is designed to be user-friendly, modular, and extensible. We conduct an evaluation of 21 RALLMs across three task levels and two representative domains, revealing significant variations in the effectiveness of RALLMs across different tasks and domains. Our analysis emphasizes the importance of considering both task and domain requirements when choosing a RAG workflow and LLM combination. We are committed to continuously maintaining our platform at https://github.com/THU-KEG/R-Eval to facilitate both the industry and the researchers.  © 2024 Copyright held by the owner/author(s).","domain knowledge; evaluation; large language model","Metadata; Problem oriented languages; Search engines; Domain knowledge; Domain specific; Evaluation; Evaluation tool; Language model; Large language model; Specific problems; Testing data; User friendly; Work-flows; Unified Modeling Language","","Association for Computing Machinery","English","Conference paper","Final","All Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85203674705"
"Munley C.; Jarmusch A.; Chandrasekaran S.","Munley, Christian (57873428000); Jarmusch, Aaron (57874346600); Chandrasekaran, Sunita (35117488100)","57873428000; 57874346600; 35117488100","LLM4VV: Developing LLM-driven testsuite for compiler validation","2024","Future Generation Computer Systems","160","","","1","13","12","2","10.1016/j.future.2024.05.034","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194929614&doi=10.1016%2fj.future.2024.05.034&partnerID=40&md5=967f5af5ebfbb63548a8976987efd250","Department of Computer & Information Sciences, University of Delaware, Newark, 19716, United States","Munley C., Department of Computer & Information Sciences, University of Delaware, Newark, 19716, United States; Jarmusch A., Department of Computer & Information Sciences, University of Delaware, Newark, 19716, United States; Chandrasekaran S., Department of Computer & Information Sciences, University of Delaware, Newark, 19716, United States","Large language models (LLMs) are a new and powerful tool for a wide span of applications involving natural language and demonstrate impressive code generation abilities. The goal of this work is to automatically generate tests and use these tests to validate and verify compiler implementations of a directive-based parallel programming paradigm, OpenACC. To do so, in this paper, we explore the capabilities of state-of-the-art LLMs, including open-source LLMs - Meta's Codellama, Phind's fine-tuned version of Codellama, Deepseek's Deepseek Coder and closed-source LLMs - OpenAI's GPT-3.5-Turbo and GPT-4-Turbo. We further fine-tune the open-source LLMs and GPT-3.5-Turbo using our own testsuite dataset along with using the OpenACC specification. We also explored these LLMs using various prompt engineering techniques that include code template, template with retrieval-augmented generation (RAG), one-shot example, one-shot with RAG, expressive prompt with code template and RAG. This paper highlights our findings from over 5000 tests generated via all the above mentioned methods. Our contributions include: (a) exploring the capabilities of the latest and relevant LLMs for code generation, (b) investigating fine-tuning and prompt methods, and (c) analyzing the outcome of LLMs generated tests including manually analysis of representative set of tests. We found the LLM Deepseek-Coder-33b-Instruct produced the most passing tests followed by GPT-4-Turbo. © 2024 Elsevier B.V.","Code generation; Large language models; OpenACC; Validation and verification","Computational linguistics; Natural language processing systems; Open source software; Open systems; Parallel programming; Program compilers; Codegeneration; Compiler implementation; Compiler validation; Language model; Large language model; Model-driven; Natural languages; Open-source; OpenACC; Validation and verification; C (programming language)","","Elsevier B.V.","English","Article","Final","","Scopus","2-s2.0-85194929614"
"Luangaphirom T.; Jocknoi L.; Wunchum C.; Chokerungreang K.; Siriborvornratanakul T.","Luangaphirom, Thananan (59349807700); Jocknoi, Lojrutai (59350382700); Wunchum, Chalermchai (59350382800); Chokerungreang, Kittitee (59349924100); Siriborvornratanakul, Thitirat (26425265700)","59349807700; 59350382700; 59350382800; 59349924100; 26425265700","ThaiNutriChat: development of a Thai large language model-based chatbot for health food services","2024","Multimedia Systems","30","5","298","","","","0","10.1007/s00530-024-01495-6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205342319&doi=10.1007%2fs00530-024-01495-6&partnerID=40&md5=03aa819762696f24cac05052a2f9e1cd","Graduate School of Applied Statistics, National Institute of Development Administration, 148 SeriThai Road, Klong-Chan, Bangkapi, Bangkok, 10240, Thailand","Luangaphirom T., Graduate School of Applied Statistics, National Institute of Development Administration, 148 SeriThai Road, Klong-Chan, Bangkapi, Bangkok, 10240, Thailand; Jocknoi L., Graduate School of Applied Statistics, National Institute of Development Administration, 148 SeriThai Road, Klong-Chan, Bangkapi, Bangkok, 10240, Thailand; Wunchum C., Graduate School of Applied Statistics, National Institute of Development Administration, 148 SeriThai Road, Klong-Chan, Bangkapi, Bangkok, 10240, Thailand; Chokerungreang K., Graduate School of Applied Statistics, National Institute of Development Administration, 148 SeriThai Road, Klong-Chan, Bangkapi, Bangkok, 10240, Thailand; Siriborvornratanakul T., Graduate School of Applied Statistics, National Institute of Development Administration, 148 SeriThai Road, Klong-Chan, Bangkapi, Bangkok, 10240, Thailand","Thailand is facing a shortage of medical personnel to provide health consultations to the public, especially in the area of Non-Communicable Diseases (NCDs), which include diseases related to lifestyle and dietary habits. With advancements in technology, there have been efforts to develop Chatbots to assist in answering questions and providing health-related information. In this work, the ThaiNutriChat Chatbot was developed for health consultation on NCDs, and the effectiveness of the Large Language Model (LLM) was evaluated by two forms of dataset collection, academic journal data from Thai health organizations and a set of 1000 Q&A pairs using the text recognition method via Tesseract OCR and augmenting the dataset from Typologically Diverse Question Answering (TyDi QA). Following that, ThaiNutriChat incorporated the dataset into the LLM refinement process through three main stages: (1) Retrieval Augmented Generation (RAG), (2) Fine-tuning using the Low-Rank Adaptation of Large Language Models (LoRA) technique, and (3) Employing a combination of RAG and fine-tuning. Subsequently, the effectiveness of ThaiNutriChat in all three configurations was assessed by medical experts, and divided into two domains: general knowledge about NCDs and specific knowledge related to NCDs. The performance accuracy in answering questions was compared between ThaiNutriChat and other Thai language models that support the same set of questions. The results showed that ThaiNutriChat has higher accuracy in answering questions related to specific knowledge related to NCDs compared to other Thai language models. © The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature 2024.","Chatbot; Large Language Model; Low-Rank Adaptation of Large Language Models; Retrieval Augmented Generation","Diseases; Chatbots; Fine tuning; Language model; Large language model; Low-rank adaptation of large language model; Non-communicable disease; Retrieval augmented generation; Specific knowledge; Thai language model; Electronic health record","","Springer Science and Business Media Deutschland GmbH","English","Article","Final","","Scopus","2-s2.0-85205342319"
"Siddharth L.; Luo J.","Siddharth, L. (57194033012); Luo, Jianxi (36844141600)","57194033012; 36844141600","Retrieval augmented generation using engineering design knowledge","2024","Knowledge-Based Systems","303","","112410","","","","0","10.1016/j.knosys.2024.112410","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202757647&doi=10.1016%2fj.knosys.2024.112410&partnerID=40&md5=d59e39885e452cf081b410d636826cdf","Engineering Product Development, Singapore University of Technology and Design (SUTD), 8, Somapah Road, Singapore; Department of Systems Engineering, City University of Hong Kong, 83 Tat Chee Ave, Kowloon Tong, Hong Kong","Siddharth L., Engineering Product Development, Singapore University of Technology and Design (SUTD), 8, Somapah Road, Singapore; Luo J., Department of Systems Engineering, City University of Hong Kong, 83 Tat Chee Ave, Kowloon Tong, Hong Kong","Aiming to support Retrieval Augmented Generation (RAG) in the design process, we present a method to identify explicit, engineering design facts – {head entity:: relationship:: tail entity} from patented artefact descriptions. Given a sentence with a pair of entities (selected from noun phrases) marked in a unique manner, our method extracts their relationship that is explicitly communicated in the sentence. For this task, we create a dataset of 375,084 examples and fine-tune language models for relation identification (token classification task) and relation elicitation (sequence-to-sequence task). The token classification approach achieves up to 99.7% accuracy. Upon applying the method to a domain of 4,870 fan system patents, we populate a knowledge base of over 2.93 million facts. Using this knowledge base, we demonstrate how Large Language Models (LLMs) are guided by explicit facts to synthesise knowledge and generate technical and cohesive responses when sought out for knowledge retrieval tasks in the design process. © 2024 Elsevier B.V.","Engineering design knowledge; Graph neural networks; Knowledge graphs; Large-language models; Patent documents; Retrieval-augmented generation","Graph neural networks; Patents and inventions; Design-process; Engineering design; Engineering design knowledge; Entity-relationship; Graph neural networks; Knowledge graphs; Language model; Large-language model; Patent documents; Retrieval-augmented generation; Knowledge graph","","Elsevier B.V.","English","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85202757647"
"Liu X.; Wang R.; Song Y.; Kong L.","Liu, Xuanqing (57210642015); Wang, Runhui (57211586546); Song, Yang (59324263900); Kong, Luyang (57224818780)","57210642015; 57211586546; 59324263900; 57224818780","GRAM: Generative Retrieval Augmented Matching of Data Schemas in the Context of Data Security","2024","Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining","","","","5476","5486","10","0","10.1145/3637528.3671602","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203708949&doi=10.1145%2f3637528.3671602&partnerID=40&md5=d90e5a97aa461b4d050af4e2367c5194","Amazon Web Services, Seattle, WA, United States","Liu X., Amazon Web Services, Seattle, WA, United States; Wang R., Amazon Web Services, Seattle, WA, United States; Song Y., Amazon Web Services, Seattle, WA, United States; Kong L., Amazon Web Services, Seattle, WA, United States","Schema matching constitutes a pivotal phase in the data ingestion process for contemporary database systems. Its objective is to discern pairwise similarities between two sets of attributes, each associated with a distinct data table. This challenge emerges at the initial stages of data analytics, such as when incorporating a third-party table into existing databases to inform business insights. Given its significance in the realm of database systems, schema matching has been under investigation since the 2000s. This study revisits this foundational problem within the context of large language models. Adhering to increasingly stringent data security policies, our focus lies on the zero-shot and few-shot scenarios: the model should analyze only a minimal amount of customer data to execute the matching task, contrasting with the conventional approach of scrutinizing the entire data table. We emphasize that the zero-shot or few-shot assumption is imperative to safeguard the identity and privacy of customer data, even at the potential cost of accuracy. The capability to accurately match attributes under such stringent requirements distinguishes our work from previous literature in this domain.  © 2024 Copyright held by the owner/author(s).","generative modeling; retrieval augmented generation; schema matching","Data assimilation; Customer data; Data analytics; Data ingestions; Data tables; Foundational problems; Generative model; Matchings; Retrieval augmented generation; Schema matching; Third parties; Generative adversarial networks","","Association for Computing Machinery","English","Conference paper","Final","All Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85203708949"
"Xu Y.; Cai T.; Jiang J.; Song X.","Xu, Yunqi (59208173500); Cai, Tianchi (57222177665); Jiang, Jiyan (57223836013); Song, Xierui (58134549400)","59208173500; 57222177665; 57223836013; 58134549400","Face4Rag: Factual Consistency Evaluation for Retrieval Augmented Generation in Chinese","2024","Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining","","","","6083","6094","11","1","10.1145/3637528.3671656","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203693281&doi=10.1145%2f3637528.3671656&partnerID=40&md5=e80772af32ba48c09f14cdb78e5f6bac","Ant Group, Shanghai, China; Tsinghua University, Beijing, China","Xu Y., Ant Group, Shanghai, China; Cai T., Ant Group, Shanghai, China; Jiang J., Tsinghua University, Beijing, China; Song X., Ant Group, Shanghai, China","The prevailing issue of factual inconsistency errors in conventional Retrieval Augmented Generation (RAG) motivates the study of Factual Consistency Evaluation (FCE). Despite the various FCE methods proposed earlier, these methods are evaluated on datasets generated by specific Large Language Models (LLMs). Without a comprehensive benchmark, it remains unexplored how these FCE methods perform on other LLMs with different error distributions or even unseen error types, as these methods may fail to detect the error types generated by other LLMs. To fill this gap, in this paper, we propose the first comprehensive FCE benchmark Face4RAG for RAG independent of the underlying LLM. Our benchmark consists of a synthetic dataset built upon a carefully designed typology for factuality inconsistency error and a real-world dataset constructed from six commonly used LLMs, enabling evaluation of FCE methods on specific error types or real-world error distributions. On the proposed benchmark, we discover the failure of existing FCE methods to detect the logical fallacy, which refers to a mismatch of logic structures between the answer and the retrieved reference. To fix this issue, we further propose a new method called L-Face4RAG with two novel designs of logic-preserving answer decomposition and fact-logic FCE. Extensive experiments show L-Face4RAG substantially outperforms previous methods for factual inconsistency detection on a wide range of tasks, notably beyond the RAG task from which it is originally motivated. Both the benchmark and our proposed method are publicly available. https://huggingface.co/datasets/yq27/Face4RAG  © 2024 Copyright held by the owner/author(s).","factual consistency evaluation; large language model","Benchmarking; Error distributions; Error types; Evaluation methods; Factual consistency evaluation; Inconsistency error; Language model; Large language model; Prevailing issues; Real-world datasets; Synthetic datasets; Computer circuits","","Association for Computing Machinery","English","Conference paper","Final","All Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85203693281"
"LIU H.; REN Y.; LI X.; DENG Y.; WANG Y.; CAO Q.; DU J.; LIN Z.; WANG W.","LIU, He (59271717400); REN, Yili (57191089360); LI, Xin (58412016300); DENG, Yue (59271207300); WANG, Yongtao (35239099100); CAO, Qianwen (59272230200); DU, Jinyang (59272740800); LIN, Zhiwei (57226334550); WANG, Wenjie (58993749400)","59271717400; 57191089360; 58412016300; 59271207300; 35239099100; 59272230200; 59272740800; 57226334550; 58993749400","Research status and application of artificial intelligence large models in the oil and gas industry","2024","Petroleum Exploration and Development","51","4","","1049","1065","16","1","10.1016/S1876-3804(24)60524-0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201508707&doi=10.1016%2fS1876-3804%2824%2960524-0&partnerID=40&md5=f80142d908a6d9f10246b3457afb407e","National key Laboratory for Multi-resources Collaborative Green Production of Continental Shale Oil, Daqing, 163000, China; Research Institute of Petroleum Exploration and Development, Beijing, 100083, China; Beijing University of Aeronautics and Astronautics, Beijing, 100191, China; Peking University, Beijing, 100871, China; China University of Petroleum (Beijing), Beijing, 102249, China","LIU H., National key Laboratory for Multi-resources Collaborative Green Production of Continental Shale Oil, Daqing, 163000, China, Research Institute of Petroleum Exploration and Development, Beijing, 100083, China; REN Y., National key Laboratory for Multi-resources Collaborative Green Production of Continental Shale Oil, Daqing, 163000, China, Research Institute of Petroleum Exploration and Development, Beijing, 100083, China; LI X., National key Laboratory for Multi-resources Collaborative Green Production of Continental Shale Oil, Daqing, 163000, China, Research Institute of Petroleum Exploration and Development, Beijing, 100083, China; DENG Y., Beijing University of Aeronautics and Astronautics, Beijing, 100191, China; WANG Y., Peking University, Beijing, 100871, China; CAO Q., China University of Petroleum (Beijing), Beijing, 102249, China; DU J., Beijing University of Aeronautics and Astronautics, Beijing, 100191, China; LIN Z., Peking University, Beijing, 100871, China; WANG W., Research Institute of Petroleum Exploration and Development, Beijing, 100083, China","This article elucidates the concept of large model technology, summarizes the research status of large model technology both domestically and internationally, provides an overview of the application status of large models in vertical industries, outlines the challenges and issues confronted in applying large models in the oil and gas sector, and offers prospects for the application of large models in the oil and gas industry. The existing large models can be briefly divided into three categories: large language models, visual large models, and multimodal large models. The application of large models in the oil and gas industry is still in its infancy. Based on open-source large language models, some oil and gas enterprises have released large language model products using methods like fine-tuning and retrieval augmented generation. Scholars have attempted to develop scenario-specific models for oil and gas operations by using visual/multimodal foundation models. A few researchers have constructed pre-trained foundation models for seismic data processing and interpretation, as well as core analysis. The application of large models in the oil and gas industry faces challenges such as current data quantity and quality being difficult to support the training of large models, high research and development costs, and poor algorithm autonomy and control. The application of large models should be guided by the needs of oil and gas business, taking the application of large models as an opportunity to improve data lifecycle management, enhance data governance capabilities, promote the construction of computing power, strengthen the construction of “artificial intelligence + energy” composite teams, and boost the autonomy and control of large model technology. © 2024 Research Institute of Petroleum Exploration & Development, PetroChina","fine-tuning; foundation model; large language mode; large model of oil and gas industry; multimodal large model; pre-training; visual large model","Core analysis; Critical path analysis; Enterprise resource management; Gas industry; Gasoline; Information management; Petroleum industry; Research and development management; Seismic prospecting; Visual languages; Fine tuning; Foundation models; Large language mode; Large model of oil and gas industry; Large models; Multi-modal; Multimodal large model; Oil and Gas Industry; Pre-training; Visual large model; artificial intelligence; conceptual framework; core analysis; data interpretation; data processing; gas industry; governance approach; hydrocarbon exploration; life cycle analysis; oil industry; petroleum engineering; research work; seismic data; well technology; Petroleum prospecting","","KeAi Communications Co.","English","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85201508707"
"Santra P.","Santra, Payel (58853065900)","58853065900","Leveraging LLMs for Detecting and Modeling the Propagation of Misinformation in Social Networks","2024","SIGIR 2024 - Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval","","","","3073","","","0","10.1145/3626772.3657654","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200608375&doi=10.1145%2f3626772.3657654&partnerID=40&md5=59f6dbb654bec8ff6689054ee1c25b30","School of Mathematical and Computational Science, Indian Association for the Cultivation of Science, WB, Kolkata, India","Santra P., School of Mathematical and Computational Science, Indian Association for the Cultivation of Science, WB, Kolkata, India","Recent success in language generation capabilities of large language models (LLMs), such as GPT, Llama, etc., can potentially lead to concern about their possible misuse in inducing mass agitation and communal hatred via generating fake news and spreading misinformation. Traditional means of developing a misinformation ground-truth dataset do not scale well because of the extensive manual effort required to annotate the data. It is crucial to anticipate and counteract potential adversarial fake information to mitigate detrimental effects and promote societal harmony. To this end, this PhD proposal spans three main research directions. The first concerns investigating ways of developing unsupervised models for fake news identification leveraging retrieval augmented generation (RAG) approaches. In our second thread of work, we explore ways of creating synthetic datasets to eventually train supervised or few-shot example-based models. Another direction of research work involves tracking the propagation of fake information through social networks to develop preventive measures against it. © 2024 Owner/Author.","in-context learning; information retrieval; misinformation detection and propagation; prompt learning","Context learning; Example based; Ground-truth dataset; In contexts; In-context learning; Language generation; Language model; Misinformation detection and propagation; Prompt learning; Synthetic datasets; Fake detection","","Association for Computing Machinery, Inc","English","Conference paper","Final","","Scopus","2-s2.0-85200608375"
"Wang S.; Khramtsova E.; Zhuang S.; Zuccon G.","Wang, Shuai (57250399200); Khramtsova, Ekaterina (57814745000); Zhuang, Shengyao (57216585997); Zuccon, Guido (25927778100)","57250399200; 57814745000; 57216585997; 25927778100","FeB4RAG: Evaluating Federated Search in the Context of Retrieval Augmented Generation","2024","SIGIR 2024 - Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval","","","","763","773","10","0","10.1145/3626772.3657853","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200555863&doi=10.1145%2f3626772.3657853&partnerID=40&md5=0b5ed4a4a77069777517e48fbd1d3e51","The University of Queensland, Brisbane, QLD, Australia; CSIRO, Brisbane, QLD, Australia","Wang S., The University of Queensland, Brisbane, QLD, Australia; Khramtsova E., The University of Queensland, Brisbane, QLD, Australia; Zhuang S., CSIRO, Brisbane, QLD, Australia; Zuccon G., The University of Queensland, Brisbane, QLD, Australia","Federated search systems aggregate results from multiple search engines, selecting appropriate sources to enhance result quality and align with user intent. With the increasing uptake of Retrieval-Augmented Generation (RAG) pipelines, federated search can play a pivotal role in sourcing relevant information across heterogeneous data sources to generate informed responses. However, existing datasets, such as those developed in the past TREC FedWeb tracks, predate the RAG paradigm shift and lack representation of modern information retrieval challenges. To bridge this gap, we present FeB4RAG, a novel dataset specifically designed for federated search within RAG frameworks. This dataset, derived from 16 sub-collections of the widely used BEIR benchmarking collection, includes 790 information requests (akin to conversational queries) tailored for chatbot applications, along with top results returned by each resource and associated LLM-derived relevance judgements. Additionally, to support the need for this collection, we demonstrate the impact on response generation of a high quality federated search system for RAG compared to a naive approach to federated search. We do so by comparing answers generated by the RAG pipeline with a qualitative side-by-side comparison. Our collection fosters and supports the development and evaluation of new federated search methods, especially in the context of RAG pipelines. The resource is publicly available at https://github.com/ielab/FeB4RAG. © 2024 ACM.","federated search; large language models (llms); retrieval augmented generation (rag); test collection.","Benchmarking; Bridges; Information retrieval; Safety devices; Search engines; Federated search; Heterogeneous data sources; Language model; Large language model; Multiple search; Paradigm shifts; Retrieval augmented generation; Search system; Test Collection; Test collection.; Pipelines","","Association for Computing Machinery, Inc","English","Conference paper","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85200555863"
"Gue C.C.Y.; Rahim N.D.A.; Rojas-Carabali W.; Agrawal R.; RK P.; Abisheganaden J.; Yip W.F.","Gue, Celeste Ci Ying (59132597800); Rahim, Noorul Dharajath Abdul (59133790300); Rojas-Carabali, William (57219659910); Agrawal, Rupesh (7201475180); RK, Palvannan (59133397400); Abisheganaden, John (6701696370); Yip, Wan Fen (59254396700)","59132597800; 59133790300; 57219659910; 7201475180; 59133397400; 6701696370; 59254396700","Evaluating the OpenAI’s GPT-3.5 Turbo’s performance in extracting information from scientific articles on diabetic retinopathy","2024","Systematic Reviews","13","1","135","","","","1","10.1186/s13643-024-02523-2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193466784&doi=10.1186%2fs13643-024-02523-2&partnerID=40&md5=c1cf71de885724dd165a7cda7851adbf","Health Services and Outcomes Research, National Healthcare Group, 3 Fusionopolis Link, #03-08, Nexus@One-North, Singapore, 138543, Singapore; National Healthcare Group Eye Institute, Tan Tock Seng Hospital, 11 Jalan Tan Tock Seng, Singapore, 308433, Singapore; Lee Kong Chian School of Medicine, Nanyang Technological University, 11 Mandalay Road, Singapore, 308232, Singapore","Gue C.C.Y., Health Services and Outcomes Research, National Healthcare Group, 3 Fusionopolis Link, #03-08, Nexus@One-North, Singapore, 138543, Singapore; Rahim N.D.A., Health Services and Outcomes Research, National Healthcare Group, 3 Fusionopolis Link, #03-08, Nexus@One-North, Singapore, 138543, Singapore; Rojas-Carabali W., National Healthcare Group Eye Institute, Tan Tock Seng Hospital, 11 Jalan Tan Tock Seng, Singapore, 308433, Singapore, Lee Kong Chian School of Medicine, Nanyang Technological University, 11 Mandalay Road, Singapore, 308232, Singapore; Agrawal R., National Healthcare Group Eye Institute, Tan Tock Seng Hospital, 11 Jalan Tan Tock Seng, Singapore, 308433, Singapore, Lee Kong Chian School of Medicine, Nanyang Technological University, 11 Mandalay Road, Singapore, 308232, Singapore; RK P., Health Services and Outcomes Research, National Healthcare Group, 3 Fusionopolis Link, #03-08, Nexus@One-North, Singapore, 138543, Singapore; Abisheganaden J., Health Services and Outcomes Research, National Healthcare Group, 3 Fusionopolis Link, #03-08, Nexus@One-North, Singapore, 138543, Singapore; Yip W.F., Health Services and Outcomes Research, National Healthcare Group, 3 Fusionopolis Link, #03-08, Nexus@One-North, Singapore, 138543, Singapore","We aimed to compare the concordance of information extracted and the time taken between a large language model (OpenAI’s GPT-3.5 Turbo via API) against conventional human extraction methods in retrieving information from scientific articles on diabetic retinopathy (DR). The extraction was done using GPT3.5 Turbo as of October 2023. OpenAI’s GPT-3.5 Turbo significantly reduced the time taken for extraction. Concordance was highest at 100% for the extraction of the country of study, 64.7% for significant risk factors of DR, 47.1% for exclusion and inclusion criteria, and lastly 41.2% for odds ratio (OR) and 95% confidence interval (CI). The concordance levels seemed to indicate the complexity associated with each prompt. This suggests that OpenAI’s GPT-3.5 Turbo may be adopted to extract simple information that is easily located in the text, leaving more complex information to be extracted by the researcher. It is crucial to note that the foundation model is constantly improving significantly with new versions being released quickly. Subsequent work can focus on retrieval-augmented generation (RAG), embedding, chunking PDF into useful sections, and prompting to improve the accuracy of extraction. © The Author(s) 2024.","Concordance; GPT-3.5 Turbo; Information extraction","Data Mining; Diabetic Retinopathy; Humans; Information Storage and Retrieval; Natural Language Processing; accuracy; artificial intelligence; ChatGPT; diabetic retinopathy; embedding; human; Letter; OpenAI; risk factor; data mining; information retrieval; natural language processing; procedures","","BioMed Central Ltd","English","Letter","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85193466784"
"Kim J.; Wang K.; Weng C.; Liu C.","Kim, Junyoung (57798252800); Wang, Kai (35286098800); Weng, Chunhua (8979750700); Liu, Cong (57212921616)","57798252800; 35286098800; 8979750700; 57212921616","Assessing the utility of large language models for phenotype-driven gene prioritization in the diagnosis of rare genetic disease","2024","American journal of human genetics","111","10","","2190","2202","12","0","10.1016/j.ajhg.2024.08.010","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206019380&doi=10.1016%2fj.ajhg.2024.08.010&partnerID=40&md5=cf928c0d61985cc2dfdeb99950724960","Department of Biomedical Informatics, Columbia University, NY, 10032, NY, United States; Raymond G. Perelman Center for Cellular and Molecular Therapeutics, Children's Hospital of Philadelphia, Philadelphia, PA 19104, USA; Department of Pathology and Laboratory Medicine, University of Pennsylvania, Philadelphia, PA 19104, USA; Department of Biomedical Informatics, Columbia University, NY, 10032, NY, United States; Department of Biomedical Informatics, Columbia University, NY, 10032, NY, United States","Kim J., Department of Biomedical Informatics, Columbia University, NY, 10032, NY, United States; Wang K., Raymond G. Perelman Center for Cellular and Molecular Therapeutics, Children's Hospital of Philadelphia, Philadelphia, PA 19104, USA; Department of Pathology and Laboratory Medicine, University of Pennsylvania, Philadelphia, PA 19104, USA; Weng C., Department of Biomedical Informatics, Columbia University, NY, 10032, NY, United States; Liu C., Department of Biomedical Informatics, Columbia University, NY, 10032, NY, United States","Phenotype-driven gene prioritization is fundamental to diagnosing rare genetic disorders. While traditional approaches rely on curated knowledge graphs with phenotype-gene relations, recent advancements in large language models (LLMs) promise a streamlined text-to-gene solution. In this study, we evaluated five LLMs, including two generative pre-trained transformers (GPT) series and three Llama2 series, assessing their performance across task completeness, gene prediction accuracy, and adherence to required output structures. We conducted experiments, exploring various combinations of models, prompts, phenotypic input types, and task difficulty levels. Our findings revealed that the best-performed LLM, GPT-4, achieved an average accuracy of 17.0% in identifying diagnosed genes within the top 50 predictions, which still falls behind traditional tools. However, accuracy increased with the model size. Consistent results were observed over time, as shown in the dataset curated after 2023. Advanced techniques such as retrieval-augmented generation (RAG) and few-shot learning did not improve the accuracy. Sophisticated prompts were more likely to enhance task completeness, especially in smaller models. Conversely, complicated prompts tended to decrease output structure compliance rate. LLMs also achieved better-than-random prediction accuracy with free-text input, though performance was slightly lower than with standardized concept input. Bias analysis showed that highly cited genes, such as BRCA1, TP53, and PTEN, are more likely to be predicted. Our study provides valuable insights into integrating LLMs with genomic analysis, contributing to the ongoing discussion on their utilization in clinical workflows. Copyright © 2024 The Authors. Published by Elsevier Inc. All rights reserved.","artificial intelligence; gene prioritization; generative pre-trained transformers; large language model; phenotypes; precision medicine; rare disease diagnosis","Computational Biology; Humans; Phenotype; Rare Diseases; bioinformatics; genetics; human; phenotype; procedures; rare disease","","","English","Article","Final","All Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85206019380"
"Fan W.; Ding Y.; Ning L.; Wang S.; Li H.; Yin D.; Chua T.-S.; Li Q.","Fan, Wenqi (57188735401); Ding, Yujuan (57204467153); Ning, Liangbo (57226787855); Wang, Shijie (58583387400); Li, Hengyun (56118509900); Yin, Dawei (35759826200); Chua, Tat-Seng (58847166100); Li, Qing (57199178903)","57188735401; 57204467153; 57226787855; 58583387400; 56118509900; 35759826200; 58847166100; 57199178903","A Survey on RAG Meeting LLMs: Towards Retrieval-Augmented Large Language Models","2024","Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining","","","","6491","6501","10","1","10.1145/3637528.3671470","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199415229&doi=10.1145%2f3637528.3671470&partnerID=40&md5=207e78d3cdd0a1434759df8e0b51008a","The Hong Kong Polytechnic University, Hong Kong; Baidu Inc., Beijing, China; National university of Singapore, Singapore, Singapore","Fan W., The Hong Kong Polytechnic University, Hong Kong; Ding Y., The Hong Kong Polytechnic University, Hong Kong; Ning L., The Hong Kong Polytechnic University, Hong Kong; Wang S., The Hong Kong Polytechnic University, Hong Kong; Li H., The Hong Kong Polytechnic University, Hong Kong; Yin D., Baidu Inc., Beijing, China; Chua T.-S., National university of Singapore, Singapore, Singapore; Li Q., The Hong Kong Polytechnic University, Hong Kong","As one of the most advanced techniques in AI, Retrieval-Augmented Generation (RAG) can offer reliable and up-to-date external knowledge, providing huge convenience for numerous tasks. Particularly in the era of AI-Generated Content (AIGC), the powerful capacity of retrieval in providing additional knowledge enables RAG to assist existing generative AI in producing high-quality outputs. Recently, Large Language Models (LLMs) have demonstrated revolutionary abilities in language understanding and generation, while still facing inherent limitations such as hallucinations and out-of-date internal knowledge. Given the powerful abilities of RAG in providing the latest and helpful auxiliary information, Retrieval-Augmented Large Language Models (RA-LLMs) have emerged to harness external and authoritative knowledge bases, rather than solely relying on the model's internal knowledge, to augment the quality of the generated content of LLMs. In this survey, we comprehensively review existing research studies in RA-LLMs, covering three primary technical perspectives: Furthermore, to deliver deeper insights, we discuss current limitations and several promising directions for future research. Updated information about this survey can be found at: https://advanced-recommender-systems.github.io/RAG-Meets-LLMs/  © 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.","fine-tuning; in-context learning; large language model (llm); pre-training; prompting; retrieval augmented generation (rag)","Problem oriented languages; Context learning; External knowledge; Fine tuning; In contexts; In-context learning; Language model; Large language model; Pre-training; Prompting; Retrieval augmented generation; Recommender systems","","Association for Computing Machinery","English","Conference paper","Final","","Scopus","2-s2.0-85199415229"
"Correia J.; Nicholson M.C.; Coutinho D.; Barbosa C.; Castelluccio M.; Gerosa M.; Garcia A.; Steinmacher I.","Correia, João (57202890543); Nicholson, Morgan C. (59237851900); Coutinho, Daniel (57220410075); Barbosa, Caio (57202890969); Castelluccio, Marco (57194448883); Gerosa, Marco (10043515400); Garcia, Alessandro (7404608626); Steinmacher, Igor (36609225300)","57202890543; 59237851900; 57220410075; 57202890969; 57194448883; 10043515400; 7404608626; 36609225300","Unveiling the Potential of a Conversational Agent in Developer Support: Insights from Mozilla's PDF.js Project","2024","AIware 2024 - Proceedings of the 1st ACM International Conference on AI-Powered Software, Co-located with: ESEC/FSE 2024","","","","10","18","8","0","10.1145/3664646.3664758","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199904763&doi=10.1145%2f3664646.3664758&partnerID=40&md5=4e4b963a1bd30bad7a91cf62bb6c61d3","Pontifical Catholic University of Rio de Janeiro, RJ, Rio de Janeiro, Brazil; University of São Paulo, SP, São Paulo, Brazil; Mozilla Corporation, London, United Kingdom; Northern Arizona University, Flagstaff, AZ, United States","Correia J., Pontifical Catholic University of Rio de Janeiro, RJ, Rio de Janeiro, Brazil; Nicholson M.C., University of São Paulo, SP, São Paulo, Brazil; Coutinho D., Pontifical Catholic University of Rio de Janeiro, RJ, Rio de Janeiro, Brazil; Barbosa C., Pontifical Catholic University of Rio de Janeiro, RJ, Rio de Janeiro, Brazil; Castelluccio M., Mozilla Corporation, London, United Kingdom; Gerosa M., Northern Arizona University, Flagstaff, AZ, United States; Garcia A., Pontifical Catholic University of Rio de Janeiro, RJ, Rio de Janeiro, Brazil; Steinmacher I., Northern Arizona University, Flagstaff, AZ, United States","Large language models and other foundation models (FMs) boost productivity by automating code generation, supporting bug fixes, and generating documentation. We propose that FMs can further support Open Source Software (OSS) projects by assisting developers and guiding the community. Currently, core developers and maintainers answer queries about processes, architecture, and source code, but their time is limited, often leading to delays. To address this, we introduce DevMentorAI, a tool that enhances developer-project interactions by leveraging source code and technical documentation. DevMentorAI uses the Retrieval Augmented Generation (RAG) architecture to identify and retrieve relevant content for queries. We evaluated DevMentorAI with a case study on PDF.js project, using real questions from a development chat room and comparing the answers provided by DevMentorAI to those from humans. A Mozilla expert rated the answers, finding DevMentorAI's responses more satisfactory in 8/14 of cases, equally satisfactory in 3/14, and less satisfactory in 3/14. These results demonstrate the potential of using foundation models and the RAG approach to support developers and reduce the burden on core developers. © 2024 Copyright is held by the owner/author(s). Publication rights licensed to ACM.","Conversational Agents; Developer Assistance; Large Language Models; Software Development; Software Engineering","Computational linguistics; Open systems; Query processing; Software agents; Software design; Bug fixes; Codegeneration; Conversational agents; Core developers; Developer assistance; Foundation models; Language model; Large language model; Mozilla; Source codes; Open source software","Adams B.; Zimmermann T.; Ozkaya I.; Lin D.; Zhang J.M.","Association for Computing Machinery, Inc","English","Conference paper","Final","","Scopus","2-s2.0-85199904763"
"Sacoransky E.; Kwan B.Y.M.; Soboleski D.","Sacoransky, Ethan (58923530700); Kwan, Benjamin Y.M. (57190738311); Soboleski, Donald (6603552664)","58923530700; 57190738311; 6603552664","ChatGPT and assistive AI in structured radiology reporting: A systematic review","2024","Current Problems in Diagnostic Radiology","53","6","","728","737","9","1","10.1067/j.cpradiol.2024.07.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198545190&doi=10.1067%2fj.cpradiol.2024.07.007&partnerID=40&md5=ec11c39477d8901d71963fc4f05d5037","Queen's University School of Medicine, 15 Arch St, Kingston, K7L 3L4, ON, Canada; Department of Diagnostic Radiology, Kingston Health Sciences Centre, Kingston, ON, Canada","Sacoransky E., Queen's University School of Medicine, 15 Arch St, Kingston, K7L 3L4, ON, Canada; Kwan B.Y.M., Queen's University School of Medicine, 15 Arch St, Kingston, K7L 3L4, ON, Canada, Department of Diagnostic Radiology, Kingston Health Sciences Centre, Kingston, ON, Canada; Soboleski D., Queen's University School of Medicine, 15 Arch St, Kingston, K7L 3L4, ON, Canada, Department of Diagnostic Radiology, Kingston Health Sciences Centre, Kingston, ON, Canada","Introduction: The rise of transformer-based large language models (LLMs), such as ChatGPT, has captured global attention with recent advancements in artificial intelligence (AI). ChatGPT demonstrates growing potential in structured radiology reporting—a field where AI has traditionally focused on image analysis. Methods: A comprehensive search of MEDLINE and Embase was conducted from inception through May 2024, and primary studies discussing ChatGPT's role in structured radiology reporting were selected based on their content. Results: Of the 268 articles screened, eight were ultimately included in this review. These articles explored various applications of ChatGPT, such as generating structured reports from unstructured reports, extracting data from free text, generating impressions from radiology findings and creating structured reports from imaging data. All studies demonstrated optimism regarding ChatGPT's potential to aid radiologists, though common critiques included data privacy concerns, reliability, medical errors, and lack of medical-specific training. Conclusion: ChatGPT and assistive AI have significant potential to transform radiology reporting, enhancing accuracy and standardization while optimizing healthcare resources. Future developments may involve integrating dynamic few-shot prompting, ChatGPT, and Retrieval Augmented Generation (RAG) into diagnostic workflows. Continued research, development, and ethical oversight are crucial to fully realize AI's potential in radiology. © 2024 The Author(s)","Artificial intelligence; ChatGPT; Large language models; Radiologist; Radiology","Artificial Intelligence; Humans; Radiology; Radiology Information Systems; Article; artificial intelligence; ChatGPT; data privacy; diagnostic accuracy; health care planning; human; image analysis; large language model; medical education; medical error; optimism; radiologist; radiology; reliability; standardization; systematic review; workflow; radiology; radiology information system","","Elsevier Inc.","English","Article","Final","All Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85198545190"
"Sayed A.; Kanojia M.; Nabajja S.","Sayed, Amaan (59288707600); Kanojia, Mahendra (57194405749); Nabajja, Subhashish (59251183200)","59288707600; 57194405749; 59251183200","Advanced Subjective Question Bank Generation Using Retrieval Augmented Generation Architecture","2024","International Journal of Computer Information Systems and Industrial Management Applications","16","3","","264","277","13","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201672275&partnerID=40&md5=03ece3f3ff81a9dcd748794841f45b01","Department of Computer Science, Sheth L.U.J and Sir M.V College, Mumbai, 400069, India","Sayed A., Department of Computer Science, Sheth L.U.J and Sir M.V College, Mumbai, 400069, India; Kanojia M., Department of Computer Science, Sheth L.U.J and Sir M.V College, Mumbai, 400069, India; Nabajja S., Department of Computer Science, Sheth L.U.J and Sir M.V College, Mumbai, 400069, India","Large language models (LLMs) have shown great promise for various natural language processing tasks, including question generation. However, generating subjective questions that are relevant and informative remains a challenge. Existing approaches often rely on predefined question templates or manually crafted knowledge bases, which limit the diversity and quality of generated questions. In this paper, we propose a novel approach that leverages LLMs to generate subjective questions with the help of a custom knowledge base. Our knowledge base is constructed by extracting and embedding relevant information from a given text corpus. By combining the LLM's language generation capabilities with the domain-specific knowledge from the knowledge base, our system can generate more informative and contextually relevant subjective questions. Experimental results show that our approach beats the existing methods in terms of question quality and relevance. Specifically, the Google Gemini LLM achieved the highest score among the compared models, with an average rating of 3.92 out of 5 for question quality and an average relevance score of 0.90. Our approach has several advantages over existing methods. First, it does not rely on predefined question templates, which can limit the diversity of generated questions. Second, our custom knowledge base is constructed from a domain-specific text corpus, which ensures that the generated questions are relevant to the given domain. Third, our approach can be easily adapted to different domains by constructing a new knowledge base from the corresponding text corpus. © Cerebration Science Publishing.","generative pretrained transformers; large language models; natural language processing; question generation","","","Cerebration Science Publishing","English","Article","Final","","Scopus","2-s2.0-85201672275"
"Liu S.; Yu Z.; Huang F.; Bulbulia Y.; Bergen A.; Liut M.","Liu, Suqing (59223892700); Yu, Zezhu (59223944700); Huang, Feiran (59223892800); Bulbulia, Yousef (59223856700); Bergen, Andreas (58137170300); Liut, Michael (57217078907)","59223892700; 59223944700; 59223892800; 59223856700; 58137170300; 57217078907","Can Small Language Models With Retrieval-Augmented Generation Replace Large Language Models When Learning Computer Science?","2024","Annual Conference on Innovation and Technology in Computer Science Education, ITiCSE","1","","","388","393","5","0","10.1145/3649217.3653554","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198907269&doi=10.1145%2f3649217.3653554&partnerID=40&md5=db210ee3ac7fa614c6209f2f0ac5e3dd","University of Toronto Mississauga, Mississauga, ON, Canada","Liu S., University of Toronto Mississauga, Mississauga, ON, Canada; Yu Z., University of Toronto Mississauga, Mississauga, ON, Canada; Huang F., University of Toronto Mississauga, Mississauga, ON, Canada; Bulbulia Y., University of Toronto Mississauga, Mississauga, ON, Canada; Bergen A., University of Toronto Mississauga, Mississauga, ON, Canada; Liut M., University of Toronto Mississauga, Mississauga, ON, Canada","Leveraging Large Language Models (LLMs) for personalized learning and support is becoming a promising tool in computing education. AI Assistants can help students with programming, problem-solving, converse with them to clarify course content, explain error messages to help with debugging, and much more. However, using cloud-based LLMs poses risks around data security, privacy, but also control of the overarching system. To address these concerns, we created a locally-stored Small Language Model (SLM) that leverages different Retrieval-Augmented Generation (RAG) methods to support computing students' learning. We compare one SLM (neural-chat-7b-v3 - fine-tuned version of Mistral-7B-v0.1) against two popular LLMs (gpt-3.5-turbo and gpt-4-32k) to see the viability for computing educators to use in their course(s). We use conversations from a CS1 course (N = 1,260), providing students with an AI Assistant (using gpt-3.5-turbo) to help them learn content and support problem-solving while completing their Python programming assignment. In total, we had 269 students use the AI Assistant, with a total of 1,988 questions asked. Using this real conversational data, we re-ran student questions using our novel SLM (neural-chat-7b-v3 testing nine different RAG methods) and gpt-4-32k, then compared those results against the original gpt-3.5-turbo responses. Our findings indicate that using an SLM with RAG can perform similarly, if not better, than LLMs. This shows that it is possible for computing educators to use SLMs (with RAG) in their course(s) as a tool for scalable learning, supporting content understanding and problem-solving needs, while employing their own policies on data privacy and security. © 2024 ACM.","computing education; conversational agent; cs1; intelligence concentration; intelligent teaching assistant; intelligent tutoring system; large language models; locally deployable ai; personalized ai agent; retrieval augmented generation; small language models","Computational linguistics; Curricula; Data privacy; Education computing; Learning systems; Program debugging; Computing education; Conversational agents; Cs1; Intelligence concentration; Intelligent teaching assistant; Intelligent tutoring; Intelligent tutoring system; Language model; Large language model; Locally deployable ai; Personalized ai agent; Retrieval augmented generation; Small language model; Teaching assistants; Tutoring system; Students","","Association for Computing Machinery","English","Conference paper","Final","","Scopus","2-s2.0-85198907269"
"Bhayana R.; Fawzy A.; Deng Y.; Bleakney R.R.; Krishna S.","Bhayana, Rajesh (6506872404); Fawzy, Aly (58410985800); Deng, Yangqing (57194158392); Bleakney, Robert R. (6603253365); Krishna, Satheesh (57200833091)","6506872404; 58410985800; 57194158392; 6603253365; 57200833091","Retrieval-Augmented Generation for Large Language Models in Radiology: Another Leap Forward in Board Examination Performance","2024","Radiology","313","1","e241489","","","","1","10.1148/radiol.241489","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205779954&doi=10.1148%2fradiol.241489&partnerID=40&md5=894d888825b86bab57c90528e526b903","The University Medical Imaging Toronto, Joint Department of Medical Imaging, Toronto General Hospital, Department of Medical Imaging, University of Toronto, 200 Elizabeth St, Peter Munk Bldg, 1st Fl, Toronto, M5G 24C, ON, Canada","Bhayana R., The University Medical Imaging Toronto, Joint Department of Medical Imaging, Toronto General Hospital, Department of Medical Imaging, University of Toronto, 200 Elizabeth St, Peter Munk Bldg, 1st Fl, Toronto, M5G 24C, ON, Canada; Fawzy A., The University Medical Imaging Toronto, Joint Department of Medical Imaging, Toronto General Hospital, Department of Medical Imaging, University of Toronto, 200 Elizabeth St, Peter Munk Bldg, 1st Fl, Toronto, M5G 24C, ON, Canada; Deng Y., The University Medical Imaging Toronto, Joint Department of Medical Imaging, Toronto General Hospital, Department of Medical Imaging, University of Toronto, 200 Elizabeth St, Peter Munk Bldg, 1st Fl, Toronto, M5G 24C, ON, Canada; Bleakney R.R., The University Medical Imaging Toronto, Joint Department of Medical Imaging, Toronto General Hospital, Department of Medical Imaging, University of Toronto, 200 Elizabeth St, Peter Munk Bldg, 1st Fl, Toronto, M5G 24C, ON, Canada; Krishna S., The University Medical Imaging Toronto, Joint Department of Medical Imaging, Toronto General Hospital, Department of Medical Imaging, University of Toronto, 200 Elizabeth St, Peter Munk Bldg, 1st Fl, Toronto, M5G 24C, ON, Canada","[No abstract available]","","Clinical Competence; Educational Measurement; Humans; Radiology; Specialty Boards; Article; ChatGPT; diagnostic accuracy; human; image quality; information retrieval; large language model; machine learning; McNemar test; prospective study; radiology; signal noise ratio; certification; clinical competence; education; procedures","","Radiological Society of North America Inc.","English","Article","Final","","Scopus","2-s2.0-85205779954"
"Salemi A.; Kallumadi S.; Zamani H.","Salemi, Alireza (57223748391); Kallumadi, Surya (42261923300); Zamani, Hamed (56342230300)","57223748391; 42261923300; 56342230300","Optimization Methods for Personalizing Large Language Models through Retrieval Augmentation","2024","SIGIR 2024 - Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval","","","","752","762","10","4","10.1145/3626772.3657783","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192829605&doi=10.1145%2f3626772.3657783&partnerID=40&md5=b5cf5d3d86b2b8674e214f9514537f8e","University of Massachusetts Amherst, Amherst, MA, United States; Lowe's Companies, Inc., Charlotte, NC, United States","Salemi A., University of Massachusetts Amherst, Amherst, MA, United States; Kallumadi S., Lowe's Companies, Inc., Charlotte, NC, United States; Zamani H., University of Massachusetts Amherst, Amherst, MA, United States","This paper studies retrieval-augmented approaches for personalizing large language models (LLMs), which potentially have a substantial impact on various applications and domains. We propose the first attempt to optimize the retrieval models that deliver a limited number of personal documents to large language models for the purpose of personalized generation. We develop two optimization algorithms that solicit feedback from the downstream personalized generation tasks for retrieval optimization - one based on reinforcement learning whose reward function is defined using any arbitrary metric for personalized generation and another based on knowledge distillation from the downstream LLM to the retrieval model. This paper also introduces a pre- and post-generation retriever selection model that decides what retriever to choose for each LLM input. Extensive experiments on diverse tasks from the language model personalization (LaMP) benchmark reveal statistically significant improvements in six out of seven datasets. © 2024 Owner/Author.","personalization; ranking optimization; retrieval-augmented generation; text generation","Computational linguistics; Information retrieval; Reinforcement learning; Down-stream; Language model; Optimisations; Optimization method; Personal documents; Personalizations; Ranking optimization; Retrieval models; Retrieval-augmented generation; Text generations; Distillation","","Association for Computing Machinery, Inc","English","Conference paper","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85192829605"
"Glicksberg B.S.; Timsina P.; Patel D.; Sawant A.; Vaid A.; Raut G.; Charney A.W.; Apakama D.; Carr B.G.; Freeman R.; Nadkarni G.N.; Klang E.","Glicksberg, Benjamin S (55845627200); Timsina, Prem (57219343719); Patel, Dhaval (59298746900); Sawant, Ashwin (57232763000); Vaid, Akhil (57216200097); Raut, Ganesh (57998554100); Charney, Alexander W (25637186200); Apakama, Donald (58144850700); Carr, Brendan G (55603845600); Freeman, Robert (57215489886); Nadkarni, Girish N (36237038500); Klang, Eyal (56080228800)","55845627200; 57219343719; 59298746900; 57232763000; 57216200097; 57998554100; 25637186200; 58144850700; 55603845600; 57215489886; 36237038500; 56080228800","Evaluating the accuracy of a state-of-the-art large language model for prediction of admissions from the emergency room","2024","Journal of the American Medical Informatics Association","31","9","","1921","1928","7","4","10.1093/jamia/ocae103","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201786452&doi=10.1093%2fjamia%2focae103&partnerID=40&md5=fb8a868510125d6c891fb44d8bee8d74","Division of Data-Driven and Digital Medicine, Department of Medicine, Icahn School of Medicine at Mount Sinai, New York, 10029, NY, United States; Institute for Healthcare Delivery Science, Icahn School of Medicine at Mount Sinai, New York, 10029, NY, United States; The Charles Bronfman Department of Personalized Medicine, Icahn School of Medicine at Mount Sinai, New York, 10029, NY, United States; Department of Emergency Medicine, Icahn School of Medicine at Mount Sinai, New York, 10029, NY, United States; Department of Population Health Science and Policy, Icahn School of Medicine at Mount Sinai, New York, 10029, NY, United States","Glicksberg B.S., Division of Data-Driven and Digital Medicine, Department of Medicine, Icahn School of Medicine at Mount Sinai, New York, 10029, NY, United States; Timsina P., Division of Data-Driven and Digital Medicine, Department of Medicine, Icahn School of Medicine at Mount Sinai, New York, 10029, NY, United States, Institute for Healthcare Delivery Science, Icahn School of Medicine at Mount Sinai, New York, 10029, NY, United States; Patel D., Institute for Healthcare Delivery Science, Icahn School of Medicine at Mount Sinai, New York, 10029, NY, United States; Sawant A., Division of Data-Driven and Digital Medicine, Department of Medicine, Icahn School of Medicine at Mount Sinai, New York, 10029, NY, United States, The Charles Bronfman Department of Personalized Medicine, Icahn School of Medicine at Mount Sinai, New York, 10029, NY, United States; Vaid A., Division of Data-Driven and Digital Medicine, Department of Medicine, Icahn School of Medicine at Mount Sinai, New York, 10029, NY, United States, The Charles Bronfman Department of Personalized Medicine, Icahn School of Medicine at Mount Sinai, New York, 10029, NY, United States; Raut G., Institute for Healthcare Delivery Science, Icahn School of Medicine at Mount Sinai, New York, 10029, NY, United States; Charney A.W., The Charles Bronfman Department of Personalized Medicine, Icahn School of Medicine at Mount Sinai, New York, 10029, NY, United States; Apakama D., Department of Emergency Medicine, Icahn School of Medicine at Mount Sinai, New York, 10029, NY, United States; Carr B.G., Department of Emergency Medicine, Icahn School of Medicine at Mount Sinai, New York, 10029, NY, United States, Department of Population Health Science and Policy, Icahn School of Medicine at Mount Sinai, New York, 10029, NY, United States; Freeman R., Division of Data-Driven and Digital Medicine, Department of Medicine, Icahn School of Medicine at Mount Sinai, New York, 10029, NY, United States, Institute for Healthcare Delivery Science, Icahn School of Medicine at Mount Sinai, New York, 10029, NY, United States, The Charles Bronfman Department of Personalized Medicine, Icahn School of Medicine at Mount Sinai, New York, 10029, NY, United States; Nadkarni G.N., Division of Data-Driven and Digital Medicine, Department of Medicine, Icahn School of Medicine at Mount Sinai, New York, 10029, NY, United States, The Charles Bronfman Department of Personalized Medicine, Icahn School of Medicine at Mount Sinai, New York, 10029, NY, United States; Klang E., Division of Data-Driven and Digital Medicine, Department of Medicine, Icahn School of Medicine at Mount Sinai, New York, 10029, NY, United States, The Charles Bronfman Department of Personalized Medicine, Icahn School of Medicine at Mount Sinai, New York, 10029, NY, United States","Background: Artificial intelligence (AI) and large language models (LLMs) can play a critical role in emergency room operations by augmenting decision-making about patient admission. However, there are no studies for LLMs using real-world data and scenarios, in comparison to and being informed by traditional supervised machine learning (ML) models. We evaluated the performance of GPT-4 for predicting patient admissions from emergency department (ED) visits. We compared performance to traditional ML models both naively and when informed by few-shot examples and/or numerical probabilities. Methods: We conducted a retrospective study using electronic health records across 7 NYC hospitals. We trained Bio-Clinical-BERT and XGBoost (XGB) models on unstructured and structured data, respectively, and created an ensemble model reflecting ML performance. We then assessed GPT-4 capabilities in many scenarios: through Zero-shot, Few-shot with and without retrieval-augmented generation (RAG), and with and without ML numerical probabilities. Results: The Ensemble ML model achieved an area under the receiver operating characteristic curve (AUC) of 0.88, an area under the precision-recall curve (AUPRC) of 0.72 and an accuracy of 82.9%. The naïve GPT-4's performance (0.79 AUC, 0.48 AUPRC, and 77.5% accuracy) showed substantial improvement when given limited, relevant data to learn from (ie, RAG) and underlying ML probabilities (0.87 AUC, 0.71 AUPRC, and 83.1% accuracy). Interestingly, RAG alone boosted performance to near peak levels (0.82 AUC, 0.56 AUPRC, and 81.3% accuracy). Conclusions: The naïve LLM had limited performance but showed significant improvement in predicting ED admissions when supplemented with real-world examples to learn from, particularly through RAG, and/or numerical probabilities from traditional ML models. Its peak performance, although slightly lower than the pure ML model, is noteworthy given its potential for providing reasoning behind predictions. Further refinement of LLMs with real-world data is necessary for successful integration as decision-support tools in care settings. © 2024 The Author(s). Published by Oxford University Press on behalf of the American Medical Informatics Association. All rights reserved.","admission prediction; BERT; clinical informatics; emergency department; GPT-4; health informatics; large language models (LLMs); machine learning (ML); predictive modeling; retrieval-augmented generation (RAG); transformers","adult; aged; Article; Bio-Clinical-BERT model; clinical reasoning; comparative study; correlation coefficient; cross validation; data accuracy; electronic health record; emergency department visit; emergency ward; female; generative pretrained transformer; hospital admission; human; large language model; major clinical study; male; medical informatics; prediction; predictive model; qualitative analysis; receiver operating characteristic; retrieval augmented generation; retrospective study; sequence learning; supervised machine learning; urban health; XGBoost model","","Oxford University Press","English","Article","Final","","Scopus","2-s2.0-85201786452"
"Zhang H.; Zhang R.; Guo J.; De Rijke M.; Fan Y.; Cheng X.","Zhang, Hengran (58138377300); Zhang, Ruqing (57201357082); Guo, Jiafeng (24174196100); De Rijke, Maarten (54790525600); Fan, Yixing (57192068697); Cheng, Xueqi (55855927900)","58138377300; 57201357082; 24174196100; 54790525600; 57192068697; 55855927900","Are Large Language Models Good at Utility Judgments?","2024","SIGIR 2024 - Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval","","","","1941","1951","10","1","10.1145/3626772.3657784","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196891232&doi=10.1145%2f3626772.3657784&partnerID=40&md5=b40eb65e554e6f39506d856f5400ccf1","CAS Key Lab of Network Data Science and Technology, ICT, CAS, University of Chinese Academy of Sciences, Beijing, China; University of Amsterdam, Amsterdam, Netherlands","Zhang H., CAS Key Lab of Network Data Science and Technology, ICT, CAS, University of Chinese Academy of Sciences, Beijing, China; Zhang R., CAS Key Lab of Network Data Science and Technology, ICT, CAS, University of Chinese Academy of Sciences, Beijing, China; Guo J., CAS Key Lab of Network Data Science and Technology, ICT, CAS, University of Chinese Academy of Sciences, Beijing, China; De Rijke M., University of Amsterdam, Amsterdam, Netherlands; Fan Y., CAS Key Lab of Network Data Science and Technology, ICT, CAS, University of Chinese Academy of Sciences, Beijing, China; Cheng X., CAS Key Lab of Network Data Science and Technology, ICT, CAS, University of Chinese Academy of Sciences, Beijing, China","Retrieval-augmented generation (RAG) is considered to be a promising approach to alleviate the hallucination issue of large language models (LLMs), and it has received widespread attention from researchers recently. Due to the limitation in the semantic understanding of retrieval models, the success of RAG heavily lies on the ability of LLMs to identify passages with utility. Recent efforts have explored the ability of LLMs to assess the relevance of passages in retrieval, but there has been limited work on evaluating the utility of passages in supporting question answering. In this work, we conduct a comprehensive study about the capabilities of LLMs in utility evaluation for open-domain question answering (QA). Specifically, we introduce a benchmarking procedure and collection of candidate passages with different characteristics, facilitating a series of experiments with five representative LLMs. Our experiments reveal that: (i) well-instructed LLMs can distinguish between relevance and utility, and that LLMs are highly receptive to newly generated counterfactual passages. Moreover, (ii) we scrutinize key factors that affect utility judgments in the instruction design. And finally, (iii) to verify the efficacy of utility judgments in practical retrieval augmentation applications, we delve into LLMs' QA capabilities using the evidence judged with utility and direct dense retrieval results. (iv) We propose a k-sampling, listwise approach to reduce the dependency of LLMs on the sequence of input passages, thereby facilitating subsequent answer generation. We believe that the way we formalize and study the problem along with our findings contributes to a critical assessment of retrieval-augmented LLMs. Our code and benchmark can be found at https://github.com/ict-bigdatalab/utility_judgments. © 2024 Owner/Author.","large language models; open-domain qa; utility judgments","Computational linguistics; Natural language processing systems; Counterfactuals; Key factors; Language model; Large language model; Open domain question answering; Open-domain qa; Question Answering; Retrieval models; Semantics understanding; Utility judgment; Semantics","","Association for Computing Machinery, Inc","English","Conference paper","Final","","Scopus","2-s2.0-85196891232"
"Jearanaitanakij K.; Srithongdee C.; Ketkham S.; Ardsana O.; Kullawan T.; Yongpiyakul C.","Jearanaitanakij, Kietikul (16202862300); Srithongdee, Chananchida (59288699400); Ketkham, Sirinoot (59285146400); Ardsana, Onwanya (59285146500); Kullawan, Tiwat (59286165100); Yongpiyakul, Chankit (59288699500)","16202862300; 59288699400; 59285146400; 59285146500; 59286165100; 59288699500","Thai Question-Answering System Using Similarity Search and LLM","2024","ECTI Transactions on Computer and Information Technology","18","3","","406","416","10","0","10.37936/ecti-cit.2024183.256043","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201721475&doi=10.37936%2fecti-cit.2024183.256043&partnerID=40&md5=886dce48a759806bd9b13e7c10eb681e","Department of Computer Engineering, School of Engineering, King Mongkut's Institute of Technology Ladkrabang, Bangkok, Thailand; Dataxet Limited, Bangkok, Thailand","Jearanaitanakij K., Department of Computer Engineering, School of Engineering, King Mongkut's Institute of Technology Ladkrabang, Bangkok, Thailand; Srithongdee C., Department of Computer Engineering, School of Engineering, King Mongkut's Institute of Technology Ladkrabang, Bangkok, Thailand; Ketkham S., Department of Computer Engineering, School of Engineering, King Mongkut's Institute of Technology Ladkrabang, Bangkok, Thailand; Ardsana O., Department of Computer Engineering, School of Engineering, King Mongkut's Institute of Technology Ladkrabang, Bangkok, Thailand; Kullawan T., Dataxet Limited, Bangkok, Thailand; Yongpiyakul C., Dataxet Limited, Bangkok, Thailand","A question-answering (QA) system is essential to an organization where numerous QA pairs respond to customer queries. Choosing the right pair corresponding to the query is a complex task. Although the QA system from a commercial product like ChatGPT provides an excellent solution, it is costly, and the fine-tuned Large Language Model (LLM) cannot be downloaded for private use at the local site. In addition, the cost of using such LLM may significantly increase when the number of users grows. We propose a Thai QA system that can swiftly respond and correctly match the user query to the reference answer in the QA dataset. The proposed system encodes both QA pairs and a query into individual embeddings and finds a couple of QA pairs that are most related to the query by using the fast similarity search called Faiss (Facebook AI Similarity Search.) Afterward, the relevant QA pairs and the query are fed to the fine-tuned LLM (WangchanBERTa-pretraining multilingual transformer-based) to choose the single best match QA pair. The fine-tuned WangchanBERTa can retrieve the correct answer and respond to the query naturally. The experiment conducted on the Thai Wiki QA dataset indicates the superior ROUGE values, precision, recall, F1-score, and runtime of the proposed system against other strategies. © 2024, ECTI Association. All rights reserved.","Faiss; LSTM; mDeBERTa; Question-answering; Retrieval-Augmented Generation; Sen-tenceTransformers; WangchanBERTa","","","ECTI Association","English","Article","Final","","Scopus","2-s2.0-85201721475"
"Arslan M.; Mahdjoubi L.; Munawar S.","Arslan, Muhammad (55807840100); Mahdjoubi, Lamine (57159700300); Munawar, Saba (57201122151)","55807840100; 57159700300; 57201122151","Driving sustainable energy transitions with a multi-source RAG-LLM system","2024","Energy and Buildings","324","","114827","","","","0","10.1016/j.enbuild.2024.114827","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206092933&doi=10.1016%2fj.enbuild.2024.114827&partnerID=40&md5=78d396b5020243548e4fd9e5703704b0","Architecture and Environment, University of the West of England, Bristol, United Kingdom; Electrical (Telecommunication) Engineering, National University of Computer and Emerging Sciences (NUCES), Islamabad, Pakistan","Arslan M., Architecture and Environment, University of the West of England, Bristol, United Kingdom; Mahdjoubi L., Architecture and Environment, University of the West of England, Bristol, United Kingdom; Munawar S., Electrical (Telecommunication) Engineering, National University of Computer and Emerging Sciences (NUCES), Islamabad, Pakistan","By 2035, the UK aims to upgrade all homes to achieve a net-zero economy by 2050, thereby reducing energy consumption, household costs, and improving living conditions. Small and Medium-sized Enterprises (SMEs) play a crucial role in this transition. However, many SME contractors lack essential information on Sustainable Energy Initiatives (SEIs) and the relevant Energy landscape necessary for driving Sustainable Energy Transitions (SETs). This knowledge gap poses risks to SME interventions, potentially leading to increased costs and inefficiencies. Accessing timely information on SEIs including government policies, funding, technologies, and environmental impacts from various media sources is essential for guiding effective SETs and understanding the relevant Energy landscape, thereby facilitating informed decision-making. Currently, SMEs lack an integrated system that consolidates data from diverse media sources into a centralized Information System (IS), limiting their ability to effectively navigate SEIs. To address this gap, this research introduces an Energy Chatbot, a sustainable IS that utilizes Large Language Models (LLMs) integrated with multi-source Retrieval Augmented Generation (RAG). This system encompasses diverse media sources, including news articles, government reports, industry publications, academic research, and social media. The Energy Chatbot is designed to enhance decision-making for SMEs by providing comprehensive Energy sector insights through a Question Answering (QA) system. Key findings emphasize that this approach reduces costs by utilizing open-source models. Moreover, the Energy Chatbot provides SMEs with access to up-to-date information, enabling them to identify long-term sustainability strategies and maintain a competitive edge in the evolving Energy landscape. © 2024 The Author(s)","Data-driven operations; Information Extraction (IE); Large Language Models (LLMs); Retrieval Augmented Generation (RAG); Sustainable Development Goals (SDGs); Sustainable Energy Transitions (SETs)","Data driven; Data-driven operation; Energy transitions; Information extraction; Language model; Large language model; Retrieval augmented generation; Sustainable development goal; Sustainable energy; Sustainable energy transition","","Elsevier Ltd","English","Article","Final","","Scopus","2-s2.0-85206092933"
"Zhu X.; Dhua A.; Gray D.; Yalniz I.Z.; Yu T.; Elhoseiny M.; Plummer B.","Zhu, Xinliang (58834499300); Dhua, Arnab (16177075500); Gray, Douglas (36617378400); Yalniz, I. Zeki (35104042800); Yu, Tan (57195952255); Elhoseiny, Mohamed (55604613500); Plummer, Bryan (57189663903)","58834499300; 16177075500; 36617378400; 35104042800; 57195952255; 55604613500; 57189663903","Multimodal Representation and Retrieval [MRR 2024]","2024","SIGIR 2024 - Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval","","","","3047","3050","3","0","10.1145/3626772.3657987","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200589158&doi=10.1145%2f3626772.3657987&partnerID=40&md5=b29fb220543c7bb7f937643ddd35ebe6","Amazon, Palo Alto, CA, United States; Meta, Menlo Park, CA, United States; Nvidia, Santa Clara, CA, United States; King Abdullah University of Science and Technology, Thuwal, Saudi Arabia; Boston University, Boston, MA, United States","Zhu X., Amazon, Palo Alto, CA, United States; Dhua A., Amazon, Palo Alto, CA, United States; Gray D., Amazon, Palo Alto, CA, United States; Yalniz I.Z., Meta, Menlo Park, CA, United States; Yu T., Nvidia, Santa Clara, CA, United States; Elhoseiny M., King Abdullah University of Science and Technology, Thuwal, Saudi Arabia; Plummer B., Boston University, Boston, MA, United States","Multimodal data is available in many applications like e-commerce production listings, social media posts and short videos. However, existing algorithms dealing with those types of data still focus on uni-modal representation learning by vision-language alignment and cross-modal retrieval. In this workshop, we target to bring a new retrieval problem where both queries and documents are multimodal. With the popularity of vision language modeling, large language models (LLMs), retrieval augmented generation (RAG), and multimodal LLM, we see a lot of new opportunities for multimodal representation and retrieval tasks. This event will be a comprehensive half-day workshop focusing on the subject of multimodal representation and retrieval. The agenda includes keynote speeches, oral presentations, and an interactive panel discussion. © 2024 Owner/Author.","large language model; multimodal large language model; multimodal representation; multimodal retrieval; vision language modeling","Computational linguistics; Information retrieval; Language model; Large language model; Multi-modal; Multimodal large language model; Multimodal representation; Multimodal retrieval; Vision language modeling; Modeling languages","","Association for Computing Machinery, Inc","English","Conference paper","Final","","Scopus","2-s2.0-85200589158"
"Gilbert S.; Kather J.N.; Hogan A.","Gilbert, Stephen (16833743700); Kather, Jakob Nikolas (55550069300); Hogan, Aidan (57203013004)","16833743700; 55550069300; 57203013004","Augmented non-hallucinating large language models as medical information curators","2024","npj Digital Medicine","7","1","100","","","","6","10.1038/s41746-024-01081-0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191180518&doi=10.1038%2fs41746-024-01081-0&partnerID=40&md5=79c97a04b822871a41844f8a25f0849c","Else Kröner Fresenius Center for Digital Health, TUD Dresden University of Technology, Dresden, Germany; Department of Computer Science, Universidad de Chile, Santiago, Chile; Millennium Institute for Foundational Research on Data, DCC, Universidad de Chile, Santiago, Chile","Gilbert S., Else Kröner Fresenius Center for Digital Health, TUD Dresden University of Technology, Dresden, Germany; Kather J.N., Else Kröner Fresenius Center for Digital Health, TUD Dresden University of Technology, Dresden, Germany; Hogan A., Department of Computer Science, Universidad de Chile, Santiago, Chile, Millennium Institute for Foundational Research on Data, DCC, Universidad de Chile, Santiago, Chile","Reliably processing and interlinking medical information has been recognized as a critical foundation to the digital transformation of medical workflows, and despite the development of medical ontologies, the optimization of these has been a major bottleneck to digital medicine. The advent of large language models has brought great excitement, and maybe a solution to the medicines’ ‘communication problem’ is in sight, but how can the known weaknesses of these models, such as hallucination and non-determinism, be tempered? Retrieval Augmented Generation, particularly through knowledge graphs, is an automated approach that can deliver structured reasoning and a model of truth alongside LLMs, relevant to information structuring and therefore also to decision support. © The Author(s) 2024.","","automation; clinical decision support system; communication disorder; digital technology; human; information retrieval; knowledge base; large language model; machine learning; medical information; medical information system; Note","","Nature Research","English","Note","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85191180518"
"Liu A.; Sheng Q.; Hu X.","Liu, Aiwei (57746750500); Sheng, Qiang (57219585446); Hu, Xuming (57219742451)","57746750500; 57219585446; 57219742451","Preventing and Detecting Misinformation Generated by Large Language Models","2024","SIGIR 2024 - Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval","","","","3001","3004","3","0","10.1145/3626772.3661377","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200600676&doi=10.1145%2f3626772.3661377&partnerID=40&md5=b7c89241606fdee62862f7e28ed5d6ee","Tsinghua University, Beijing, China; Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China; The Hong Kong University of Science and Technology (Guangzhou), Beijing, China","Liu A., Tsinghua University, Beijing, China; Sheng Q., Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China; Hu X., The Hong Kong University of Science and Technology (Guangzhou), Beijing, China","As large language models (LLMs) become increasingly capable and widely deployed, the risk of them generating misinformation poses a critical challenge. Misinformation from LLMs can take various forms, from factual errors due to hallucination to intentionally deceptive content, and can have severe consequences in high-stakes domains.This tutorial covers comprehensive strategies to prevent and detect misinformation generated by LLMs. We first introduce the types of misinformation LLMs can produce and their root causes. We then explore two broad categories: Preventing misinformation generation: a) AI alignment training techniques to reduce LLMs' propensity for misinformation and refuse malicious instructions during model training. b) Training-free mitigation methods like prompt guardrails, retrieval-augmented generation (RAG), and decoding strategies to curb misinformation at inference time. Detecting misinformation after generation, including a) using LLMs themselves to detect misinformation through embedded knowledge or retrieval-enhanced judgments, and b) distinguishing LLM-generated text from human-written text through black-box approaches (e.g., classifiers, probability analysis) and white-box approaches (e.g., watermarking). We also discuss the challenges and limitations of detecting LLM-generated misinformation. © 2024 Owner/Author.","hallucination; large language models; misinformation","Critical challenges; Decoding strategy; Hallucination; Language model; Large language model; Misinformation; Mitigation methods; Model training; Root cause; Training techniques; Computational linguistics","","Association for Computing Machinery, Inc","English","Conference paper","Final","","Scopus","2-s2.0-85200600676"
"Singleton A.D.; Spielman S.","Singleton, Alex D. (25723810200); Spielman, Seth (35938922600)","25723810200; 35938922600","Segmentation using large language models: A new typology of American neighborhoods","2024","EPJ Data Science","13","1","34","","","","2","10.1140/epjds/s13688-024-00466-1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191084583&doi=10.1140%2fepjds%2fs13688-024-00466-1&partnerID=40&md5=0893f69a9950e02d5a1d16f3ee9a2313","Geographic Data Science Lab, University of Liverpool, Roxby Building, 74 Bedford St South, Liverpool, L69 7ZT, United Kingdom; Microsoft, 1650 Canyon Blvd., Boulder, 80302, CO, United States","Singleton A.D., Geographic Data Science Lab, University of Liverpool, Roxby Building, 74 Bedford St South, Liverpool, L69 7ZT, United Kingdom; Spielman S., Microsoft, 1650 Canyon Blvd., Boulder, 80302, CO, United States","In the United States, recent changes to the National Statistical System have amplified the geographic-demographic resolution trade-off. That is, when working with demographic and economic data from the American Community Survey, as one zooms in geographically one loses resolution demographically due to very large margins of error. In this paper, we present a solution to this problem in the form of an AI based open and reproducible geodemographic classification system for the United States using small area estimates from the American Community Survey (ACS). We employ a partitioning clustering algorithm to a range of socio-economic, demographic, and built environment variables. Our approach utilizes an open source software pipeline that ensures adaptability to future data updates. A key innovation is the integration of GPT4, a state-of-the-art large language model, to generate intuitive cluster descriptions and names. This represents a novel application of natural language processing in geodemographic research and showcases the potential for human-AI collaboration within the geospatial domain. © The Author(s) 2024.","American Community Survey; Artificial Intelligence (AI); Demographics; Geodemographics; Large Language Model (LLM); Neighborhoods; Retreival Augmented Generation (RAG); Segmentation","Clustering algorithms; Computational linguistics; Economic and social effects; Natural language processing systems; Open systems; Population statistics; American community survey; Artificial intelligence; Demographic; Geodemographic; Language model; Large language model; Neighbourhood; Retreival; Retreival augmented generation; Segmentation; Open source software","","Springer Science and Business Media Deutschland GmbH","English","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85191084583"
"Wu Y.; Tang B.; Xi C.; Yu Y.; Wang P.; Liu Y.; Kuang K.; Deng H.; Li Z.; Xiong F.; Hu J.; Cheng P.; Wang Z.; Wang Y.; Luo Y.; Yang M.","Wu, Yiquan (57322291700); Tang, Bo (57641537100); Xi, Chenyang (59181341200); Yu, Yu (57208509104); Wang, Pengyu (58954106600); Liu, Yifei (58023359700); Kuang, Kun (57193524618); Deng, Haiying (58749876400); Li, Zhiyu (57208229542); Xiong, Feiyu (57217171492); Hu, Jie (57226187628); Cheng, Peng (58748956500); Wang, Zhonghao (58532355900); Wang, Yi (59324398200); Luo, Yi (55712632200); Yang, Mingchuan (56171908800)","57322291700; 57641537100; 59181341200; 57208509104; 58954106600; 58023359700; 57193524618; 58749876400; 57208229542; 57217171492; 57226187628; 58748956500; 58532355900; 59324398200; 55712632200; 56171908800","Xinyu: An Efficient LLM-based System for Commentary Generation","2024","Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining","","","","6003","6014","11","0","10.1145/3637528.3671537","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203689039&doi=10.1145%2f3637528.3671537&partnerID=40&md5=d771d1dba572f7c6808d57d4328bb397","Zhejiang University, Hangzhou, China; Institute for Advanced Algorithms Research, Shanghai, China; Northeastern University, Shenyang, China; State Key Laboratory of Media Convergence Production Technology and Systems, Beijing, China","Wu Y., Zhejiang University, Hangzhou, China; Tang B., Institute for Advanced Algorithms Research, Shanghai, China; Xi C., Institute for Advanced Algorithms Research, Shanghai, China; Yu Y., Institute for Advanced Algorithms Research, Shanghai, China; Wang P., Northeastern University, Shenyang, China; Liu Y., Zhejiang University, Hangzhou, China; Kuang K., Zhejiang University, Hangzhou, China; Deng H., Northeastern University, Shenyang, China; Li Z., Institute for Advanced Algorithms Research, Shanghai, China; Xiong F., Institute for Advanced Algorithms Research, Shanghai, China; Hu J., State Key Laboratory of Media Convergence Production Technology and Systems, Beijing, China; Cheng P., Northeastern University, Shenyang, China; Wang Z., Northeastern University, Shenyang, China; Wang Y., Northeastern University, Shenyang, China; Luo Y., Northeastern University, Shenyang, China; Yang M., State Key Laboratory of Media Convergence Production Technology and Systems, Beijing, China","Commentary provides readers with a deep understanding of events by presenting diverse arguments and evidence. However, creating commentary is a time-consuming task, even for skilled commentators. Large language models (LLMs) have simplified the process of natural language generation, but their direct application in commentary creation still faces challenges due to unique task requirements. These requirements can be categorized into two levels: 1) fundamental requirements, which include creating well-structured and logically consistent narratives, and 2) advanced requirements, which involve generating quality arguments and providing convincing evidence. In this paper, we introduce Xinyu, an efficient LLM-based system designed to assist commentators in generating Chinese commentaries. To meet the fundamental requirements, we deconstruct the generation process into sequential steps, proposing targeted strategies and supervised fine-tuning (SFT) for each step. To address the advanced requirements, we present an argument ranking model for arguments and establish a comprehensive evidence database that includes up-to-date events and classic books, thereby strengthening the substantiation of the evidence with retrieval augmented generation (RAG) technology. To evaluate the generated commentaries more fairly, corresponding to the two-level requirements, we introduce a comprehensive evaluation metric that considers five distinct perspectives in commentary generation. Our experiments confirm the effectiveness of our proposed system. We also observe a significant increase in the efficiency of commentators in real-world scenarios, with the average time spent on creating a commentary dropping from 4 hours to 20 minutes. Importantly, such an increase in efficiency does not compromise the quality of the commentaries.  © 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.","commentary generation; llm-based system; retrieval augmented generation; supervised fine-tuning","Distributed computer systems; Structured Query Language; Commentary generation; Fine tuning; Language model; Level-1; Llm-based system; Model-based systems; Natural language generation; Retrieval augmented generation; Supervised fine-tuning; Time-consuming tasks; Search engines","","Association for Computing Machinery","English","Conference paper","Final","","Scopus","2-s2.0-85203689039"
"Salemi A.; Zamani H.","Salemi, Alireza (57223748391); Zamani, Hamed (56342230300)","57223748391; 56342230300","Towards a Search Engine for Machines: Unified Ranking for Multiple Retrieval-Augmented Large Language Models","2024","SIGIR 2024 - Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval","","","","741","751","10","0","10.1145/3626772.3657733","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200550925&doi=10.1145%2f3626772.3657733&partnerID=40&md5=58b383de7ec7f64524aa9a3989ff2158","University of Massachusetts Amherst, Amherst, MA, United States","Salemi A., University of Massachusetts Amherst, Amherst, MA, United States; Zamani H., University of Massachusetts Amherst, Amherst, MA, United States","This paper introduces uRAG-a framework with a unified retrieval engine that serves multiple downstream retrieval-augmented generation (RAG) systems. Each RAG system consumes the retrieval results for a unique purpose, such as open-domain question answering, fact verification, entity linking, and relation extraction. We introduce a generic training guideline that standardizes the communication between the search engine and the downstream RAG systems that engage in optimizing the retrieval model. This lays the groundwork for us to build a large-scale experimentation ecosystem consisting of 18 RAG systems that engage in training and 18 unknown RAG systems that use the uRAG as the new users of the search engine. Using this experimentation ecosystem, we answer a number of fundamental research questions that improve our understanding of promises and challenges in developing search engines for machines. © 2024 Owner/Author.","large language model; neural ranking model; retrieval augmentation; retrieval-enhanced machine learning; text generation","Computational linguistics; Ecosystems; Information retrieval; Machine learning; Down-stream; Generation systems; Language model; Large language model; Machine-learning; Neural ranking model; Ranking model; Retrieval augmentation; Retrieval-enhanced machine learning; Text generations; Search engines","","Association for Computing Machinery, Inc","English","Conference paper","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85200550925"
"Papageorgiou G.; Sarlis V.; Maragoudakis M.; Tjortjis C.","Papageorgiou, George (58636043300); Sarlis, Vangelis (57216916600); Maragoudakis, Manolis (56209990000); Tjortjis, Christos (6505849477)","58636043300; 57216916600; 56209990000; 6505849477","Enhancing E-Government Services through State-of-the-Art, Modular, and Reproducible Architecture over Large Language Models","2024","Applied Sciences (Switzerland)","14","18","8259","","","","0","10.3390/app14188259","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205274057&doi=10.3390%2fapp14188259&partnerID=40&md5=82070cdbc607480c7b578aedf2ce6cf9","School of Science and Technology, International Hellenic University, Thessaloniki, 57001, Greece; Department of Informatics, Ionian University, Corfu, 49100, Greece","Papageorgiou G., School of Science and Technology, International Hellenic University, Thessaloniki, 57001, Greece; Sarlis V., School of Science and Technology, International Hellenic University, Thessaloniki, 57001, Greece; Maragoudakis M., Department of Informatics, Ionian University, Corfu, 49100, Greece; Tjortjis C., School of Science and Technology, International Hellenic University, Thessaloniki, 57001, Greece","Integrating Large Language Models (LLMs) into e-government applications has the potential to improve public service delivery through advanced data processing and automation. This paper explores critical aspects of a modular and reproducible architecture based on Retrieval-Augmented Generation (RAG) for deploying LLM-based assistants within e-government systems. By examining current practices and challenges, we propose a framework ensuring that Artificial Intelligence (AI) systems are modular and reproducible, essential for maintaining scalability, transparency, and ethical standards. Our approach utilizing Haystack demonstrates a complete multi-agent Generative AI (GAI) virtual assistant that facilitates scalability and reproducibility by allowing individual components to be independently scaled. This research focuses on a comprehensive review of the existing literature and presents case study examples to demonstrate how such an architecture can enhance public service operations. This framework provides a valuable case study for researchers, policymakers, and practitioners interested in exploring the integration of advanced computational linguistics and LLMs into e-government services, although it could benefit from further empirical validation. © 2024 by the authors.","AI Governance; e-government; generative artificial intelligence (GAI); large language models (LLMs); modularity; reproducibility; retrieval-augmented generation (RAG)","e-government; Multi agent systems; Artificial intelligence governance; e-Government; E-government services; Generative artificial intelligence; Language model; Large language model; Modularity; Modulars; Reproducibilities; Retrieval-augmented generation; Scalability","","Multidisciplinary Digital Publishing Institute (MDPI)","English","Article","Final","","Scopus","2-s2.0-85205274057"
"Sun Z.; Feng K.; Yang J.; Qu X.; Fang H.; Ong Y.-S.; Liu W.","Sun, Zhu (57441614900); Feng, Kaidong (57821864300); Yang, Jie (56370016500); Qu, Xinghua (57190405716); Fang, Hui (55265379000); Ong, Yew-Soon (7006735298); Liu, Wenyuan (36072032200)","57441614900; 57821864300; 56370016500; 57190405716; 55265379000; 7006735298; 36072032200","Adaptive In-Context Learning with Large Language Models for Bundle Generation","2024","SIGIR 2024 - Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval","","","","966","976","10","0","10.1145/3626772.3657808","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200543793&doi=10.1145%2f3626772.3657808&partnerID=40&md5=e990428e8b77217f8a79c9967e2ed8cb","A*STAR Centre for Frontier AI Research, Singapore University of Technology and Design, Singapore, Singapore; Yanshan University, Qinhuangdao, China; Delft University of Technology, Delft, Netherlands; Shanda AI-Lab & Tianqiao and Chrissy Chen Institute, Singapore, Singapore; Shanghai University of Finance and Economics, Shanghai, China","Sun Z., A*STAR Centre for Frontier AI Research, Singapore University of Technology and Design, Singapore, Singapore; Feng K., Yanshan University, Qinhuangdao, China; Yang J., Delft University of Technology, Delft, Netherlands; Qu X., Shanda AI-Lab & Tianqiao and Chrissy Chen Institute, Singapore, Singapore; Fang H., Shanghai University of Finance and Economics, Shanghai, China; Ong Y.-S., A*STAR Centre for Frontier AI Research, Singapore University of Technology and Design, Singapore, Singapore; Liu W., Yanshan University, Qinhuangdao, China","Most existing bundle generation approaches fall short in generating fixed-size bundles. Furthermore, they often neglect the underlying user intents reflected by the bundles in the generation process, resulting in less intelligible bundles. This paper addresses these limitations through the exploration of two interrelated tasks, i.e., personalized bundle generation and the underlying intent inference, based on different user sessions. Inspired by the reasoning capabilities of large language models (LLMs), we propose an adaptive in-context learning paradigm, which allows LLMs to draw tailored lessons from related sessions as demonstrations, enhancing the performance on target sessions. Specifically, we first employ retrieval augmented generation to identify nearest neighbor sessions, and then carefully design prompts to guide LLMs in executing both tasks on these neighbor sessions. To tackle reliability and hallucination challenges, we further introduce (1) a self-correction strategy promoting mutual improvements of the two tasks without supervision signals and (2) an auto-feedback mechanism for adaptive supervision based on the distinct mistakes made by LLMs on different neighbor sessions. Thereby, the target session can gain customized lessons for improved performance by observing the demonstrations of its neighbor sessions. Experiments on three real-world datasets demonstrate the effectiveness of our proposed method. © 2024 ACM.","bundle generation; in-context learning; large language models; recommendation; user intent inference","Computational linguistics; Bundle generation; Context learning; In contexts; In-context learning; Intent inference; Language model; Large language model; Performance; Recommendation; User intent inference; Learning systems","","Association for Computing Machinery, Inc","English","Conference paper","Final","","Scopus","2-s2.0-85200543793"
"Soong D.; Sridhar S.; Si H.; Wagner J.-S.; Sá A.C.C.; Yu C.Y.; Karagoz K.; Guan M.; Kumar S.; Hamadeh H.; Higgs B.W.","Soong, David (58822728100); Sridhar, Sriram (58343100600); Si, Han (58343755600); Wagner, Jan-Samuel (58345039200); Sá, Ana Caroline Costa (58341134500); Yu, Christina Y. (58345683200); Karagoz, Kubra (58342450700); Guan, Meijian (58343100700); Kumar, Sanyam (59295863500); Hamadeh, Hisham (7004287729); Higgs, Brandon W. (36926952100)","58822728100; 58343100600; 58343755600; 58345039200; 58341134500; 58345683200; 58342450700; 58343100700; 59295863500; 7004287729; 36926952100","Improving accuracy of GPT-3/4 results on biomedical data using a retrieval-augmented language model","2024","PLOS Digital Health","3","8","e0000568","","","","0","10.1371/journal.pdig.0000568","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201891306&doi=10.1371%2fjournal.pdig.0000568&partnerID=40&md5=dcf3faf68764b7f318e46afcd12309b9","Translational Data Sciences, Genmab, Princeton, NJ, United States; Data Sciences and AI, Genmab, Princeton, NJ, United States; Commercial Data Sciences, Genmab, Princeton, NJ, United States","Soong D., Translational Data Sciences, Genmab, Princeton, NJ, United States; Sridhar S., Translational Data Sciences, Genmab, Princeton, NJ, United States; Si H., Translational Data Sciences, Genmab, Princeton, NJ, United States; Wagner J.-S., Data Sciences and AI, Genmab, Princeton, NJ, United States; Sá A.C.C., Translational Data Sciences, Genmab, Princeton, NJ, United States; Yu C.Y., Translational Data Sciences, Genmab, Princeton, NJ, United States; Karagoz K., Translational Data Sciences, Genmab, Princeton, NJ, United States; Guan M., Translational Data Sciences, Genmab, Princeton, NJ, United States; Kumar S., Commercial Data Sciences, Genmab, Princeton, NJ, United States; Hamadeh H., Data Sciences and AI, Genmab, Princeton, NJ, United States; Higgs B.W., Translational Data Sciences, Genmab, Princeton, NJ, United States","Large language models (LLMs) have made a significant impact on the fields of general artificial intelligence. General purpose LLMs exhibit strong logic and reasoning skills and general world knowledge but can sometimes generate misleading results when prompted on specific subject areas. LLMs trained with domain-specific knowledge can reduce the generation of misleading information (i.e. hallucinations) and enhance the precision of LLMs in specialized contexts. Training new LLMs on specific corpora however can be resource intensive. Here we explored the use of a retrieval-augmented generation (RAG) model which we tested on literature specific to a biomedical research area. OpenAI’s GPT-3.5, GPT-4, Microsoft’s Prometheus, and a custom RAG model were used to answer 19 questions pertaining to diffuse large B-cell lymphoma (DLBCL) disease biology and treatment. Eight independent reviewers assessed LLM responses based on accuracy, relevance, and readability, rating responses on a 3-point scale for each category. These scores were then used to compare LLM performance. The performance of the LLMs varied across scoring categories. On accuracy and relevance, the RAG model outperformed other models with higher scores on average and the most top scores across questions. GPT-4 was more comparable to the RAG model on relevance versus accuracy. By the same measures, GPT-4 and GPT-3.5 had the highest scores for readability of answers when compared to the other LLMs. GPT-4 and 3.5 also had more answers with hallucinations than the other LLMs, due to non-existent references and inaccurate responses to clinical questions. Our findings suggest that an oncology research-focused RAG model may outperform general-purpose LLMs in accuracy and relevance when answering subject-related questions. This framework can be tailored to Q&A in other subject areas. Further research will help understand the impact of LLM architectures, RAG methodologies, and prompting techniques in answering questions across different subject areas. © 2024 Soong et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.","","","","Public Library of Science","English","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85201891306"
"Wysocka M.; Wysocki O.; Delmas M.; Mutel V.; Freitas A.","Wysocka, Magdalena (57201570923); Wysocki, Oskar (57204597866); Delmas, Maxime (57222311959); Mutel, Vincent (7003820145); Freitas, André (36631806600)","57201570923; 57204597866; 57222311959; 7003820145; 36631806600","Large Language Models, scientific knowledge and factuality: A framework to streamline human expert evaluation","2024","Journal of Biomedical Informatics","158","","104724","","","","0","10.1016/j.jbi.2024.104724","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204180438&doi=10.1016%2fj.jbi.2024.104724&partnerID=40&md5=09756764e50423151d306bfa7af1341d","Digital Cancer Research, CRUK National Biomarker Centre, Manchester, United Kingdom; Department of Computer Science, University of Manchester, Manchester, United Kingdom; Idiap Research Institute, Martigny, Switzerland; Inflamalps SA, Monthey, Switzerland","Wysocka M., Digital Cancer Research, CRUK National Biomarker Centre, Manchester, United Kingdom, Department of Computer Science, University of Manchester, Manchester, United Kingdom; Wysocki O., Digital Cancer Research, CRUK National Biomarker Centre, Manchester, United Kingdom, Idiap Research Institute, Martigny, Switzerland; Delmas M., Idiap Research Institute, Martigny, Switzerland; Mutel V., Inflamalps SA, Monthey, Switzerland; Freitas A., Digital Cancer Research, CRUK National Biomarker Centre, Manchester, United Kingdom, Department of Computer Science, University of Manchester, Manchester, United Kingdom, Idiap Research Institute, Martigny, Switzerland","Objective: The paper introduces a framework for the evaluation of the encoding of factual scientific knowledge, designed to streamline the manual evaluation process typically conducted by domain experts. Inferring over and extracting information from Large Language Models (LLMs) trained on a large corpus of scientific literature can potentially define a step change in biomedical discovery, reducing the barriers for accessing and integrating existing medical evidence. This work explores the potential of LLMs for dialoguing with biomedical background knowledge, using the context of antibiotic discovery. Methods: The framework involves three evaluation steps, each assessing different aspects sequentially: fluency, prompt alignment, semantic coherence, factual knowledge, and specificity of the generated responses. By splitting these tasks between non-experts and experts, the framework reduces the effort required from the latter. The work provides a systematic assessment on the ability of eleven state-of-the-art LLMs, including ChatGPT, GPT-4 and Llama 2, in two prompting-based tasks: chemical compound definition generation and chemical compound–fungus relation determination. Results: Although recent models have improved in fluency, factual accuracy is still low and models are biased towards over-represented entities. The ability of LLMs to serve as biomedical knowledge bases is questioned, and the need for additional systematic evaluation frameworks is highlighted. Conclusion: While LLMs are currently not fit for purpose to be used as biomedical factual knowledge bases in a zero-shot setting, there is a promising emerging property in the direction of factuality as the models become domain specialised, scale up in size and level of human feedback. © 2024 The Author(s)","Antibiotic discovery; Factual knowledge; Large language models; Retrieval-augmented generation","Anti-Bacterial Agents; Humans; Natural Language Processing; Semantics; chemical compound; antiinfective agent; Antibiotic discovery; Domain experts; Encodings; Expert evaluation; Factual knowledge; Human expert; Language model; Large language model; Retrieval-augmented generation; Scientific knowledge; accuracy; Article; Aspergillus fumigatus; ChatGPT; human; information retrieval; knowledge; knowledge base; large language model; nonhuman; reliability; scale up; semantics; sensitivity and specificity; natural language processing; Semantics","","Academic Press Inc.","English","Article","Final","","Scopus","2-s2.0-85204180438"
"Askarbekuly N.; Aničić N.","Askarbekuly, Nursultan (57216863408); Aničić, Nenad (15847585900)","57216863408; 15847585900","LLM examiner: automating assessment in informal self-directed e-learning using ChatGPT","2024","Knowledge and Information Systems","66","10","","6133","6150","17","0","10.1007/s10115-024-02156-w","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195569900&doi=10.1007%2fs10115-024-02156-w&partnerID=40&md5=cd60aacdb29b99a91ee34eca194b464a","Faculty of Computer Science and Engineering, Innopolis University, Innopolis, Russian Federation; Faculty of Organizational Sciences, The University of Belgrade, Belgrade, Serbia","Askarbekuly N., Faculty of Computer Science and Engineering, Innopolis University, Innopolis, Russian Federation, Faculty of Organizational Sciences, The University of Belgrade, Belgrade, Serbia; Aničić N., Faculty of Organizational Sciences, The University of Belgrade, Belgrade, Serbia","Informal e-learning systems often lack structured assessment mechanisms, making it difficult to assess the learning outcomes. This work aims to automate outcome-based assessment through the use of a large language AI model, in particular ChatGPT. Such automation can be of value to educators and developers of educational software, as it tackles the non-trivial task of evaluating educational trajectories from the outcome-based perspective. To achieve this aim, we proposed a system and validated it through a case study and two evaluation stages. In the first stage, we generated 40 assessment questions of various types, 12 of which were approved as high quality. In the second stage, we generated another 45 questions and conducted 5 individual peer evaluation sessions. The most significant automation aspects in guaranteeing the assessment quality were found to be the instructor involvement to monitor the process, the use of a high quality custom knowledge base, and formulation of the correct prompt instructions on the basis of the learning outcome statements. © The Author(s), under exclusive licence to Springer-Verlag London Ltd., part of Springer Nature 2024.","Assessment; Educational technology; Informal e-learning; Large language models; Learning outcomes; Retrieval-augmented generation","E-learning; Learning systems; Assessment; E - learning; E-learning systems; High quality; Informal e-learning; Language model; Large language model; Learning outcome; Retrieval-augmented generation; Self-directed; Knowledge based systems","","Springer Science and Business Media Deutschland GmbH","English","Article","Final","","Scopus","2-s2.0-85195569900"
"Stankevičius L.; Lukoševičius M.","Stankevičius, Lukas (57189462187); Lukoševičius, Mantas (16432444400)","57189462187; 16432444400","Extracting Sentence Embeddings from Pretrained Transformer Models","2024","Applied Sciences (Switzerland)","14","19","8887","","","","0","10.3390/app14198887","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206330250&doi=10.3390%2fapp14198887&partnerID=40&md5=aeefee05c6e7a9440619e8e9c72b2e98","Faculty of Informatics, Kaunas University of Technology, Kaunas, LT-51368, Lithuania","Stankevičius L., Faculty of Informatics, Kaunas University of Technology, Kaunas, LT-51368, Lithuania; Lukoševičius M., Faculty of Informatics, Kaunas University of Technology, Kaunas, LT-51368, Lithuania","Pre-trained transformer models shine in many natural language processing tasks and therefore are expected to bear the representation of the input sentence or text meaning. These sentence-level embeddings are also important in retrieval-augmented generation. But do commonly used plain averaging or prompt templates sufficiently capture and represent the underlying meaning? After providing a comprehensive review of existing sentence embedding extraction and refinement methods, we thoroughly test different combinations and our original extensions of the most promising ones on pretrained models. Namely, given 110 M parameters, BERT’s hidden representations from multiple layers, and many tokens, we try diverse ways to extract optimal sentence embeddings. We test various token aggregation and representation post-processing techniques. We also test multiple ways of using a general Wikitext dataset to complement BERT’s sentence embeddings. All methods are tested on eight Semantic Textual Similarity (STS), six short text clustering, and twelve classification tasks. We also evaluate our representation-shaping techniques on other static models, including random token representations. Proposed representation extraction methods improve the performance on STS and clustering tasks for all models considered. Very high improvements for static token-based models, especially random embeddings for STS tasks, almost reach the performance of BERT-derived representations. Our work shows that the representation-shaping techniques significantly improve sentence embeddings extracted from BERT-based and simple baseline models. © 2024 by the authors.","BERT; embeddings; large language models; natural language processing; prompt engineering; semantic similarity; sentence vector representation; text embeddings; transformer models; unsupervised learning","Embeddings; Natural language processing systems; Unsupervised learning; BERT; Embeddings; Language model; Language processing; Large language model; Natural language processing; Natural languages; Prompt engineering; Semantic similarity; Sentence vector representation; Text embedding; Transformer modeling; Vector representations; Semantics","","Multidisciplinary Digital Publishing Institute (MDPI)","English","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85206330250"
"Cuconasu F.; Trappolini G.; Siciliano F.; Filice S.; Campagnano C.; Maarek Y.; Tonellotto N.; Silvestri F.","Cuconasu, Florin (58540430900); Trappolini, Giovanni (57219766943); Siciliano, Federico (57251083200); Filice, Simone (55096124500); Campagnano, Cesare (57223725222); Maarek, Yoelle (55903308800); Tonellotto, Nicola (8964950100); Silvestri, Fabrizio (8964950200)","58540430900; 57219766943; 57251083200; 55096124500; 57223725222; 55903308800; 8964950100; 8964950200","The Power of Noise: Redefining Retrieval for RAG Systems","2024","SIGIR 2024 - Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval","","","","719","729","10","0","10.1145/3626772.3657834","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200546708&doi=10.1145%2f3626772.3657834&partnerID=40&md5=58eeae3de6cdc120c3abf444631bc54f","Sapienza University of Rome, Rome, Italy; Technology Innovation Institute, Haifa, Israel; University of Pisa, Pisa, Italy","Cuconasu F., Sapienza University of Rome, Rome, Italy; Trappolini G., Sapienza University of Rome, Rome, Italy; Siciliano F., Sapienza University of Rome, Rome, Italy; Filice S., Technology Innovation Institute, Haifa, Israel; Campagnano C., Sapienza University of Rome, Rome, Italy; Maarek Y., Technology Innovation Institute, Haifa, Israel; Tonellotto N., University of Pisa, Pisa, Italy; Silvestri F., Sapienza University of Rome, Rome, Italy","Retrieval-Augmented Generation (RAG) has recently emerged as a method to extend beyond the pre-trained knowledge of Large Language Models by augmenting the original prompt with relevant passages or documents retrieved by an Information Retrieval (IR) system. RAG has become increasingly important for Generative AI solutions, especially in enterprise settings or in any domain in which knowledge is constantly refreshed and cannot be memorized in the LLM. We argue here that the retrieval component of RAG systems, be it dense or sparse, deserves increased attention from the research community, and accordingly, we conduct the first comprehensive and systematic examination of the retrieval strategy of RAG systems. We focus, in particular, on the type of passages IR systems within a RAG solution should retrieve. Our analysis considers multiple factors, such as the relevance of the passages included in the prompt context, their position, and their number. One counter-intuitive finding of this work is that the retriever's highest-scoring documents that are not directly relevant to the query (e.g., do not contain the answer) negatively impact the effectiveness of the LLM. Even more surprising, we discovered that adding random documents in the prompt improves the LLM accuracy by up to 35%. These results highlight the need to investigate the appropriate strategies when integrating retrieval with LLMs, thereby laying the groundwork for future research in this area. © 2024 Owner/Author.","information retrieval; llm; rag","Query processing; Search engines; Generation systems; Information-retrieval systems; Language model; Llm; Multiple factors; Power; Rag; Research communities; Retrieval strategies; Information retrieval","","Association for Computing Machinery, Inc","English","Conference paper","Final","","Scopus","2-s2.0-85200546708"
"Xu K.; Zhang G.L.; Yin X.; Zhuo C.; Schlichtmann U.; Li B.","Xu, Kangwei (57457280000); Zhang, Grace Li (57189644383); Yin, Xunzhao (57189500865); Zhuo, Cheng (17436666200); Schlichtmann, Ulf (6603456416); Li, Bing (58539269600)","57457280000; 57189644383; 57189500865; 17436666200; 6603456416; 58539269600","Automated C/C++ Program Repair for High-Level Synthesis via Large Language Models","2024","MLCAD 2024 - Proceedings of the 2024 ACM/IEEE International Symposium on Machine Learning for CAD","","","15","","","","0","10.1145/3670474.3685953","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204985066&doi=10.1145%2f3670474.3685953&partnerID=40&md5=fa65e785d803ad636cf8d21fc5c6259e","Technical University of Munich (TUM), Munich, Germany; Hardware for Artificial Intelligence Group, Technical University of Darmstadt, Darmstadt, Germany; College of Information Science and Electronic Engineering, Zhejiang University, Hangzhou, China; Research Group of Digital Integrated Systems, University of Siegen, Siegen, Germany","Xu K., Technical University of Munich (TUM), Munich, Germany; Zhang G.L., Hardware for Artificial Intelligence Group, Technical University of Darmstadt, Darmstadt, Germany; Yin X., College of Information Science and Electronic Engineering, Zhejiang University, Hangzhou, China; Zhuo C., College of Information Science and Electronic Engineering, Zhejiang University, Hangzhou, China; Schlichtmann U., Technical University of Munich (TUM), Munich, Germany; Li B., Research Group of Digital Integrated Systems, University of Siegen, Siegen, Germany","In High-Level Synthesis (HLS), converting a regular C/C++ program into its HLS-compatible counterpart (HLS-C) still requires tremendous manual effort. Various program scripts have been introduced to automate this process. But the resulting codes usually contain many issues that should be manually repaired by developers. Since Large Language Models (LLMs) have the ability to automate code generation, they can also be used for automated program repair in HLS. However, due to the limited training of LLMs considering hardware and software simultaneously, hallucinations may occur during program repair using LLMs, leading to compilation failures. Besides, using LLMs for iterative repair also incurs a high cost. To address these challenges, we propose an LLM-driven program repair framework that takes regular C/C++ code as input and automatically generates its corresponding HLS-C code for synthesis while minimizing human repair effort. To mitigate the hallucinations in LLMs and enhance the prompt quality, a Retrieval-Augmented Generation (RAG) paradigm is introduced to guide the LLMs toward correct repair. In addition, we use LLMs to create a static bit width optimization program to identify the optimized bit widths for variables. Moreover, LLM-driven HLS optimization strategies are introduced to add/tune pragmas in HLS-C programs for circuit optimization. Experimental results demonstrate that the proposed LLM-driven automated framework can achieve much higher repair pass rates in 24 real-world applications compared with the traditional scripts and the direct application of LLMs for program repair. The codes are open-sourced at this link: https://github.com/code-source1/catapult. © 2024 Owner/Author.","","Application programs; Automatic programming; C++ (programming language); Computer software selection and evaluation; Open source software; Problem oriented languages; Systems analysis; Bit-width optimizations; C++ codes; C/C++ programs; Codegeneration; Hardware and software; High costs; High-level synthesis; Language model; Model-driven; Optimization project; High level synthesis","","Association for Computing Machinery, Inc","English","Conference paper","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85204985066"
"Ascorbe P.; Campos M.S.; Domínguez C.; Heras J.; Pérez M.; Terroba-Reinares A.R.","Ascorbe, Pablo (58690439100); Campos, María S. (36086139200); Domínguez, César (36185069000); Heras, Jónathan (7005455102); Pérez, Magdalena (59198510300); Terroba-Reinares, Ana Rosa (58020863300)","58690439100; 36086139200; 36185069000; 7005455102; 59198510300; 58020863300","Automatic and Manual Evaluation of a Spanish Suicide Information Chatbot; [Evaluación automática y manual de un chatbot para proporcionar información sobre suicidio en castellano]","2024","Procesamiento del Lenguaje Natural","","73","","151","164","13","0","10.26342/2024-73-11","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206528473&doi=10.26342%2f2024-73-11&partnerID=40&md5=3ff42ba39491bc80270a1076c9cdfceb","Universidad de La Rioja, La Rioja, Logroño, Spain; Unidad de Salud Mental Espartero, La Rioja, Logroño, Spain; Teléfono de la Esperanza; Fundación Rioja Salud, Spain","Ascorbe P., Universidad de La Rioja, La Rioja, Logroño, Spain; Campos M.S., Unidad de Salud Mental Espartero, La Rioja, Logroño, Spain; Domínguez C., Universidad de La Rioja, La Rioja, Logroño, Spain; Heras J., Universidad de La Rioja, La Rioja, Logroño, Spain; Pérez M., Teléfono de la Esperanza; Terroba-Reinares A.R., Universidad de La Rioja, La Rioja, Logroño, Spain, Fundación Rioja Salud, Spain","Chatbots have a great potential in sensitive fields like mental health; however, a careful evaluation, either by manual or automatic methods is a must to ensure the reliability of these systems. In this work, a library for automatically evaluating Spanish Retrieval Augmented Generation (RAG) chatbots using Large Language Models (LLMs) is presented. Then, a thorough analysis of several LLMs candidates to be used in a RAG system which provides suicide prevention information is conducted. Towards that aim, we use a manual evaluation, an automatic evaluation based on metrics, and an automatic evaluation based on LLMs. All evaluation methods agree on a preferred model, but they exhibit subtle differences. Automatic methods may overlook unsafe answers; the automatic methods based on metrics are correlated on precision and completeness with human evaluation but not on faithfulness; and some automatic methods based on LLMs do not detect some errors. As a general conclusion, even if automatic methods can reduce manual evaluation efforts, manual evaluation remains essential, particularly in sensitive contexts like those related to mental health. © 2024 Sociedad Española para el Procesamiento del Lenguaje Natural.","Chatbot; Evaluation; Retrieval Augmented Generation; Suicide","","","Sociedad Espanola para el Procesamiento del Lenguaje Natural","English","Article","Final","","Scopus","2-s2.0-85206528473"
"Hu Q.; Li H.; Bai J.; Wang Z.; Song Y.","Hu, Qi (58558606200); Li, Haoran (56023457100); Bai, Jiaxin (57211989884); Wang, Zihao (57202647584); Song, Yangqiu (59140403600)","58558606200; 56023457100; 57211989884; 57202647584; 59140403600","Privacy-Preserved Neural Graph Databases","2024","Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining","","","","1108","1118","10","0","10.1145/3637528.3671678","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203717627&doi=10.1145%2f3637528.3671678&partnerID=40&md5=e1389fbd76b5f8550448c59ad07b38d3","Department of CSE, Hong Kong University of Science and Technology, Hong Kong","Hu Q., Department of CSE, Hong Kong University of Science and Technology, Hong Kong; Li H., Department of CSE, Hong Kong University of Science and Technology, Hong Kong; Bai J., Department of CSE, Hong Kong University of Science and Technology, Hong Kong; Wang Z., Department of CSE, Hong Kong University of Science and Technology, Hong Kong; Song Y., Department of CSE, Hong Kong University of Science and Technology, Hong Kong","In the era of large language models (LLMs), efficient and accurate data retrieval has become increasingly crucial for the use of domain-specific or private data in the retrieval augmented generation (RAG). Neural graph databases (NGDBs) have emerged as a powerful paradigm that combines the strengths of graph databases (GDBs) and neural networks to enable efficient storage, retrieval, and analysis of graph-structured data which can be adaptively trained with LLMs. The usage of neural embedding storage and Complex neural logical Query Answering (CQA) provides NGDBs with generalization ability. When the graph is incomplete, by extracting latent patterns and representations, neural graph databases can fill gaps in the graph structure, revealing hidden relationships and enabling accurate query answering. Nevertheless, this capability comes with inherent trade-offs, as it introduces additional privacy risks to the domain-specific or private databases. Malicious attackers can infer more sensitive information in the database using well-designed queries such as from the answer sets of where Turing Award winners born before 1950 and after 1940 lived, the living places of Turing Award winner Hinton are probably exposed, although the living places may have been deleted in the training stage due to the privacy concerns. In this work, we propose a privacy-preserved neural graph database (P-NGDB) framework to alleviate the risks of privacy leakage in NGDBs. We introduce adversarial training techniques in the training stage to enforce the NGDBs to generate indistinguishable answers when queried with private information, enhancing the difficulty of inferring sensitive information through combinations of multiple innocuous queries. Extensive experimental results on three datasets show that our framework can effectively protect private information in the graph database while delivering high-quality public answers responses to queries. The code is available at https://github.com/HKUST-KnowComp/PrivateNGDB.  © 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.","complex query answering (cqa); knowledge graphs (kgs); neural graph databases (ngdbs); privacy preserving","Database systems; Graph neural networks; Information leakage; Question answering; Structured Query Language; Complex queries; Complex query answering; Domain specific; Graph database; Knowledge graph; Knowledge graphs; Language model; Neural graph database; Privacy preserving; Query answering; Differential privacy","","Association for Computing Machinery","English","Conference paper","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85203717627"
"Varaliya M.; Kanojia M.; Nabajja S.","Varaliya, Mohammed (59299939400); Kanojia, Mahendra (57194405749); Nabajja, Subhashish (59251183200)","59299939400; 57194405749; 59251183200","Optimizing Automated Conversational Large Language Models for Higher Educational Institution","2024","International Journal of Computer Information Systems and Industrial Management Applications","16","3","","596","612","16","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202163432&partnerID=40&md5=b61d8c4672ee203a53d68e503724a24a","Sheth L.U.J and Sir M.V. College, Maharashtra, Mumbai, 400069, India","Varaliya M., Sheth L.U.J and Sir M.V. College, Maharashtra, Mumbai, 400069, India; Kanojia M., Sheth L.U.J and Sir M.V. College, Maharashtra, Mumbai, 400069, India; Nabajja S., Sheth L.U.J and Sir M.V. College, Maharashtra, Mumbai, 400069, India","Higher education institutions need to improve their query systems in order to improve communication, response times, and information access. This study investigates a novel method of combining large language models (LLMs) with knowledge bases created especially for higher education institutions in order to meet this critical requirement. We adhered with all higher education institution regulations and gathered data in both structured and unstructured formats from Sheth L. U. J. College of Arts and Sir M. V. College of Science and Commerce in Mumbai, India. Our system, employing the Llama-Index framework for text embedding and the two primary large language models, Google Gemini 1.0 and OpenAI GPT-3.5, for response generation, achieved an impressive average response time of 5 seconds for both models. Additionally, it attained an average relevancy score of 0.96 for Google Gemini 1.0 and 0.93 for OpenAI GPT-3.5 across diverse query categories. These findings clearly show how LLM-powered systems can improve communication and offer incredibly helpful, relevant information in higher education settings. We strongly encourage the deployment of these systems in order to greatly improve communication and the user experience in the context of higher education. In order to further enhance the efficiency and coverage of these systems, we plan to expand our knowledge sources and host them on cloud platforms, making them easily accessible. © Cerebration Science Publishing.","chatbots; generative AI; generative pretrained transformer; large language models; natural language processing; question answering; retrieval augmented generation","","","Cerebration Science Publishing","English","Article","Final","","Scopus","2-s2.0-85202163432"
"Giuffrè M.; Kresevic S.; Pugliese N.; You K.; Shung D.L.","Giuffrè, Mauro (57210704630); Kresevic, Simone (58189580900); Pugliese, Nicola (58183244900); You, Kisung (57214821854); Shung, Dennis L. (56447050200)","57210704630; 58189580900; 58183244900; 57214821854; 56447050200","Optimizing large language models in digestive disease: strategies and challenges to improve clinical outcomes","2024","Liver International","44","9","","2114","2124","10","3","10.1111/liv.15974","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194568175&doi=10.1111%2fliv.15974&partnerID=40&md5=d93b82c0e36bc8a796e56a31df03fdf4","Department of Internal Medicine (Digestive Diseases), Yale School of Medicine, New Haven, CT, United States; Department of Medical, Surgical, and Health Sciences, University of Trieste, Trieste, Italy; Department of Engineering and Architecture, University of Trieste, Trieste, Italy; Division of Internal Medicine and Hepatology, Department of Gastroenterology, IRCCS Humanitas Research Hospital, Rozzano, Italy; Department of Biomedical Sciences, Humanitas University, Pieve Emanuele, Italy; Department of Mathematics, Baruch College, City University of New York, New York, NY, United States","Giuffrè M., Department of Internal Medicine (Digestive Diseases), Yale School of Medicine, New Haven, CT, United States, Department of Medical, Surgical, and Health Sciences, University of Trieste, Trieste, Italy; Kresevic S., Department of Engineering and Architecture, University of Trieste, Trieste, Italy; Pugliese N., Division of Internal Medicine and Hepatology, Department of Gastroenterology, IRCCS Humanitas Research Hospital, Rozzano, Italy, Department of Biomedical Sciences, Humanitas University, Pieve Emanuele, Italy; You K., Department of Mathematics, Baruch College, City University of New York, New York, NY, United States; Shung D.L., Department of Internal Medicine (Digestive Diseases), Yale School of Medicine, New Haven, CT, United States","Large Language Models (LLMs) are transformer-based neural networks with billions of parameters trained on very large text corpora from diverse sources. LLMs have the potential to improve healthcare due to their capability to parse complex concepts and generate context-based responses. The interest in LLMs has not spared digestive disease academics, who have mainly investigated foundational LLM accuracy, which ranges from 25% to 90% and is influenced by the lack of standardized rules to report methodologies and results for LLM-oriented research. In addition, a critical issue is the absence of a universally accepted definition of accuracy, varying from binary to scalar interpretations, often tied to grader expertise without reference to clinical guidelines. We address strategies and challenges to increase accuracy. In particular, LLMs can be infused with domain knowledge using Retrieval Augmented Generation (RAG) or Supervised Fine-Tuning (SFT) with reinforcement learning from human feedback (RLHF). RAG faces challenges with in-context window limits and accurate information retrieval from the provided context. SFT, a deeper adaptation method, is computationally demanding and requires specialized knowledge. LLMs may increase patient quality of care across the field of digestive diseases, where physicians are often engaged in screening, treatment and surveillance for a broad range of pathologies for which in-context learning or SFT with RLHF could improve clinical decision-making and patient outcomes. However, despite their potential, the safe deployment of LLMs in healthcare still needs to overcome hurdles in accuracy, suggesting a need for strategies that integrate human feedback with advanced model training. © 2024 John Wiley & Sons A/S. Published by John Wiley & Sons Ltd.","ChatGPT; Fine-tuning; In-context Learning; Large Language Models; LLMs; Reinforcement Learning from Human Feedback; Retrieval Augmented Generation; RHLF; Supervised Fine-Tuning","Digestive System Diseases; Humans; Natural Language Processing; Neural Networks, Computer; artificial neural network; digestive system disease; human; natural language processing; therapy","","John Wiley and Sons Inc","English","Review","Final","All Open Access; Bronze Open Access","Scopus","2-s2.0-85194568175"
"Mansurova A.; Mansurova A.; Nugumanova A.","Mansurova, Aigerim (58614576700); Mansurova, Aiganym (59233698800); Nugumanova, Aliya (55864815200)","58614576700; 59233698800; 55864815200","QA-RAG: Exploring LLM Reliance on External Knowledge","2024","Big Data and Cognitive Computing","8","9","115","","","","0","10.3390/bdcc8090115","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204935690&doi=10.3390%2fbdcc8090115&partnerID=40&md5=ffa9d02cd8f60e15e08f4f33a5a439e2","Big Data and Blockchain Technologies Science and Innovation Center, Astana IT University, Astana, 020000, Kazakhstan","Mansurova A., Big Data and Blockchain Technologies Science and Innovation Center, Astana IT University, Astana, 020000, Kazakhstan; Mansurova A., Big Data and Blockchain Technologies Science and Innovation Center, Astana IT University, Astana, 020000, Kazakhstan; Nugumanova A., Big Data and Blockchain Technologies Science and Innovation Center, Astana IT University, Astana, 020000, Kazakhstan","Large language models (LLMs) can store factual knowledge within their parameters and have achieved superior results in question-answering tasks. However, challenges persist in providing provenance for their decisions and keeping their knowledge up to date. Some approaches aim to address these challenges by combining external knowledge with parametric memory. In contrast, our proposed QA-RAG solution relies solely on the data stored within an external knowledge base, specifically a dense vector index database. In this paper, we compare RAG configurations using two LLMs—Llama 2 7b and 13b—systematically examining their performance in three key RAG capabilities: noise robustness, knowledge gap detection, and external truth integration. The evaluation reveals that while our approach achieves an accuracy of 83.3%, showcasing its effectiveness across all baselines, the model still struggles significantly in terms of external truth integration. These findings suggest that considerable work is still required to fully leverage RAG in question-answering tasks. © 2024 by the authors.","external knowledge base; large language model; question-answering system; retrieval-augmented generation","External knowledge; External knowledge base; Factual knowledge; Index database; Language model; Large language model; Question answering systems; Question Answering Task; Retrieval-augmented generation; Vector index; Question answering","","Multidisciplinary Digital Publishing Institute (MDPI)","English","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85204935690"
"Yao S.; Ke Q.; Wang Q.; Li K.; Hu J.","Yao, Shunyu (57217295494); Ke, Qingqing (59362530900); Wang, Qiwei (58670775200); Li, Kangtong (59362926200); Hu, Jie (57226187628)","57217295494; 59362530900; 58670775200; 59362926200; 57226187628","Lawyer GPT: A Legal Large Language Model with Enhanced Domain Knowledge and Reasoning Capabilities","2024","ACM International Conference Proceeding Series","","","","108","112","4","0","10.1145/3689299.3689319","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206110118&doi=10.1145%2f3689299.3689319&partnerID=40&md5=e9866e601d2dd338ea8b2747b395888d","Big Data and Artificial Intelligence Institute, China Telecom Research Institute, Beijing, China; China Telecom, Beijing, China; Beijing University of Posts and Telecommunications, Beijing, China","Yao S., Big Data and Artificial Intelligence Institute, China Telecom Research Institute, Beijing, China; Ke Q., China Telecom, Beijing, China; Wang Q., Beijing University of Posts and Telecommunications, Beijing, China; Li K., Beijing University of Posts and Telecommunications, Beijing, China; Hu J., Big Data and Artificial Intelligence Institute, China Telecom Research Institute, Beijing, China","The emergence of large language models has brought about revolutionary changes in the field of natural language processing and has shown extraordinary potential in general tasks and various specific domain tasks, especially in the legal field. However, there are still many factors that constrain the application of large language models in the legal field, with the main problems being the lack of domain knowledge and the ability to apply knowledge to solve problems. Therefore, we propose Lawyer GPT, a legal large model that incorporates domain knowledge by using an external knowledge retrieval module to combine an external knowledge base and possesses legal reasoning capabilities. We have collected a large amount of legal domain data and combined it with general domain data, using GPT-4 Turbo to build a high-quality legal dataset. To make Lawyer GPT's legal reasoning capabilities more reliable, we have performed supervised fine-tuning on this dataset, providing it with a good ability to apply domain knowledge to solve problems and enabling it to independently handle various legal professional issues. In addition, we have constructed a legal knowledge base and used retrieval enhancement techniques to provide Lawyer GPT with tools to retrieve external domain knowledge, thereby improving the factual and rationality of the generated content. Experimental results show that Lawyer GPT has demonstrated good performance in both subjective and objective legal domain tests, showing a strong ability to handle legal issues. © 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.","Autonomous Agents; Large Language Models; Legal Dataset; Legal Domain; Retrieval-augmented Generation","Large datasets; Metadata; Natural language processing systems; Domain knowledge; External knowledge; Knowledge capabilities; Language model; Large language model; Legal dataset; Legal domains; Legal reasoning; Reasoning capabilities; Retrieval-augmented generation; Domain Knowledge","","Association for Computing Machinery","English","Conference paper","Final","","Scopus","2-s2.0-85206110118"
"Li Y.; Shi E.; Zheng D.; Duan K.; Chen J.; Wang Y.","Li, Yifan (59254679400); Shi, Ensheng (57226182242); Zheng, Dewu (58757740200); Duan, Kefeng (59253934300); Chen, Jiachi (57184505400); Wang, Yanlin (57222817085)","59254679400; 57226182242; 58757740200; 59253934300; 57184505400; 57222817085","RepoMinCoder: Improving Repository-Level Code Generation Based on Information Loss Screening","2024","ACM International Conference Proceeding Series","","","","229","238","9","0","10.1145/3671016.3674819","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200888830&doi=10.1145%2f3671016.3674819&partnerID=40&md5=2a799c7e2c278bd3d568a9639ed7f195","Sun Yat-sen University, Zhuhai, China; Xi'an Jiaotong University, Xi'an, China","Li Y., Sun Yat-sen University, Zhuhai, China; Shi E., Xi'an Jiaotong University, Xi'an, China; Zheng D., Sun Yat-sen University, Zhuhai, China; Duan K., Sun Yat-sen University, Zhuhai, China; Chen J., Sun Yat-sen University, Zhuhai, China; Wang Y., Sun Yat-sen University, Zhuhai, China","Repository-level code generation task involves generating code at a specified location based on unfinished code with repository context. Existing research mainly rely on retrieval-augmented generation methods to complete code. Existing work mainly investigates on improving retrieval results based on the unfinished code, but rarely pays attention to the information loss in the prompt encoding process. In this paper, we propose RepoMinCoder, a novel repository-level code generation framework that adds another round of screening and ranking based on information loss, building upon the canonical retrieval-augmented generation method. Extensive experimental results demonstrate that RepoMinCoder consistently outperforms state-of-the-art methods on public benchmark RepoEval, achieving 3.3% EM and 2.1% ES improvement over previous methods. Moreover, we conduct additional experiments to study the effect of various factors in the existing code generation pipeline, including the number of retrieval candidates, the slicing strategy of the retrieval database, and different prompting strategies. © 2024 ACM.","Code Generation; Large Language Model; Screening and Ranking","Additional experiments; Codegeneration; Encoding process; Generation method; Information loss; Language model; Large language model; Location based; Screening and ranking; State-of-the-art methods; Information retrieval","","Association for Computing Machinery","English","Conference paper","Final","","Scopus","2-s2.0-85200888830"
"Wang Z.J.; Chau D.H.","Wang, Zijie J. (57218772437); Chau, Duen Horng (14035167900)","57218772437; 14035167900","MeMemo: On-device Retrieval Augmentation for Private and Personalized Text Generation","2024","SIGIR 2024 - Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval","","","","2765","2770","5","0","10.1145/3626772.3657662","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200596976&doi=10.1145%2f3626772.3657662&partnerID=40&md5=9278fdd705833c6c45c07020dbc8e201","Georgia Institute of Technology, Atlanta, GA, United States","Wang Z.J., Georgia Institute of Technology, Atlanta, GA, United States; Chau D.H., Georgia Institute of Technology, Atlanta, GA, United States","Retrieval-augmented text generation (RAG) addresses the common limitations of large language models (LLMs), such as hallucination, by retrieving information from an updatable external knowledge base. However, existing approaches often require dedicated backend servers for data storage and retrieval, thereby limiting their applicability in use cases that require strict data privacy, such as personal finance, education, and medicine. To address the pressing need for client-side dense retrieval, we introduce MeMemo, the first open-source JavaScript toolkit that adapts the state-of-the-art approximate nearest neighbor search technique HNSW to browser environments. Developed with modern and native Web technologies, such as IndexedDB and Web Workers, our toolkit leverages client-side hardware capabilities to enable researchers and developers to efficiently search through millions of high-dimensional vectors in the browser. MeMemo enables exciting new design and research opportunities, such as private and personalized content creation and interactive prototyping, as demonstrated in our example application RAG Playground. Reflecting on our work, we discuss the opportunities and challenges for on-device dense retrieval. MeMemo is available at https://github.com/poloclub/mememo. © 2024 Owner/Author.","large language models; neural information retrieval; on-device","Computational linguistics; Digital storage; Information retrieval; Knowledge based systems; Nearest neighbor search; Software prototyping; Back-end servers; Client sides; Data storage; External knowledge; Language model; Large language model; Neural information; Neural information retrieval; On-device; Text generations; Data privacy","","Association for Computing Machinery, Inc","English","Conference paper","Final","","Scopus","2-s2.0-85200596976"
"Jho H.","Jho, Hunkoog (56136159300)","56136159300","Leveraging Generative AI in Physics Education: Addressing Hallucination Issues in Large Language Models; [물리교육에서 생성형 인공지능의 활용과 문제 해결 방안: 거대 언어 모델의 환각 문제를 중심으로]","2024","New Physics: Sae Mulli","74","8","","812","823","11","0","10.3938/NPSM.74.812","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203444362&doi=10.3938%2fNPSM.74.812&partnerID=40&md5=267ccc64a82620c9bd57bb000186b08b","Department of Science Education, Dankook University, Yongin, 16890, South Korea","Jho H., Department of Science Education, Dankook University, Yongin, 16890, South Korea","In recent years, generative AI technology, especially large language models (LLMs), has garnered significant attention for its potential to transform education. This paper provides an overview of generative AI’s development and examines its impact on education, focusing on the issue of ‘hallucinations’ in LLMs. It explores the causes and proposes solutions such as finetuning, reasoning, iterative querying, and Retrieval-Augmented Generation (RAG). These methods aim to enhance the accuracy and reliability of AI responses. Examples of AI applications in education include real-time student query responses, personalized learning pathways, and assessment feedback. While these technologies promise to improve educational quality, they also raise concerns about biases and data privacy. This paper discusses strategies to effectively utilize generative AI in education, aiming to improve quality while minimizing negative impacts. © 2024 Korean Physical Society. All rights reserved.","Artificial intelligence; Hallucination; Large language model; Natural language processing; Retrieval-augmented generation","","","Korean Physical Society","Korean","Review","Final","","Scopus","2-s2.0-85203444362"
"Zhang Q.; Zeng B.; Zhou C.; Go G.; Shi H.; Jiang Y.","Zhang, Quan (57215971065); Zeng, Binqi (58134248900); Zhou, Chijin (57205028572); Go, Gwihwan (59140087900); Shi, Heyuan (57192187933); Jiang, Yu (56193157500)","57215971065; 58134248900; 57205028572; 59140087900; 57192187933; 56193157500","Human-Imperceptible Retrieval Poisoning Attacks in LLM-Powered Applications","2024","FSE Companion - Companion Proceedings of the 32nd ACM International Conference on the Foundations of Software Engineering","","","","502","506","4","0","10.1145/3663529.3663786","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199035135&doi=10.1145%2f3663529.3663786&partnerID=40&md5=4c5a55d6a4e4eb92484b089790a20b81","Tsinghua University, China; Central South University, China","Zhang Q., Tsinghua University, China; Zeng B., Central South University, China; Zhou C., Tsinghua University, China; Go G., Tsinghua University, China; Shi H., Central South University, China; Jiang Y., Tsinghua University, China","Presently, with the assistance of advanced LLM application development frameworks, more and more LLM-powered applications can effortlessly augment the LLMs’ knowledge with external content using the retrieval augmented generation (RAG) technique. However, these frameworks’ designs do not have sufficient consideration of the risk of external content, thereby allowing attackers to undermine the applications developed with these frameworks. In this paper, we reveal a new threat to LLM-powered applications, termed retrieval poisoning, where attackers can guide the application to yield malicious responses during the RAG process. Specifically, through the analysis of LLM application frameworks, attackers can craft documents visually indistinguishable from benign ones. Despite the documents providing correct information, once they are used as reference sources for RAG, the application is misled into generating incorrect responses. Our preliminary experiments indicate that attackers can mislead LLMs with an 88.33% success rate, and achieve a 66.67% success rate in the real-world application, demonstrating the potential impact of retrieval poisoning. © 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.","Large Language Models; Retrieval Poisoning Attack","Application development frameworks; Application frameworks; Framework designs; Generation process; Generation techniques; Language model; Large language model; Poisoning attacks; Reference source; Retrieval poisoning attack","d�Amorim M.","Association for Computing Machinery, Inc","English","Conference paper","Final","","Scopus","2-s2.0-85199035135"
"Wang Y.; Leutner S.; Ingrisch M.; Klein C.; Hinske L.C.; Danhauser K.","Wang, Yingding (59297892800); Leutner, Simon (59297685400); Ingrisch, Michael (24074048500); Klein, Christoph (26642986500); Hinske, Ludwig Christian (26635250300); Danhauser, Katharina (36681187400)","59297892800; 59297685400; 24074048500; 26642986500; 26635250300; 36681187400","Optimizing Data Extraction: Harnessing RAG and LLMs for German Medical Documents","2024","Studies in Health Technology and Informatics","316","","","949","950","1","0","10.3233/SHTI240567","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202001990&doi=10.3233%2fSHTI240567&partnerID=40&md5=38cb881f033992913e6bf99a9a085c5a","Department of Pediatrics, Dr. von Hauner Children's Hospital, University Hospital, LMU Munich, Munich, Germany; Medical Technology and IT (MIT), University Hospital, LMU Munich, Munich, Germany; Department of Radiology, University Hospital, LMU Munich, Munich, Germany; Institute for Digital Medicine, University Hospital Augsburg, Augsburg, Germany","Wang Y., Department of Pediatrics, Dr. von Hauner Children's Hospital, University Hospital, LMU Munich, Munich, Germany; Leutner S., Medical Technology and IT (MIT), University Hospital, LMU Munich, Munich, Germany; Ingrisch M., Department of Radiology, University Hospital, LMU Munich, Munich, Germany; Klein C., Department of Pediatrics, Dr. von Hauner Children's Hospital, University Hospital, LMU Munich, Munich, Germany; Hinske L.C., Institute for Digital Medicine, University Hospital Augsburg, Augsburg, Germany; Danhauser K., Department of Pediatrics, Dr. von Hauner Children's Hospital, University Hospital, LMU Munich, Munich, Germany","In the field of medical data analysis, converting unstructured text documents into a structured format suitable for further use is a significant challenge. This study introduces an automated local deployed data privacy secure pipeline that uses open-source Large Language Models (LLMs) with Retrieval-Augmented Generation (RAG) architecture to convert medical German language documents with sensitive health-related information into a structured format. Testing on a proprietary dataset of 800 unstructured original medical reports demonstrated an accuracy of up to 90% in data extraction of the pipeline compared to data extracted manually by physicians and medical students. This highlights the pipeline's potential as a valuable tool for efficiently extracting relevant data from unstructured sources. © 2024 The Authors.","Data extraction; German; OSS-LLM; RAG; Real-life medical reports","Computer Security; Data Mining; Electronic Health Records; Germany; Humans; Information Storage and Retrieval; Natural Language Processing; Data accuracy; Data privacy; Data transfer; Electronic health record; Metadata; Network security; Data extraction; German; Language model; Medical data analysis; Medical documents; OSS-large language model; Real-life medical report; Retrieval-augmented generation; Text document; Unstructured texts; computer security; data mining; electronic health record; Germany; human; information retrieval; natural language processing; procedures; Data assimilation","Mantas J.; Hasman A.; Demiris G.; Saranto K.; Marschollek M.; Arvanitis T.N.; Ognjanovic I.; Benis A.; Gallos P.; Zoulias E.; Andrikopoulou E.","IOS Press BV","English","Conference paper","Final","All Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85202001990"
"Xu L.; Lu L.; Liu M.; Song C.; Wu L.","Xu, Liang (58656518200); Lu, Lu (58205080400); Liu, Minglu (58655565000); Song, Chengxuan (58980254900); Wu, Lizhen (58979509200)","58656518200; 58205080400; 58655565000; 58980254900; 58979509200","Nanjing Yunjin intelligent question-answering system based on knowledge graphs and retrieval augmented generation technology","2024","Heritage Science","12","1","118","","","","1","10.1186/s40494-024-01231-3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189988524&doi=10.1186%2fs40494-024-01231-3&partnerID=40&md5=fa422be6944ff08e26848af12bba0f7b","Hangzhou Dianzi University, Lib, Hangzhou, 310018, China; Nanjing Forestry University, Nanjing, 210037, China; Unicom (Zhejiang) Industrial Internet Co. Ltd., Hangzhou, 311103, China; Nanjing University of Information Science and Technology, Nanjing, 210044, China","Xu L., Hangzhou Dianzi University, Lib, Hangzhou, 310018, China; Lu L., Nanjing Forestry University, Nanjing, 210037, China; Liu M., Unicom (Zhejiang) Industrial Internet Co. Ltd., Hangzhou, 311103, China; Song C., Nanjing University of Information Science and Technology, Nanjing, 210044, China; Wu L., Hangzhou Dianzi University, Lib, Hangzhou, 310018, China","Nanjing Yunjin, a traditional Chinese silk weaving craft, is celebrated globally for its unique local characteristics and exquisite workmanship, forming an integral part of the world's intangible cultural heritage. However, with the advancement of information technology, the experiential knowledge of the Nanjing Yunjin production process is predominantly stored in text format. As a highly specialized and vertical domain, this information is not readily convert into usable data. Previous studies on a knowledge graph-based Nanjing Yunjin Question-Answering System have partially addressed this issue. However, knowledge graphs need to be constantly updated and rely on predefined entities and relationship types. Faced with ambiguous or complex natural language problems, knowledge graph information retrieval faces some challenges. Therefore, this study proposes a Nanjing Yunjin Question-Answering System that integrates Knowledge Graphs and Retrieval Augmented Generation techniques. In this system, the ROBERTA model is first utilized to vectorize Nanjing Yunjin textual information, delving deep into textual semantics to unveil its profound cultural connotations. Additionally, the FAISS vector database is employed for efficient storage and retrieval of Nanjing Yunjin information, achieving a deep semantic match between questions and answers. Ultimately, related retrieval results are fed into the Large Language Model for enhanced generation, aiming for more accurate text generation outcomes and improving the interpretability and logic of the Question-Answering System. This research merges technologies like text embedding, vectorized retrieval, and natural language generation, aiming to overcome the limitations of knowledge graphs-based Question-Answering System in terms of graph updating, dependency on predefined types, and semantic understanding. System implementation and testing have shown that the Nanjing Yunjin Intelligent Question-Answering System, constructed on the basis of Knowledge Graphs and Retrieval Augmented Generation, possesses a broader knowledge base that considers context, resolving issues of polysemy, vague language, and sentence ambiguity, and efficiently and accurately generates answers to natural language queries. This significantly facilitates the retrieval and utilization of Yunjin knowledge, providing a paradigm for constructing Question-Answering System for other intangible cultural heritages, and holds substantial theoretical and practical significance for the deep exploration and discovery of the knowledge structure of human intangible heritage, promoting cultural inheritance and protection. © The Author(s) 2024.","Knowledge graphs; Nanjing Yunjin; Question-Answering System; Retrieval augmented generation; Vector retrieval","","","Springer Science and Business Media Deutschland GmbH","English","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85189988524"
"Arun G.; Perumal V.; Urias F.P.J.B.; Ler Y.E.; Tan B.W.T.; Vallabhajosyula R.; Tan E.; Ng O.; Ng K.B.; Mogali S.R.","Arun, Gautham (59285215100); Perumal, Vivek (55804251500); Urias, Francis Paul John Bato (59285215200); Ler, Yan En (59286223500); Tan, Bryan Wen Tao (59286731600); Vallabhajosyula, Ranganath (35387121500); Tan, Emmanuel (59286731700); Ng, Olivia (57219946443); Ng, Kian Bee (57428429000); Mogali, Sreenivasulu Reddy (57194267294)","59285215100; 55804251500; 59285215200; 59286223500; 59286731600; 35387121500; 59286731700; 57219946443; 57428429000; 57194267294","ChatGPT versus a customized AI chatbot (Anatbuddy) for anatomy education: A comparative pilot study","2024","Anatomical Sciences Education","17","7","","1396","1405","9","0","10.1002/ase.2502","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201691243&doi=10.1002%2fase.2502&partnerID=40&md5=2fb12befe986e8543bfe1903d4f332aa","Lee Kong Chian School of Medicine, Nanyang Technological University Singapore, Singapore, Singapore; Singapore Polytechnic, Singapore, Singapore","Arun G., Lee Kong Chian School of Medicine, Nanyang Technological University Singapore, Singapore, Singapore, Singapore Polytechnic, Singapore, Singapore; Perumal V., Lee Kong Chian School of Medicine, Nanyang Technological University Singapore, Singapore, Singapore; Urias F.P.J.B., Singapore Polytechnic, Singapore, Singapore; Ler Y.E., Singapore Polytechnic, Singapore, Singapore; Tan B.W.T., Singapore Polytechnic, Singapore, Singapore; Vallabhajosyula R., Lee Kong Chian School of Medicine, Nanyang Technological University Singapore, Singapore, Singapore; Tan E., Lee Kong Chian School of Medicine, Nanyang Technological University Singapore, Singapore, Singapore; Ng O., Lee Kong Chian School of Medicine, Nanyang Technological University Singapore, Singapore, Singapore; Ng K.B., Lee Kong Chian School of Medicine, Nanyang Technological University Singapore, Singapore, Singapore; Mogali S.R., Lee Kong Chian School of Medicine, Nanyang Technological University Singapore, Singapore, Singapore","Large Language Models (LLMs) have the potential to improve education by personalizing learning. However, ChatGPT-generated content has been criticized for sometimes producing false, biased, and/or hallucinatory information. To evaluate AI's ability to return clear and accurate anatomy information, this study generated a custom interactive and intelligent chatbot (Anatbuddy) through an Open AI Application Programming Interface (API) that enables seamless AI-driven interactions within a secured cloud infrastructure. Anatbuddy was programmed through a Retrieval Augmented Generation (RAG) method to provide context-aware responses to user queries based on a predetermined knowledge base. To compare their outputs, various queries (i.e., prompts) on thoracic anatomy (n = 18) were fed into Anatbuddy and ChatGPT 3.5. A panel comprising three experienced anatomists evaluated both tools' responses for factual accuracy, relevance, completeness, coherence, and fluency on a 5-point Likert scale. These ratings were reviewed by a third party blinded to the study, who revised and finalized scores as needed. Anatbuddy's factual accuracy (mean ± SD = 4.78/5.00 ± 0.43; median = 5.00) was rated significantly higher (U = 84, p = 0.01) than ChatGPT's accuracy (4.11 ± 0.83; median = 4.00). No statistically significant differences were detected between the chatbots for the other variables. Given ChatGPT's current content knowledge limitations, we strongly recommend the anatomy profession develop a custom AI chatbot for anatomy education utilizing a carefully curated knowledge base to ensure accuracy. Further research is needed to determine students' acceptance of custom chatbots for anatomy education and their influence on learning experiences and outcomes. © 2024 American Association for Anatomy.","anatomical education; artificial intelligence; chatbot; ChatGPT; personalized learning; retrieval augmented generation","Anatomy; Artificial Intelligence; Computer-Assisted Instruction; Educational Measurement; Humans; Learning; Pilot Projects; Software; anatomy; artificial intelligence; comparative study; education; human; learning; pilot study; procedures; software; teaching","","John Wiley and Sons Inc","English","Article","Final","","Scopus","2-s2.0-85201691243"
"Rahmani H.A.; Siro C.; Aliannejadi M.; Craswell N.; Clarke C.L.A.; Faggioli G.; Mitra B.; Thomas P.; Yilmaz E.","Rahmani, Hossein A. (57211506304); Siro, Clemencia (57222719443); Aliannejadi, Mohammad (56401068500); Craswell, Nick (6602824438); Clarke, Charles L. A. (7401438213); Faggioli, Guglielmo (57204691379); Mitra, Bhaskar (56286147100); Thomas, Paul (55658056963); Yilmaz, Emine (57203056765)","57211506304; 57222719443; 56401068500; 6602824438; 7401438213; 57204691379; 56286147100; 55658056963; 57203056765","LLM4Eval: Large Language Model for Evaluation in IR","2024","SIGIR 2024 - Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval","","","","3040","3043","3","1","10.1145/3626772.3657992","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200578005&doi=10.1145%2f3626772.3657992&partnerID=40&md5=8d41e565990dc38590b8606635256e67","University College London, London, United Kingdom; University of Amsterdam, Amsterdam, Netherlands; Microsoft, Seattle, United States; University of Waterloo, Waterloo, Canada; University of Padua, Padua, Italy; Microsoft, Montreal, QC, Canada; Microsoft, Adelaide, Australia; University College London, Amazon, London, United Kingdom","Rahmani H.A., University College London, London, United Kingdom; Siro C., University of Amsterdam, Amsterdam, Netherlands; Aliannejadi M., University of Amsterdam, Amsterdam, Netherlands; Craswell N., Microsoft, Seattle, United States; Clarke C.L.A., University of Waterloo, Waterloo, Canada; Faggioli G., University of Padua, Padua, Italy; Mitra B., Microsoft, Montreal, QC, Canada; Thomas P., Microsoft, Adelaide, Australia; Yilmaz E., University College London, Amazon, London, United Kingdom","Large language models (LLMs) have demonstrated increasing task-solving abilities not present in smaller models. Utilizing the capabilities and responsibilities of LLMs for automated evaluation (LLM4Eval) has recently attracted considerable attention in multiple research communities. For instance, LLM4Eval models have been studied in the context of automated judgments, natural language generation, and retrieval augmented generation systems. We believe that the information retrieval community can significantly contribute to this growing research area by designing, implementing, analyzing, and evaluating various aspects of LLMs with applications to LLM4Eval tasks. The main goal of LLM4Eval workshop is to bring together researchers from industry and academia to discuss various aspects of LLMs for evaluation in information retrieval, including automated judgments, retrieval-augmented generation pipeline evaluation, altering human evaluation, robustness, and trustworthiness of LLMs for evaluation in addition to their impact on real-world applications. We also plan to run an automated judgment challenge prior to the workshop, where participants will be asked to generate labels for a given dataset while maximising correlation with human judgments. The format of the workshop is interactive, including roundtable and keynote sessions and tends to avoid the one-sided dialogue of a mini-conference. © 2024 Owner/Author.","automated evaluation; generative models; large language models","Automation; Computational linguistics; Natural language processing systems; Search engines; Automated evaluation; Generation systems; Generative model; Human evaluation; Language model; Large language model; Multiple research; Natural language generation; Research areas; Research communities; Information retrieval","","Association for Computing Machinery, Inc","English","Conference paper","Final","","Scopus","2-s2.0-85200578005"
"Zelin C.; Chung W.K.; Jeanne M.; Zhang G.; Weng C.","Zelin, Charlotte (59253044600); Chung, Wendy K. (57211703344); Jeanne, Mederic (59253226700); Zhang, Gongbo (58745536500); Weng, Chunhua (8979750700)","59253044600; 57211703344; 59253226700; 58745536500; 8979750700","Rare disease diagnosis using knowledge guided retrieval augmentation for ChatGPT","2024","Journal of Biomedical Informatics","157","","104702","","","","0","10.1016/j.jbi.2024.104702","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200823618&doi=10.1016%2fj.jbi.2024.104702&partnerID=40&md5=b7050cb19aabaf9f72eefb4913bafcd3","Blind Brook High School, Rye Brook, NY, United States; Department of Pediatrics, Boston Children's Hospital, Boston, MA, United States; Harvard Medical School, Boston, MA, United States; Department of Biomedical Informatics, Columbia University, New York City, 10032, NY, United States","Zelin C., Blind Brook High School, Rye Brook, NY, United States; Chung W.K., Department of Pediatrics, Boston Children's Hospital, Boston, MA, United States, Harvard Medical School, Boston, MA, United States; Jeanne M., Department of Pediatrics, Boston Children's Hospital, Boston, MA, United States, Harvard Medical School, Boston, MA, United States; Zhang G., Department of Biomedical Informatics, Columbia University, New York City, 10032, NY, United States; Weng C., Department of Biomedical Informatics, Columbia University, New York City, 10032, NY, United States","Although rare diseases individually have a low prevalence, they collectively affect nearly 400 million individuals around the world. On average, it takes five years for an accurate rare disease diagnosis, but many patients remain undiagnosed or misdiagnosed. As machine learning technologies have been used to aid diagnostics in the past, this study aims to test ChatGPT's suitability for rare disease diagnostic support with the enhancement provided by Retrieval Augmented Generation (RAG). RareDxGPT, our enhanced ChatGPT model, supplies ChatGPT with information about 717 rare diseases from an external knowledge resource, the RareDis Corpus, through RAG. In RareDxGPT, when a query is entered, the three documents most relevant to the query in the RareDis Corpus are retrieved. Along with the query, they are returned to ChatGPT to provide a diagnosis. Additionally, phenotypes for thirty different diseases were extracted from free text from PubMed's Case Reports. They were each entered with three different prompt types: “prompt”, “prompt + explanation” and “prompt + role play.” The accuracy of ChatGPT and RareDxGPT with each prompt was then measured. With “Prompt”, RareDxGPT had a 40 % accuracy, while ChatGPT 3.5 got 37 % of the cases correct. With “Prompt + Explanation”, RareDxGPT had a 43 % accuracy, while ChatGPT 3.5 got 23 % of the cases correct. With “Prompt + Role Play”, RareDxGPT had a 40 % accuracy, while ChatGPT 3.5 got 23 % of the cases correct. To conclude, ChatGPT, especially when supplying extra domain specific knowledge, demonstrates early potential for rare disease diagnosis with adjustments. © 2024 Elsevier Inc.","Diagnostic Decision Support; Generative AI; Large Language Models; Rare Disease","Algorithms; Data Mining; Databases, Factual; Diagnosis, Computer-Assisted; Humans; Information Storage and Retrieval; Machine Learning; Rare Diseases; Decision support systems; Diagnosis; Domain Knowledge; Learning systems; Decision supports; Diagnostic decision support; Diagnostic decisions; Disease diagnosis; Generative AI; Language model; Large language model; Machine learning technology; Rare disease; Role-plays; Article; ChatGPT; child; clinical decision support system; controlled study; data extraction; diagnostic accuracy; human; information retrieval; knowledge; machine learning; major clinical study; male; Medline; phenotype; prevalence; rare disease; algorithm; computer assisted diagnosis; data mining; diagnosis; factual database; information retrieval; machine learning; procedures; rare disease; Diseases","","Academic Press Inc.","English","Article","Final","","Scopus","2-s2.0-85200823618"
"Aykut A.; Sezenoz A.S.","Aykut, Aslan (36536459300); Sezenoz, Almila Sarigul (56662097600)","36536459300; 56662097600","Exploring the Potential of Code-Free Custom GPTs in Ophthalmology: An Early Analysis of GPT Store and User-Creator Guidance","2024","Ophthalmology and Therapy","13","10","","2697","2713","16","0","10.1007/s40123-024-01014-w","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201201033&doi=10.1007%2fs40123-024-01014-w&partnerID=40&md5=81a54596c94b6a63225395711b4bbb7d","Department of Ophthalmology and Visual Sciences, Kellogg Eye Center, University of Michigan, 1000 Wall St, Rm 641, Ann Arbor, 48105, MI, United States; Department of Ophthalmology, School of Medicine, Marmara University, Istanbul, 34854, Turkey; Department of Ophthalmology, Faculty of Medicine, Başkent University, Ankara, 06790, Turkey","Aykut A., Department of Ophthalmology and Visual Sciences, Kellogg Eye Center, University of Michigan, 1000 Wall St, Rm 641, Ann Arbor, 48105, MI, United States, Department of Ophthalmology, School of Medicine, Marmara University, Istanbul, 34854, Turkey; Sezenoz A.S., Department of Ophthalmology and Visual Sciences, Kellogg Eye Center, University of Michigan, 1000 Wall St, Rm 641, Ann Arbor, 48105, MI, United States, Department of Ophthalmology, Faculty of Medicine, Başkent University, Ankara, 06790, Turkey","Introduction: OpenAI recently introduced the ability to create custom generative pre-trained transformers (cGPTs) using text-based instruction and/or external documents using retrieval-augmented generation (RAG) architecture without coding knowledge. This study aimed to analyze the features of ophthalmology-related cGPTs and explore their potential utilities. Methods: Data collection took place on January 20 and 21, 2024, and custom GPTs were found by entering ophthalmology keywords into the “Explore GPTS” section of the website. General and specific features of cGPTs were recorded, such as knowledge other than GPT-4 training data. The instruction and description sections were analyzed for compatibility using the Likert scale. We analyzed two custom GPTs with the highest Likert score in detail. We attempted to create a convincingly presented yet potentially harmful cGPT to test safety features. Results: We analyzed 22 ophthalmic cGPTs, of which 55% were for general use and the most common subspecialty was glaucoma (18%). Over half (55%) contained knowledge other than GPT-4 training data. The representation of the instructions through the description was between “Moderately representative” and “Very representative” with a median Likert score of 3.5 (IQR 3.0–4.0). The instruction word count was significantly associated with Likert scores (P = 0.03). Tested cGPTs demonstrated potential for specific conversational tone, information, retrieval and combining knowledge from an uploaded source. With these safety settings, creating a malicious GPT was possible. Conclusions: This is the first study to our knowledge to examine the GPT store for a medical field. Our findings suggest that these cGPTs can be immediately implemented in practice and may offer more targeted and effective solutions compared to the standard GPT-4. However, further research is necessary to evaluate their capabilities and limitations comprehensively. The safety features currently appear to be rather limited. It may be helpful for the user to review the instruction section before using a cGPT. © The Author(s) 2024.","Artificial intelligence; ChatGPT; Code-free; Custom GPT; Large language models; Ophthalmology","Article; binocular vision; cataract; central serous retinopathy; clinical practice; cornea dystrophy; cornea lesion; custom generative pre trained transformer; diplopia; eye fundus; eye photography; eyelid retraction; generative pretrained transformer; glaucoma; gonioscopy; human; lens capsule rupture; Likert scale; macular degeneration; neuroophthalmology; ophthalmology; optical coherence tomography; papilledema; phacoemulsification; pigmentary glaucoma; retina vein occlusion; Schnyder corneal dystrophy; software; strabismus; stromal dystrophy; visual disorder","","Adis","English","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85201201033"
"Guo T.; Yang Q.; Wang C.; Liu Y.; Li P.; Tang J.; Li D.; Wen Y.","Guo, Tiezheng (58794857500); Yang, Qingwen (58793655400); Wang, Chen (57222615399); Liu, Yanyi (57681444100); Li, Pan (58794129900); Tang, Jiawei (58549195700); Li, Dapeng (57226877010); Wen, Yingyou (15047271200)","58794857500; 58793655400; 57222615399; 57681444100; 58794129900; 58549195700; 57226877010; 15047271200","KnowledgeNavigator: leveraging large language models for enhanced reasoning over knowledge graph","2024","Complex and Intelligent Systems","10","5","","7063","7076","13","0","10.1007/s40747-024-01527-8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197269337&doi=10.1007%2fs40747-024-01527-8&partnerID=40&md5=97e6c8171dd93a547ec050c0fe99dfd9","School of Computer Science and Engineering, Northeastern University, Shenyang, 110167, China; Neusoft AI Magic Technology Research, Shenyang, 110179, China; Neusoft Institute of Intelligent Medical Research, Shenyang, 110179, China","Guo T., School of Computer Science and Engineering, Northeastern University, Shenyang, 110167, China, Neusoft AI Magic Technology Research, Shenyang, 110179, China; Yang Q., School of Computer Science and Engineering, Northeastern University, Shenyang, 110167, China, Neusoft AI Magic Technology Research, Shenyang, 110179, China; Wang C., School of Computer Science and Engineering, Northeastern University, Shenyang, 110167, China, Neusoft AI Magic Technology Research, Shenyang, 110179, China; Liu Y., School of Computer Science and Engineering, Northeastern University, Shenyang, 110167, China; Li P., School of Computer Science and Engineering, Northeastern University, Shenyang, 110167, China, Neusoft AI Magic Technology Research, Shenyang, 110179, China; Tang J., School of Computer Science and Engineering, Northeastern University, Shenyang, 110167, China, Neusoft AI Magic Technology Research, Shenyang, 110179, China; Li D., Neusoft AI Magic Technology Research, Shenyang, 110179, China; Wen Y., School of Computer Science and Engineering, Northeastern University, Shenyang, 110167, China, Neusoft AI Magic Technology Research, Shenyang, 110179, China, Neusoft Institute of Intelligent Medical Research, Shenyang, 110179, China","Large language models have achieved outstanding performance on various downstream tasks with their advanced understanding of natural language and zero-shot capability. However, they struggle with knowledge constraints, particularly in tasks requiring complex reasoning or extended logical sequences. These limitations can affect their performance in question answering by leading to inaccuracies and hallucinations. This paper proposes a novel framework called KnowledgeNavigator that leverages large language models on knowledge graphs to achieve accurate and interpretable multi-hop reasoning. Especially with an analysis-retrieval-reasoning process, KnowledgeNavigator searches the optimal path iteratively to retrieve external knowledge and guide the reasoning to reliable answers. KnowledgeNavigator treats knowledge graphs and large language models as flexible components that can be switched between different tasks without additional costs. Experiments on three benchmarks demonstrate that KnowledgeNavigator significantly improves the performance of large language models in question answering and outperforms all large language models-based baselines. © The Author(s) 2024.","Knowledge retrieval; Large language model; Question answering; Retrieval augmented generation","","","Springer International Publishing","English","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85197269337"
"Hammoud A.; Goyal C.; Pathen S.; Dai A.; Li A.; Kielian G.; Saligane M.","Hammoud, Ali (57297228900); Goyal, Chetanya (58602769700); Pathen, Sakib (59343976600); Dai, Arlene (59343514500); Li, Anhang (58096037900); Kielian, Gregory (58912733100); Saligane, Mehdi (56534123800)","57297228900; 58602769700; 59343976600; 59343514500; 58096037900; 58912733100; 56534123800","Human Language to Analog Layout Using GLayout Layout Automation Framework","2024","MLCAD 2024 - Proceedings of the 2024 ACM/IEEE International Symposium on Machine Learning for CAD","","","33","","","","0","10.1145/3670474.3685971","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204954107&doi=10.1145%2f3670474.3685971&partnerID=40&md5=f2948a8fab8b42d17ecaec943f5c0bfe","University of Michigan, United States; IIIT Hyderabad, India; Google AI","Hammoud A., University of Michigan, United States; Goyal C., IIIT Hyderabad, India; Pathen S., University of Michigan, United States; Dai A., University of Michigan, United States; Li A., University of Michigan, United States; Kielian G., Google AI; Saligane M., University of Michigan, United States","Current approaches to Analog Layout Automation apply ML techniques such as Graph Convolutional Neural Networks (GCN) to translate netlist to layout. While these ML approaches have proven to be effective, they lack the powerful reasoning capabilities, an intuitive human interface, and standard evaluation benchmarks that have been improving at a rapid development pace in Large Language Models (LLMs). The GLayout framework introduced in this work translates analog layout into an expressive, technology generic, compact text representation. Then, an LLM is taught to understand analog layout through fine-tuning and in-context learning using Retrieval Augmented Generation (RAG). The LLM is able to successfully layout unseen circuits based on new information provided in-context. We train 3.8, 7, and 22 Billion parameter quantized LLMs on a dataset of less than 50 unique circuits, and text documents providing layout knowledge. The 22B parameter model is tuned in 2 hours on a single NVIDIA A100 GPU. The open-source evaluation set is proposed as an automation benchmark for LLM layout automation tasks, and ranges from 2-transistor circuits to a ΔΣ ADC. The 22B model completes 70% of the tasks in the evaluation set, and passes DRC and LVS verification on 44% of evaluations with verified correct blocks up to 4 transistors in size. © 2024 ACM.","Analog Layout Automation; GLayout; Large Language Model; Open Source; Parameter Efficient Fine Tuning; Quantized Low Rank Adaptation (QLORA); Retrieval Augmented Generation (RAG)","Benchmarking; Graph neural networks; Integrated circuit layout; Photomapping; Problem oriented languages; Translation (languages); Analog layout; Analog layout automation; Fine tuning; Glayout; Language model; Large language model; Open-source; Parameter efficient fine tuning; Quantized low rank adaptation; Retrieval augmented generation; Convolutional neural networks","","Association for Computing Machinery, Inc","English","Conference paper","Final","","Scopus","2-s2.0-85204954107"
"Li Y.; Zhao J.; Li M.; Dang Y.; Yu E.; Li J.; Sun Z.; Hussein U.; Wen J.; Abdelhameed A.M.; Mai J.; Li S.; Yu Y.; Hu X.; Yang D.; Feng J.; Li Z.; He J.; Tao W.; Duan T.; Lou Y.; Li F.; Tao C.","Li, Yiming (57953353000); Zhao, Jeff (59294014200); Li, Manqi (59293857900); Dang, Yifang (57225101371); Yu, Evan (57802018200); Li, Jianfu (57214731196); Sun, Zenan (58084688000); Hussein, Usama (56556858300); Wen, Jianguo (59293858000); Abdelhameed, Ahmed M. (57202580063); Mai, Junhua (16744030000); Li, Shenduo (57888950800); Yu, Yue (57211907673); Hu, Xinyue (57222552565); Yang, Daowei (58201993200); Feng, Jingna (57476061000); Li, Zehan (58173993600); He, Jianping (57229984100); Tao, Wei (57225107417); Duan, Tiehang (57191254333); Lou, Yanyan (7202581996); Li, Fang (57207457538); Tao, Cui (8245410000)","57953353000; 59294014200; 59293857900; 57225101371; 57802018200; 57214731196; 58084688000; 56556858300; 59293858000; 57202580063; 16744030000; 57888950800; 57211907673; 57222552565; 58201993200; 57476061000; 58173993600; 57229984100; 57225107417; 57191254333; 7202581996; 57207457538; 8245410000","RefAI: a GPT-powered retrieval-augmented generative tool for biomedical literature recommendation and summarization","2024","Journal of the American Medical Informatics Association","31","9","","2030","2039","9","4","10.1093/jamia/ocae129","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198666791&doi=10.1093%2fjamia%2focae129&partnerID=40&md5=d333d1845410c45cc0a19e7ecc9f8fcb","McWilliams School of Biomedical Informatics, The University of Texas Health Science Center at Houston, Houston, 77030, TX, United States; Department of Computer Science, College of Natural Sciences, University of Texas at Austin, Austin, 78712, TX, United States; Department of Biostatistics & Data Science, School of Public Health, The University of Texas Health Science Center at Houston, Houston, 77030, TX, United States; Department of Artificial Intelligence and Informatics, Mayo Clinic, Jacksonville, 32224, FL, United States; Department of Lymphoma and Myeloma, The University of Texas MD Anderson Cancer Center, Houston, 77030, TX, United States; Department of Nanomedicine, Houston Methodist Academic Institute, Houston, 77030, TX, United States; Division of Hematology and Oncology, Department of Medicine, Mayo Clinic, Jacksonville, 32224, FL, United States; Department of Quantitative Health Sciences, Mayo Clinic, Rochester, 55905, MN, United States; Department of Translational Molecular Pathology, The University of Texas MD Anderson Cancer Center, Houston, 77030, TX, United States","Li Y., McWilliams School of Biomedical Informatics, The University of Texas Health Science Center at Houston, Houston, 77030, TX, United States; Zhao J., Department of Computer Science, College of Natural Sciences, University of Texas at Austin, Austin, 78712, TX, United States; Li M., McWilliams School of Biomedical Informatics, The University of Texas Health Science Center at Houston, Houston, 77030, TX, United States, Department of Biostatistics & Data Science, School of Public Health, The University of Texas Health Science Center at Houston, Houston, 77030, TX, United States; Dang Y., McWilliams School of Biomedical Informatics, The University of Texas Health Science Center at Houston, Houston, 77030, TX, United States; Yu E., McWilliams School of Biomedical Informatics, The University of Texas Health Science Center at Houston, Houston, 77030, TX, United States; Li J., Department of Artificial Intelligence and Informatics, Mayo Clinic, Jacksonville, 32224, FL, United States; Sun Z., McWilliams School of Biomedical Informatics, The University of Texas Health Science Center at Houston, Houston, 77030, TX, United States; Hussein U., Department of Lymphoma and Myeloma, The University of Texas MD Anderson Cancer Center, Houston, 77030, TX, United States; Wen J., McWilliams School of Biomedical Informatics, The University of Texas Health Science Center at Houston, Houston, 77030, TX, United States; Abdelhameed A.M., Department of Artificial Intelligence and Informatics, Mayo Clinic, Jacksonville, 32224, FL, United States; Mai J., Department of Nanomedicine, Houston Methodist Academic Institute, Houston, 77030, TX, United States; Li S., Division of Hematology and Oncology, Department of Medicine, Mayo Clinic, Jacksonville, 32224, FL, United States; Yu Y., Department of Quantitative Health Sciences, Mayo Clinic, Rochester, 55905, MN, United States; Hu X., Department of Artificial Intelligence and Informatics, Mayo Clinic, Jacksonville, 32224, FL, United States; Yang D., Department of Translational Molecular Pathology, The University of Texas MD Anderson Cancer Center, Houston, 77030, TX, United States; Feng J., Department of Artificial Intelligence and Informatics, Mayo Clinic, Jacksonville, 32224, FL, United States; Li Z., McWilliams School of Biomedical Informatics, The University of Texas Health Science Center at Houston, Houston, 77030, TX, United States; He J., McWilliams School of Biomedical Informatics, The University of Texas Health Science Center at Houston, Houston, 77030, TX, United States; Tao W., Department of Biostatistics & Data Science, School of Public Health, The University of Texas Health Science Center at Houston, Houston, 77030, TX, United States; Duan T., Department of Artificial Intelligence and Informatics, Mayo Clinic, Jacksonville, 32224, FL, United States; Lou Y., Division of Hematology and Oncology, Department of Medicine, Mayo Clinic, Jacksonville, 32224, FL, United States; Li F., Department of Artificial Intelligence and Informatics, Mayo Clinic, Jacksonville, 32224, FL, United States; Tao C., Department of Artificial Intelligence and Informatics, Mayo Clinic, Jacksonville, 32224, FL, United States","Objectives: Precise literature recommendation and summarization are crucial for biomedical professionals. While the latest iteration of generative pretrained transformer (GPT) incorporates 2 distinct modes—real-time search and pretrained model utilization—it encounters challenges in dealing with these tasks. Specifically, the real-time search can pinpoint some relevant articles but occasionally provides fabricated papers, whereas the pretrained model excels in generating well-structured summaries but struggles to cite specific sources. In response, this study introduces RefAI, an innovative retrieval-augmented generative tool designed to synergize the strengths of large language models (LLMs) while overcoming their limitations. Materials and Methods: RefAI utilized PubMed for systematic literature retrieval, employed a novel multivariable algorithm for article recommendation, and leveraged GPT-4 turbo for summarization. Ten queries under 2 prevalent topics (“cancer immunotherapy and target therapy” and “LLMs in medicine”) were chosen as use cases and 3 established counterparts (ChatGPT-4, ScholarAI, and Gemini) as our baselines. The evaluation was conducted by 10 domain experts through standard statistical analyses for performance comparison. Results: The overall performance of RefAI surpassed that of the baselines across 5 evaluated dimensions—relevance and quality for literature recommendation, accuracy, comprehensiveness, and reference integration for summarization, with the majority exhibiting statistically significant improvements (P-values <.05). Discussion: RefAI demonstrated substantial improvements in literature recommendation and summarization over existing tools, addressing issues like fabricated papers, metadata inaccuracies, restricted recommendations, and poor reference integration. Conclusion: By augmenting LLM with external resources and a novel ranking algorithm, RefAI is uniquely capable of recommending high-quality literature and generating well-structured summaries, holding the potential to meet the critical needs of biomedical professionals in navigating and synthesizing vast amounts of scientific literature. # The Author(s) 2024. Published by Oxford University Press on behalf of the American Medical Informatics Association. All rights reserved.","generative pretrained transformer; large language model; literature recommendation; retrieval-augmented generation; text summarization","Algorithms; Information Storage and Retrieval; Natural Language Processing; PubMed; Article; artificial intelligence; cancer immunotherapy; ChatGPT; citation metrics; comparative study; data accuracy; data integration; generative pretrained transformer; human; information retrieval; journal impact factor; large language model; medical informatics; medical information system; medical literature; Medline; metadata; molecularly targeted therapy; post hoc analysis; RefAI; search engine; algorithm; Medline; natural language processing; procedures","","Oxford University Press","English","Article","Final","","Scopus","2-s2.0-85198666791"
"Kim S.; Yoon J.","Kim, Seonho (56479372000); Yoon, Juntae (7403587525)","56479372000; 7403587525","VAIV bio-discovery service using transformer model and retrieval augmented generation","2024","BMC Bioinformatics","25","1","273","","","","0","10.1186/s12859-024-05903-6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201733274&doi=10.1186%2fs12859-024-05903-6&partnerID=40&md5=5bffafc8b5b0a0277cc0fe14dd16c17a","Department of Computer Science, Sogang University, 35, Baekbeom-Ro, Mapo-Gu, Seoul, South Korea; VAIV Company Inc, 97, Dokseodang-Ro, Yongsan-Gu, Seoul, South Korea","Kim S., Department of Computer Science, Sogang University, 35, Baekbeom-Ro, Mapo-Gu, Seoul, South Korea; Yoon J., VAIV Company Inc, 97, Dokseodang-Ro, Yongsan-Gu, Seoul, South Korea","Background: There has been a considerable advancement in AI technologies like LLM and machine learning to support biomedical knowledge discovery. Main body: We propose a novel biomedical neural search service called ‘VAIV Bio-Discovery’, which supports enhanced knowledge discovery and document search on unstructured text such as PubMed. It mainly handles with information related to chemical compound/drugs, gene/proteins, diseases, and their interactions (chemical compounds/drugs-proteins/gene including drugs-targets, drug-drug, and drug-disease). To provide comprehensive knowledge, the system offers four search options: basic search, entity and interaction search, and natural language search. We employ T5slim_dec, which adapts the autoregressive generation task of the T5 (text-to-text transfer transformer) to the interaction extraction task by removing the self-attention layer in the decoder block. It also assists in interpreting research findings by summarizing the retrieved search results for a given natural language query with Retrieval Augmented Generation (RAG). The search engine is built with a hybrid method that combines neural search with the probabilistic search, BM25. Conclusion: As a result, our system can better understand the context, semantics and relationships between terms within the document, enhancing search accuracy. This research contributes to the rapidly evolving biomedical field by introducing a new service to access and discover relevant knowledge. © The Author(s) 2024.","Biomedical interaction extraction; Embedding; LLM; Natural language processing; Neural search; RAG; T5; Text mining; Transformer","Data Mining; Information Storage and Retrieval; Knowledge Discovery; Machine Learning; Natural Language Processing; Neural Networks, Computer; PubMed; Search Engine; Drug interactions; Organometallics; Phosphate minerals; Biomedical interaction extraction; Embeddings; Interaction extraction; Language processing; LLM; Natural language processing; Natural languages; Neural search; Retrieval augmented generation; T5; Text-mining; Transformer; artificial neural network; data mining; information retrieval; knowledge discovery; machine learning; Medline; natural language processing; procedures; search engine; Drug discovery","","BioMed Central Ltd","English","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85201733274"
"Li L.; Shi R.; Guo X.; Jiang H.","Li, Li (59368968700); Shi, Rongliang (58604900500); Guo, Xu (59369275000); Jiang, Hongxin (59369071200)","59368968700; 58604900500; 59369275000; 59369071200","Diagnosis of Power System Defects by Large Language Models and Graph Neural Networks; [融合大模型与图神经网络的电力设备缺陷诊断]","2024","Journal of Frontiers of Computer Science and Technology","18","10","","2643","2655","12","0","10.3778/j.issn.1673-9418.2405085","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206550784&doi=10.3778%2fj.issn.1673-9418.2405085&partnerID=40&md5=784afa6099fe281304ef879b993f663a","Department of Computer, North China Electric Power University, Hebei, Baoding, 071003, China; Hebei Key Laboratory of Knowledge Computing for Energy & Power, Hebei, Baoding, 071003, China; Beijing Join Bright Digital Power Technology Co., Ltd., Beijing, 100085, China","Li L., Department of Computer, North China Electric Power University, Hebei, Baoding, 071003, China, Hebei Key Laboratory of Knowledge Computing for Energy & Power, Hebei, Baoding, 071003, China; Shi R., Department of Computer, North China Electric Power University, Hebei, Baoding, 071003, China, Beijing Join Bright Digital Power Technology Co., Ltd., Beijing, 100085, China; Guo X., Department of Computer, North China Electric Power University, Hebei, Baoding, 071003, China; Jiang H., Department of Computer, North China Electric Power University, Hebei, Baoding, 071003, China","Defect ratings and analysis and processing of different devices and equipment in the power system are often affected by the subjectivity of operation and maintenance personnel, resulting in different severity ratings for the same defect text description. Differences in expertise also lead to differences in diagnostic analysis and different diagnostic efficiency. In order to improve the accuracy and efficiency of defect diagnosis, a defect text rating classification method based on graph neural network and a large model intelligent diagnosis and analysis assistant are proposed. Firstly, a professional dictionary is constructed to normalize the text description using natural language processing algorithms. Secondly, the semantic representation of defective text is optimized by statistical methods. Then, graph attention neural network and robustly optimized BERT approach (RoBERTa) are integrated to accurately rate and classify defective text. Finally, low-rank adaptation (LoRA) fine-tuning training based on the large language model Qwen1.5-14B-Chat is performed to obtain the large model Qwen-ElecDiag for power equipment diagnosis, which is combined with retrieval enhancement to generate the assistant for defect diagnosis of technology development equipment. In addition, the collation provides the instruction dataset for fine-tuning the power equipment diagnosis macro-model. Comparative experimental results show that the proposed graph neural network-based defect rating classification method improves nearly 8 percentage points in accuracy over the optimal baseline model BERT; the diagnostic assistant’s power knowledge as well as defect diagnostic capability is improved. By improving the accuracy of defect ratings and providing comprehensive specialized diagnostic suggestions, it not only improves the intelligent level of power equipment O&M, but also provides new solutions for intelligent O&M in other vertical fields. © 2024 Journal of Computer Engineering and Applications Beijing Co., Ltd.; Science Press. All rights reserved.","defect diagnosis; graph neural networks; intelligent operation; large language model; low-rank adaptation (LoRA) fine-tuning; maintenance; power system; retrieval-augmented generation","","","Journal of Computer Engineering and Applications Beijing Co., Ltd.; Science Press","Chinese","Article","Final","","Scopus","2-s2.0-85206550784"
"Gargari O.K.; Fatehi F.; Mohammadi I.; Firouzabadi S.R.; Shafiee A.; Habibi G.","Gargari, Omid Kohandel (57395032400); Fatehi, Farhad (25622350500); Mohammadi, Ida (58085064700); Firouzabadi, Shahryar Rajai (57213062369); Shafiee, Arman (57449054000); Habibi, Gholamreza (57225831786)","57395032400; 25622350500; 58085064700; 57213062369; 57449054000; 57225831786","Diagnostic accuracy of large language models in psychiatry","2024","Asian Journal of Psychiatry","100","","104168","","","","0","10.1016/j.ajp.2024.104168","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200587599&doi=10.1016%2fj.ajp.2024.104168&partnerID=40&md5=23c61c347d4c82d18dbd1e31cef318df","Farzan Artificial Intelligence Team, Farzan Clinical Research Institute, Tehran, Iran; Centre for Health Services Research, Faculty of Medicine, The University of Queensland, Brisbane, Australia; School of Psychological Sciences, Monash University, Melbourne, Australia","Gargari O.K., Farzan Artificial Intelligence Team, Farzan Clinical Research Institute, Tehran, Iran; Fatehi F., Centre for Health Services Research, Faculty of Medicine, The University of Queensland, Brisbane, Australia, School of Psychological Sciences, Monash University, Melbourne, Australia; Mohammadi I., Farzan Artificial Intelligence Team, Farzan Clinical Research Institute, Tehran, Iran; Firouzabadi S.R., Farzan Artificial Intelligence Team, Farzan Clinical Research Institute, Tehran, Iran; Shafiee A., Farzan Artificial Intelligence Team, Farzan Clinical Research Institute, Tehran, Iran; Habibi G., Farzan Artificial Intelligence Team, Farzan Clinical Research Institute, Tehran, Iran","Introduction: Medical decision-making is crucial for effective treatment, especially in psychiatry where diagnosis often relies on subjective patient reports and a lack of high-specificity symptoms. Artificial intelligence (AI), particularly Large Language Models (LLMs) like GPT, has emerged as a promising tool to enhance diagnostic accuracy in psychiatry. This comparative study explores the diagnostic capabilities of several AI models, including Aya, GPT-3.5, GPT-4, GPT-3.5 clinical assistant (CA), Nemotron, and Nemotron CA, using clinical cases from the DSM-5. Methods: We curated 20 clinical cases from the DSM-5 Clinical Cases book, covering a wide range of psychiatric diagnoses. Four advanced AI models (GPT-3.5 Turbo, GPT-4, Aya, Nemotron) were tested using prompts to elicit detailed diagnoses and reasoning. The models' performances were evaluated based on accuracy and quality of reasoning, with additional analysis using the Retrieval Augmented Generation (RAG) methodology for models accessing the DSM-5 text. Results: The AI models showed varied diagnostic accuracy, with GPT-3.5 and GPT-4 performing notably better than Aya and Nemotron in terms of both accuracy and reasoning quality. While models struggled with specific disorders such as cyclothymic and disruptive mood dysregulation disorders, others excelled, particularly in diagnosing psychotic and bipolar disorders. Statistical analysis highlighted significant differences in accuracy and reasoning, emphasizing the superiority of the GPT models. Discussion: The application of AI in psychiatry offers potential improvements in diagnostic accuracy. The superior performance of the GPT models can be attributed to their advanced natural language processing capabilities and extensive training on diverse text data, enabling more effective interpretation of psychiatric language. However, models like Aya and Nemotron showed limitations in reasoning, indicating a need for further refinement in their training and application. Conclusion: AI holds significant promise for enhancing psychiatric diagnostics, with certain models demonstrating high potential in interpreting complex clinical descriptions accurately. Future research should focus on expanding the dataset and integrating multimodal data to further enhance the diagnostic capabilities of AI in psychiatry. © 2024 Elsevier B.V.","Artificial intelligence (AI); Diagnostic accuracy; DSM-5 clinical vignettes; Large Language Models (LLMs); Natural Language Processing (NLP); Psychiatry","Adult; Artificial Intelligence; Clinical Decision-Making; Diagnostic and Statistical Manual of Mental Disorders; Humans; Mental Disorders; Natural Language Processing; Psychiatry; anxiety disorder; Article; artificial intelligence; bipolar disorder; Clinical Assistant; depression; diagnostic accuracy; DSM-5; GPT-3.5; GPT-4; human; language model; large language model; Nemotron; Nemotron CA; psychiatry; adult; artificial intelligence; clinical decision making; comparative study; diagnosis; Diagnostic and Statistical Manual of Mental Disorders; mental disease; natural language processing; procedures","","Elsevier B.V.","English","Article","Final","","Scopus","2-s2.0-85200587599"
"Rome S.; Chen T.; Tang R.; Zhou L.; Ture F.","Rome, Scott (57223274218); Chen, Tianwen (57223287328); Tang, Raphael (57204048147); Zhou, Luwei (59144651900); Ture, Ferhan (25926158000)","57223274218; 57223287328; 57204048147; 59144651900; 25926158000","""Ask Me Anything"": How Comcast Uses LLMs to Assist Agents in Real Time","2024","SIGIR 2024 - Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval","","","","2827","2831","4","0","10.1145/3626772.3661345","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200538709&doi=10.1145%2f3626772.3661345&partnerID=40&md5=cb075503431f16e2d0fe2355321d27fc","Comcast AI Technologies, Philadelphia, PA, United States","Rome S., Comcast AI Technologies, Philadelphia, PA, United States; Chen T., Comcast AI Technologies, Philadelphia, PA, United States; Tang R., Comcast AI Technologies, Philadelphia, PA, United States; Zhou L., Comcast AI Technologies, Philadelphia, PA, United States; Ture F., Comcast AI Technologies, Philadelphia, PA, United States","Customer service is how companies interface with their customers. It can contribute heavily towards the overall customer satisfaction. However, high-quality service can become expensive, creating an incentive to make it as cost efficient as possible and prompting most companies to utilize AI-powered assistants, or ""chat bots"". On the other hand, human-to-human interaction is still desired by customers, especially when it comes to complex scenarios such as disputes and sensitive topics like bill payment. This raises the bar for customer service agents. They need to accurately understand the customer's question or concern, identify a solution that is acceptable yet feasible (and within the company's policy), all while handling multiple conversations at once. In this work, we introduce ""Ask Me Anything""(AMA) as an add-on feature to an agent-facing customer service interface. AMA allows agents to ask questions to a large language model (LLM) on demand, as they are handling customer conversations - -the LLM provides accurate responses in real-time, reducing the amount of context switching the agent needs. In our internal experiments, we find that agents using AMA versus a traditional search experience spend approximately 10% fewer seconds per conversation containing a search, translating to millions of dollars of savings annually. Agents that used the AMA feature provided positive feedback nearly 80% of the time, demonstrating its usefulness as an AI-assisted feature for customer care. © 2024 ACM.","assistive ai; customer care; llm; rag; reranking; vector db","Customer satisfaction; Assistive; Assistive ai; Customer care; Customer-service; Language model; Llm; Rag; Re-ranking; Real- time; Vector db; Sales","","Association for Computing Machinery, Inc","English","Conference paper","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85200538709"
"Ye L.; Lei Z.; Yin J.; Chen Q.; Zhou J.; He L.","Ye, Linhao (58550374200); Lei, Zhikai (58550269000); Yin, Jianghao (57442443700); Chen, Qin (56482442600); Zhou, Jie (57756978000); He, Liang (35758919600)","58550374200; 58550269000; 57442443700; 56482442600; 57756978000; 35758919600","Boosting Conversational Question Answering with Fine-Grained Retrieval-Augmentation and Self-Check","2024","SIGIR 2024 - Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval","","","","2301","2305","4","0","10.1145/3626772.3657980","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200608699&doi=10.1145%2f3626772.3657980&partnerID=40&md5=caab94ebb614ec78cb80317aaed568bc","East China Normal University, ShangHai, China","Ye L., East China Normal University, ShangHai, China; Lei Z., East China Normal University, ShangHai, China; Yin J., East China Normal University, ShangHai, China; Chen Q., East China Normal University, ShangHai, China; Zhou J., East China Normal University, ShangHai, China; He L., East China Normal University, ShangHai, China","Retrieval-Augmented Generation (RAG) aims to generate more reliable and accurate responses, by augmenting large language models(LLMs) with the external vast and dynamic knowledge. Most previous work focuses on using RAG for single-round question answering, while how to adapt RAG to the complex conversational setting wherein the question is interdependent on the preceding context is not well studied. In this paper, we propose a conversation-level RAG (ConvRAG) approach, which incorporates fine-grained retrieval augmentation and self-check for conversational question answering (CQA). In particular, our approach consists of three components, namely conversational question refiner, fine-grained retriever and self-check based response generator, which work collaboratively for question understanding and relevant information acquisition in conversational settings. Extensive experiments demonstrate the great advantages of our approach over the state-of-the-art baselines. Moreover, we also release a Chinese CQA dataset with new features including reformulated question, extracted keyword, retrieved paragraphs and their helpfulness, which facilitates further researches in RAG enhanced CQA. © 2024 ACM.","conversational question answering; large language models; retrieval-augmented generation","Information retrieval; Accurate response; Conversational question answering; Fine grained; Information acquisitions; Language model; Large language model; Question Answering; Retrieval-augmented generation; State of the art; Three-component; Computational linguistics","","Association for Computing Machinery, Inc","English","Conference paper","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85200608699"
"Abdulnazar A.; Roller R.; Schulz S.; Kreuzthaler M.","Abdulnazar, Akhila (58264199400); Roller, Roland (35485584600); Schulz, Stefan (57189519350); Kreuzthaler, Markus (16039723400)","58264199400; 35485584600; 57189519350; 16039723400","Large Language Models for Clinical Text Cleansing Enhance Medical Concept Normalization","2024","IEEE Access","","","","","","","0","10.1109/ACCESS.2024.3472500","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205853418&doi=10.1109%2fACCESS.2024.3472500&partnerID=40&md5=5d09e5da19a89b62a50d4c17e38c24b8","Medical University of Graz, Institute for Medical Informatics, Statistics and Documentation, Austria; CBmed GmbH - Center for Biomarker Research in Medicine, Graz, Austria; German Research Center for Artificial Intelligence (DFKI), Berlin, Germany","Abdulnazar A., Medical University of Graz, Institute for Medical Informatics, Statistics and Documentation, Austria, CBmed GmbH - Center for Biomarker Research in Medicine, Graz, Austria; Roller R., German Research Center for Artificial Intelligence (DFKI), Berlin, Germany; Schulz S., Medical University of Graz, Institute for Medical Informatics, Statistics and Documentation, Austria; Kreuzthaler M., Medical University of Graz, Institute for Medical Informatics, Statistics and Documentation, Austria","Most clinical information is only available as free text. Large language models (LLMs) are increasingly applied to clinical data to streamline communication, enhance the accuracy of clinical documentation, and ultimately improve healthcare delivery. This study focuses on a corpus of anonymized clinical narratives in German. On the one hand it evaluates the use of ChatGPT for text cleaning, i.e., the automatic rephrasing of raw text into a more readable and standardized form, and on the other hand for retrieval-augmented generation (RAG). In both tasks, the final goal was medical concept normalization (MCN), i.e., the annotation of text segments with codes from a controlled vocabulary using natural language processing.We found that ChatGPT (GPT-4) significantly improves precision and recall compared to simple dictionary matching. For all scenarios, the importance of the underlying terminological basis was also demonstrated. Maximum F1 scores of 0.607, 0.735 and 0.754 (i.e, for top 1, 5 and 10 matches) were achieved through a pipeline including document cleaning, bi-encoder-based term matching based on a large domain dictionary linked to SNOMED CT, and finally re-ranking using RAG. © 2013 IEEE.","ChatGPT; Medical Concept Normalization; Retrieval Augmented Generation; Text Cleansing","Electronic health record; Medical informatics; Natural language processing systems; ChatGPT; Clinical data; Clinical information; Free texts; Language model; Medical concept normalization; Medical concepts; Normalisation; Retrieval augmented generation; Text cleansing; Pipeline codes","","Institute of Electrical and Electronics Engineers Inc.","English","Article","Article in press","All Open Access; Gold Open Access","Scopus","2-s2.0-85205853418"
"Qayyum K.; Hassan M.; Ahmadi-Pour S.; Jha C.K.; Drechsler R.","Qayyum, Khushboo (57221965749); Hassan, Muhammad (56018112700); Ahmadi-Pour, Sallar (57211430953); Jha, Chandan Kumar (57225085520); Drechsler, Rolf (55172914000)","57221965749; 56018112700; 57211430953; 57225085520; 55172914000","From Bugs to Fixes: HDL Bug Identification and Patching using LLMs and RAG","2024","2024 IEEE LLM Aided Design Workshop, LAD 2024","","","","","","","0","10.1109/LAD62341.2024.10691874","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206634939&doi=10.1109%2fLAD62341.2024.10691874&partnerID=40&md5=c67291c419fe718f73921effd8d05c3a","Dfki GmbH, Cyber-Physical Systems, Bremen, 28359, Germany; University of Bremen, Institute of Computer Science, Bremen, 28359, Germany","Qayyum K., Dfki GmbH, Cyber-Physical Systems, Bremen, 28359, Germany; Hassan M., Dfki GmbH, Cyber-Physical Systems, Bremen, 28359, Germany, University of Bremen, Institute of Computer Science, Bremen, 28359, Germany; Ahmadi-Pour S., University of Bremen, Institute of Computer Science, Bremen, 28359, Germany; Jha C.K., University of Bremen, Institute of Computer Science, Bremen, 28359, Germany; Drechsler R., Dfki GmbH, Cyber-Physical Systems, Bremen, 28359, Germany, University of Bremen, Institute of Computer Science, Bremen, 28359, Germany","In this paper, for the first time, we present a methodology that combines Retrieval Augmented Generation (RAG) with Large Language Models (LLM) to help with the identification and patching of Verilog Hardware Descriptive Language (HDL). If the methodology fails to patch a bug, an iterative and systematic bug patching closure technique is used. Additionally, we classify different types of bugs that are found in hardware and assess the performance of our approach for identifying and patching of bugs from each category. We tested our approach on three different OpenTitan designs and found out that our methodology can patch all bugs as long as they are not constant values.  © 2024 IEEE.","Formal verification; Large Language Models; LLMs; RAG; Retrieval Augmented Generation","Computer hardware description languages; Formal languages; Modeling languages; Constant values; Hardware descriptive languages; Language model; Large language model; LLM; Performance; Retrieval augmented generation; Formal verification","","Institute of Electrical and Electronics Engineers Inc.","English","Conference paper","Final","","Scopus","2-s2.0-85206634939"
"Arefeen M.A.; Debnath B.; Sarwar Uddin M.Y.; Chakradhar S.","Arefeen, Md Adnan (57220584745); Debnath, Biplob (24469971600); Sarwar Uddin, Md Yusuf (57506768100); Chakradhar, Srimat (7003995360)","57220584745; 24469971600; 57506768100; 7003995360","ViTA: An Efficient Video-to-Text Algorithm using VLM for RAG-based Video Analysis System","2024","IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops","","","","2266","2274","8","0","10.1109/CVPRW63382.2024.00232","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206471705&doi=10.1109%2fCVPRW63382.2024.00232&partnerID=40&md5=9eacb58958d02d38f965321a2c41cfae","Nec Laboratories America, United States; University of Missouri-Kansas City, United States","Arefeen M.A., Nec Laboratories America, United States, University of Missouri-Kansas City, United States; Debnath B., Nec Laboratories America, United States; Sarwar Uddin M.Y., University of Missouri-Kansas City, United States; Chakradhar S., Nec Laboratories America, United States","Retrieval-augmented generation (RAG) is used in natural language processing (NLP) to provide query-relevant information in enterprise documents to large language models (LLMs). Such enterprise context enables the LLMs to generate more informed and accurate responses. When enterprise data is primarily videos, AI models like vision language models (VLMs) are necessary to convert information in videos into text. While essential, this conversion is a bottleneck, especially for large corpus of videos. It delays the timely use of enterprise videos to generate useful responses.We propose ViTA, a novel method that leverages two unique characteristics of VLMs to expedite the conversion process. As VLMs output more text tokens, they incur higher latency. In addition, large (heavyweight) VLMs can extract intricate details from images and videos, but they incur much higher latency per output token when compared to smaller (lightweight) VLMs that may miss details. To expedite conversion, ViTA first employs a lightweight VLM to quickly understand the gist or overview of an image or a video clip, and directs a heavyweight VLM (through prompt engineering) to extract additional details by using only a few (preset number of) output tokens. Our experimental results show that ViTA expedites the conversion time by as much as 43%, without compromising the accuracy of responses when compared to a baseline system that only uses a heavyweight VLM. © 2024 IEEE.","Large Language Models (LLMs); Natural Language Processing; Retrieval Augmented Generation (RAG); Video Analytics; Vision Language Models (VLMs)","Human computer interaction; Metadata; Modeling languages; Natural language processing systems; Query languages; Query processing; Search engines; Structured Query Language; Video analysis; Video signal processing; Visual analytics; Language model; Language processing; Large language model; Natural language processing; Natural languages; Retrieval augmented generation; Video analysis; Video analytics; Vision language model; Visual languages","","IEEE Computer Society","English","Conference paper","Final","","Scopus","2-s2.0-85206471705"
"Luu R.K.; Buehler M.J.","Luu, Rachel K. (57869652200); Buehler, Markus J. (7102467930)","57869652200; 7102467930","BioinspiredLLM: Conversational Large Language Model for the Mechanics of Biological and Bio-Inspired Materials","2024","Advanced Science","11","10","2306724","","","","15","10.1002/advs.202306724","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180443194&doi=10.1002%2fadvs.202306724&partnerID=40&md5=3c1f14b7571c7f547995d81baa7cefbf","Laboratory for Atomistic and Molecular Mechanics (LAMM), Massachusetts Institute of Technology, 77 Massachusetts Avenue, Cambridge, 02139, MA, United States; Department of Materials Science and Engineering, Massachusetts Institute of Technology, 77 Massachusetts Avenue, Cambridge, 02139, MA, United States; Center for Computational Science and Engineering, Schwarzman College of Computing, Massachusetts Institute of Technology, 77 Massachusetts Avenue, Cambridge, 02139, MA, United States","Luu R.K., Laboratory for Atomistic and Molecular Mechanics (LAMM), Massachusetts Institute of Technology, 77 Massachusetts Avenue, Cambridge, 02139, MA, United States, Department of Materials Science and Engineering, Massachusetts Institute of Technology, 77 Massachusetts Avenue, Cambridge, 02139, MA, United States; Buehler M.J., Laboratory for Atomistic and Molecular Mechanics (LAMM), Massachusetts Institute of Technology, 77 Massachusetts Avenue, Cambridge, 02139, MA, United States, Center for Computational Science and Engineering, Schwarzman College of Computing, Massachusetts Institute of Technology, 77 Massachusetts Avenue, Cambridge, 02139, MA, United States","The study of biological materials and bio-inspired materials science is well established; however, surprisingly little knowledge is systematically translated to engineering solutions. To accelerate discovery and guide insights, an open-source autoregressive transformer large language model (LLM), BioinspiredLLM, is reported. The model is finetuned with a corpus of over a thousand peer-reviewed articles in the field of structural biological and bio-inspired materials and can be prompted to recall information, assist with research tasks, and function as an engine for creativity. The model has proven that it is able to accurately recall information about biological materials and is further strengthened with enhanced reasoning ability, as well as with Retrieval-Augmented Generation (RAG) to incorporate new data during generation that can also help to traceback sources, update the knowledge base, and connect knowledge domains. BioinspiredLLM also has shown to develop sound hypotheses regarding biological materials design and remarkably so for materials that have never been explicitly studied before. Lastly, the model shows impressive promise in collaborating with other generative artificial intelligence models in a workflow that can reshape the traditional materials design process. This collaborative generative artificial intelligence method can stimulate and enhance bio-inspired materials design workflows. Biological materials are at a critical intersection of multiple scientific fields and models like BioinspiredLLM help to connect knowledge domains. © 2023 The Authors. Advanced Science published by Wiley-VCH GmbH.","bio-inspiration; biological materials; generative artificial intelligence; hierarchical structures; large language models; mechanical properties","Artificial Intelligence; Biomimetic Materials; Engineering; Language; Biomechanics; Biomimetics; Computational linguistics; Degrees of freedom (mechanics); Knowledge based systems; Structural design; biomimetic material; Bio-inspiration; Bio-inspired materials; Engineering solutions; Generative artificial intelligence; Hierarchical structures; Knowledge domains; Language model; Large language model; Material science; Materials design; artificial intelligence; chemistry; engineering; language; Biological materials","","John Wiley and Sons Inc","English","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85180443194"
"Cvetković S.; Špeletić M.; Nikolić S.V.","Cvetković, Stevica (55407310900); Špeletić, Matija (59366912200); Nikolić, Saša V. (7102082765)","55407310900; 59366912200; 7102082765","Semantic Exploration of Industrial Standards Using Large Language Models","2024","Lecture Notes in Networks and Systems","860 LNNS","","","289","298","9","0","10.1007/978-3-031-71419-1_25","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206382037&doi=10.1007%2f978-3-031-71419-1_25&partnerID=40&md5=1e056c93e05a9c6244ab73deac1aa775","Faculty of Electronic Engineering, University of Niš, Niš, 18000, Serbia","Cvetković S., Faculty of Electronic Engineering, University of Niš, Niš, 18000, Serbia; Špeletić M., Faculty of Electronic Engineering, University of Niš, Niš, 18000, Serbia; Nikolić S.V., Faculty of Electronic Engineering, University of Niš, Niš, 18000, Serbia","This paper investigates the effectiveness of using Large Language Models (LLMs) within specialized domains, such as industrial standards semantic exploration. While pre-trained LLMs have demonstrated remarkable proficiency in various generic language tasks, their application to domain-specific knowledge tasks requires a cautious approach due to the potential risk of hallucination in responses. Recently, the Retrieval Augmented Generation (RAG) framework has been proposed to enhance pre-trained LLMs with data retrieval mechanisms, enabling them to incorporate precise, context-relevant information from external data sources. Motivated by this, we adapted a RAG approach to the context of the OPC UA industrial standard documentation. To ensure a fair evaluation, we introduced a preliminary benchmark dataset comprising the most prevalent questions and answers related to the OPC UA standard. Our experimental results indicate that the RAG approach can be effectively employed for the semantic search of OPC UA standard documentation. We found the RAG approach significantly improves faithfulness of existing pre-trained LLMs, offering substantial potential for further exploration and generalization towards a comprehensive semantic understanding approach for industrial standards on a global scale. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.","Industrial Standards; Large Language Models (LLM); OPC UA Standard; Retrieval Augmented Generation (RAG); Semantic Search","Benchmarking; Metadata; Modeling languages; Online searching; Domain-specific knowledge; Industrial standards; Knowledge tasks; Language model; Large language model; OPC UA standard; Potential risks; Retrieval augmented generation; Semantic search; Standard documentation; Semantics","Trajanović M.; Zdravković M.; Filipović N.","Springer Science and Business Media Deutschland GmbH","English","Conference paper","Final","","Scopus","2-s2.0-85206382037"
"Visciarelli M.; Guidi G.; Morselli L.; Brandoni D.; Fiameni G.; Monti L.; Bianchini S.; Tommasi C.","Visciarelli, Michele (59353518700); Guidi, Giovanni (59353801100); Morselli, Laura (59352953900); Brandoni, Domitilla (57214589369); Fiameni, Giuseppe (35084827400); Monti, Luisa (59353661600); Bianchini, Stefano (58709420400); Tommasi, Cosimo (59353234300)","59353518700; 59353801100; 59352953900; 57214589369; 35084827400; 59353661600; 58709420400; 59353234300","SAVIA: Artificial Intelligence in support of the lawmaking process","2024","CEUR Workshop Proceedings","3762","","","436","440","4","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205585505&partnerID=40&md5=a08b95d679e777674556004bf4c7052c","CINECA, via Magnanelli 6/3, B0, Casalecchio di Reno, 40033, Italy; NVIDIA AI Technology Center, Milan, Italy; Assemblea Legislativa Emilia Romagna, viale Aldo Moro 50, Bologna, 41127, Italy","Visciarelli M., CINECA, via Magnanelli 6/3, B0, Casalecchio di Reno, 40033, Italy; Guidi G., CINECA, via Magnanelli 6/3, B0, Casalecchio di Reno, 40033, Italy; Morselli L., CINECA, via Magnanelli 6/3, B0, Casalecchio di Reno, 40033, Italy; Brandoni D., CINECA, via Magnanelli 6/3, B0, Casalecchio di Reno, 40033, Italy; Fiameni G., NVIDIA AI Technology Center, Milan, Italy; Monti L., Assemblea Legislativa Emilia Romagna, viale Aldo Moro 50, Bologna, 41127, Italy; Bianchini S., Assemblea Legislativa Emilia Romagna, viale Aldo Moro 50, Bologna, 41127, Italy; Tommasi C., Assemblea Legislativa Emilia Romagna, viale Aldo Moro 50, Bologna, 41127, Italy","We explore the use of open-source Large Language Models (LLMs) to support legal professionals, lawmakers, and citizens in accessing information on the current and past legislation of the Emilia-Romagna region. We develop a generative AI tool based on the Retrieval-Augmented Generation (RAG) technique to answer questions related to regional laws and their implementing acts, retrieving relevant information from the Emilia-Romagna law corpus. To adapt pre-trained LLMs to this downstream task, we follow a multi-step approach. First, we use the QLoRa technique to quantize and adapt the pre-trained LLMs to the regional legal text dataset. Next, we fine-tune the domain-adapted models using an ""ad-hoc"" instruction-based dataset. We then implement a module to retrieve relevant contextual information from the legal documents dataset. Finally, we align the models with domain-specific instructions using RAG-based prompting. We evaluate the performance of the domain-adapted models using the perplexity metric, and the results of the final fine-tuned models are assessed by domain experts, focusing on the quality of the generated text and the relevance of the answers. Our results show that domain adaptation on domain-specific text is a crucial step for enhancing the quality of the generated text in expert domains, such as legal texts, which contain a vast amount of specialized vocabulary and expressions. This approach leads to higher performance compared to models fine-tuned only on small Question-Answer datasets. Additionally, our findings highlight the importance of the retrieval module, which must be able to reliably find the most relevant documents to provide useful and up-to-date insights to lawmakers and citizens. © 2024 Copyright for this paper by its authors.","Generative AI; Legal AI; LLM; NLP","Generative adversarial networks; Laws and legislation; 'current; Domain specific; Generation techniques; Generative AI; Language model; Large language model; Legal AI; Legal texts; Open-source; Performance; Open systems","Di Martino S.; University of Naples Federico II, Department of Electrical Engineering and Information Technology (DIETI), Via Claudio 21, Naples; Sansone C.; University of Naples Federico II, Department of Electrical Engineering and Information Technology (DIETI), Via Claudio 21, Naples; Masciari E.; University of Naples Federico II, Department of Electrical Engineering and Information Technology (DIETI), Via Claudio 21, Naples; Rossi S.; University of Naples Federico II, Department of Electrical Engineering and Information Technology (DIETI), Via Claudio 21, Naples; Gravina M.; University of Naples Federico II, Department of Electrical Engineering and Information Technology (DIETI), Via Claudio 21, Naples","CEUR-WS","English","Conference paper","Final","","Scopus","2-s2.0-85205585505"
"Wu L.; Xu J.; Thakkar S.; Gray M.; Qu Y.; Li D.; Tong W.","Wu, Leihong (55521475100); Xu, Joshua (24577976100); Thakkar, Shraddha (46161659500); Gray, Magnus (58535227000); Qu, Yanyan (58543861500); Li, Dongying (56045443100); Tong, Weida (7202449311)","55521475100; 24577976100; 46161659500; 58535227000; 58543861500; 56045443100; 7202449311","A framework enabling LLMs into regulatory environment for transparency and trustworthiness and its application to drug labeling document","2024","Regulatory Toxicology and Pharmacology","149","","105613","","","","0","10.1016/j.yrtph.2024.105613","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189677808&doi=10.1016%2fj.yrtph.2024.105613&partnerID=40&md5=70ba7ad28540dd61140a9166c0ce217a","Division of Bioinformatics and Biostatistics, National Center for Toxicological Research, US FDA, 3900 NCTR Rd, Jefferson AR, 72211, United States; Office of Translational Sciences, Center for Drug Evaluation and Research (CDER), US FDA, 10903 New Hampshire Avenue, Silver Spring, 20993, MD, United States","Wu L., Division of Bioinformatics and Biostatistics, National Center for Toxicological Research, US FDA, 3900 NCTR Rd, Jefferson AR, 72211, United States; Xu J., Division of Bioinformatics and Biostatistics, National Center for Toxicological Research, US FDA, 3900 NCTR Rd, Jefferson AR, 72211, United States; Thakkar S., Office of Translational Sciences, Center for Drug Evaluation and Research (CDER), US FDA, 10903 New Hampshire Avenue, Silver Spring, 20993, MD, United States; Gray M., Division of Bioinformatics and Biostatistics, National Center for Toxicological Research, US FDA, 3900 NCTR Rd, Jefferson AR, 72211, United States; Qu Y., Division of Bioinformatics and Biostatistics, National Center for Toxicological Research, US FDA, 3900 NCTR Rd, Jefferson AR, 72211, United States; Li D., Division of Bioinformatics and Biostatistics, National Center for Toxicological Research, US FDA, 3900 NCTR Rd, Jefferson AR, 72211, United States; Tong W., Division of Bioinformatics and Biostatistics, National Center for Toxicological Research, US FDA, 3900 NCTR Rd, Jefferson AR, 72211, United States","Regulatory agencies consistently deal with extensive document reviews, ranging from product submissions to both internal and external communications. Large Language Models (LLMs) like ChatGPT can be invaluable tools for these tasks, however present several challenges, particularly the proprietary information, combining customized function with specific review needs, and transparency and explainability of the model's output. Hence, a localized and customized solution is imperative. To tackle these challenges, we formulated a framework named askFDALabel on FDA drug labeling documents that is a crucial resource in the FDA drug review process. AskFDALabel operates within a secure IT environment and comprises two key modules: a semantic search and a Q&A/text-generation module. The Module S built on word embeddings to enable comprehensive semantic queries within labeling documents. The Module T utilizes a tuned LLM to generate responses based on references from Module S. As the result, our framework enabled small LLMs to perform comparably to ChatGPT with as a computationally inexpensive solution for regulatory application. To conclude, through AskFDALabel, we have showcased a pathway that harnesses LLMs to support agency operations within a secure environment, offering tailored functions for the needs of regulatory research. © 2024","Artificial intelligence; Drug labeling; FDALabel; Large language models (LLMs); Regulatory science; Retrieval-augmented generation (RAG); Transparency; Trustworthy","Drug Labeling; Humans; United States; United States Food and Drug Administration; Article; artificial intelligence; cardiotoxicity; ChatGPT; comparative study; controlled study; data processing; drug labeling; Food and Drug Administration; information processing; information retrieval; large language model; model; parameters; regulatory mechanism; regulatory science; retrieval augmented generation; semantics; transparency; trustworthiness; Food and Drug Administration; human; United States","","Academic Press Inc.","English","Article","Final","All Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85189677808"
"Miao J.; Thongprayoon C.; Craici I.M.; Cheungpasitporn W.","Miao, Jing (57221522072); Thongprayoon, Charat (55512490600); Craici, Iasmina M. (8730515900); Cheungpasitporn, Wisit (47160959700)","57221522072; 55512490600; 8730515900; 47160959700","How to improve ChatGPT performance for nephrologists: a technique guide","2024","Journal of Nephrology","37","5","","1397","1403","6","4","10.1007/s40620-024-01974-z","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193737083&doi=10.1007%2fs40620-024-01974-z&partnerID=40&md5=f72059946dbb0079c1d24e574789ef60","Division of Nephrology and Hypertension, Department of Medicine, Mayo Clinic, Rochester, MN, United States","Miao J., Division of Nephrology and Hypertension, Department of Medicine, Mayo Clinic, Rochester, MN, United States; Thongprayoon C., Division of Nephrology and Hypertension, Department of Medicine, Mayo Clinic, Rochester, MN, United States; Craici I.M., Division of Nephrology and Hypertension, Department of Medicine, Mayo Clinic, Rochester, MN, United States; Cheungpasitporn W., Division of Nephrology and Hypertension, Department of Medicine, Mayo Clinic, Rochester, MN, United States","Background: The integration of ChatGPT into nephrology presents opportunities for enhanced decision-making and patient care. However, refining its performance to meet the specific needs of nephrologists remains a challenge. This guide offers a strategic roadmap for advancing ChatGPT’s effectiveness in nephrological applications. Methods: Utilizing the advanced capabilities of GPT-4, we customized user profiles to optimize the model’s response quality for nephrological inquiries. We assessed the efficacy of chain-of-thought prompting versus standard prompting in delineating the diagnostic pathway for nephrogenic diabetes insipidus-associated hypernatremia and polyuria. Additionally, we explored the influence of integrating retrieval-augmented generation on the model’s proficiency in detailing pharmacological interventions to decelerate the progression from chronic kidney disease (CKD) G3 to end-stage kidney disease (ESKD), comparing it to responses without retrieval-augmented generation. Results: In contrast to the standard prompting, the chain-of-thought method offers a step-by-step diagnostic process that mirrors the intricate thought processes needed for diagnosing nephrogenic diabetes insipidus-related hypernatremia and polyuria. This begins with an initial assessment, notably including a water deprivation test. After evaluating the outcomes of this test, the approach continues by identifying potential causes. Furthermore, if a patient’s history suggests lithium usage, the chain-of-thought model adjusts by proposing a more customized course of action. In response to “List medication treatment to help slow progression of CKD G3 to ESKD?”, GPT-4 only provides a general summary of medication options. Nevertheless, a specialized GPT-4 model equipped with a retrieval-augmented generation system delivers more precise responses, including renin-angiotensin system inhibitors, sodium-glucose cotransporter-2 inhibitors, and mineralocorticoid receptor antagonists. This aligns well with the 2024 KDIGO guidelines. Conclusions: GPT-4, when integrated with chain-of-thought prompting and retrieval-augmented generation techniques, demonstrates enhanced performance in the nephrology domain. This guide underscores the transformative potential of chain-of-thought and retrieval-augmented generation techniques in optimizing ChatGPT for nephrology, and highlights the ongoing need for innovative, tailored AI solutions in specialized medical fields. Graphical Abstract: (Figure presented.) © The Author(s) under exclusive licence to Italian Society of Nephrology 2024.","Artificial intelligence; ChatGPT; Large language model; LLM; Nephrology; Technique guide","Diabetes Insipidus, Nephrogenic; Disease Progression; Humans; Hypernatremia; Kidney Failure, Chronic; Nephrologists; Nephrology; Polyuria; Renal Insufficiency, Chronic; mineralocorticoid antagonist; sodium glucose cotransporter 2; Article; artificial intelligence; ChatGPT; chronic kidney failure; decision making; diabetes insipidus; end stage renal disease; human; hyperglycemia; hypernatremia; nephrologist; polydipsia; polyuria; renin angiotensin aldosterone system; complication; diagnosis; disease exacerbation; nephrogenic diabetes insipidus; nephrology; therapy","","Springer Science and Business Media Deutschland GmbH","English","Article","Final","","Scopus","2-s2.0-85193737083"
"Wang C.; Gao X.-C.; Li X.-Y.; Xie Y.-D.","Wang, Chen (58407574200); Gao, Xin-Chang (59220392400); Li, Xin-Yong (59220609100); Xie, Yi-Ding (59220392500)","58407574200; 59220392400; 59220609100; 59220392500","Natural Language Interface for 3D Symbology: An Initial Design and Application to Utility Networks","2024","International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives","48","4/W11-2024","","145","151","6","0","10.5194/isprs-archives-XLVIII-4-W11-2024-145-2024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198651437&doi=10.5194%2fisprs-archives-XLVIII-4-W11-2024-145-2024&partnerID=40&md5=823cb88599fb0398f727067f5856218c","Anhui Province Key Laboratory of Wetland Ecosystem Protection and Restoration, Anhui University, Hefei, 230601, China; School of Resources and Environmental Engineering, Anhui University, Hefei, 230601, China","Wang C., Anhui Province Key Laboratory of Wetland Ecosystem Protection and Restoration, Anhui University, Hefei, 230601, China, School of Resources and Environmental Engineering, Anhui University, Hefei, 230601, China; Gao X.-C., Anhui Province Key Laboratory of Wetland Ecosystem Protection and Restoration, Anhui University, Hefei, 230601, China, School of Resources and Environmental Engineering, Anhui University, Hefei, 230601, China; Li X.-Y., Anhui Province Key Laboratory of Wetland Ecosystem Protection and Restoration, Anhui University, Hefei, 230601, China, School of Resources and Environmental Engineering, Anhui University, Hefei, 230601, China; Xie Y.-D., Anhui Province Key Laboratory of Wetland Ecosystem Protection and Restoration, Anhui University, Hefei, 230601, China, School of Resources and Environmental Engineering, Anhui University, Hefei, 230601, China","The growing adoption of digital twins in geomatics sectors requires efficient 3D mapping techniques. However, the complexity and cost of producing cartographically enriched 3D scenes pose significant challenges, hindering widespread application, particularly in domains with limited mapping expertise and budgets. The proposed methodology in this paper leverages recent advances in natural language processing and artificial intelligence, particularly large language models (LLMs), to reduce the expertise required for 3D mapping and to address the high costs and complexity associated with traditional cartographic processes. It introduces a natural language interface for 3D symbology, aimed at simplifying the design and automating the creation of cartographically enriched 3D scene. By allowing cartographers converse with the mapping system, the system translates verbal descriptions into structured symbology rules in 3D digital cartographic model, which are then used to generate cartographically enriched 3D scenes. The method chains multiple ad-hoc LLM-based agents for entity linking, conversation handling, and symbology rule verification. Prompt engineering methods, such as chain-of-though and retrieval augmented generation, have been used to guide the agents’ reasoning process or leverage knowledge base, respectively. Experiment and application in utility networks demonstrates the method’s capability to accurately interpret and execute 3D symbology rules from natural language inputs, resulting in cartographically enriched 3D scenes that are reproducible and scalable. This work represents a pioneer study to implement a natural language interface for 3D mapping. It not only enhances the usability and accessibility of 3D mapping in digital twins but also sets a foundational method for future research in natural language-based mapping interfaces. © Author(s) 2024.","3D cartography; Artificial Intelligence; Large Language Model; Natural Language Processing; Symbology","Artificial intelligence; Complex networks; Computational linguistics; Knowledge management; Mapping; Natural language processing systems; Three dimensional computer graphics; 3-D mapping; 3d cartography; 3D scenes; Language model; Language processing; Large language model; Natural language interfaces; Natural language processing; Natural languages; Symbology; Budget control","Diaz-Vilarino L.; Balado J.","International Society for Photogrammetry and Remote Sensing","English","Conference paper","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85198651437"
"Sun T.; Somalwar A.; Chan H.","Sun, Tienlan (59364224400); Somalwar, Anaiy (57221249283); Chan, Hinson (59364224500)","59364224400; 57221249283; 59364224500","Multimodal Retrieval Augmented Generation Evaluation Benchmark","2024","IEEE Vehicular Technology Conference","","","","","","","0","10.1109/VTC2024-Spring62846.2024.10683437","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206212550&doi=10.1109%2fVTC2024-Spring62846.2024.10683437&partnerID=40&md5=5eb97614f7585a3d697012b097374139","EduBeyond, BC, Canada; Uc Berkeley, CA, United States","Sun T., EduBeyond, BC, Canada; Somalwar A., Uc Berkeley, CA, United States; Chan H., EduBeyond, BC, Canada","While advances in prompt engineering and RAG have improved LLM proficiency in field-specific, specialized tasks, there has yet to be an industry standard or accepted evaluation metric of the highly fragmented RAG solutions that are currently being deployed. Thus, in this work, we focused on building a robust LLM and RAG evaluation platform. We contribute 1) a platform that evaluates an RAG system's performance on a multimodal input context for LLM question answering and 2) MRAFE: Multimodal Retrieval Augmented Feature Extractor, which processes information from the input to our platform. Through various automated and systematic hand testing, we find that our evaluation benchmarks are useful in determining noise robustness, negative rejection, information integration, and counterfactual rejection. Such a platform would serve as a useful tool for developers iterating on retrieval systems and regulatory bodies creating AI-focused governance alike. © 2024 IEEE.","Artificial Intelligence; Large Language Models; Machine Learning; Retrieval Augmented Generation","Adversarial machine learning; Benchmarking; Contrastive Learning; Information retrieval; Machine learning; Modeling languages; Question answering; Search engines; Evaluation metrics; Evaluation platforms; In-field; Industry standards; Language model; Large language model; Machine-learning; Multi-modal; Retrieval augmented generation; Systems performance; Integration testing","","Institute of Electrical and Electronics Engineers Inc.","English","Conference paper","Final","","Scopus","2-s2.0-85206212550"
"Rejithkumar G.; Anish P.R.; Shukla J.; Ghaisas S.","Rejithkumar, Gokul (57226691163); Anish, Preethu Rose (55892550700); Shukla, Jyoti (57716623800); Ghaisas, Smita (36188418900)","57226691163; 55892550700; 57716623800; 36188418900","Probing with Precision: Probing Question Generation for Architectural Information Elicitation","2024","Proceedings - 2024 IEEE/ACM Workshop on Multi-disciplinary, Open, and RElevant Requirements Engineering, MO2RE 2024","","","","8","14","6","0","10.1145/3643666.3648577","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202449923&doi=10.1145%2f3643666.3648577&partnerID=40&md5=acafcc84d8ceba7ee6483e45adbd3ee8","Tcs Research, Pune, India","Rejithkumar G., Tcs Research, Pune, India; Anish P.R., Tcs Research, Pune, India; Shukla J., Tcs Research, Pune, India; Ghaisas S., Tcs Research, Pune, India","Software Requirements Specifications (SRS) often lack the necessary level of specificity required by software architects to make well-informed architectural decisions. This deficiency compels software architects to probe business analysts to collect more details pertinent to architectural requirements from the clients. In our previous work, we introduced Probing Question-flows (PQ-flows) that can assist business analysts to probe stakeholders and gather architecturally significant information for the creation of a more comprehensive SRS. Key limitations of our previous work were the manually created templatized PQ-flows and the mapping of PQ-flows to the software requirements based on standard Vector Space Model. In this study, we propose a Retrieval Augmented Generation (RAG) prompting framework to address these limitations. We conducted experiments using ChatGPT and Mistral-7B models. We present our findings utilizing human and automated evaluation metrics on a subset of the publicly available PUblic REquirements (PURE) dataset. © 2024 Copyright is held by the owner/author(s). Publication rights licensed to ACM.","ChatGPT; large language models; mistral; probing questions; prompting; requirements engineering; retrieval augmented generation","Computer software selection and evaluation; Modeling languages; Question answering; Search engines; Software architecture; Specifications; ChatGPT; Language model; Large language model; Mistral; Probing question; Prompting; Requirement engineering; Retrieval augmented generation; Software architects; Software requirements specifications; Requirements engineering","","Association for Computing Machinery, Inc","English","Conference paper","Final","","Scopus","2-s2.0-85202449923"
"Lin F.; Li X.; Lei W.; Rodriguez-Andina J.J.; Guerrero J.M.; Wen C.; Zhang X.; Ma H.","Lin, Fanfan (57209911667); Li, Xinze (57212465237); Lei, Weihao (59359711200); Rodriguez-Andina, Juan J. (57216616882); Guerrero, Josep M. (35588010400); Wen, Changyun (7201366998); Zhang, Xin (56044348100); Ma, Hao (8600581600)","57209911667; 57212465237; 59359711200; 57216616882; 35588010400; 7201366998; 56044348100; 8600581600","PE-GPT: A New Paradigm for Power Electronics Design","2024","IEEE Transactions on Industrial Electronics","","","","","","","0","10.1109/TIE.2024.3454408","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205933140&doi=10.1109%2fTIE.2024.3454408&partnerID=40&md5=d3e2ee1d09b131d2abd81b3bc6c5bb6f","Zhejiang University, University of Illinois Urbana-Champaign Institute, Haining, 314400, China; Huanjiang Lab, Zhuji, 311816, China; University of Arkansas, Fayetteville, 72701, AR, United States; Zhejiang University, College of Electrical Engineering, Hangzhou, 310027, China; University of Vigo, Department of Electronic Technology, Vigo, 36310, Spain; Catalan Institution for Research and Advanced Studies (ICREA), Barcelona, 08010, Spain; Nanyang Technological University, School of Electrical and Electronic Engineering, Singapore, 639798, Singapore","Lin F., Zhejiang University, University of Illinois Urbana-Champaign Institute, Haining, 314400, China, Huanjiang Lab, Zhuji, 311816, China; Li X., University of Arkansas, Fayetteville, 72701, AR, United States; Lei W., Zhejiang University, College of Electrical Engineering, Hangzhou, 310027, China; Rodriguez-Andina J.J., University of Vigo, Department of Electronic Technology, Vigo, 36310, Spain; Guerrero J.M., Catalan Institution for Research and Advanced Studies (ICREA), Barcelona, 08010, Spain; Wen C., Nanyang Technological University, School of Electrical and Electronic Engineering, Singapore, 639798, Singapore; Zhang X., Zhejiang University, College of Electrical Engineering, Hangzhou, 310027, China; Ma H., Zhejiang University, College of Electrical Engineering, Hangzhou, 310027, China","Large language models (LLMs) have shown exciting potential in powering the growth of many industries, yet their adoption in the power electronics (PE) sector is hindered by a lack of specialized PE technical expertise and challenges in processing PE-specific data. This study presents a pioneering approach to establish a multimodal LLM tailored for PE design applications, named PE-GPT. The methodology involves enhancing PE-GPT with retrieval augmented generation from a PE knowledge base, and proposes a hybrid framework that integrates an LLM agent with metaheuristic algorithms, Model Zoo, and Simulation Repository. This enhances its multimodal processing capabilities and enables integration into the existing design workflow. The PE-GPT methodology is demonstrated with two case studies: modulation design of the dual-active bridge (DAB) converter and circuit parameter design of the buck converter. PE-GPT demonstrates a 22.2% increase in correctness compared to human experts. Against other leading LLMs, PE-GPT shows a 35.6% improvement in correctness and a 15.4% enhancement in consistency, reducing hallucination. Hardware experiments validate PE-GPT's multimodal capabilities in optimizing a five-degree-of-freedom modulation strategy for the DAB converter. The generalizability of PE-GPT to other PE design applications and associated AI ethical considerations are also discussed. This research concludes by outlining inspiring future research directions, encouraging researchers to expand the boundaries of the PE industry and advance toward a more intelligent era. © 1982-2012 IEEE.","Large language model (LLM); multimodal AI; physics-informed AI; power converter design; power electronics (PE) design","","","Institute of Electrical and Electronics Engineers Inc.","English","Article","Article in press","","Scopus","2-s2.0-85205933140"
"Barzizza E.; Biasetton N.; Caligiuri G.; Pennisi D.; Salmaso L.","Barzizza, Elena (57721090800); Biasetton, Nicolò (57721122500); Caligiuri, Giorgio (59354713900); Pennisi, Daniele (59355422800); Salmaso, Luigi (55911856100)","57721090800; 57721122500; 59354713900; 59355422800; 55911856100","Large Language Model Application and Tuning For Product Analysis: A Preliminary Investigation","2024","Proceedings of the International Conference on Statistics","","","","","","4","0","10.11159/icsta24.149","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205662112&doi=10.11159%2ficsta24.149&partnerID=40&md5=50ef0ee8bea98cfeccef4361705d8a26","University of Padova, Department of Management Engineering, Stradella San Nicola, 3, Vicenza, 36100, Italy; University of Padova, Department of Civil Environmental and Architectural Engineering, Via Marzolo, 9, Padova, 35131, Italy","Barzizza E., University of Padova, Department of Management Engineering, Stradella San Nicola, 3, Vicenza, 36100, Italy; Biasetton N., University of Padova, Department of Management Engineering, Stradella San Nicola, 3, Vicenza, 36100, Italy; Caligiuri G., University of Padova, Department of Civil Environmental and Architectural Engineering, Via Marzolo, 9, Padova, 35131, Italy; Pennisi D., University of Padova, Department of Civil Environmental and Architectural Engineering, Via Marzolo, 9, Padova, 35131, Italy; Salmaso L., University of Padova, Department of Management Engineering, Stradella San Nicola, 3, Vicenza, 36100, Italy","In today's competitive market, staying abreast of concurrent product characteristics is imperative for companies to maintain a competitive edge. Leveraging open-source Large Language Models (LLMs) presents a promising avenue for efficient and comprehensive analysis. This paper delves into the current landscape of commercial and open-source LLMs, assessing their potential for analyzing product characteristics. Additionally, it explores the feasibility of fine-tuning these models, including the utilization of Retrieval Augmented Generation (RAG), to enhance response accuracy and depth. Through evaluation, Mistral 7B emerges as a suitable open-source model for implementation, balancing performance with computational constraints. Furthermore, it outlines the process of refining LLMs using proprietary data, market intelligence, patent insights, and data gathered from web scraping to develop a comprehensive analytical tool for R&D purposes. This tool enables efficient extraction, analysis, and visualization of pertinent information, empowering decision-makers to steer innovation effectively. © 2024, Avestia Publishing. All rights reserved.","Large Language Models; Product Characteristics; R&D; Smart data","","Samia N.","Avestia Publishing","English","Conference paper","Final","","Scopus","2-s2.0-85205662112"
"Majumder S.; Dong L.; Doudi F.; Cai Y.; Tian C.; Kalathil D.; Ding K.; Thatte A.A.; Li N.; Xie L.","Majumder, Subir (58759565600); Dong, Lin (59136839300); Doudi, Fatemeh (58959904800); Cai, Yuting (58960742000); Tian, Chao (58960531100); Kalathil, Dileep (36100329500); Ding, Kevin (57195447087); Thatte, Anupam A. (22837020100); Li, Na (59136796600); Xie, Le (36447712900)","58759565600; 59136839300; 58959904800; 58960742000; 58960531100; 36100329500; 57195447087; 22837020100; 59136796600; 36447712900","Exploring the capabilities and limitations of large language models in the electric energy sector","2024","Joule","8","6","","1544","1549","5","3","10.1016/j.joule.2024.05.009","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196019956&doi=10.1016%2fj.joule.2024.05.009&partnerID=40&md5=b9eec91a645326a3b3dfcb14338ebeaf","Department of Electrical and Computer Engineering Texas A&M University, College Station, TX, United States; CenterPoint Energy, Houston, TX, United States; Midcontinent Independent System Operator (MISO), Carmel, IN, United States; School of Engineering and Applied Sciences Harvard University, Cambridge, MA, United States; Department of Electrical and Computer Engineering Texas A&M University, and Texas A&M Energy Institute, College Station, TX, United States","Majumder S., Department of Electrical and Computer Engineering Texas A&M University, College Station, TX, United States; Dong L., Department of Electrical and Computer Engineering Texas A&M University, College Station, TX, United States; Doudi F., Department of Electrical and Computer Engineering Texas A&M University, College Station, TX, United States; Cai Y., Department of Electrical and Computer Engineering Texas A&M University, College Station, TX, United States; Tian C., Department of Electrical and Computer Engineering Texas A&M University, College Station, TX, United States; Kalathil D., Department of Electrical and Computer Engineering Texas A&M University, College Station, TX, United States; Ding K., CenterPoint Energy, Houston, TX, United States; Thatte A.A., Midcontinent Independent System Operator (MISO), Carmel, IN, United States; Li N., School of Engineering and Applied Sciences Harvard University, Cambridge, MA, United States; Xie L., Department of Electrical and Computer Engineering Texas A&M University, and Texas A&M Energy Institute, College Station, TX, United States","Large language models (LLMs) as ChatBots have drawn remarkable attention thanks to their versatile capability in natural language processing as well as in a wide range of tasks. While there has been great enthusiasm toward adopting such foundational model-based artificial intelligence tools in all sectors possible, the capabilities and limitations of such LLMs in improving the operation of the electric energy sector need to be explored, and this commentary identifies fruitful directions in this regard. Key future research directions include data collection systems for fine-tuning LLMs, embedding power system-specific tools in the LLMs, and retrieval augmented generation (RAG)-based knowledge pool to improve the quality of LLM responses and LLMs in safety-critical use cases. © 2024 Elsevier Inc.","","","","Cell Press","English","Note","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85196019956"
"Lin Y.-C.; Kumar A.; Chang N.; Zhang W.; Zakir M.; Apte R.; He H.; Wang C.; Jang J.-S.R.","Lin, Yu-Chen (57207857121); Kumar, Akhilesh (57219338215); Chang, Norman (7202467883); Zhang, Wenliang (56206556600); Zakir, Muhammad (58752564800); Apte, Rucha (58485174800); He, Haiyang (57221036981); Wang, Chao (58095857000); Jang, Jyh-Shing Roger (7402965041)","57207857121; 57219338215; 7202467883; 56206556600; 58752564800; 58485174800; 57221036981; 58095857000; 7402965041","Novel Preprocessing Technique for Data Embedding in Engineering Code Generation Using Large Language Model","2024","2024 IEEE LLM Aided Design Workshop, LAD 2024","","","","","","","0","10.1109/LAD62341.2024.10691715","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206626244&doi=10.1109%2fLAD62341.2024.10691715&partnerID=40&md5=3006c6e2e2db5ec105138f86761fd510","National Taiwan University, Taipei, Taiwan; Ansys, Inc., San Jose, CA, United States","Lin Y.-C., National Taiwan University, Taipei, Taiwan; Kumar A., Ansys, Inc., San Jose, CA, United States; Chang N., Ansys, Inc., San Jose, CA, United States; Zhang W., Ansys, Inc., San Jose, CA, United States; Zakir M., Ansys, Inc., San Jose, CA, United States; Apte R., Ansys, Inc., San Jose, CA, United States; He H., Ansys, Inc., San Jose, CA, United States; Wang C., Ansys, Inc., San Jose, CA, United States; Jang J.-S.R., National Taiwan University, Taipei, Taiwan","We introduce four principal contributions to augment the capabilities of Large Language Models (LLMs) in generating domain-specific code: (i) leveraging LLM-based data splitting and data renovation techniques to refine the semantic representation within the embedding space; (ii) proposing an effective method for refactoring existing scripts, enabling the generation of new and high-quality scripts with the aid of LLMs; (iii) developing the Implicit Knowledge Expansion and Contemplation (IKEC) Prompt technique; and (iv) showcasing the efficacy of our data pre-processing approach through a case study using engineering simulation software RedHawk-SC. Our contributions collectively advance the Retrieval-Augmented Generation (RAG) framework, enabling more relevant and precise information retrieval. An arena-style evaluation by 28 domain experts and 182 votes confirms the significant effectiveness of our methods. Notably, our approach achieves up to 1.43 times the improvement in code generation for MapReduce applications compared to the Chain-of-Thought (CoT) technique.  © 2024 IEEE.","code generation; data preprocessing; data renovation; data splitter; domain-specific; domain-specific; Large language models (LLMs); MapReduce; prompt engineering; RedHawk-SC (RH-SC); Retrieval-Augmented Generation (RAG)","Computer software selection and evaluation; Embeddings; Metadata; Program debugging; Search engines; Codegeneration; Data preprocessing; Data renovation; Data splitter; Domain specific; Language model; Large language model; Map-reduce; Prompt engineering; Redhawk-SC; Retrieval-augmented generation; MapReduce","","Institute of Electrical and Electronics Engineers Inc.","English","Conference paper","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85206626244"
"Jeong M.; Sohn J.; Sung M.; Kang J.","Jeong, Minbyul (57209640341); Sohn, Jiwoong (58866624300); Sung, Mujeen (57209639404); Kang, Jaewoo (8914056400)","57209640341; 58866624300; 57209639404; 8914056400","Improving medical reasoning through retrieval and self-reflection with retrieval-augmented large language models","2024","Bioinformatics","40","","","i119","i129","10","1","10.1093/bioinformatics/btae238","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197105929&doi=10.1093%2fbioinformatics%2fbtae238&partnerID=40&md5=f1adb2f19c35ef97cf0e62185ccfcfa1","Department of Computer Science, Korea University, Seoul, 02841, South Korea; Department of Software Convergence, School of Computing, Kyung Hee University, South Korea; AIGEN Sciences, Seoul, 04778, South Korea","Jeong M., Department of Computer Science, Korea University, Seoul, 02841, South Korea; Sohn J., Department of Computer Science, Korea University, Seoul, 02841, South Korea; Sung M., Department of Software Convergence, School of Computing, Kyung Hee University, South Korea; Kang J., Department of Computer Science, Korea University, Seoul, 02841, South Korea, AIGEN Sciences, Seoul, 04778, South Korea","Recent proprietary large language models (LLMs), such as GPT-4, have achieved a milestone in tackling diverse challenges in the biomedical domain, ranging from multiple-choice questions to long-form generations. To address challenges that still cannot be handled with the encoded knowledge of LLMs, various retrieval-augmented generation (RAG) methods have been developed by searching documents from the knowledge corpus and appending them unconditionally or selectively to the input of LLMs for generation. However, when applying existing methods to different domain-specific problems, poor generalization becomes apparent, leading to fetching incorrect documents or making inaccurate judgments. In this paper, we introduce Self-BioRAG, a framework reliable for biomedical text that specializes in generating explanations, retrieving domain-specific documents, and self-reflecting generated responses. We utilize 84k filtered biomedical instruction sets to train Self- BioRAG that can assess its generated explanations with customized reflective tokens. Our work proves that domain-specific components, such as a retriever, domain-related document corpus, and instruction sets are necessary for adhering to domain-related instructions. Using three major medical question-answering benchmark datasets, experimental results of Self-BioRAG demonstrate significant performance gains by achieving a 7.2% absolute improvement on average over the state-of-the-art open-foundation model with a parameter size of 7B or less. Similarly, Self-BioRAG outperforms RAG by 8% Rouge-1 score in generating more proficient answers on two long-form question-answering benchmarks on average. Overall, we analyze that Self-BioRAG finds the clues in the question, retrieves relevant documents if needed, and understands how to answer with information from retrieved documents and encoded knowledge as a medical expert does. We release our data and code for training our framework components and model weights (7B and 13B) to enhance capabilities in biomedical and clinical domains. © The Author(s) 2024.","","Humans; Information Storage and Retrieval; Natural Language Processing; human; information retrieval; natural language processing; procedures","","Oxford University Press","English","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85197105929"
"Pathiyan Cherumanal S.; Tian L.; Abushaqra F.M.; De Paula A.F.M.; Ji K.; Ali H.; Hettiachchi D.; Trippas J.R.; Scholer F.; Spina D.","Pathiyan Cherumanal, Sachin (57244526600); Tian, Lin (58154607700); Abushaqra, Futoon M. (57223193150); De Paula, Angel Felipe Magnossão (57232483700); Ji, Kaixin (57387302600); Ali, Halil (59271091600); Hettiachchi, Danula (57211167107); Trippas, Johanne R. (57044702200); Scholer, Falk (56254255800); Spina, Damiano (52365020500)","57244526600; 58154607700; 57223193150; 57232483700; 57387302600; 59271091600; 57211167107; 57044702200; 56254255800; 52365020500","Walert: Putting Conversational Information Seeking Knowledge into Action by Building and Evaluating a Large Language Model-Powered Chatbot","2024","CHIIR 2024 - Proceedings of the 2024 Conference on Human Information Interaction and Retrieval","","","","401","405","4","2","10.1145/3627508.3638309","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188731297&doi=10.1145%2f3627508.3638309&partnerID=40&md5=2f91cdbe10360a3ead5569815aac5697","School of Computing Technologies, Rmit University, Melbourne, Australia; Universitat Politècnica de València, Valencia, Spain","Pathiyan Cherumanal S., School of Computing Technologies, Rmit University, Melbourne, Australia; Tian L., School of Computing Technologies, Rmit University, Melbourne, Australia; Abushaqra F.M., School of Computing Technologies, Rmit University, Melbourne, Australia; De Paula A.F.M., Universitat Politècnica de València, Valencia, Spain; Ji K., School of Computing Technologies, Rmit University, Melbourne, Australia; Ali H., School of Computing Technologies, Rmit University, Melbourne, Australia; Hettiachchi D., School of Computing Technologies, Rmit University, Melbourne, Australia; Trippas J.R., School of Computing Technologies, Rmit University, Melbourne, Australia; Scholer F., School of Computing Technologies, Rmit University, Melbourne, Australia; Spina D., School of Computing Technologies, Rmit University, Melbourne, Australia","Creating and deploying customized applications is crucial for operational success and enriching user experiences in the rapidly evolving modern business world. A prominent facet of modern user experiences is the integration of chatbots or voice assistants. The rapid evolution of Large Language Models (LLMs) has provided a powerful tool to build conversational applications. We present Walert, a customized LLM-based conversational agent able to answer frequently asked questions about computer science degrees and programs at RMIT University. Our demo aims to showcase how conversational information-seeking researchers can effectively communicate the benefits of using best practices to stakeholders interested in developing and deploying LLM-based chatbots. These practices are well-known in our community but often overlooked by practitioners who may not have access to this knowledge. The methodology and resources used in this demo serve as a bridge to facilitate knowledge transfer from experts, address industry professionals' practical needs, and foster a collaborative environment. The data and code of the demo are available at https://github.com/rmit-ir/walert. © 2024 Owner/Author.","conversational information seeking; large language models; retrieval-augmented generation","Computational linguistics; Information retrieval; Information use; Chatbots; Conversational agents; Conversational information seeking; Frequently asked questions; Information seeking; Language model; Large language model; Model-based OPC; Retrieval-augmented generation; Users' experiences; Knowledge management","","Association for Computing Machinery, Inc","English","Conference paper","Final","All Open Access; Bronze Open Access","Scopus","2-s2.0-85188731297"
"Upadhyaya D.P.; Shaikh A.G.; Cakir G.B.; Prantzalos K.; Golnari P.; Ghasia F.F.; Sahoo S.S.","Upadhyaya, Dipak P. (57218833515); Shaikh, Aasef G. (7101736514); Cakir, Gokce Busra (58939712800); Prantzalos, Katrina (57536831200); Golnari, Pedram (15044444400); Ghasia, Fatema F. (8888315600); Sahoo, Satya S. (9735293400)","57218833515; 7101736514; 58939712800; 57536831200; 15044444400; 8888315600; 9735293400","A 360° View for Large Language Models: Early Detection of Amblyopia in Children Using Multi-view Eye Movement Recordings","2024","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","14845 LNAI","","","165","175","10","0","10.1007/978-3-031-66535-6_19","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206217603&doi=10.1007%2f978-3-031-66535-6_19&partnerID=40&md5=d38a4023121866b0c7de300eae835bf1","Department of Population and Quantitative Health Sciences, School of Medicine, Case Western Reserve University, Cleveland, OH, United States; National VA Parkinson’s Consortium Center, Louis Stokes Cleveland VA Medical Center, Cleveland, Cleveland, OH, United States; Visual Neuroscience Laboratory, Cole Eye Institute, Cleveland Clinic, Cleveland, OH, United States","Upadhyaya D.P., Department of Population and Quantitative Health Sciences, School of Medicine, Case Western Reserve University, Cleveland, OH, United States; Shaikh A.G., National VA Parkinson’s Consortium Center, Louis Stokes Cleveland VA Medical Center, Cleveland, Cleveland, OH, United States; Cakir G.B., Visual Neuroscience Laboratory, Cole Eye Institute, Cleveland Clinic, Cleveland, OH, United States; Prantzalos K., Department of Population and Quantitative Health Sciences, School of Medicine, Case Western Reserve University, Cleveland, OH, United States; Golnari P., Department of Population and Quantitative Health Sciences, School of Medicine, Case Western Reserve University, Cleveland, OH, United States; Ghasia F.F., Visual Neuroscience Laboratory, Cole Eye Institute, Cleveland Clinic, Cleveland, OH, United States; Sahoo S.S., Department of Population and Quantitative Health Sciences, School of Medicine, Case Western Reserve University, Cleveland, OH, United States","Amblyopia is a neurodevelopmental visual disorder that affects approximately 3–5% of children globally and it can lead to vision loss if it is not diagnosed and treated early. Traditional diagnostic methods, which rely on subjective assessments and expert interpretation of eye movement recordings presents challenges in resource-limited eye care centers. This study introduces a new approach that integrates the Gemini large language model (LLM) with eye-tracking data to develop a classification tool for diagnosis of patients with amblyopia. The study demonstrates: (1) LLMs can be successfully applied to the analysis of fixation eye movement data to diagnose patients with amblyopia; and (2) Input of medical subject matter expertise, introduced in this study in the form of medical expert augmented generation (MEAG), is an effective adaption of the generic retrieval augmented generation (RAG) approach for medical applications using LLMs. This study introduces a new multi-view prompting framework for ophthalmology applications that incorporates fine granularity feedback from pediatric ophthalmologist together with in-context learning to report an accuracy of 80% in diagnosing patients with amblyopia. In addition to the binary classification task, the classification tool is generalizable to specific subpopulations of amblyopic patients based on severity of amblyopia, type of amblyopia, and with or without nystagmus. The model reports an accuracy of: (1) 83% in classifying patients with moderate or severe amblyopia, (2) 81% in classifying patients with mild or treated amblyopia; and (3) 85% accuracy in classifying patients with nystagmus. To the best of our knowledge, this is the first study that defines a multi-view prompting framework with MEAG to analyze eye tracking data for the diagnosis of amblyopic patients. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.","amblyopia diagnosis; fixation eye movement; in-context learning; large language models; Transfer learning","Diagnosis; Diseases; Fracture fixation; Pediatrics; Amblyopia diagnose; Context learning; Eye-tracking; Fixation eye movement; In contexts; In-context learning; Language model; Large language model; Multi-views; Transfer learning; Ophthalmology","Finkelstein J.; Moskovitch R.; Parimbelli E.","Springer Science and Business Media Deutschland GmbH","English","Conference paper","Final","","Scopus","2-s2.0-85206217603"
"Keswani G.; Bisen W.; Padwad H.; Wankhedkar Y.; Pandey S.; Soni A.","Keswani, Gunjan (57210734407); Bisen, Wani (58888352900); Padwad, Hirkani (58101286900); Wankhedkar, Yash (58888067800); Pandey, Sudhanshu (58887925900); Soni, Ayushi (57215599506)","57210734407; 58888352900; 58101286900; 58888067800; 58887925900; 57215599506","Abstractive Long Text Summarization using Large Language Models","2024","International Journal of Intelligent Systems and Applications in Engineering","12","12s","","160","168","8","3","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185110158&partnerID=40&md5=d59ad2a45e9522fdce747444d5060b37","Department of Computer Science and Engineering, Shri Ramdeobaba College of Engineering and Management (RCOEM), Nagpur, India","Keswani G., Department of Computer Science and Engineering, Shri Ramdeobaba College of Engineering and Management (RCOEM), Nagpur, India; Bisen W., Department of Computer Science and Engineering, Shri Ramdeobaba College of Engineering and Management (RCOEM), Nagpur, India; Padwad H., Department of Computer Science and Engineering, Shri Ramdeobaba College of Engineering and Management (RCOEM), Nagpur, India; Wankhedkar Y., Department of Computer Science and Engineering, Shri Ramdeobaba College of Engineering and Management (RCOEM), Nagpur, India; Pandey S., Department of Computer Science and Engineering, Shri Ramdeobaba College of Engineering and Management (RCOEM), Nagpur, India; Soni A., Department of Computer Science and Engineering, Shri Ramdeobaba College of Engineering and Management (RCOEM), Nagpur, India","Large Language Models (LLMs) have made significant strides in processing human-written texts. However, a major challenge persists-the retention of context over extensive texts or multiple documents. The current approach of LLMs to retain context is often inefficient, both in terms of storage and time. To address this issue, this paper proposes a novel approach for two key tasks-Summarization and Question Answering. The methodology ensures that the LLM is not overwhelmed with unrelated, repetitive, or redundant data, thereby saving considerable time and resources. This approach facilitates the generation of effective summaries and answers for the user, enhancing the overall performance and efficiency of the LLM. © 2024, Ismail Saritas. All rights reserved.","Abstractive summarization; LangChain; Large Language Models; Natural Language Processing; Retrieval-Augmented Generation","","","Ismail Saritas","English","Article","Final","","Scopus","2-s2.0-85185110158"
"Chen J.; Lin H.; Han X.; Sun L.","Chen, Jiawei (57274822700); Lin, Hongyu (57207858382); Han, Xianpei (35302334000); Sun, Le (55453689000)","57274822700; 57207858382; 35302334000; 55453689000","Benchmarking Large Language Models in Retrieval-Augmented Generation","2024","Proceedings of the AAAI Conference on Artificial Intelligence","38","16","","17754","17762","8","17","10.1609/aaai.v38i16.29728","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189613527&doi=10.1609%2faaai.v38i16.29728&partnerID=40&md5=6f78ac42d80af63bf434a065136db443","Chinese Information Processing Laboratory, Institute of Software, Chinese Academy of Sciences, Beijing, China; State Key Laboratory of Computer Science, Institute of Software, Chinese Academy of Sciences, Beijing, China; University of Chinese Academy of Sciences, Beijing, China","Chen J., Chinese Information Processing Laboratory, Institute of Software, Chinese Academy of Sciences, Beijing, China, University of Chinese Academy of Sciences, Beijing, China; Lin H., Chinese Information Processing Laboratory, Institute of Software, Chinese Academy of Sciences, Beijing, China; Han X., Chinese Information Processing Laboratory, Institute of Software, Chinese Academy of Sciences, Beijing, China, State Key Laboratory of Computer Science, Institute of Software, Chinese Academy of Sciences, Beijing, China; Sun L., Chinese Information Processing Laboratory, Institute of Software, Chinese Academy of Sciences, Beijing, China, State Key Laboratory of Computer Science, Institute of Software, Chinese Academy of Sciences, Beijing, China","Retrieval-Augmented Generation (RAG) is a promising approach for mitigating the hallucination of large language models (LLMs). However, existing research lacks rigorous evaluation of the impact of retrieval-augmented generation on different large language models, which make it challenging to identify the potential bottlenecks in the capabilities of RAG for different LLMs. In this paper, we systematically investigate the impact of Retrieval-Augmented Generation on large language models. We analyze the performance of different large language models in 4 fundamental abilities required for RAG, including noise robustness, negative rejection, information integration, and counterfactual robustness. To this end, we establish Retrieval-Augmented Generation Benchmark (RGB), a new corpus for RAG evaluation in both English and Chinese. RGB divides the instances within the benchmark into 4 separate testbeds based on the aforementioned fundamental abilities required to resolve the case. Then we evaluate 6 representative LLMs on RGB to diagnose the challenges of current LLMs when applying RAG. Evaluation reveals that while LLMs exhibit a certain degree of noise robustness, they still struggle significantly in terms of negative rejection, information integration, and dealing with false information. The aforementioned assessment outcomes indicate that there is still a considerable journey ahead to effectively apply RAG to LLMs. Copyright © 2024, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.","","Artificial intelligence; Benchmarking; Computational linguistics; 'current; Counterfactuals; Degree of noise; Information integration; Language model; Noise robustness; Performance; Rigorous evaluation; Information retrieval","Wooldridge M.; Dy J.; Natarajan S.","Association for the Advancement of Artificial Intelligence","English","Conference paper","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85189613527"
"Crisp D.; Newsted J.; Brendon B.; Barnes D.; Hayes C.; Prantner J.","Crisp, Dakota (57835969700); Newsted, Jacob (59252362300); Brendon, Kirouac (59252692000); Barnes, Danielle (58303119400); Hayes, Catherine (59252850500); Prantner, Jonathan (57210732893)","57835969700; 59252362300; 59252692000; 58303119400; 59252850500; 57210732893","Customising generative AI: Harnessing document retrieval and fine-tuning alternatives for dynamic marketing insights","2024","Applied Marketing Analytics","10","1","","18","31","13","0","10.69554/ybxq5617","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200775428&doi=10.69554%2fybxq5617&partnerID=40&md5=d59dad551d42e1278565077947b67684","OneMagnify, United States; OneMagnify, United States; OneMagnify, United States; OneMagnify, United States; OneMagnify, United States; OneMagnify, United States; OneMagnify, 12 N Main St #100, Ann Arbor, 48104, MI, United States","Crisp D., OneMagnify, United States, OneMagnify, 12 N Main St #100, Ann Arbor, 48104, MI, United States; Newsted J., OneMagnify, United States, OneMagnify, 12 N Main St #100, Ann Arbor, 48104, MI, United States; Brendon B., OneMagnify, United States, OneMagnify, 12 N Main St #100, Ann Arbor, 48104, MI, United States; Barnes D., OneMagnify, United States, OneMagnify, 12 N Main St #100, Ann Arbor, 48104, MI, United States; Hayes C., OneMagnify, United States, OneMagnify, 12 N Main St #100, Ann Arbor, 48104, MI, United States; Prantner J., OneMagnify, United States, OneMagnify, 12 N Main St #100, Ann Arbor, 48104, MI, United States","This study delves into the transformative impact of leveraging large language models (LLMs) in marketing analytics, particularly emphasising a paradigm shift from fine-tuning models to the strategic application of document retrieval techniques and more. Focusing on innovative methods, such as retrieval augmented generation and low-rank adaptation, the paper explores how marketers can now activate against vast and unstructured datasets, such as call centre transcripts, unlocking valuable insights that were previously overlooked. By harnessing the power of document retrieval and adaptation, marketers can bring their data to life, enabling a more nuanced and adaptive approach to understanding consumer behaviour and preferences. This research contributes to the evolving landscape of applied marketing analytics by demonstrating  the efficacy of document retrieval in enhancing the utilisation of LLMs for dynamic and data-driven marketing strategies. © 2024, Henry Stewart Publications. All rights reserved.","call centre; document retrieval techniques; generative AI; low-rank adaptation; marketing analytics; natural language processing; retrieval augmented generation","","","Henry Stewart Publications","English","Article","Final","","Scopus","2-s2.0-85200775428"
"Xia Y.; Huang Y.; Qiu Q.; Zhang X.; Miao L.; Chen Y.","Xia, Yongqi (58984348000); Huang, Yi (57205534994); Qiu, Qianqian (57212080786); Zhang, Xueying (55715721800); Miao, Lizhi (23005525700); Chen, Yixiang (50660895400)","58984348000; 57205534994; 57212080786; 55715721800; 23005525700; 50660895400","A Question and Answering Service of Typhoon Disasters Based on the T5 Large Language Model","2024","ISPRS International Journal of Geo-Information","13","5","165","","","","1","10.3390/ijgi13050165","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194378271&doi=10.3390%2fijgi13050165&partnerID=40&md5=1362077fd2bff547b34f5583c2921d78","School of Internet of Things, Nanjing University of Posts and Telecommunications, Nanjing, 210023, China; Key Laboratory of Virtual Geographic Environment, Nanjing Normal University, Ministry of Education, Nanjing, 210023, China; Jiangsu Center for Collaborative Innovation in Geographical Information Resource Development and Application, Nanjing, 210023, China; Jiangsu Province Surveying & Mapping Engineering Institute, Nanjing, 210019, China","Xia Y., School of Internet of Things, Nanjing University of Posts and Telecommunications, Nanjing, 210023, China; Huang Y., School of Internet of Things, Nanjing University of Posts and Telecommunications, Nanjing, 210023, China, Key Laboratory of Virtual Geographic Environment, Nanjing Normal University, Ministry of Education, Nanjing, 210023, China, Jiangsu Center for Collaborative Innovation in Geographical Information Resource Development and Application, Nanjing, 210023, China; Qiu Q., Jiangsu Province Surveying & Mapping Engineering Institute, Nanjing, 210019, China; Zhang X., Key Laboratory of Virtual Geographic Environment, Nanjing Normal University, Ministry of Education, Nanjing, 210023, China, Jiangsu Center for Collaborative Innovation in Geographical Information Resource Development and Application, Nanjing, 210023, China; Miao L., School of Internet of Things, Nanjing University of Posts and Telecommunications, Nanjing, 210023, China; Chen Y., School of Internet of Things, Nanjing University of Posts and Telecommunications, Nanjing, 210023, China","A typhoon disaster is a common meteorological disaster that seriously impacts natural ecology, social economy, and even human sustainable development. It is crucial to access the typhoon disaster information, and the corresponding disaster prevention and reduction strategies. However, traditional question and answering (Q&A) methods exhibit shortcomings like low information retrieval efficiency and poor interactivity. This makes it difficult to satisfy users’ demands for obtaining accurate information. Consequently, this work proposes a typhoon disaster knowledge Q&A approach based on LLM (T5). This method integrates two technical paradigms of domain fine-tuning and retrieval-augmented generation (RAG) to optimize user interaction experience and improve the precision of disaster information retrieval. The process specifically includes the following steps. First, this study selects information about typhoon disasters from open-source databases, such as Baidu Encyclopedia and Wikipedia. Utilizing techniques such as slicing and masked language modeling, we generate a training set and 2204 Q&A pairs specifically focused on typhoon disaster knowledge. Second, we continuously pretrain the T5 model using the training set. This process involves encoding typhoon knowledge as parameters in the neural network’s weights and fine-tuning the pretrained model with Q&A pairs to adapt the T5 model for downstream Q&A tasks. Third, when responding to user queries, we retrieve passages from external knowledge bases semantically similar to the queries to enhance the prompts. This action further improves the response quality of the fine-tuned model. Finally, we evaluate the constructed typhoon agent (Typhoon-T5) using different similarity-matching approaches. Furthermore, the method proposed in this work lays the foundation for the cross-integration of large language models with disaster information. It is expected to promote the further development of GeoAI. © 2024 by the authors.","information retrieval; large language models; question and answering; typhoon disaster","","","Multidisciplinary Digital Publishing Institute (MDPI)","English","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85194378271"
"Schmidt S.; Zelch I.; Bevendorff J.; Stein B.; Hagen M.; Potthast M.","Schmidt, Sebastian (57866685900); Zelch, Ines (58662537900); Bevendorff, Janek (57201362871); Stein, Benno (23013265500); Hagen, Matthias (16309692700); Potthast, Martin (23012600600)","57866685900; 58662537900; 57201362871; 23013265500; 16309692700; 23012600600","Detecting Generated Native Ads in Conversational Search","2024","WWW 2024 Companion - Companion Proceedings of the ACM Web Conference","","","","722","725","3","1","10.1145/3589335.3651489","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194474841&doi=10.1145%2f3589335.3651489&partnerID=40&md5=727fae4c64a69f6e947d5045e292184b","Leipzig University, Germany; Leipzig University, Friedrich-Schiller-Universität Jena, Germany; Leipzig University, Bauhaus-Universität Weimar, Germany; Bauhaus-Universität Weimar, Germany; Friedrich-Schiller-Universität Jena, Germany; Leipzig University, ScaDS.AI, Germany","Schmidt S., Leipzig University, Germany; Zelch I., Leipzig University, Friedrich-Schiller-Universität Jena, Germany; Bevendorff J., Leipzig University, Bauhaus-Universität Weimar, Germany; Stein B., Bauhaus-Universität Weimar, Germany; Hagen M., Friedrich-Schiller-Universität Jena, Germany; Potthast M., Leipzig University, ScaDS.AI, Germany","Conversational search engines such as YouChat and Microsoft Copilot use large language models (LLMs) to generate responses to queries. It is only a small step to also let the same technology insert ads within the generated responses—instead of separately placing ads next to a response. Inserted ads would be reminiscent of native advertising and product placement, both of which are very effective forms of subtle and manipulative advertising. Considering the high computational costs associated with LLMs, for which providers need to develop sustainable business models, users of conversational search engines may very well be confronted with generated native ads in the near future. In this paper, we thus take a first step to investigate whether LLMs can also be used as a countermeasure, i.e., to block generated native ads. We compile the Webis Generated Native Ads 2024 dataset of queries and generated responses with automatically inserted ads, and evaluate whether LLMs or fine-tuned sentence transformers can detect the ads. In our experiments, the investigated LLMs struggle with the task but sentence transformers achieve precision and recall values above 0.9. © 2024 Copyright held by the owner/author(s).","Advertising; LLM; Retrieval-augmented Generation","Search engines; Advertizing; Business models; Computational costs; Language model; Large language model; MicroSoft; Precision and recall; Product placement; Retrieval-augmented generation; Sustainable business; Marketing","","Association for Computing Machinery, Inc","English","Conference paper","Final","All Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85194474841"
"Faruqui S.H.A.; Tasnim N.; Basith I.I.; Obeidat S.M.; Yildiz F.","Faruqui, Syed Hasib Akhter (57196328841); Tasnim, Nazia (59145965600); Basith, Iftekhar Ibne (36975121700); Obeidat, Suleiman M. (23974665300); Yildiz, Faruk (23096584300)","57196328841; 59145965600; 36975121700; 23974665300; 23096584300","Board 46: Integrating AI in Higher-Education Protocol for a Pilot Study with'SAMCares An Adaptive Learning Hub'","2024","ASEE Annual Conference and Exposition, Conference Proceedings","","","","","","","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202055079&partnerID=40&md5=0bc78f35f2fdaaa4d98596d20bd6a702","Sam Houston State University, United States; College of Education, University of Texas, Austin, United States","Faruqui S.H.A., Sam Houston State University, United States; Tasnim N., College of Education, University of Texas, Austin, United States; Basith I.I., Sam Houston State University, United States; Obeidat S.M., Sam Houston State University, United States; Yildiz F., Sam Houston State University, United States","Learning never ends, and there is no age limit to grow yourself. However, the educational landscape may face challenges in effectively catering to students' inclusion and diverse learning needs. These students should have access to state-of-the-art methods for lecture delivery, online resources, and technology needs. However, with all the diverse learning sources, it becomes harder for students to comprehend a large amount of knowledge in a short period of time. Traditional assistive technologies and learning aids often lack the dynamic adaptability required for individualized education plans. Large Language Models (LLM) have been used in language translation, text summarization, and content generation applications. With rapid growth in AI over the past years, AI-powered chatbots and virtual assistants have been developed. This research aims to bridge this gap by introducing an innovative study buddy we will be calling the 'SAMCares'. The system leverages a Large Language Model (LLM) (in our case, LLaMa-2 70B as the base model) and Retriever-Augmented Generation (RAG) to offer real-time, context-aware, and adaptive educational support. The context of the model will be limited to the knowledge base of Sam Houston State University (SHSU) course notes. The LLM component enables a chat-like environment to interact with it to meet the unique learning requirements of each student. For this, we will build a custom web-based GUI. At the same time, RAG enhances real-time information retrieval and text generation, in turn providing more accurate and context-specific assistance. An option to upload additional study materials in the web GUI is added in case additional knowledge support is required. The system's efficacy will be evaluated through controlled trials and iterative feedback mechanisms. By interlinking Artificial Intelligence and assistive technology in an educational setting, this project aspires to advance personalized learning experiences for students, making meaningful strides in inclusive education. © American Society for Engineering Education, 2024.","Adaptive Learning; Interactive Learning; Large Language Model; Retriever Augmented Generation; SAMCares","Adversarial machine learning; Computer aided language translation; Contrastive Learning; Curricula; Federated learning; Graphical user interfaces; Knowledge based systems; Teaching; Adaptive learning; Assistive technology; High educations; Interactive learning; Language model; Large language model; Pilot studies; Retriever augmented generation; Samcare; State-of-the-art methods; Students","","American Society for Engineering Education","English","Conference paper","Final","","Scopus","2-s2.0-85202055079"
"Hung T.K.W.; Kuperman G.J.; Sherman E.J.; Ho A.L.; Weng C.; Pfister D.G.; Mao J.J.","Hung, Tony K.W. (57215314522); Kuperman, Gilad J. (7007145367); Sherman, Eric J. (7005978948); Ho, Alan L. (7402675254); Weng, Chunhua (8979750700); Pfister, David G. (7005653932); Mao, Jun J. (57213041237)","57215314522; 7007145367; 7005978948; 7402675254; 8979750700; 7005653932; 57213041237","Performance of Retrieval-Augmented Large Language Models to Recommend Head and Neck Cancer Clinical Trials","2024","Journal of Medical Internet Research","26","","e60695","","","","0","10.2196/60695","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206558566&doi=10.2196%2f60695&partnerID=40&md5=71c0ac9cc9f13658f9e1cfbd7a11b4f6","Memorial Sloan Kettering Cancer Center, New York, NY, United States; Columbia University, Department of Biomedical Informatics, New York, NY, United States","Hung T.K.W., Memorial Sloan Kettering Cancer Center, New York, NY, United States; Kuperman G.J., Memorial Sloan Kettering Cancer Center, New York, NY, United States; Sherman E.J., Memorial Sloan Kettering Cancer Center, New York, NY, United States; Ho A.L., Memorial Sloan Kettering Cancer Center, New York, NY, United States; Weng C., Columbia University, Department of Biomedical Informatics, New York, NY, United States; Pfister D.G., Memorial Sloan Kettering Cancer Center, New York, NY, United States; Mao J.J., Memorial Sloan Kettering Cancer Center, New York, NY, United States","[No abstract available]","AI; artificial intelligence; cancer care delivery; ChatGPT; clinical trials; decision support; GPT-4; head and neck cancer; head and neck oncology; large language model; LLM; LookUpTrials; retrieval augmented generation","Clinical Trials as Topic; Head and Neck Neoplasms; Humans; Information Storage and Retrieval; clinical trial (topic); head and neck tumor; human; information retrieval; procedures; therapy","","JMIR Publications Inc.","English","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85206558566"
"Urban M.; Binnig C.","Urban, Matthias (58113393900); Binnig, Carsten (16548747700)","58113393900; 16548747700","Demonstrating CAESURA: Language Models as Multi-Modal Query Planners","2024","Proceedings of the ACM SIGMOD International Conference on Management of Data","","","","472","475","3","0","10.1145/3626246.3654732","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196362792&doi=10.1145%2f3626246.3654732&partnerID=40&md5=9d110858bcdcf1319d5c2c7f15286497","Technical University of Darmstadt, Darmstadt, Germany; Technical University of Darmstadt, Dfki, Darmstadt, Germany","Urban M., Technical University of Darmstadt, Darmstadt, Germany; Binnig C., Technical University of Darmstadt, Dfki, Darmstadt, Germany","In many domains, multi-modal data takes an important role and modern question-answering systems based on LLMs allow users to query this data using simple natural language queries. Retrieval Augmented Generation (RAG) is a recent approach that extends Large Language Models (LLM) with database technology to enable such multi-modal QA systems. In RAG, relevant data is first retrieved from a vector database and then fed into an LLM that computes the query result. However, RAG-based approaches have severe issues, such as regarding efficiency and scalability, since LLMs have high inference costs and can only process limited amounts of data. Therefore, in this demo paper, we propose CAESURA, a database-first approach that extends databases with LLMs. The main idea is that CAESURA utilizes the reasoning capabilities of LLMs to translate natural language queries into execution plans. Using such execution plans allows CAESURA to process multi-modal data outside the LLM using query operators and optimization strategies that are footed in scalable query execution strategies of databases. Our demo allows users to experience CAESURA on two example datasets containing tables, texts, and images1.  © 2024 ACM.","large language models; multi-modal; query planning","Computational linguistics; Modal analysis; Natural language processing systems; Query processing; Search engines; Execution plans; Language model; Large language model; Multi-modal; Multi-modal data; Multi-modal queries; Natural language queries; Query planning; Question answering systems; Simple++; Database systems","","Association for Computing Machinery","English","Conference paper","Final","","Scopus","2-s2.0-85196362792"
"Wen S.; Qian L.; Hu M.; Chang Z.","Wen, Sen (58537135500); Qian, Li (57210576321); Hu, Maodi (59031474500); Chang, Zhijun (57221599101)","58537135500; 57210576321; 59031474500; 57221599101","Review of Research Progress on Question-Answering Techniques Based on Large Language Models; [基于大语言模型的问答技术研究进展综述]","2024","Data Analysis and Knowledge Discovery","8","6","","16","29","13","0","10.11925/infotech.2096-3467.2023.0839","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200354998&doi=10.11925%2finfotech.2096-3467.2023.0839&partnerID=40&md5=be7449d1c12cd29949f628bb53b910e0","National Science Library, Chinese Academy of Sciences, Beijing, 100190, China; Department of Information Resources Management, School of Economics and Management, University of Chinese Academy of Sciences, Beijing, 100190, China; Key Laboratory of New Publishing and Knowledge Services for Scholarly Journals, Beijing, 100190, China","Wen S., National Science Library, Chinese Academy of Sciences, Beijing, 100190, China, Department of Information Resources Management, School of Economics and Management, University of Chinese Academy of Sciences, Beijing, 100190, China; Qian L., National Science Library, Chinese Academy of Sciences, Beijing, 100190, China, Department of Information Resources Management, School of Economics and Management, University of Chinese Academy of Sciences, Beijing, 100190, China, Key Laboratory of New Publishing and Knowledge Services for Scholarly Journals, Beijing, 100190, China; Hu M., National Science Library, Chinese Academy of Sciences, Beijing, 100190, China, Department of Information Resources Management, School of Economics and Management, University of Chinese Academy of Sciences, Beijing, 100190, China; Chang Z., National Science Library, Chinese Academy of Sciences, Beijing, 100190, China, Department of Information Resources Management, School of Economics and Management, University of Chinese Academy of Sciences, Beijing, 100190, China","[Objective] This paper aims to comprehensively review and summarize the current development status, mechanism principles, and application trends of question-answering techniques based on large language models. [Coverage] We retrieved a total of 73 relevant papers. [Methods] The study systematically reviews the development status of large language models and efficient parameter fine-tuning strategies. It analyzes the principles, mechanisms, application value, and existing issues of various techniques. It focuses on retrieval-enhanced generation question-answering inference for simple questions and prompt engineering question inference for complex questions. Through qualitative analysis, the research progress of question-answering techniques based on large language models is comprehensively summarized, and future research directions are proposed. [Results] Open-sourced pre-trained large language models continue to emerge, and efficient fine-tuning strategies can significantly improve model adaptability in vertical domains. Retrieval-augmented generation techniques, aided by text embeddings and approximate nearest neighbor retrieval technology, effectively enhance the interpretability and credibility of question-answering. With carefully crafted prompt engineering, the inference capabilities of large models for complex questions can be significantly expanded. [Limitations] The rapid development of research related to large models may result in incomplete coverage of relevant survey work. [Conclusions] Question-answering techniques based on large language models have made remarkable progress in semantic representation, complex reasoning, and other aspects. Retrieval-enhanced generation techniques and prompt engineering, which integrate external knowledge, are the main research hotspots in large models. Future research may focus on exploring aspects such as controllable and credible content generation. © 2024 Chinese Academy of Sciences. All rights reserved.","Large Language Models; Prompt Engineering; Q&A Technology; Vector Retrieval","Computational linguistics; Semantics; Development status; Fine tuning; Language model; Large language model; Large models; Prompt engineering; Q&A technology; Question Answering; Tuning strategy; Vector retrieval; Nearest neighbor search","","Chinese Academy of Sciences","Chinese","Review","Final","","Scopus","2-s2.0-85200354998"
"Buehler M.J.","Buehler, Markus J. (7102467930)","7102467930","MechGPT, a Language-Based Strategy for Mechanics and Materials Modeling That Connects Knowledge Across Scales, Disciplines, and Modalities","2024","Applied Mechanics Reviews","76","2","021001","","","","16","10.1115/1.4063843","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184374431&doi=10.1115%2f1.4063843&partnerID=40&md5=084eb60d2696016fb425056f373995e0","Laboratory for Atomistic and Molecular Mechanics (LAMM), Massachusetts Institute of Technology, 77 Massachusetts Avenue, Cambridge, 02139, MA, United States; Center for Computational Science and Engineering, Schwarzman College of Computing, Massachusetts Institute of Technology, 77 Massachusetts Avenue, Cambridge, 02139, MA, United States","Buehler M.J., Laboratory for Atomistic and Molecular Mechanics (LAMM), Massachusetts Institute of Technology, 77 Massachusetts Avenue, Cambridge, 02139, MA, United States, Center for Computational Science and Engineering, Schwarzman College of Computing, Massachusetts Institute of Technology, 77 Massachusetts Avenue, Cambridge, 02139, MA, United States","For centuries, researchers have sought out ways to connect disparate areas of knowledge. While early scholars (Galileo, da Vinci, etc.) were experts across fields, specialization took hold later. With the advent of Artificial Intelligence, we can now explore relationships across areas (e.g., mechanics-biology) or disparate domains (e.g., failure mechanics-art). To achieve this, we use a fine-tuned large language model (LLM), here for a subset of knowledge in multiscale materials failure. The approach includes the use of a general-purpose LLM to distill question-answer pairs from raw sources followed by LLM fine-tuning. The resulting MechGPTLLMfoundation model is used in a series of computational experiments to explore its capacity for knowledge retrieval, various language tasks, hypothesis generation, and connecting knowledge across disparate areas. While the model has some ability to recall knowledge from training, we find that LLMs are particularly useful for extracting structural insights through Ontological Knowledge Graphs. These interpretable graph structures provide explanatory insights, frameworks for new research questions, and visual representations of knowledge that also can be used in retrieval-augmented generation. Three versions of MechGPT are discussed, featuring different sizes from 13×109 to 70×109 parameters, and reaching context lengths of more than 10,000 tokens. This provides ample capacity for sophisticated retrieval augmented strategies, as well as agentbased modeling where multiple LLMs interact collaboratively and/or adversarially, the incorporation of new data from the literature or web searches, as well as multimodality.  Copyright © 2024 by ASME.","AI; attention; failure; GPT; human-machine; language model; materials; mechanics; scientific ML; transformer","Computational linguistics; Graphic methods; Knowledge graph; Modeling languages; Attention; GALILEO; GPT; Human-machine; Language model; Material modeling; Mechanic model; Scientific ML; Specialisation; Transformer; Failure (mechanical)","","American Society of Mechanical Engineers (ASME)","English","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85184374431"
"Garlyal J.S.; Hariharan B.; Singh A.K.","Garlyal, Jaideep Singh (58797777300); Hariharan, B. (57211274463); Singh, Adarsh Kumar (59360743500)","58797777300; 57211274463; 59360743500","An Analysis on Integrating Advanced Conversational AI in Legal Summarization and Information Retrieval","2024","Proceedings - 2024 2nd International Conference on Inventive Computing and Informatics, ICICI 2024","","","","43","46","3","0","10.1109/ICICI62254.2024.00016","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205958338&doi=10.1109%2fICICI62254.2024.00016&partnerID=40&md5=ba3473589d0d452a23657fee1cd714b8","SRM Institute of Science & Technology, Department of Computational Intelligence, Chennai, India","Garlyal J.S., SRM Institute of Science & Technology, Department of Computational Intelligence, Chennai, India; Hariharan B., SRM Institute of Science & Technology, Department of Computational Intelligence, Chennai, India; Singh A.K., SRM Institute of Science & Technology, Department of Computational Intelligence, Chennai, India","This research study explores the impact of advanced conversational AI, particularly LawGPT, on legal practice. Specializing in the Indian Penal Code (IPC) and integrated with the Legal Language Model (LLM), LawGPT offers precise interpretation of legal queries. By utilizing advanced pre-processing techniques, Dense Passage Retriever (DPR) for retrieval, and BART architecture for generation, LawGPT ensures contextually relevant responses. Through validation against human-generated responses, its efficacy and accuracy are affirmed, democratizing access to legal knowledge for professionals and laypersons. LawGPT's adoption promises to revolutionize legal research, enhancing efficiency and inclusivity in legal interactions. This study analyzes its widespread integration, recognizing its potential to shape a more accessible and efficient legal system, contributing to the ongoing research on exploring AI's role in legal practice.  © 2024 IEEE.","LawGPT; Legal Document Summarizer; LLM; RAG Architecture","Computer architecture; Laws and legislation; Language model; LawGPT; Legal document summarizer; Legal documents; Legal knowledge; Legal language model; Legal queries; Pre-processing techniques; RAG architecture; Research studies; Query languages","","Institute of Electrical and Electronics Engineers Inc.","English","Conference paper","Final","","Scopus","2-s2.0-85205958338"
"Wei Z.; Zhang Q.; Duan Q.; Wang G.; Li R.; Li X.; Chen Q.; Yang T.; Zhang L.; Jiang K.","Wei, Zizhong (58676956000); Zhang, Qilai (58701628800); Duan, Qiang (57211990771); Wang, Guangxin (59169316900); Li, Rui (57211802295); Li, Xue (57286456800); Chen, Qibin (57742494400); Yang, Tong (59074582900); Zhang, Lei (59169781100); Jiang, Kai (57742591900)","58676956000; 58701628800; 57211990771; 59169316900; 57211802295; 57286456800; 57742494400; 59074582900; 59169781100; 57742591900","TAR: A Think-Action-Reflection Framework for Complex Problem Solving with Large Language Models","2024","ACM International Conference Proceeding Series","","","","282","286","4","0","10.1145/3677779.3677825","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205445583&doi=10.1145%2f3677779.3677825&partnerID=40&md5=571dd9e055caea2bd48d829c30d9b777","Inspur Academy of Science and Technology, Shandong, Jinan, China; School of Control Science and Engineering, Shandong University, Jinan, 250061, China","Wei Z., Inspur Academy of Science and Technology, Shandong, Jinan, China; Zhang Q., Inspur Academy of Science and Technology, Shandong, Jinan, China; Duan Q., Inspur Academy of Science and Technology, Shandong, Jinan, China, School of Control Science and Engineering, Shandong University, Jinan, 250061, China; Wang G., Inspur Academy of Science and Technology, Shandong, Jinan, China; Li R., Inspur Academy of Science and Technology, Shandong, Jinan, China; Li X., Inspur Academy of Science and Technology, Shandong, Jinan, China; Chen Q., Inspur Academy of Science and Technology, Shandong, Jinan, China; Yang T., Inspur Academy of Science and Technology, Shandong, Jinan, China; Zhang L., Inspur Academy of Science and Technology, Shandong, Jinan, China; Jiang K., Inspur Academy of Science and Technology, Shandong, Jinan, China","In real-world user interactions, complex problems often involve multiple intents, such as retrieval, RAG (Retrieval-Augmented Generation), and generation. However, existing methods such as ReAct and COT (Chain-of-Thought) are designed for single tasks, resulting in a gap between research and practical applications. To bridge this gap, we propose a novel complex problem-solving framework called TAR (Think-Action-Reflection). The framework consists of three key stages: the Think stage conducts fine-grained, multidimensional analysis of the problem to form a structured problem representation; the Action stage dynamically schedules execution tools based on the output of the Think stage, flexibly adapting to the solving requirements of different problems; and the Reflection stage assesses the alignment between the outputs from the Action stage and the initial user intent, initiating iterative enhancements where necessary. To verify the effectiveness of the TAR framework, we conducted experiments on two types of datasets. Firstly, we constructed a business scenario dataset to validate the effectiveness of the proposed method in addressing real-world problems. Secondly, we evaluated the effectiveness of the Think stage using open-domain question answering datasets such as HotpotQA, TriviaQA, and Natural Questions (NQ). The results demonstrate that, compared with existing methods, the TAR framework achieves significant performance improvements across various complex problem tasks, exhibiting advantages in problem understanding, task execution, and result optimization. These findings confirm the effectiveness of the TAR framework as a paradigm for complex problem-solving in real-world user interactions. © 2024 Copyright held by the owner/author(s).","Chain-of-thought prompting; Large language models; Retrieval-augmented generation; Think-Action-Reflection framework","Human computer interaction; Large datasets; Metadata; Modeling languages; Problem oriented languages; Chain-of-thought prompting; Complex problem solving; Complex problems; Fine grained; Language model; Large language model; Real-world; Retrieval-augmented generation; Think-action-reflection framework; User interaction; Tar","","Association for Computing Machinery","English","Conference paper","Final","","Scopus","2-s2.0-85205445583"
"Barnett S.; Kurniawan S.; Thudumu S.; Brannelly Z.; Abdelrazek M.","Barnett, Scott (56890458900); Kurniawan, Stefanus (58059538300); Thudumu, Srikanth (57193405438); Brannelly, Zach (58827596500); Abdelrazek, Mohamed (56080446200)","56890458900; 58059538300; 57193405438; 58827596500; 56080446200","Seven failure points when engineering a retrieval augmented generation system","2024","Proceedings - 2024 IEEE/ACM 3rd International Conference on AI Engineering - Software Engineering for AI, CAIN 2024","","","","194","199","5","0","10.1145/3644815.3644945","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196561155&doi=10.1145%2f3644815.3644945&partnerID=40&md5=c8c44f4e0167b8e8534b619c35347a49","Applied Artificial Intelligence Institute, Deakin University, Geelong, VIC, Australia","Barnett S., Applied Artificial Intelligence Institute, Deakin University, Geelong, VIC, Australia; Kurniawan S., Applied Artificial Intelligence Institute, Deakin University, Geelong, VIC, Australia; Thudumu S., Applied Artificial Intelligence Institute, Deakin University, Geelong, VIC, Australia; Brannelly Z., Applied Artificial Intelligence Institute, Deakin University, Geelong, VIC, Australia; Abdelrazek M., Applied Artificial Intelligence Institute, Deakin University, Geelong, VIC, Australia","Software engineers are increasingly adding semantic search capabilities to applications using a strategy known as Retrieval Augmented Generation (RAG). A RAG system involves finding documents that semantically match a query and then passing the documents to a large language model (LLM) such as ChatGPT to extract the right answer using an LLM. RAG systems aim to: a) reduce the problem of hallucinated responses from LLMs, b) link sources/references to generated responses, and c) remove the need for annotating documents with meta-data. However, RAG systems suffer from limitations inherent to information retrieval systems and from reliance on LLMs. In this paper, we present an experience report on the failure points of RAG systems from three case studies from separate domains: research, education, and biomedical. We share the lessons learned and present 7 failure points to consider when designing a RAG system. The two key takeaways arising from our work are: 1) validation of a RAG system is only feasible during operation, and 2) the robustness of a RAG system evolves rather than designed in at the start. We conclude with a list of potential research directions on RAG systems for the software engineering community. © 2024 Copyright is held by the owner/author(s). Publication rights licensed to ACM.","case study; RAG; retrieval augmented generation; SE4AI","Application programs; Failure (mechanical); Information retrieval; Query processing; Search engines; Semantics; Case-studies; Failure points; Generation systems; Information-retrieval systems; Language model; Retrieval augmented generation; SE4AI; Search capabilities; Semantic search; Information retrieval systems","","Association for Computing Machinery, Inc","English","Conference paper","Final","All Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85196561155"
"Suresh K.; Kackar N.; Schleck L.; Fanelli C.","Suresh, Karthik (57210555594); Kackar, Neeltje (58973775800); Schleck, Luke (58973893000); Fanelli, Cristiano (56855698200)","57210555594; 58973775800; 58973893000; 56855698200","Towards a RAG-based summarization for the Electron Ion Collider","2024","Journal of Instrumentation","19","7","C07006","","","","0","10.1088/1748-0221/19/07/C07006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199201270&doi=10.1088%2f1748-0221%2f19%2f07%2fC07006&partnerID=40&md5=b3ed1d4187c039cb86eaab0ebadda222","Department of Data Science, College of William & Mary, VA, Williamsburg, 23185, United States; Department of Physics, College of William & Mary, VA, Williamsburg, 23185, United States","Suresh K., Department of Data Science, College of William & Mary, VA, Williamsburg, 23185, United States; Kackar N., Department of Data Science, College of William & Mary, VA, Williamsburg, 23185, United States; Schleck L., Department of Data Science, College of William & Mary, VA, Williamsburg, 23185, United States; Fanelli C., Department of Data Science, College of William & Mary, VA, Williamsburg, 23185, United States, Department of Physics, College of William & Mary, VA, Williamsburg, 23185, United States","The complexity and sheer volume of information — encompassing documents, papers, data, and other resources — from large-scale experiments demand significant time and effort to navigate, making the task of accessing and utilizing these varied forms of information daunting, particularly for new collaborators and early-career scientists. To tackle this issue, a Retrieval Augmented Generation (RAG)-based Summarization AI for EIC (RAGS4EIC) is under development. This AI-Agent not only condenses information but also effectively references relevant responses, offering substantial advantages for collaborators. Our project involves a two-step approach: first, querying a comprehensive vector database containing all pertinent experiment information; second, utilizing a Large Language Model (LLM) to generate concise summaries enriched with citations based on user queries and retrieved data. We describe the evaluation methods that use RAG assessments (RAGAs) scoring mechanisms to assess the effectiveness of responses. Furthermore, we describe the concept of prompt template based instruction-tuning which provides flexibility and accuracy in summarization. Importantly, the implementation relies on LangChain [1], which serves as the foundation of our entire workflow. This integration ensures efficiency and scalability, facilitating smooth deployment and accessibility for various user groups within the Electron Ion Collider (EIC) community. This innovative AI-driven framework not only simplifies the understanding of vast datasets but also encourages collaborative participation, thereby empowering researchers. As a demonstration, a web application has been developed to explain each stage of the RAG Agent development in detail. The application can be accessed at https://rags4eic-ai4eic.streamlit.app.[A tagged version of the source code can be found in https://github.com/ai4eic/EIC-RAG-Project/releases/tag/AI4EIC2023_PROCEEDING.] © 2024 The Author(s)","Analysis and statistical methods; Computing (architecture, farms, GRID for recording, storage, archiving, and distribution of data); Software architectures (event data models, frameworks and databases)","Computational linguistics; High energy physics; Query processing; Analyse and statistical method; Computing (architecture, farm, GRID for recording, storage, archiving, and distribution of data); Computing architecture; Electron ions; Language model; Large scale experiments; Modelling framework; Software architecture (event data model, framework and database); Two-step approach; User query; Digital storage","","Institute of Physics","English","Article","Final","","Scopus","2-s2.0-85199201270"
"Oro E.; Granata F.M.; Lanza A.; Bachir A.; De Grandis L.; Ruffolo M.","Oro, Ermelinda (25925359300); Granata, Francesco Maria (59300481900); Lanza, Antonio (58296996700); Bachir, Amir (59353230300); De Grandis, Luca (59299745300); Ruffolo, Massimo (8951963200)","25925359300; 59300481900; 58296996700; 59353230300; 59299745300; 8951963200","Evaluating Retrieval-Augmented Generation for Question Answering with Large Language Models","2024","CEUR Workshop Proceedings","3762","","","129","134","5","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205590448&partnerID=40&md5=db794c2d8058e9c827a5d03c019d5441","National Research Council, Institute for High Performance Computing and Networking, via P. Bucci 8/9C, CS, Rende, 87036, Italy; Altilia srl, TechNest Start-up Incubator of University of Calabria, Piazza Vermicelli, CS, Rende, 87036, Italy","Oro E., National Research Council, Institute for High Performance Computing and Networking, via P. Bucci 8/9C, CS, Rende, 87036, Italy, Altilia srl, TechNest Start-up Incubator of University of Calabria, Piazza Vermicelli, CS, Rende, 87036, Italy; Granata F.M., Altilia srl, TechNest Start-up Incubator of University of Calabria, Piazza Vermicelli, CS, Rende, 87036, Italy; Lanza A., Altilia srl, TechNest Start-up Incubator of University of Calabria, Piazza Vermicelli, CS, Rende, 87036, Italy; Bachir A., Altilia srl, TechNest Start-up Incubator of University of Calabria, Piazza Vermicelli, CS, Rende, 87036, Italy; De Grandis L., Altilia srl, TechNest Start-up Incubator of University of Calabria, Piazza Vermicelli, CS, Rende, 87036, Italy; Ruffolo M., National Research Council, Institute for High Performance Computing and Networking, via P. Bucci 8/9C, CS, Rende, 87036, Italy, Altilia srl, TechNest Start-up Incubator of University of Calabria, Piazza Vermicelli, CS, Rende, 87036, Italy","We present a comprehensive framework for evaluating retrieval-augmented generation (RAG) systems designed for question-answering tasks using large language models (LLMs). The proposed framework integrates document ingestion, information retrieval, answer generation, and evaluation phases. Both ground truth-based and reference-free evaluation metrics are implemented to provide a multi-faceted assessment approach. Through experiments across diverse datasets like NarrativeQA and a proprietary financial dataset (FinAM-it), the reliability of existing metrics is investigated by comparing them against rigorous human evaluations. The results demonstrate that ground truth-based metrics such as BEM and RAGAS Answer Correctness exhibit a moderately strong correlation with human judgments. However, reference-free metrics still struggle to capture nuances in answer quality without predefined correct responses accurately. An in-depth analysis of Spearman correlation coefficients sheds light on the interrelationships and relative effectiveness of various evaluation approaches across multiple domains. While highlighting the current limitations of reference-free methodologies, the study underscores the need for more sophisticated techniques to better approximate human perception of answer relevance and correctness. Overall, this research contributes to ongoing efforts in developing reliable evaluation frameworks for RAG systems, paving the way for advancements in natural language processing and the realization of highly accurate and human-like AI systems. © 2024 Copyright for this paper by its authors.","Evaluation; Large Language Model (LLM); Question Answering (QA); Retrieval; Retrieval Augmented Generation (RAG)","Natural language processing systems; Evaluation; Generation systems; Ground truth; Language model; Large language model; Question Answering; Reference-free; Retrieval; Retrieval augmented generation; Question answering","Di Martino S.; University of Naples Federico II, Department of Electrical Engineering and Information Technology (DIETI), Via Claudio 21, Naples; Sansone C.; University of Naples Federico II, Department of Electrical Engineering and Information Technology (DIETI), Via Claudio 21, Naples; Masciari E.; University of Naples Federico II, Department of Electrical Engineering and Information Technology (DIETI), Via Claudio 21, Naples; Rossi S.; University of Naples Federico II, Department of Electrical Engineering and Information Technology (DIETI), Via Claudio 21, Naples; Gravina M.; University of Naples Federico II, Department of Electrical Engineering and Information Technology (DIETI), Via Claudio 21, Naples","CEUR-WS","English","Conference paper","Final","","Scopus","2-s2.0-85205590448"
"Arslan M.; Munawar S.; Cruz C.","Arslan, Muhammad (55807840100); Munawar, Saba (57201122151); Cruz, Christophe (7202701902)","55807840100; 57201122151; 7202701902","Business insights using RAG–LLMs: a review and case study","2024","Journal of Decision Systems","","","","","","","0","10.1080/12460125.2024.2410040","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205882314&doi=10.1080%2f12460125.2024.2410040&partnerID=40&md5=e7ee02c4f292a7b2479d870529801016","School of Architecture and Environment, University of the West of England, Bristol, United Kingdom; Laboratoire Interdisciplinaire Carnot de Bourgogne (ICB), Université de Bourgogne, Dijon, France; Electrical (Telecommunication) Engineering Department, National University of Computer and Emerging Sciences (NUCES), Islamabad, Pakistan","Arslan M., School of Architecture and Environment, University of the West of England, Bristol, United Kingdom, Laboratoire Interdisciplinaire Carnot de Bourgogne (ICB), Université de Bourgogne, Dijon, France; Munawar S., Electrical (Telecommunication) Engineering Department, National University of Computer and Emerging Sciences (NUCES), Islamabad, Pakistan; Cruz C., Laboratoire Interdisciplinaire Carnot de Bourgogne (ICB), Université de Bourgogne, Dijon, France","As organizations increasingly rely on diverse data sources like invoices and surveys, efficient Information Extraction (IE) is crucial. Natural Language Processing (NLP) enhances IE through tasks such as Named Entity Recognition (NER), Relation Extraction (RE), Event Extraction (EE), Term Extraction (TE), and Topic Modeling (TM). However, implementing these methods requires significant expertise, which smaller organizations often lack. Large Language Models (LLMs), powered by Generative Artificial Intelligence (GenAI), can address this by performing multiple IE tasks without extensive development costs. However, LLMs may struggle with domain-specific accuracy. Integrating Retrieval-Augmented Generation (RAG) with LLMs improves precision by incorporating external data. Despite the potential, research on RAG-LLM applications in the business domain is limited. This article reviews Business IE systems, explores RAG-LLM applications across disciplines, and presents a case study demonstrating how RAG-LLMs can enhance business insights, offering scalable, cost-effective solutions. © 2024 Informa UK Limited, trading as Taylor & Francis Group.","generative artificial intelligence; Information extraction; large language models; natural language processing; retrieval-augmented generation","Data assimilation; Data integration; Metadata; Natural language processing systems; Case-studies; Generative artificial intelligence; Information extraction; Language model; Language processing; Large language model; Model application; Natural language processing; Natural languages; Retrieval-augmented generation; Modeling languages","","Taylor and Francis Ltd.","English","Article","Article in press","","Scopus","2-s2.0-85205882314"
"Shi L.; Kazda M.; Sears B.; Shropshire N.; Puri R.","Shi, Luyao (55819105300); Kazda, Michael (56728171000); Sears, Bradley (59196959500); Shropshire, Nick (59196120700); Puri, Ruchir (57205888332)","55819105300; 56728171000; 59196959500; 59196120700; 57205888332","Ask-EDA: A Design Assistant Empowered by LLM, Hybrid RAG and Abbreviation De-hallucination","2024","2024 IEEE LLM Aided Design Workshop, LAD 2024","","","","","","","0","10.1109/LAD62341.2024.10691824","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206643062&doi=10.1109%2fLAD62341.2024.10691824&partnerID=40&md5=b6f225642584aca86678123ba1774c6a","Ibm Research, San Jose, CA, United States; Ibm Infrastructure, Poughkeepsie, NY, United States; Ibm Infrastructure, Austin, TX, United States; Ibm Research, Yorktown Heights, NY, United States","Shi L., Ibm Research, San Jose, CA, United States; Kazda M., Ibm Infrastructure, Poughkeepsie, NY, United States; Sears B., Ibm Infrastructure, Austin, TX, United States; Shropshire N., Ibm Infrastructure, Austin, TX, United States; Puri R., Ibm Research, Yorktown Heights, NY, United States","Electronic design engineers are challenged to find relevant information efficiently for a myriad of tasks within design construction, verification and technology development. Large language models (LLM) have the potential to help improve productivity by serving as conversational agents that effectively function as subject-matter experts. In this paper we demonstrate Ask-EDA, a chat agent designed to serve as a 24×7 expert available to provide guidance to design engineers. Ask-EDA leverages LLM, hybrid retrieval augmented generation (RAG) and abbreviation de-hallucination (ADH) techniques to deliver more relevant and accurate responses. We curated three evaluation datasets, namely q2a-100, cmds-100 and abbr-100. Each dataset is tailored to assess a distinct aspect: general design question answering, design command handling and abbreviation resolution. We demonstrated that hybrid RAG offers over a 40% improvement in Recall on the q2a-100 dataset and over a 60% improvement on the cmds-100 dataset compared to not using RAG, while ADH yields over a 70% enhancement in Recall on the abbr-100 dataset. The evaluation results show that Ask-EDA can effectively respond to design-related inquiries.  © 2024 IEEE.","chatbot; de-hallucination; design assistant; EDA; hybrid search; Large language models; LLM; RAG; retrieval augmented generation","Behavioral research; Electronic design automation; Integrated circuit design; Structural dynamics; Chatbots; De-hallucination; Design assistant; EDA; Hybrid search; Language model; Large language model; Retrieval augmented generation; Chatbots","","Institute of Electrical and Electronics Engineers Inc.","English","Conference paper","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85206643062"
"Shen J.; He H.; Shen W.; Shen T.","Shen, Jie (59362876100); He, Huaiyuan (59362477500); Shen, Wenzhuo (59363399100); Shen, Tiyan (18233785000)","59362876100; 59362477500; 59363399100; 18233785000","Enhancing the RAG Retrieval Engine Through Multi-Encoder Fusion","2024","2024 5th International Conference on Electronic Communication and Artificial Intelligence, ICECAI 2024","","","","227","230","3","0","10.1109/ICECAI62591.2024.10674962","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206106165&doi=10.1109%2fICECAI62591.2024.10674962&partnerID=40&md5=bf4c7aeb3a6c6ea602409f1e16834660","PKU-WUHAN Institute for Artificial Intelligence, Wuhan, 430223, China; Wuhan Research Institute of Posts and Telecommunications, Wuhan, 430074, China; School of Government Peking University, Beijing, 100871, China; School of Information and Communication Engineering, Beijing University of Posts and Telecommunications, Beijing, 100876, China","Shen J., PKU-WUHAN Institute for Artificial Intelligence, Wuhan, 430223, China, Wuhan Research Institute of Posts and Telecommunications, Wuhan, 430074, China; He H., PKU-WUHAN Institute for Artificial Intelligence, Wuhan, 430223, China, School of Government Peking University, Beijing, 100871, China; Shen W., School of Information and Communication Engineering, Beijing University of Posts and Telecommunications, Beijing, 100876, China; Shen T., PKU-WUHAN Institute for Artificial Intelligence, Wuhan, 430223, China, School of Government Peking University, Beijing, 100871, China","With the rapid advancement of large language model technology, Retriever-Augmented Generation (RAG), which is based on vector databases, has demonstrated extensive potential for application. This paper focuses on the text retrieval phase of RAG, enhancing text recall by introducing multiple text encoders. Consequently, this paper designs a neural network model and loss function for multi-encoder fusion and determines the optimal weight allocation for multi-encoder fusion through neural network training. Experimental results demonstrate that the predicted fusion weights from the neural network trained in this paper can be closely aligned with the optimal fusion weights. By using the predicted BCE and BGE encoding model weights, an improvement of 6% in Mean Reciprocal Rank (MRR) is achieved. © 2024 IEEE.","component; Large Language Model; Retriever-Augmented Generation; Vector database","Encoding (symbols); Modeling languages; Network coding; Component; Language model; Large language model; Modeling technology; Network loss; Neural network model; Retrieval engines; Retriever-augmented generation; Text retrieval; Vector database; Neural networks","","Institute of Electrical and Electronics Engineers Inc.","English","Conference paper","Final","","Scopus","2-s2.0-85206106165"
"Hou F.; Chen Y.; Shi X.; Li M.; Zhao X.","Hou, Fuqing (59357598500); Chen, Yibing (57202870960); Shi, Xin (57208385618); Li, Min (58795985700); Zhao, Xueqing (57207136397)","59357598500; 57202870960; 57208385618; 58795985700; 57207136397","LLM-based user requirement analysis and intelligent Q&A toward Chang'an Twelve Hours","2024","Proceedings - 2024 International Conference on Culture-Oriented Science and Technology, CoST 2024","","","","151","155","4","0","10.1109/CoST64302.2024.00038","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205777312&doi=10.1109%2fCoST64302.2024.00038&partnerID=40&md5=6ed5e409feff889f27c5c5240214a173","Ministry of Culture and Tourism, China, National Center for Public Culture Development, Beijing, China; Xi'an Polytechnic University, School of Computer Science, Xi'an, China; Communication University of China, School of Information and Communication, Xi'an, China","Hou F., Xi'an Polytechnic University, School of Computer Science, Xi'an, China; Chen Y., Ministry of Culture and Tourism, China, National Center for Public Culture Development, Beijing, China; Shi X., Xi'an Polytechnic University, School of Computer Science, Xi'an, China, Communication University of China, School of Information and Communication, Xi'an, China; Li M., Xi'an Polytechnic University, School of Computer Science, Xi'an, China; Zhao X., Xi'an Polytechnic University, School of Computer Science, Xi'an, China","The new technology of artificial intelligence can bring users a fresh experience and accelerate the rapid development of cultural and tourism integration. In this paper, we use a large language model (LLM) to mine user implicit demands and implement intelligent Q&A reasoning for the Chang'an Twelve Hours Scenic Area. First, multi-faceted data related to Chang'an Twelve Hours is collected to construct a vector database. Next, the LLM is utilized to mine the implicit requirements of user questions by combining attribute features such as gender and age. Then, the user demand vectors are retrieved and matched with the content vectors in the vector database. Finally, the similar content obtained from user demand and retrieval feedback is used to populate the prompt template and input into the LLM, realizing intelligent Q&A and reasoning for the Twelve Hours of Chang'an. On this basis, a prototype of an intelligent Q&A system tailored to the Twelve Hours of Chang'an is constructed. Experimental comparisons with the traditional Retrieval-Augmented Generation (RAG) technique demonstrate that using an LLM enables finer mining of user requirements and generates more accurate answers. The intelligent Q&A system for Chang'an Twelve Hours developed in this paper effectively addresses users' customized inquiries, thereby enhancing the user experience and improving the operational efficiency of the scenic spot. Additionally, this system can serve as a reference model for implementation at other cultural tourism attractions.  © 2024 IEEE.","Large language model; Questions and answers; Retrieval augmented generation; User requirements","Intelligent databases; Modeling languages; Experimental comparison; Language model; Large language model; Model-based OPC; Question and answer; Retrieval augmented generation; Scenic areas; User demands; User requirement analysis; User requirements; Tourism","","Institute of Electrical and Electronics Engineers Inc.","English","Conference paper","Final","","Scopus","2-s2.0-85205777312"
"Schilling A.; Anurathan J.; Mühlberger J.; Gerschner F.; Rössle M.; Theissler A.; Klaiber M.","Schilling, Alexander (57866223900); Anurathan, James (57866419300); Mühlberger, Johannes (59362418100); Gerschner, Felix (57668444300); Rössle, Manfred (56365981300); Theissler, Andreas (55337910800); Klaiber, Marco (57286817100)","57866223900; 57866419300; 59362418100; 57668444300; 56365981300; 55337910800; 57286817100","Querying Football Matches for Event Data: Towards Using Large Language Models","2024","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","14794 LNCS","","","216","227","11","0","10.1007/978-3-031-69073-0_19","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206095713&doi=10.1007%2f978-3-031-69073-0_19&partnerID=40&md5=12d6e46a6b58167966bce2d73c045053","Aalen University of Applied Sciences, Beethovenstr. 1, Aalen, 73430, Germany","Schilling A., Aalen University of Applied Sciences, Beethovenstr. 1, Aalen, 73430, Germany; Anurathan J., Aalen University of Applied Sciences, Beethovenstr. 1, Aalen, 73430, Germany; Mühlberger J., Aalen University of Applied Sciences, Beethovenstr. 1, Aalen, 73430, Germany; Gerschner F., Aalen University of Applied Sciences, Beethovenstr. 1, Aalen, 73430, Germany; Rössle M., Aalen University of Applied Sciences, Beethovenstr. 1, Aalen, 73430, Germany; Theissler A., Aalen University of Applied Sciences, Beethovenstr. 1, Aalen, 73430, Germany; Klaiber M., Aalen University of Applied Sciences, Beethovenstr. 1, Aalen, 73430, Germany","Football, being one of the most popular sports in the world, has attracted significant attention from researchers exploring the potential of Artificial Intelligence (AI). In particular, Large Language Models (LLMs), exemplified by digital assistants such as ChatGPT, have proven their capabilities and offer a potentially effective avenue for football research. However, accessibility of football data remains a challenge, as the datasets collected by providers are often inaccessible. This case study presents a proof-of-concept that addresses this challenge by introducing an innovative web scraping approach to extract football event data and making it accessible e.g. for scientific research with LLMs. To this end, the extracted data is structured into coherent sentences for linguistic compatibility. The results show the successful integration of LLMs with football event data, enabling the extraction of information through retrieval-augmented generation. This work makes a first contribution to the field by bridging the gap between football and LLMs, demonstrating the potential for further analysis. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.","Event Data; Football; Large Language Models","Modeling languages; Query languages; Case-studies; Digital assistants; Event data; Extraction of information; Language model; Large language model; Proof of concept; Scientific researches; Web scrapings; Structured Query Language","Dong J.S.; Izadi M.; Hou Z.","Springer Science and Business Media Deutschland GmbH","English","Conference paper","Final","","Scopus","2-s2.0-85206095713"
"Fadillah A.; Athahirah N.; Lai K.T.","Fadillah, Amar (58665598300); Athahirah, Nuke (59357270600); Lai, Kuan Ting (26028875000)","58665598300; 59357270600; 26028875000","Chunking Strategy for Retrieval Augmented Generation in Regulation Documents","2024","11th IEEE International Conference on Consumer Electronics - Taiwan, ICCE-Taiwan 2024","","","","279","280","1","0","10.1109/ICCE-Taiwan62264.2024.10674113","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205792675&doi=10.1109%2fICCE-Taiwan62264.2024.10674113&partnerID=40&md5=bce9a73e46faa976cfb0105aa41a309d","National Taipei University of Technology, College of Electrical Engineering and Computer Science, Taipei, Taiwan; Universitas Pendidikan Indonesia, Industrial Automation and Robotics Engineering Education, Bandung, Indonesia","Fadillah A., National Taipei University of Technology, College of Electrical Engineering and Computer Science, Taipei, Taiwan; Athahirah N., Universitas Pendidikan Indonesia, Industrial Automation and Robotics Engineering Education, Bandung, Indonesia; Lai K.T., National Taipei University of Technology, College of Electrical Engineering and Computer Science, Taipei, Taiwan","Large language model (LLM) have been proven to be capable of performing various text processing tasks. LLMs have the potential to be used as a tool for analyzing regulation documents. To enhance the ability of LLMs to analyze regulation documents, we propose a regulation document chunking method that improves the accuracy of the analysis results. Our proposed method produces better accuracy than the sequential chunking method. © 2024 IEEE.","Chunking; LLM; Regulation Documents","Chunking; Language model; Large language model; Regulation document; Text-processing; Modeling languages","","Institute of Electrical and Electronics Engineers Inc.","English","Conference paper","Final","","Scopus","2-s2.0-85205792675"
"Murugan M.; Yuan B.; Venner E.; Ballantyne C.M.; Robinson K.M.; Coons J.C.; Wang L.; Empey P.E.; Gibbs R.A.","Murugan, Mullai (57201728158); Yuan, Bo (56283019200); Venner, Eric (28168023200); Ballantyne, Christie M. (7101711066); Robinson, Katherine M. (58946611400); Coons, James C. (6701601052); Wang, Liwen (58945989600); Empey, Philip E. (12142118600); Gibbs, Richard A. (58189912700)","57201728158; 56283019200; 28168023200; 7101711066; 58946611400; 6701601052; 58945989600; 12142118600; 58189912700","Empowering personalized pharmacogenomics with generative AI solutions","2024","Journal of the American Medical Informatics Association","31","6","","1356","1366","10","5","10.1093/jamia/ocae039","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192852527&doi=10.1093%2fjamia%2focae039&partnerID=40&md5=aa44f956ec73ccc322e963e119240924","Human Genome Sequencing Center, Baylor College of Medicine, Houston, TX, United States; Department of Molecular and Human Genetics, Baylor College of Medicine, Houston, TX, United States; Sections of Cardiology and Cardiovascular Research, Department of Medicine, Baylor College of Medicine, Houston, TX, United States; School of Pharmacy, University of Pittsburgh, Pittsburgh, PA, United States; Department of Pharmacy, UPMC Presbyterian-Shadyside Hospital, Pittsburgh, PA, United States; Institute for Precision Medicine, UPMC, University of Pittsburgh, Pittsburgh, PA, United States","Murugan M., Human Genome Sequencing Center, Baylor College of Medicine, Houston, TX, United States; Yuan B., Human Genome Sequencing Center, Baylor College of Medicine, Houston, TX, United States, Department of Molecular and Human Genetics, Baylor College of Medicine, Houston, TX, United States; Venner E., Human Genome Sequencing Center, Baylor College of Medicine, Houston, TX, United States, Department of Molecular and Human Genetics, Baylor College of Medicine, Houston, TX, United States; Ballantyne C.M., Sections of Cardiology and Cardiovascular Research, Department of Medicine, Baylor College of Medicine, Houston, TX, United States; Robinson K.M., School of Pharmacy, University of Pittsburgh, Pittsburgh, PA, United States; Coons J.C., School of Pharmacy, University of Pittsburgh, Pittsburgh, PA, United States, Department of Pharmacy, UPMC Presbyterian-Shadyside Hospital, Pittsburgh, PA, United States; Wang L., Human Genome Sequencing Center, Baylor College of Medicine, Houston, TX, United States; Empey P.E., School of Pharmacy, University of Pittsburgh, Pittsburgh, PA, United States, Institute for Precision Medicine, UPMC, University of Pittsburgh, Pittsburgh, PA, United States; Gibbs R.A., Human Genome Sequencing Center, Baylor College of Medicine, Houston, TX, United States, Department of Molecular and Human Genetics, Baylor College of Medicine, Houston, TX, United States","Objective: This study evaluates an AI assistant developed using OpenAI's GPT-4 for interpreting pharmacogenomic (PGx) testing results, aiming to improve decision-making and knowledge sharing in clinical genetics and to enhance patient care with equitable access. Materials and Methods: The AI assistant employs retrieval-augmented generation (RAG), which combines retrieval and generative techniques, by harnessing a knowledge base (KB) that comprises data from the Clinical Pharmacogenetics Implementation Consortium (CPIC). It uses context-aware GPT-4 to generate tailored responses to user queries from this KB, further refined through prompt engineering and guardrails. Results: Evaluated against a specialized PGx question catalog, the AI assistant showed high efficacy in addressing user queries. Compared with OpenAI's ChatGPT 3.5, it demonstrated better performance, especially in provider-specific queries requiring specialized data and citations. Key areas for improvement include enhancing accuracy, relevancy, and representative language in responses. Discussion: The integration of context-aware GPT-4 with RAG significantly enhanced the AI assistant's utility. RAG's ability to incorporate domain-specific CPIC data, including recent literature, proved beneficial. Challenges persist, such as the need for specialized genetic/PGx models to improve accuracy and relevancy and addressing ethical, regulatory, and safety concerns. Conclusion: This study underscores generative AI's potential for transforming healthcare provider support and patient accessibility to complex pharmacogenomic information. While careful implementation of large language models like GPT-4 is necessary, it is clear that they can substantially improve understanding of pharmacogenomic data. With further development, these tools could augment healthcare expertise, provider productivity, and the delivery of equitable, patient-centered healthcare services.  © 2024 The Author(s). Published by Oxford University Press on behalf of the American Medical Informatics Association. All rights reserved.","AI assistant; generative AI; large language models; OpenAI GPT-4; pharmacogenomic testing; retrieval-augmented generation","Artificial Intelligence; Humans; Information Storage and Retrieval; Knowledge Bases; Pharmacogenetics; Pharmacogenomic Testing; Precision Medicine; Article; artificial intelligence; clinical decision making; human; knowledge base; medical genetics; patient care; pharmacogenomics; artificial intelligence; information retrieval; personalized medicine; pharmacogenetic testing; pharmacogenetics; procedures","","Oxford University Press","English","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85192852527"
"Jokinen K.; Wilcock G.","Jokinen, Kristiina (23397498500); Wilcock, Graham (36603777300)","23397498500; 36603777300","Exploring a Japanese Cooking Database A robot uses GenAI and a knowledge graph to chat about culinary delights","2024","ACM/IEEE International Conference on Human-Robot Interaction","","","","578","582","4","1","10.1145/3610978.3640622","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188145575&doi=10.1145%2f3610978.3640622&partnerID=40&md5=0ccf9d796d5978baf041e64afed529dd","AI Research Center, National Institute of Advanced Industrial Science and Technology, Tokyo, Japan; CDM Interact, University of Helsinki, Helsinki, Finland","Jokinen K., AI Research Center, National Institute of Advanced Industrial Science and Technology, Tokyo, Japan; Wilcock G., CDM Interact, University of Helsinki, Helsinki, Finland","The paper describes ongoing work applying Generative AI to a real world application. We use Retrieval Augmented Generation and other GenAI tools that combine large language models with Neo4j knowledge graphs. These tools help a robot to chat in English about Japanese cooking using a knowledge base that is in Japanese. © 2024 Copyright held by the owner/author(s)","Cypher query language; Generative AI; graph databases; Japanese cooking; knowledge graphs; large language models; retrieval augmented generation; semantic search; social robots","Computational linguistics; Query languages; Query processing; Robots; Semantics; Cipher query language; Generative AI; Graph database; Japanese cooking; Knowledge graphs; Language model; Large language model; Retrieval augmented generation; Semantic search; Social robots; Knowledge graph","","IEEE Computer Society","English","Conference paper","Final","","Scopus","2-s2.0-85188145575"
"Miao J.; Thongprayoon C.; Suppadungsuk S.; Garcia Valencia O.A.; Cheungpasitporn W.","Miao, Jing (57221522072); Thongprayoon, Charat (55512490600); Suppadungsuk, Supawadee (56027786100); Garcia Valencia, Oscar A. (57205373508); Cheungpasitporn, Wisit (47160959700)","57221522072; 55512490600; 56027786100; 57205373508; 47160959700","Integrating Retrieval-Augmented Generation with Large Language Models in Nephrology: Advancing Practical Applications","2024","Medicina (Lithuania)","60","3","445","","","","8","10.3390/medicina60030445","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188954082&doi=10.3390%2fmedicina60030445&partnerID=40&md5=c1e7d483b1c9621a773a1979a00eef1e","Division of Nephrology and Hypertension, Department of Medicine, Mayo Clinic, Rochester, 55905, MN, United States; Chakri Naruebodindra Medical Institute, Faculty of Medicine Ramathibodi Hospital, Mahidol University, Samut Prakan, 10540, Thailand","Miao J., Division of Nephrology and Hypertension, Department of Medicine, Mayo Clinic, Rochester, 55905, MN, United States; Thongprayoon C., Division of Nephrology and Hypertension, Department of Medicine, Mayo Clinic, Rochester, 55905, MN, United States; Suppadungsuk S., Division of Nephrology and Hypertension, Department of Medicine, Mayo Clinic, Rochester, 55905, MN, United States, Chakri Naruebodindra Medical Institute, Faculty of Medicine Ramathibodi Hospital, Mahidol University, Samut Prakan, 10540, Thailand; Garcia Valencia O.A., Division of Nephrology and Hypertension, Department of Medicine, Mayo Clinic, Rochester, 55905, MN, United States; Cheungpasitporn W., Division of Nephrology and Hypertension, Department of Medicine, Mayo Clinic, Rochester, 55905, MN, United States","The integration of large language models (LLMs) into healthcare, particularly in nephrology, represents a significant advancement in applying advanced technology to patient care, medical research, and education. These advanced models have progressed from simple text processors to tools capable of deep language understanding, offering innovative ways to handle health-related data, thus improving medical practice efficiency and effectiveness. A significant challenge in medical applications of LLMs is their imperfect accuracy and/or tendency to produce hallucinations—outputs that are factually incorrect or irrelevant. This issue is particularly critical in healthcare, where precision is essential, as inaccuracies can undermine the reliability of these models in crucial decision-making processes. To overcome these challenges, various strategies have been developed. One such strategy is prompt engineering, like the chain-of-thought approach, which directs LLMs towards more accurate responses by breaking down the problem into intermediate steps or reasoning sequences. Another one is the retrieval-augmented generation (RAG) strategy, which helps address hallucinations by integrating external data, enhancing output accuracy and relevance. Hence, RAG is favored for tasks requiring up-to-date, comprehensive information, such as in clinical decision making or educational applications. In this article, we showcase the creation of a specialized ChatGPT model integrated with a RAG system, tailored to align with the KDIGO 2023 guidelines for chronic kidney disease. This example demonstrates its potential in providing specialized, accurate medical advice, marking a step towards more reliable and efficient nephrology practices. © 2024 by the authors.","artificial intelligence; chronic kidney disease; large language models (LLMs); nephrology; retrieval-augmented generation (RAG)","Educational Status; Hallucinations; Humans; Language; Nephrology; Reproducibility of Results; educational status; hallucination; human; language; nephrology; reproducibility","","Multidisciplinary Digital Publishing Institute (MDPI)","English","Review","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85188954082"
"Chui C.K.; Yang L.; Kao B.","Chui, Chun Kit (21741958100); Yang, Lei (59298570800); Kao, Ben (35221592600)","21741958100; 59298570800; 35221592600","Empowering Students in Emerging Technology: A Framework for Developing Hands-on Competency in Generative AI with Ethical Considerations","2024","ASEE Annual Conference and Exposition, Conference Proceedings","","","","","","","1","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202040200&partnerID=40&md5=4510327b037ceff3f56b264ed12e7bd2","The University of Hong Kong, Hong Kong","Chui C.K., The University of Hong Kong, Hong Kong; Yang L., The University of Hong Kong, Hong Kong; Kao B., The University of Hong Kong, Hong Kong","This practice paper introduces a framework to enhance the practical skills of undergraduate engineering students in generative AI technologies. Our goal is to transform students from users of generative AI software into professional creators of new AI technologies. We begin by defining guidelines, emphasizing ethical, responsible, and lawful practices. Then we define the core practical competencies and design learning activities. The framework involves collaboration among undergraduate students, postgraduate tutors, instructors, technicians, legal experts, academic partners, and industry professionals. The framework adopts a three-stage progression approach. At the adoption stage, students become familiar with generative AI software, such as composing textual prompts for image generation with the stable diffusion model. This helps students stay updated on the latest tools and developments in generative AI applications. In the development stage, the focus is on technical training for application programming interfaces (APIs), including language completion, text-to-speech conversion, and semantic search. This covers hands-on learning of using open-source large language models such as Llama2, and commercial cloud services such as Microsoft Azure OpenAI and Google GCP Vertex AI, etc. Techniques like Retrieval-Augmented Generation (RAG) and model fine-tuning are part of this training, equipping students with the necessary skills to enter the final application stage. In this stage, students participate in designing and developing generative AI-based solutions to address real-world problems. Our partnerships extend to the law and social science faculties, where we build customized chatbot solutions. The framework was implemented and evaluated at the Tam Wing Fan Innovation Wing (a.k.a. HKU Inno Wing) [1], a facility within the Faculty of Engineering at the University of Hong Kong dedicated to improving students' practical abilities. Students demonstrate increased awareness of ethical, responsible, and lawful practices in generative AI technologies under the careful guidance of instructors. We conducted an analysis of the written reflections from students in the 2023/24 cohort regarding their understanding of the strengths and weaknesses of generative AI technologies. Furthermore, we assessed how students' awareness of generative AI ethics, responsibility, and legal considerations evolved throughout their reflections. By identifying common blind spots, we gained valuable insights to continually enhance guidance for students at various stages of their learning progress. © American Society for Engineering Education, 2024.","AI competency; AI ethics; Generative AI","Economic and social effects; Ethical technology; Laws and legislation; Personnel training; Problem oriented languages; Teaching; Windows operating system; AI competency; AI ethic; AI Technologies; Design learning; Emerging technologies; Ethical considerations; Generative AI; Learning Activity; Practical skill; Undergraduate engineering students; Students","","American Society for Engineering Education","English","Conference paper","Final","","Scopus","2-s2.0-85202040200"
"Liang Z.; Xie K.; Lu S.; Shi Y.; Yeerpan T.; Wang Z.","Liang, Zehui (59351664700); Xie, Keli (57203863472); Lu, Siyuan (57207115122); Shi, Yubo (57225053548); Yeerpan, Tuohetiyaer (59352007400); Wang, Zhongfeng (57203515197)","59351664700; 57203863472; 57207115122; 57225053548; 59352007400; 57203515197","ECR: An Expertise-Enriched Conclude-Then-Refine Summarization Framework for Professional Articles","2024","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","14763 LNCS","","","96","106","10","0","10.1007/978-3-031-70242-6_10","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205487634&doi=10.1007%2f978-3-031-70242-6_10&partnerID=40&md5=62156782585b33384fa998ae104aa94c","School of Electronic Science and Engineering, Nanjing University, Nanjing, China; Nanjing Windyword Intellgence Information Technology Co. Ltd., Nanjing, China; School of Integrated Circuits, Sun Yet-Sen University, Shenzhen, China","Liang Z., School of Electronic Science and Engineering, Nanjing University, Nanjing, China, Nanjing Windyword Intellgence Information Technology Co. Ltd., Nanjing, China; Xie K., School of Electronic Science and Engineering, Nanjing University, Nanjing, China, Nanjing Windyword Intellgence Information Technology Co. Ltd., Nanjing, China; Lu S., School of Electronic Science and Engineering, Nanjing University, Nanjing, China, Nanjing Windyword Intellgence Information Technology Co. Ltd., Nanjing, China; Shi Y., School of Electronic Science and Engineering, Nanjing University, Nanjing, China, Nanjing Windyword Intellgence Information Technology Co. Ltd., Nanjing, China; Yeerpan T., School of Electronic Science and Engineering, Nanjing University, Nanjing, China, Nanjing Windyword Intellgence Information Technology Co. Ltd., Nanjing, China; Wang Z., School of Electronic Science and Engineering, Nanjing University, Nanjing, China, School of Integrated Circuits, Sun Yet-Sen University, Shenzhen, China","Summary generation using large language models (LLMs) is characterized by its flexibility, high quality, and efficiency. However, professional articles usually contain domain-specific background knowledge and many professional terminologies. It’s hard for the generated summary to maintain professionalism and good writing style using simple prompts coupled with LLMs, which is the common summarization method. While developing task-specific LLMs can improve the summary quality, it demands a high training cost. To enhance the summary quality cost-efficiently, we present ECR, a two-stage expertise-enriched conclude-then-refine summarization framework for professional articles. Firstly, the Key Information Conclusion Stage (KICS) distills the article content through elaborated prompt engineering. Subsequently, the Refinement and Term Enrichment Stage (RTES) enhances coherence, conciseness, and professionalism. Experimental results indicate that our approach offers superior summaries to the summaries generated by the common method across diverse domains. ECR shows an over 80% win rate in structural consistency evaluated by the LLM, alongside a 2x increase in terminology integration. The framework also provides sufficient flexibility to replace components within it. Furthermore, a test dataset comprising 100 articles and an evaluation method for assessing professionalism are proposed. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.","Knowledge Enhanced; LLM; RAG; Summarization; Summary Evaluation","Terminology; Domain specific; High quality; Higher efficiency; Knowledge enhanced; Language model; Large language model; RAG; Summarization; Summary evaluation; Summary generation; Professional aspects","Rapp A.; Di Caro L.; Meziane F.; Sugumaran V.","Springer Science and Business Media Deutschland GmbH","English","Conference paper","Final","","Scopus","2-s2.0-85205487634"
"Franklin G.; Stephens R.; Piracha M.; Tiosano S.; Lehouillier F.; Koppel R.; Elkin P.L.","Franklin, Gillian (57222631008); Stephens, Rachel (59197771700); Piracha, Muhammad (59198015200); Tiosano, Shmuel (57140688400); Lehouillier, Frank (57361357200); Koppel, Ross (9279794500); Elkin, Peter L. (7005495988)","57222631008; 59197771700; 59198015200; 57140688400; 57361357200; 9279794500; 7005495988","The Sociodemographic Biases in Machine Learning Algorithms: A Biomedical Informatics Perspective","2024","Life","14","6","652","","","","0","10.3390/life14060652","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197252425&doi=10.3390%2flife14060652&partnerID=40&md5=465213d9a406abba1a91aa9ece86fb9a","Department of Biomedical Informatics, University at Buffalo, Buffalo, 14203, NY, United States; Department of Veterans Affairs, Knowledge Based Systems and Western New York, Veterans Affairs, Buffalo, 14215, NY, United States; Institute for Biomedical Informatics, Perelman School of Medicine, and Sociology Department, University of Pennsylvania, Philadelphia, 19104, PA, United States","Franklin G., Department of Biomedical Informatics, University at Buffalo, Buffalo, 14203, NY, United States, Department of Veterans Affairs, Knowledge Based Systems and Western New York, Veterans Affairs, Buffalo, 14215, NY, United States; Stephens R., Department of Biomedical Informatics, University at Buffalo, Buffalo, 14203, NY, United States; Piracha M., Department of Biomedical Informatics, University at Buffalo, Buffalo, 14203, NY, United States; Tiosano S., Department of Biomedical Informatics, University at Buffalo, Buffalo, 14203, NY, United States; Lehouillier F., Department of Biomedical Informatics, University at Buffalo, Buffalo, 14203, NY, United States, Department of Veterans Affairs, Knowledge Based Systems and Western New York, Veterans Affairs, Buffalo, 14215, NY, United States; Koppel R., Department of Biomedical Informatics, University at Buffalo, Buffalo, 14203, NY, United States, Institute for Biomedical Informatics, Perelman School of Medicine, and Sociology Department, University of Pennsylvania, Philadelphia, 19104, PA, United States; Elkin P.L., Department of Biomedical Informatics, University at Buffalo, Buffalo, 14203, NY, United States, Department of Veterans Affairs, Knowledge Based Systems and Western New York, Veterans Affairs, Buffalo, 14215, NY, United States","Artificial intelligence models represented in machine learning algorithms are promising tools for risk assessment used to guide clinical and other health care decisions. Machine learning algorithms, however, may house biases that propagate stereotypes, inequities, and discrimination that contribute to socioeconomic health care disparities. The biases include those related to some sociodemographic characteristics such as race, ethnicity, gender, age, insurance, and socioeconomic status from the use of erroneous electronic health record data. Additionally, there is concern that training data and algorithmic biases in large language models pose potential drawbacks. These biases affect the lives and livelihoods of a significant percentage of the population in the United States and globally. The social and economic consequences of the associated backlash cannot be underestimated. Here, we outline some of the sociodemographic, training data, and algorithmic biases that undermine sound health care risk assessment and medical decision-making that should be addressed in the health care system. We present a perspective and overview of these biases by gender, race, ethnicity, age, historically marginalized communities, algorithmic bias, biased evaluations, implicit bias, selection/sampling bias, socioeconomic status biases, biased data distributions, cultural biases and insurance status bias, conformation bias, information bias and anchoring biases and make recommendations to improve large language model training data, including de-biasing techniques such as counterfactual role-reversed sentences during knowledge distillation, fine-tuning, prefix attachment at training time, the use of toxicity classifiers, retrieval augmented generation and algorithmic modification to mitigate the biases moving forward. © 2024 by the authors.","algorithms; artificial intelligence; bias; biomedical informatics; electronic health records; health care; machine learning; models; sociodemographic","","","Multidisciplinary Digital Publishing Institute (MDPI)","English","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85197252425"
"Gopi S.; Dehbozorgi N.","Gopi, Sreekanth (58838880200); Dehbozorgi, Nasrin (57192573637)","58838880200; 57192573637","SerenePulse: A Web App Pipeline for Real-time Physiological Monitoring Using rPPG and OpenAI LLMs","2024","ASEE Annual Conference and Exposition, Conference Proceedings","","","","","","","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202058489&partnerID=40&md5=59b782ad1912341d2488669c598a6b2d","Kennesaw State University, Marietta, 30060, GA, United States","Gopi S., Kennesaw State University, Marietta, 30060, GA, United States; Dehbozorgi N., Kennesaw State University, Marietta, 30060, GA, United States","With 15% of working-age adults facing mental disorders and an annual loss of US$ 1 trillion in the world due to impaired productivity from depression and anxiety, the necessity for real-time emotional and physiological monitoring is paramount [1]. As similar levels of stress and mental health disorders are found among engineering students, mental health management is imperative in engineering education [2]. However, the high costs associated with mental health management tools, the necessity for additional gadgets, and rare usage among students pose significant barriers to widespread adoption and utilization in engineering education [3], [4]. In this study, we examine the integration of Remote Photoplethysmography (rPPG), a wireless stress measurement technology for real-time physiological monitoring by detecting light intensity variations on the skin. By advanced rPPG signal processing, Heart Rate Variability (HRV) metrics like Standard Deviation of Normal-to-Normal Intervals(SDNN), Root Mean Square of Successive Differences(RMSSD), and the Low-Frequency/High-Frequency Ratio(LF/HF) are calculated to offer stress insights. Our results resulted in an accuracy of 92% as validated with the ground truth dataset. Moving forward, we aim to enhance performance and deploy an app for widespread, low-cost access to stress management and monitoring. © American Society for Engineering Education, 2024.","Engineering education; GPT-4; Heart Coherence; heart rate variability; LLM; RAG; relaxation practices; Remote photoplethysmography; rPPG; stress reduction","Arthroplasty; Cardiology; Cost engineering; Diseases; Electrotherapeutics; Fetal monitoring; Medical problems; mHealth; Neonatal monitoring; Photoplethysmography; Physiological models; Remote patient monitoring; Stress measurement; GPT-4; Heart coherence; Heart rate variability; LLM; RAG; Real- time; Relaxation practice; Remote photoplethysmography; Stress reduction; Heart","","American Society for Engineering Education","English","Conference paper","Final","","Scopus","2-s2.0-85202058489"
"Darnell B.; Chopra H.; Councilman A.; Grove D.; Wang Y.-X.; Adve V.","Darnell, Benjamin (59288209300); Chopra, Hetarth (57223167415); Councilman, Aaron (57787866800); Grove, David (35607061900); Wang, Yu-Xiong (36072566200); Adve, Vikram (6701828487)","59288209300; 57223167415; 57787866800; 35607061900; 36072566200; 6701828487","An Empirical Comparison of Code Generation Approaches for Ansible","2024","Proceedings - 2024 IEEE/ACM 2nd International Workshop on Interpretability, Robustness, and Benchmarking in Neural Software Engineering, InteNSE 2024","","","","1","6","5","0","10.1145/3643661.3643951","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201660730&doi=10.1145%2f3643661.3643951&partnerID=40&md5=0b53bf2ce11db9f8a249bad7f4300c26","University of Illinois at Urbana-Champaign, Urbana, IL, United States; Ibm Research, Yorktown Heights, NY, United States","Darnell B., University of Illinois at Urbana-Champaign, Urbana, IL, United States; Chopra H., University of Illinois at Urbana-Champaign, Urbana, IL, United States; Councilman A., University of Illinois at Urbana-Champaign, Urbana, IL, United States; Grove D., Ibm Research, Yorktown Heights, NY, United States; Wang Y.-X., University of Illinois at Urbana-Champaign, Urbana, IL, United States; Adve V., University of Illinois at Urbana-Champaign, Urbana, IL, United States","The rapid proliferation of LLM-based programming assistants has enabled fast and accurate automatic code generation for general purpose programming languages. Domain-specific languages like Ansible, a DSL for IT Automation, have seen a lack of support despite being critical to many fields, due to limited public-domain code for training models and a lack of interest from tool developers. To address this issue, we collect a novel dataset of permissively licensed Ansible code, and use it to create Warp, an LLM for code fine-tuned to produce Ansible tasks from a natural language prompt. We evaluate state-of-the-art tools for LLM-based code generation models, comparing multiple common strategies, including fine-tuning base models on Ansible code and retrieval-augmented-generation using documentation, in order to understand challenges with existing methodology and identify future research directions to enable better code generation for DSLs. © 2024 Copyright held by the owner/author(s).","ansible; code generation; domain specific languages; large language models","Codes (symbols); Digital subscriber lines; Ansible; Automatic code generations; Codegeneration; Domains specific languages; Empirical comparison; General-purpose programming language; Language model; Large language model; Public domains; Training model; Automatic programming","","Association for Computing Machinery, Inc","English","Conference paper","Final","","Scopus","2-s2.0-85201660730"
"Zhang T.; Tian Y.; Lin F.; Ni Q.; Song P.; Dai X.; Li J.; Wu N.; Li D.; Wang F.-Y.","Zhang, Tengchao (59250401200); Tian, Yonglin (57200618718); Lin, Fei (59154111000); Ni, Qinghua (58565019000); Song, Ping (59250280600); Dai, Xingyuan (57195433080); Li, Juanjuan (54581126500); Wu, Naiqi (7201444208); Li, Dinglie (59250238200); Wang, Fei-Yue (57211758869)","59250401200; 57200618718; 59154111000; 58565019000; 59250280600; 57195433080; 54581126500; 7201444208; 59250238200; 57211758869","Parallel tourism:foundation intelligence driven smart trip services; [平行旅游：基础智能驱动的智慧出游服务]","2024","Chinese Journal of Intelligent Science and Technology","6","2","","164","178","14","0","10.11959/j.issn.2096-6652.202420","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200640476&doi=10.11959%2fj.issn.2096-6652.202420&partnerID=40&md5=28e5b2da6c7a0a495caa0a5790eb1515","Faculty of Innovation Engineering, Macau University of Science and Technology, 999078, Macao; State Key Laboratory for Management and Control of Complex Systems, Institute of Automation, Chinese Academy of Sciences, Beijing, 100190, China; Dazhou Artificial Intelligence Institute, Sichuan, 635755, China; State Key Laboratory of Multimodal Artificial Intelligence Systems, Institute of Automation, Chinese Academy of Sciences, Beijing, 100190, China; School of Hospitality and Tourism Management, Macau University of Science and Technology, 999078, Macao; School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, 100049, China","Zhang T., Faculty of Innovation Engineering, Macau University of Science and Technology, 999078, Macao; Tian Y., State Key Laboratory for Management and Control of Complex Systems, Institute of Automation, Chinese Academy of Sciences, Beijing, 100190, China, Dazhou Artificial Intelligence Institute, Sichuan, 635755, China; Lin F., Faculty of Innovation Engineering, Macau University of Science and Technology, 999078, Macao; Ni Q., Faculty of Innovation Engineering, Macau University of Science and Technology, 999078, Macao; Song P., Faculty of Innovation Engineering, Macau University of Science and Technology, 999078, Macao; Dai X., Dazhou Artificial Intelligence Institute, Sichuan, 635755, China, State Key Laboratory of Multimodal Artificial Intelligence Systems, Institute of Automation, Chinese Academy of Sciences, Beijing, 100190, China; Li J., Dazhou Artificial Intelligence Institute, Sichuan, 635755, China, State Key Laboratory of Multimodal Artificial Intelligence Systems, Institute of Automation, Chinese Academy of Sciences, Beijing, 100190, China; Wu N., Faculty of Innovation Engineering, Macau University of Science and Technology, 999078, Macao; Li D., School of Hospitality and Tourism Management, Macau University of Science and Technology, 999078, Macao; Wang F.-Y., Faculty of Innovation Engineering, Macau University of Science and Technology, 999078, Macao, State Key Laboratory for Management and Control of Complex Systems, Institute of Automation, Chinese Academy of Sciences, Beijing, 100190, China, School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, 100049, China","Tourism, as an activity that satisfies people’s desire for diverse life experiences and knowledge, has had profound impacts on the economy, culture, and other fields. However, with the rapid development of technologies, such as the Internet of Things and multimodal large language models, traditional tourism is unable to meet the demand for intelligent and personalized travel experiences. To address this, this paper proposes an interactive personalized tourism service system based on the concept of parallel intelligence, utilizing the ACP approach and multimodal large language models. The system constructs a comprehensive tourism model and leverages retrieval-augmented generation and multi-agent collaboration systems to create a new paradigm for personalized tourism services. Additionally, this paper explores the application ecosystem of parallel tourism, expanding the tourism ecosystem from four aspects: clothing, food, accommodation and transportation. This paper analyzes the integration of other industries with personalized tourism services. Parallel tourism is poised to bring new possibilities for the development of the tourism service industry. © 2024 Beijing Xintong Media Co., Ltd.. All rights reserved.","ACP approach; metaverse; multimodal large language models; parallel systems; parallel tourism; retrieval-augmented generation","","","Beijing Xintong Media Co., Ltd.","Chinese","Article","Final","","Scopus","2-s2.0-85200640476"
"Odede J.; Frommholz I.","Odede, Julius (58956655200); Frommholz, Ingo (57193978412)","58956655200; 57193978412","JayBot - Aiding University Students and Admission with an LLM-based Chatbot","2024","CHIIR 2024 - Proceedings of the 2024 Conference on Human Information Interaction and Retrieval","","","","391","395","4","2","10.1145/3627508.3638293","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188697324&doi=10.1145%2f3627508.3638293&partnerID=40&md5=a7199fed9b0c9a76dd43bef4455d8341","University of Wolverhampton, Wolverhampton, United Kingdom","Odede J., University of Wolverhampton, Wolverhampton, United Kingdom; Frommholz I., University of Wolverhampton, Wolverhampton, United Kingdom","This demo paper presents JayBot, an LLM-based chatbot system aimed at enhancing the user experience of prospective and current students, faculty, and staff at a UK university. The objective of JayBot is to provide information to users on general enquiries regarding course modules, duration, fees, entry requirements, lecturers, internship, career paths, course employability and other related aspects. Leveraging the use cases of generative artificial intelligence (AI), the chatbot application was built using OpenAI's advanced large language model (GPT-3.5 turbo); to tackle issues such as hallucination as well as focus and timeliness of results, an embedding transformer model has been combined with a vector database and vector search. Prompt engineering techniques were employed to enhance the chatbot's response abilities. Preliminary user studies indicate JayBot's effectiveness and efficiency. The demo will showcase JayBot in a university admission use case and discuss further application scenarios. © 2024 Owner/Author.","Artificial Intelligence; Chatbot; Interactive Information Retrieval; Large Language Models; Machine Learning; Retrieval Augmented Generation; Vector Database","Learning systems; Machine learning; Chatbots; Interactive information retrieval; Language model; Large language model; Machine-learning; Retrieval augmented generation; University admissions; University students; Users' experiences; Vector database; Computational linguistics","","Association for Computing Machinery, Inc","English","Conference paper","Final","","Scopus","2-s2.0-85188697324"
"","","","Proceedings of CONECCT 2024 - 10th IEEE International Conference on Electronics, Computing and Communication Technologies","2024","Proceedings of CONECCT 2024 - 10th IEEE International Conference on Electronics, Computing and Communication Technologies","","","","","","1833","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205813127&partnerID=40&md5=e59e19053f142da05443a80778c41347","","","The proceedings contain 310 papers. The topics discussed include: PIPS: personality insights and prediction using smartphone non-private content; enhancing network resilience for flood response and rehabilitation using SDN; Urdu and MNIST datasets digit recognition using CNN encoder with K-means clustering; vision in versatility: dual CCD-CMOS imaging with compressed sensing for sustainable IoT surveillance drones; India’s net-zero scenarios: assessing the influence of renewable energy expansion on grid emission factors; wavelet based microgrid protection in presence of UPFC using machine learning approach; virtual embodiment: revolutionizing motor imagery in VR-enabled BCI with digital twins; ZCS switched-capacitor cell balancing circuit with bidirectional buck-boost charging; mixer design for 5G FR1 compatible with software defined radio; and AeroQuery RAG and LLM for aerospace query in designs, development, standards, certifications.","","","","Institute of Electrical and Electronics Engineers Inc.","English","Conference review","Final","","Scopus","2-s2.0-85205813127"
"Fichtenkamm M.; Kofler M.; Schekotihin K.; Burmer C.","Fichtenkamm, Maik (59369710700); Kofler, Markus (59370072200); Schekotihin, Konstantin (57202912802); Burmer, Christian (6507124175)","59369710700; 59370072200; 57202912802; 6507124175","Towards an FA ChatBot with Retrieval-Augmented Language Modeling","2024","Proceedings of the International Symposium on the Physical and Failure Analysis of Integrated Circuits, IPFA","","","","","","","0","10.1109/IPFA61654.2024.10691083","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206577128&doi=10.1109%2fIPFA61654.2024.10691083&partnerID=40&md5=dac8be38c19981fb3251fdc0fba4d93d","Infineon Technologies, Siemensstr. 2, Villach, 9500, Austria; University Klagenfurt, Universitätsstr. 65-67, Klagenfurt, 9020, Austria; Infineon Technologies, Universit tsstr. 65-67, Klagenfurt, 9020, Austria","Fichtenkamm M., Infineon Technologies, Siemensstr. 2, Villach, 9500, Austria, University Klagenfurt, Universitätsstr. 65-67, Klagenfurt, 9020, Austria; Kofler M., University Klagenfurt, Universitätsstr. 65-67, Klagenfurt, 9020, Austria, Infineon Technologies, Universit tsstr. 65-67, Klagenfurt, 9020, Austria; Schekotihin K., Infineon Technologies, Universit tsstr. 65-67, Klagenfurt, 9020, Austria; Burmer C., Infineon Technologies, Siemensstr. 2, Villach, 9500, Austria","Failure Analysis (FA) data storages, like databases or file shares, host a lot of textual data comprising important information about products, best practices, or past cases. FA engineers require this information at their fingertips to accomplish their tasks efficiently. However, common keyword search interfaces provided by most information systems and databases are insufficient as they force an engineer to formulate a correct query, read returned documents, and manually extract required knowledge from them. In this paper, we suggest a cost-effective approach that augments retrieval systems with the capabilities of modern Large Language Models (LLMs) to provide straight-to-point answers to engineers' questions. Preliminary evaluation shows that the suggested system can generate high-quality responses to a set of simple benchmark queries but also lacks complex reasoning capabilities for answering complex queries.  © 2024 IEEE.","AI; generative models; retrieval-augmented generation","Query languages; Search engines; Structured Query Language; Best practices; Chatbots; Data storage; File share; Generative model; Keyword search; Language model; Retrieval-augmented generation; Search interfaces; Textual data; Modeling languages","","Institute of Electrical and Electronics Engineers Inc.","English","Conference paper","Final","","Scopus","2-s2.0-85206577128"
"Chaubey H.K.; Tripathi G.; Ranjan R.; Gopalaiyengar S.K.","Chaubey, Harshit Kumar (58262130900); Tripathi, Gaurav (59369700000); Ranjan, Rajnish (59369973300); Gopalaiyengar, Srinivasa K. (54083260800)","58262130900; 59369700000; 59369973300; 54083260800","Comparative Analysis of RAG, Fine-Tuning, and Prompt Engineering in Chatbot Development","2024","ICFTSS 2024 - International Conference on Future Technologies for Smart Society","","","","169","172","3","0","10.1109/ICFTSS61109.2024.10691338","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206576310&doi=10.1109%2fICFTSS61109.2024.10691338&partnerID=40&md5=b4854f1bff032e8c5e271ac26b948af0","Iiit Naya Raipur, Computer Science and Engineering, Raipur, India; Iiit Naya Raipur, Electronics and Communication Engineering, Raipur, India; Iit, Data Science and Applications, Madras, Chennai, India; Iiit, Data Science and Artificial Intelligence, Naya Raipur, Raipur, India","Chaubey H.K., Iiit Naya Raipur, Computer Science and Engineering, Raipur, India; Tripathi G., Iiit Naya Raipur, Electronics and Communication Engineering, Raipur, India; Ranjan R., Iit, Data Science and Applications, Madras, Chennai, India; Gopalaiyengar S.K., Iiit, Data Science and Artificial Intelligence, Naya Raipur, Raipur, India","This paper examines the integration and comparative effectiveness of Retriever-Augmented Generation (RAG), fine-tuning, and prompt engineering in the development of advanced chatbots. By employing domain-specific fine-tuning, the study addresses contextual misunderstandings and inaccuracies prevalent in base Large Language Models (LLMs). RAG enhances chatbot functionality by incorporating real-time data retrieval, ensuring relevance in dynamically changing environments. Prompt engineering is utilized to refine input prompts, thereby optimizing the accuracy of responses. Employing the 'openassistant-guanaco' dataset from Hugging Face, this research assesses the performance improvements offered by these methodologies, both quantitatively and qualitatively. The fine-tuned model outperforms other methods with an accuracy of 87.8 % and a BLEU score of 0.81, proving its effectiveness in generating the most relevant responses. In contrast, while the RAG with LLM approach shows promising results with a reasonable accuracy of 84.5 %, the Prompt Engineering method, though slightly less effective with an accuracy of 83.2 %, still maintains competitive performance. This study highlights the unique and combined strengths of these technologies, contributing valuable insights into their synergistic potential for enhancing chatbot interactions  © 2024 IEEE.","Chatbots; Fine-tuning; Large Language Models (LLM); Prompt Engineering; Retriever-Augmented Generation (RAG)","Chatbots; Comparative analyzes; Comparative effectiveness; Domain specific; Fine tuning; Language model; Large language model; Prompt engineering; Real-time data; Retriever-augmented generation; Search engines","","Institute of Electrical and Electronics Engineers Inc.","English","Conference paper","Final","","Scopus","2-s2.0-85206576310"
"Lang C.; Schneider R.; Tu N.D.T.","Lang, Christian (57191404900); Schneider, Roman (55449219800); Tu, Ngoc Duyen Tanja (57218242494)","57191404900; 55449219800; 57218242494","Automatic Question Answering for the Linguistic Domain – An Evaluation of LLM Knowledge Base Extension with RAG","2024","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","14763 LNCS","","","161","171","10","0","10.1007/978-3-031-70242-6_16","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205491211&doi=10.1007%2f978-3-031-70242-6_16&partnerID=40&md5=22026082cc642388244b08c83aa61bd4","Leibniz Institute for the German Language, Mannheim, Germany","Lang C., Leibniz Institute for the German Language, Mannheim, Germany; Schneider R., Leibniz Institute for the German Language, Mannheim, Germany; Tu N.D.T., Leibniz Institute for the German Language, Mannheim, Germany","We investigate the extent to which Retrieval Augmented Generation improves the quality of Large Language Models’ answers to technical questions in the field of linguistics—a domain known for its broad terminological inventory and theory-dependent use of technical terms. Furthermore, this application is not only about terminological information on language, but also about information on its well-formedness. We present the results of an empirical evaluation of automatically generated answers based on authentic data from a language consulting service, with special emphasis on different question types. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.","Domain Specificity; Large Language Model; Quality Evaluation; Question Answering; Retrieval Augmented Generation","Domain Knowledge; Linguistics; Automatic question answering; Base extensions; Domain specificity; Empirical evaluations; Language model; Large language model; Quality evaluation; Question Answering; Retrieval augmented generation; Technical terms; Question answering","Rapp A.; Di Caro L.; Meziane F.; Sugumaran V.","Springer Science and Business Media Deutschland GmbH","English","Conference paper","Final","","Scopus","2-s2.0-85205491211"
"Radeva I.; Popchev I.; Doukovska L.; Dimitrova M.","Radeva, Irina (55649655800); Popchev, Ivan (6603842485); Doukovska, Lyubka (6504336404); Dimitrova, Miroslava (58799857200)","55649655800; 6603842485; 6504336404; 58799857200","Web Application for Retrieval-Augmented Generation: Implementation and Testing","2024","Electronics (Switzerland)","13","7","1361","","","","1","10.3390/electronics13071361","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190247370&doi=10.3390%2felectronics13071361&partnerID=40&md5=98127f704ebc956877e09657488d85c9","Intelligent Systems Department, Institute of Information and Communication Technologies, Bulgarian Academy of Sciences, Sofia, 1113, Bulgaria; Bulgarian Academy of Sciences, Sofia, 1040, Bulgaria","Radeva I., Intelligent Systems Department, Institute of Information and Communication Technologies, Bulgarian Academy of Sciences, Sofia, 1113, Bulgaria; Popchev I., Bulgarian Academy of Sciences, Sofia, 1040, Bulgaria; Doukovska L., Intelligent Systems Department, Institute of Information and Communication Technologies, Bulgarian Academy of Sciences, Sofia, 1113, Bulgaria; Dimitrova M., Intelligent Systems Department, Institute of Information and Communication Technologies, Bulgarian Academy of Sciences, Sofia, 1113, Bulgaria","The purpose of this paper is to explore the implementation of retrieval-augmented generation (RAG) technology with open-source large language models (LLMs). A dedicated web-based application, PaSSER, was developed, integrating RAG with Mistral:7b, Llama2:7b, and Orca2:7b models. Various software instruments were used in the application’s development. PaSSER employs a set of evaluation metrics, including METEOR, ROUGE, BLEU, perplexity, cosine similarity, Pearson correlation, and F1 score, to assess LLMs’ performance, particularly within the smart agriculture domain. The paper presents the results and analyses of two tests. One test assessed the performance of LLMs across different hardware configurations, while the other determined which model delivered the most accurate and contextually relevant responses within RAG. The paper discusses the integration of blockchain with LLMs to manage and store assessment results within a blockchain environment. The tests revealed that GPUs are essential for fast text generation, even for 7b models. Orca2:7b on Mac M1 was the fastest, and Mistral:7b had superior performance on the 446 question–answer dataset. The discussion is on technical and hardware considerations affecting LLMs’ performance. The conclusion outlines future developments in leveraging other LLMs, fine-tuning approaches, and further integration with blockchain and IPFS. © 2024 by the authors.","Antelope blockchain; LangChain; Llama2:7b; Mistral:7b; Ollama; open-source large language models (LLMs); Orca2:7b; retrieval-augmented generation (RAG); smart agriculture","","","Multidisciplinary Digital Publishing Institute (MDPI)","English","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85190247370"
"Wang C.; Ong J.; Wang C.; Ong H.; Cheng R.; Ong D.","Wang, Calvin (58346258900); Ong, Joshua (57214792343); Wang, Chara (58517153300); Ong, Hannah (57250743400); Cheng, Rebekah (58350694900); Ong, Dennis (58346887400)","58346258900; 57214792343; 58517153300; 57250743400; 58350694900; 58346887400","Potential for GPT Technology to Optimize Future Clinical Decision-Making Using Retrieval-Augmented Generation","2024","Annals of Biomedical Engineering","52","5","","1115","1118","3","12","10.1007/s10439-023-03327-6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166430984&doi=10.1007%2fs10439-023-03327-6&partnerID=40&md5=957ade6fbd24da21a12d41787213b874","College of Medicine - Robert Wood Johnson Medical School, Rutgers University, New Brunswick, 08901, NJ, United States; Michigan Medicine, University of Michigan, Ann Arbor, MI, United States; Biotechnology High School, Freehold, NJ, United States; College of Medicine, The Ohio State University, Columbus, OH, United States; Department of Physical Therapy, Virginia Commonwealth University, Richmond, VA, United States; Amazon Web Services, Amazon, Seattle, WA, United States","Wang C., College of Medicine - Robert Wood Johnson Medical School, Rutgers University, New Brunswick, 08901, NJ, United States; Ong J., Michigan Medicine, University of Michigan, Ann Arbor, MI, United States; Wang C., Biotechnology High School, Freehold, NJ, United States; Ong H., College of Medicine, The Ohio State University, Columbus, OH, United States; Cheng R., Department of Physical Therapy, Virginia Commonwealth University, Richmond, VA, United States; Ong D., Amazon Web Services, Amazon, Seattle, WA, United States","Advancements in artificial intelligence (AI) provide many helpful tools for healthcare, one of which includes AI chatbots that use natural language processing to create humanlike, conversational dialog. These chatbots have general cognitive skills and are able to engage with clinicians and patients to discuss patients’ health conditions and what they may be at risk for. While chatbot engines have access to a wide range of medical texts and research papers, they currently provide high-level, generic responses and are limited in their ability to provide diagnostic guidance and clinical advice to patients on an individual level. The essay discusses the use of retrieval-augmented generation (RAG), which can be used to improve the specificity of user-entered prompts and thereby enhance the detail in AI chatbot responses. By embedding more recent clinical data and trusted medical sources, such as clinical guidelines, into the chatbot models, AI chatbots can provide more patient-specific guidance, faster diagnoses and treatment recommendations, and greater improvement of patient outcomes. © The Author(s) under exclusive licence to Biomedical Engineering Society 2023.","Clinical; GPT; Large language model; Patient","Artificial Intelligence; Clinical Decision-Making; Humans; Software; Technology; Clinical research; Decision making; Health risks; Natural language processing systems; Patient treatment; Chatbots; Clinical; Clinical decision making; Cognitive skill; GPT; Language model; Language processing; Large language model; Natural languages; Patient; artificial intelligence; ChatGPT; clinical decision making; clinical effectiveness; information retrieval; Letter; natural language processing; practice guideline; retrieval augmented generation; treatment outcome; clinical decision making; human; software; technology; Diagnosis","","Springer","English","Letter","Final","","Scopus","2-s2.0-85166430984"
"Guan C.; Huang M.; Zhang P.","Guan, Che (58976415000); Huang, Mengyu (58976005600); Zhang, Peng (56739586000)","58976415000; 58976005600; 56739586000","MFORT-QA: Multi-hop Few-shot Open Rich Table Question Answering","2024","ACM International Conference Proceeding Series","","","","434","442","8","0","10.1145/3669754.3669822","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203807534&doi=10.1145%2f3669754.3669822&partnerID=40&md5=91f225abfad614968a40b6701d347aed","AllianceBernstein, Nashville, TN, United States; Snowflake, United States; Vanderbilt University, Nashville, TN, United States","Guan C., AllianceBernstein, Nashville, TN, United States; Huang M., Snowflake, United States; Zhang P., Vanderbilt University, Nashville, TN, United States","In today's fast-paced industry, professionals face the challenge of summarizing a large number of documents and extracting vital information from them on a daily basis. These metrics are frequently hidden away in tables and/or their nested hyperlinks. To address this challenge, the approach of Table Question Answering (QA) has been developed to extract the relevant information. However, traditional Table QA training tasks that provide a table and an answer(s) from a gold cell coordinate(s) for a question may not always ensure extracting the accurate answer(s). Recent advancements in Large Language Models (LLMs) have opened up new possibilities for extracting information from tabular data using prompts. In this paper, we introduce the Multi-hop Few-shot Open Rich Table QA (MFORT-QA) approach, which consists of two major steps. The first step involves Few-Shot Learning (FSL), where relevant tables and associated contexts of hyperlinks are retrieved based on a given question. The retrieved content is then used to construct few-shot prompts as inputs to an LLM, such as ChatGPT. To tackle the challenge of answering complex questions, the second step leverages Chain-of-Thought (CoT) prompting to decompose the complex question into a sequential chain of questions and reasoning thoughts in a multi-hop manner. Retrieval-Augmented Generation (RAG) enhances this process by retrieving relevant tables and contexts of hyperlinks that are relevant to the resulting reasoning thoughts and questions. These additional contexts are then used to supplement the prompt used in the first step, resulting in more accurate answers from an LLM. Empirical results from OTT-QA demonstrate that our abstractive QA approach significantly improves the accuracy of extractive Table QA methods. © 2024 Owner/Author.","Chain-of-Thought Prompting; Few-Shot Learning; Information Retrieval; Large Language Models; Open Table Question-Answering","Hypertext systems; Modeling languages; Zero-shot learning; Chain-of-thought prompting; Complex questions; Few-shot learning; Hyperlinks; Language model; Large language model; Multi-hops; OPEN table; Open table question-answering; Question Answering; Question answering","","Association for Computing Machinery","English","Conference paper","Final","","Scopus","2-s2.0-85203807534"
"Shao J.; Tong J.; Wu Q.; Guo W.; Li Z.; Lin Z.; Zhang J.","Shao, Jiawei (57218794768); Tong, Jingwen (57215812285); Wu, Qiong (57207980184); Guo, Wei (59044085200); Li, Zijian (57883576900); Lin, Zehong (57201897125); Zhang, Jun (36659981100)","57218794768; 57215812285; 57207980184; 59044085200; 57883576900; 57201897125; 36659981100","WirelessLLM: Empowering Large Language Models Towards Wireless Intelligence","2024","Journal of Communications and Information Networks","9","2","","99","112","13","0","10.23919/JCIN.2024.10582827","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199110790&doi=10.23919%2fJCIN.2024.10582827&partnerID=40&md5=58f8c406350a47a7db6efe6f6b8f6af7","Department of Electronic and Computer Engineering, The Hong Kong University of Science and Technology, 999077, Hong Kong","Shao J., Department of Electronic and Computer Engineering, The Hong Kong University of Science and Technology, 999077, Hong Kong; Tong J., Department of Electronic and Computer Engineering, The Hong Kong University of Science and Technology, 999077, Hong Kong; Wu Q., Department of Electronic and Computer Engineering, The Hong Kong University of Science and Technology, 999077, Hong Kong; Guo W., Department of Electronic and Computer Engineering, The Hong Kong University of Science and Technology, 999077, Hong Kong; Li Z., Department of Electronic and Computer Engineering, The Hong Kong University of Science and Technology, 999077, Hong Kong; Lin Z., Department of Electronic and Computer Engineering, The Hong Kong University of Science and Technology, 999077, Hong Kong; Zhang J., Department of Electronic and Computer Engineering, The Hong Kong University of Science and Technology, 999077, Hong Kong","The rapid evolution of wireless technologies and the growing complexity of network infrastructures necessitate a paradigm shift in how communication networks are designed, configured, and managed. Recent advancements in large language models (LLMs) have sparked interest in their potential to revolutionize wireless communication systems. However, existing studies on LLMs for wireless systems are limited to a direct application for telecom language understanding. To empower LLMs with knowledge and expertise in the wireless domain, this paper proposes WirelessLLM, a comprehensive framework for adapting and enhancing LLMs to address the unique challenges and requirements of wireless communication networks. We first identify three foundational principles that underpin WirelessLLM: knowledge alignment, knowledge fusion, and knowledge evolution. Then, we investigate the enabling technologies to build WirelessLLM, including prompt engineering, retrieval augmented generation, tool usage, multi-modal pre-training, and domain-specific fine-tuning. Moreover, we present three case studies to demonstrate the practical applicability and benefits of WirelessLLM for solving typical problems in wireless networks. Finally, we conclude this paper by highlighting key challenges and outlining potential avenues for future research. © 2024, Posts and Telecom Press Co Ltd. All rights reserved.","large language models; multi-modal mod-els; power allocation; protocol understanding; spectrum sensing; wireless communications","Computational linguistics; Language model; Large language model; Multi-modal; Multi-modal mod-els; Network infrastructure; Power allocations; Protocol understanding; Spectrum sensing; Wireless communications; Wireless technologies; Wireless networks","","Posts and Telecom Press Co Ltd","English","Article","Final","","Scopus","2-s2.0-85199110790"
"Wan L.J.; Ye H.; Wang J.; Jha M.; Chen D.","Wan, Lily Jiaxin (58968332600); Ye, Hanchen (57205508990); Wang, Jinghua (57222239144); Jha, Manvi (59208153100); Chen, Deming (7405452600)","58968332600; 57205508990; 57222239144; 59208153100; 7405452600","An Iteratively-refined Dataset for High-Level Synthesis Functional Verification through LLM-Aided Bug Injection","2024","2024 IEEE LLM Aided Design Workshop, LAD 2024","","","","","","","0","10.1109/LAD62341.2024.10691860","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206654740&doi=10.1109%2fLAD62341.2024.10691860&partnerID=40&md5=87fdd3521df58830a62e5ee0f79180a6","University of Illinois Urbana-Champaign, United States","Wan L.J., University of Illinois Urbana-Champaign, United States; Ye H., University of Illinois Urbana-Champaign, United States; Wang J., University of Illinois Urbana-Champaign, United States; Jha M., University of Illinois Urbana-Champaign, United States; Chen D., University of Illinois Urbana-Champaign, United States","This paper explores the application of Large Language Models (LLMs) in the domain of High-Level Synthesis (HLS) for hardware design and verification, focusing on functional verification challenges. The scarcity of open-source HLS codebases, especially those containing bugs, poses a significant challenge, as LLMs require extensive datasets for efficient fine-tuning and evaluation. To tackle this, we introduce an innovative bug injection methodology working with a new dataset that we curated from a wide range of open-source HLS benchmark suites. This dataset features over 1,500 designs, with both the version injected with bugs and the corresponding bug-free version. Our bug injection method synergizes In-Context Learning (ICL) with Retrieval Augmented Generation (RAG), and Chain of Thought (CoT). This approach significantly boosts the dataset's overall validity rate for single-bug injections. We demonstrate our solution quality using GPT-4 Turbo for injecting either logic bugs or non-ideal pragmas (compiler directives) into HLS designs. For logic bugs, we achieve an 84.8% ratio for valid injection attempts. Furthermore, our approach maintains an 88.0% dataset validity rate (the valid bug injection rate). In addition, we also evaluate the quality of HLS pragma injections (focusing on non-ideal pragmas), and achieve a 74.0% attempt and an 87.9% valid injection ratio. Compared to brute-force prompting, our strategy yields a 20.4% and a 54.0% validity improvement for the bug and non-ideal pragma injection, respectively. The Chrysalis dataset is accessible at https://github.com/UIUC-ChenLab/Chrysalis-HLS.  © 2024 IEEE.","dataset; functional verification; High-Level Synthesis; Large Language Models","Benchmarking; Hardware-software codesign; High level languages; Integrated circuit design; Open source software; Program compilers; Program debugging; Dataset; Fine tuning; Functional verification; Hardware design and verification; High-level synthesis; Language model; Large language model; Nonideal; Open-source; Pragmas; High level synthesis","","Institute of Electrical and Electronics Engineers Inc.","English","Conference paper","Final","","Scopus","2-s2.0-85206654740"
"Yadav S.","Yadav, Surendra (59357549900)","59357549900","AeroQuery RAG and LLM for Aerospace Query in Designs, Development, Standards, Certifications","2024","Proceedings of CONECCT 2024 - 10th IEEE International Conference on Electronics, Computing and Communication Technologies","","","","","","","0","10.1109/CONECCT62155.2024.10677028","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205791208&doi=10.1109%2fCONECCT62155.2024.10677028&partnerID=40&md5=55b394ae4f633f042ff10bbcc2dac721","Honeywell Technology Solutions Lab Private Limited, Hts Aerospace Technologies, Karnataka, Bengaluru, India","Yadav S., Honeywell Technology Solutions Lab Private Limited, Hts Aerospace Technologies, Karnataka, Bengaluru, India","In the realm of avionics and aerospace, the demand for swift access to critical data is hindered by vast documentation, causing hallucinations, delays, and inefficiencies.To address this issue, our approach leverages the concepts of Retrieval-Augmented Generation (RAG) and Large Language Models (LLMs).Our approach aims to overcome the limitations of LLMs by incorporating real-time data retrieval capabilities through RAG, enabling seamless access to current information. This envisioned chatbot utilizes advanced natural language processing and proactive pattern identification to streamline information retrieval and communication across various aerospace domains.By leveraging advancements in text summarization and utilizing models like Google's PaLM2, Facebook's LLaMA, or OpenAI's GPT-4, we aim to enhance the performance of chatbots in information retrieval. This involves generating training examples and improving text summarization to efficiently address general inquiries related to standards and communication protocols within the aerospace sector but not limited to this.For instance, an aerospace engineer can quickly obtain relevant information on industry standards or communication protocols through the chatbot equipped with RAG, effortlessly taps into external sources to provide up-to-date and relevant information, reducing the need for exhaustive explanations and improving efficiency in information retrieval and communication processes.  © 2024 IEEE.","Aerospace; Generative AI; Industry-Specific AI; Large Language Models; Retrieval-Augmented Generation","Digital avionics; Metadata; Modeling languages; Natural language processing systems; Online searching; Query languages; Query processing; Aerospace; Chatbots; Communications protocols; Generative AI; Industry-specific AI; Language model; Large language model; Retrieval-augmented generation; Standard protocols; Text Summarisation; Aerospace industry","","Institute of Electrical and Electronics Engineers Inc.","English","Conference paper","Final","","Scopus","2-s2.0-85205791208"
"Alghamdi H.M.; Mostafa A.","Alghamdi, Hanan M. (55490047800); Mostafa, Abeer (57220485277)","55490047800; 57220485277","Towards Reliable Healthcare LLM Agents: A Case Study for Pilgrims during Hajj","2024","Information (Switzerland)","15","7","371","","","","0","10.3390/info15070371","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199859230&doi=10.3390%2finfo15070371&partnerID=40&md5=4ecfe4efdc5f7ef3d8b47f645e1e5ebe","Department of Computers, College of Engineering and Computing Al Qunfidhah, Umm Al-Qura University, Makkah, 24382, Saudi Arabia; Department of Computer Science and Engineering, Egypt-Japan University of Science and Technology, Alexandria, 21934, Egypt","Alghamdi H.M., Department of Computers, College of Engineering and Computing Al Qunfidhah, Umm Al-Qura University, Makkah, 24382, Saudi Arabia; Mostafa A., Department of Computer Science and Engineering, Egypt-Japan University of Science and Technology, Alexandria, 21934, Egypt","There is a pressing need for healthcare conversational agents with domain-specific expertise to ensure the provision of accurate and reliable information tailored to specific medical contexts. Moreover, there is a notable gap in research ensuring the credibility and trustworthiness of the information provided by these healthcare agents, particularly in critical scenarios such as medical emergencies. Pilgrims come from diverse cultural and linguistic backgrounds, often facing difficulties in accessing medical advice and information. Establishing an AI-powered multilingual chatbot can bridge this gap by providing readily available medical guidance and support, contributing to the well-being and safety of pilgrims. In this paper, we present a comprehensive methodology aimed at enhancing the reliability and efficacy of healthcare conversational agents, with a specific focus on addressing the needs of Hajj pilgrims. Our approach leverages domain-specific fine-tuning techniques on a large language model, alongside synthetic data augmentation strategies, to optimize performance in delivering contextually relevant healthcare information by introducing the HajjHealthQA dataset. Additionally, we employ a retrieval-augmented generation (RAG) module as a crucial component to validate uncertain generated responses, which improves model performance by 5%. Moreover, we train a secondary AI agent on a well-known health fact-checking dataset and use it to validate medical information in the generated responses. Our approach significantly elevates the chatbot’s accuracy, demonstrating its adaptability to a wide range of pilgrim queries. We evaluate the chatbot’s performance using quantitative and qualitative metrics, highlighting its proficiency in generating accurate responses and achieve competitive results compared to state-of-the-art models, in addition to mitigating the risk of misinformation and providing users with trustworthy health information. © 2024 by the authors.","deep learning; Hajj; healthcare chatbot; large language models (LLMs); text generation","Computational linguistics; Deep learning; Health risks; Large datasets; Chatbots; Conversational agents; Deep learning; Domain specific; Hajj; Healthcare chatbot; Language model; Large language model; Performance; Text generations; Health care","","Multidisciplinary Digital Publishing Institute (MDPI)","English","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85199859230"
"Matsumoto N.; Moran J.; Choi H.; Hernandez M.E.; Venkatesan M.; Wang P.; Moore J.H.","Matsumoto, Nicholas (57222154847); Moran, Jay (58661604100); Choi, Hyunjun (58106287400); Hernandez, Miguel E. (58661642400); Venkatesan, Mythreye (58124852300); Wang, Paul (59168877400); Moore, Jason H. (7405241093)","57222154847; 58661604100; 58106287400; 58661642400; 58124852300; 59168877400; 7405241093","KRAGEN: a knowledge graph-enhanced RAG framework for biomedical problem solving using large language models","2024","Bioinformatics","40","6","btae353","","","","3","10.1093/bioinformatics/btae353","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195708984&doi=10.1093%2fbioinformatics%2fbtae353&partnerID=40&md5=49772a06afcf45f4ba0772adca738910","Department of Computational Biomedicine, Center for Artificial Intelligence Research and Education, Cedars Sinai Medical Center, West Hollywood, 90069, CA, United States","Matsumoto N., Department of Computational Biomedicine, Center for Artificial Intelligence Research and Education, Cedars Sinai Medical Center, West Hollywood, 90069, CA, United States; Moran J., Department of Computational Biomedicine, Center for Artificial Intelligence Research and Education, Cedars Sinai Medical Center, West Hollywood, 90069, CA, United States; Choi H., Department of Computational Biomedicine, Center for Artificial Intelligence Research and Education, Cedars Sinai Medical Center, West Hollywood, 90069, CA, United States; Hernandez M.E., Department of Computational Biomedicine, Center for Artificial Intelligence Research and Education, Cedars Sinai Medical Center, West Hollywood, 90069, CA, United States; Venkatesan M., Department of Computational Biomedicine, Center for Artificial Intelligence Research and Education, Cedars Sinai Medical Center, West Hollywood, 90069, CA, United States; Wang P., Department of Computational Biomedicine, Center for Artificial Intelligence Research and Education, Cedars Sinai Medical Center, West Hollywood, 90069, CA, United States; Moore J.H., Department of Computational Biomedicine, Center for Artificial Intelligence Research and Education, Cedars Sinai Medical Center, West Hollywood, 90069, CA, United States","Motivation: Answering and solving complex problems using a large language model (LLM) given a certain domain such as biomedicine is a challenging task that requires both factual consistency and logic, and LLMs often suffer from some major limitations, such as hallucinating false or irrelevant information, or being influenced by noisy data. These issues can compromise the trustworthiness, accuracy, and compliance of LLM-generated text and insights. Results: Knowledge Retrieval Augmented Generation ENgine (KRAGEN) is a new tool that combines knowledge graphs, Retrieval Augmented Generation (RAG), and advanced prompting techniques to solve complex problems with natural language. KRAGEN converts knowledge graphs into a vector database and uses RAG to retrieve relevant facts from it. KRAGEN uses advanced prompting techniques: namely graph-of-thoughts (GoT), to dynamically break down a complex problem into smaller subproblems, and proceeds to solve each subproblem by using the relevant knowledge through the RAG framework, which limits the hallucinations, and finally, consolidates the subproblems and provides a solution. KRAGEN’s graph visualization allows the user to interact with and evaluate the quality of the solution’s GoT structure and logic. © The Author(s) 2024. Published by Oxford University Press.","","Algorithms; Computational Biology; Databases, Factual; Humans; Information Storage and Retrieval; Natural Language Processing; Problem Solving; Software; algorithm; bioinformatics; factual database; human; information retrieval; natural language processing; problem solving; procedures; software","","Oxford University Press","English","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85195708984"
"Leekha R.; Simek O.; Dagli C.","Leekha, Rohan (58990344200); Simek, Olga (6507045650); Dagli, Charlie (7006792256)","58990344200; 6507045650; 7006792256","War of Words: Harnessing the Potential of Large Language Models and Retrieval Augmented Generation to Classify, Counter and Diffuse Hate Speech","2024","Proceedings of the International Florida Artificial Intelligence Research Society Conference, FLAIRS","37","","","","","","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200443688&partnerID=40&md5=1dc1aaa21c3e1c7f352b573c2dcd7709","MIT Lincoln Laboratory, 244 Wood Street, Lexington, MA, United States","Leekha R., MIT Lincoln Laboratory, 244 Wood Street, Lexington, MA, United States; Simek O., MIT Lincoln Laboratory, 244 Wood Street, Lexington, MA, United States; Dagli C., MIT Lincoln Laboratory, 244 Wood Street, Lexington, MA, United States","This paper explores the emergence of divergent narratives in the wake of the Russian-Ukraine war, which began on February 24, 2022, and the innovative application of AI language models, specifically Retrieval-Augmented Generation (RAG) and instruction-based large language models (LLMs), in countering hateful speech on social media. We design a pipeline to automatically discover and then respond to hateful content trending on social media platforms. Monitoring via traditional topic/narrative modeling often focuses on low-level content, which is difficult to interpret. In addition, workflows for prioritization and response generation are often highly manual. We utilize several large language models (LLMs) throughout our pipeline to detect and summarize topics, to determine whether tweets contain hate speech and to generate counter narratives. We test our approach on Ukraine Bio-Lab Tweet Corpus of 500k Tweets and evaluate the counter-narrative generation performance across several dimensions: relevance, grammaticality, factuality, and diversity. Our approach outperforms existing state of the art algorithms for hate speech detection and promising counter-narrative generation performance scores across our metrics reflect effectiveness of our pipeline in addressing hateful social media posts. Copyright © 2024 by the authors.","","Computational linguistics; Social networking (online); Speech recognition; Applications of AI; Divergents; Language model; Performance; Prioritization; Response generation; Social media; Social media platforms; Ukraine; Work-flows; Pipelines","","Florida Online Journals, University of Florida","English","Conference paper","Final","","Scopus","2-s2.0-85200443688"
"Ngom A.L.; Kraska T.","Ngom, Amadou Latyr (57219646195); Kraska, Tim (25823846800)","57219646195; 25823846800","Mallet: SQL Dialect Translation with LLM Rule Generation","2024","Proceedings of the 7th International Workshop on Exploiting Artificial Intelligence Techniques for Data Management, aiDM  2024, In conjunction with the 2024 ACM SIGMOD/PODS Conference","","","3","","","","0","10.1145/3663742.3663973","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198464427&doi=10.1145%2f3663742.3663973&partnerID=40&md5=b75f70f4175fce1f5d3a8380fd8c058e","MIT CSAIL, AWS, United States","Ngom A.L., MIT CSAIL, AWS, United States; Kraska T., MIT CSAIL, AWS, United States","Translating between the SQL dialects of different systems is important for migration and federated query processing. Existing approaches rely on hand-crafted translation rules, which tend to be incomplete and hard to maintain, especially as the number of dialects to translate increases. Thus, dialect translation remains a largely unsolved problem. To address this issue, we introduce Mallet, a system that leverages Large Language Models (LLMs) to automate the generation of SQL-to-SQL translation rules, namely schema conversion, automated UDF generation, extension selection, and expression composition. Once the rules are generated, they are infinitely reusable on new workloads without putting the LLM on the critical path of query execution. Mallet enhances the accuracy of the LLMs by (1) performing retrieval augmented generation (RAG) over system documentation and human expertise, (2) subjecting the rules to empirical validation using the actual SQL systems to detect hallucinations, and (3) automatically creating accurate few-shot learning instances. Contributors, without knowing the system's code, can improve Mallet by providing natural-language expertise for RAG. © 2024 Owner/Author.","","Information retrieval; Critical Paths; Empirical validation; Federated queries; Human expertise; Language model; Query execution; Rule generation; Schema conversion; Translation rules; Unsolved problems; Translation (languages)","","Association for Computing Machinery, Inc","English","Conference paper","Final","","Scopus","2-s2.0-85198464427"
"Bernardi M.L.; Casciani A.; Cimitile M.; Marrella A.","Bernardi, Mario Luca (57195515766); Casciani, Angelo (58997870900); Cimitile, Marta (23392132800); Marrella, Andrea (23569686800)","57195515766; 58997870900; 23392132800; 23569686800","A preliminary study on Business Process-aware Large Language Models","2024","CEUR Workshop Proceedings","3762","","","413","418","5","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205583365&partnerID=40&md5=43312e342527495bdea8a510dfc164f2","Department of Engineering, University of Sannio, Piazza Roma 21, Benevento, 82100, Italy; Department of Computer, Control and Management Engineering, Sapienza University of Rome, Via Ariosto 25, Rome, 00185, Italy; Department of Law and Digital Society, UnitelmaSapienza, Piazza Sassari, Rome, 00185, Italy","Bernardi M.L., Department of Engineering, University of Sannio, Piazza Roma 21, Benevento, 82100, Italy; Casciani A., Department of Computer, Control and Management Engineering, Sapienza University of Rome, Via Ariosto 25, Rome, 00185, Italy; Cimitile M., Department of Law and Digital Society, UnitelmaSapienza, Piazza Sassari, Rome, 00185, Italy; Marrella A., Department of Computer, Control and Management Engineering, Sapienza University of Rome, Via Ariosto 25, Rome, 00185, Italy","AI-Augmented Business Process Management Systems (ABPMSs) are innovative information systems with increased flexibility, autonomy, and conversational capability. These systems can be boosted by Large Language Models (LLMs), renowned for their ability to handle natural language processing tasks. Nevertheless, no significant empirical validations exist about their usefulness in process-driven decision support. In this study, we propose a business process-oriented LLM framework, for enacting actionable conversations with workers involved in a business process, leveraging Retrieval-Augmented Generation (RAG) to enrich process-specific knowledge. The methodology has been assessed to evaluate its capacity to produce precise responses to inquiries posed by users within a public administration context. The preliminary study shows the framework’s ability to identify specific activities and sequence flows within the targeted process model, thereby providing valuable insights into its potential for improving ABPMSs. © 2024 Copyright for this paper by its authors.","Business Process; Decision Support Systems; Large Language Models; Retrieval-Augmented Generation","Enterprise resource management; Information management; Natural language processing systems; Business Process; Business process management systems; Decision supports; Increased flexibility; Language model; Language processing; Large language model; Natural languages; Retrieval-augmented generation; Support systems; Decision support systems","Di Martino S.; University of Naples Federico II, Department of Electrical Engineering and Information Technology (DIETI), Via Claudio 21, Naples; Sansone C.; University of Naples Federico II, Department of Electrical Engineering and Information Technology (DIETI), Via Claudio 21, Naples; Masciari E.; University of Naples Federico II, Department of Electrical Engineering and Information Technology (DIETI), Via Claudio 21, Naples; Rossi S.; University of Naples Federico II, Department of Electrical Engineering and Information Technology (DIETI), Via Claudio 21, Naples; Gravina M.; University of Naples Federico II, Department of Electrical Engineering and Information Technology (DIETI), Via Claudio 21, Naples","CEUR-WS","English","Conference paper","Final","","Scopus","2-s2.0-85205583365"
"Vizgirda V.; Zhao R.; Goel N.","Vizgirda, Vidminas (58285217600); Zhao, Rui (58285167600); Goel, Naman (56818596900)","58285217600; 58285167600; 56818596900","SocialGenPod: Privacy-Friendly Generative AI Social Web Applications with Decentralised Personal Data Stores","2024","WWW 2024 Companion - Companion Proceedings of the ACM Web Conference","","","","1067","1070","3","0","10.1145/3589335.3651251","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194498225&doi=10.1145%2f3589335.3651251&partnerID=40&md5=713514567dc37a74da0b7ca7cac62a73","University of Edinburgh, Edinburgh, United Kingdom; University of Oxford, Oxford, United Kingdom","Vizgirda V., University of Edinburgh, Edinburgh, United Kingdom; Zhao R., University of Oxford, Oxford, United Kingdom; Goel N., University of Oxford, Oxford, United Kingdom","We present SocialGenPod, a decentralised and privacy-friendly way of deploying generative AI Web applications. Unlike centralised Web and data architectures that keep user data tied to application and service providers, we show how one can use Solid — a decentralised Web specification — to decouple user data from generative AI applications. We demonstrate SocialGenPod using a prototype that allows users to converse with different Large Language Models, optionally leveraging Retrieval Augmented Generation to generate answers grounded in private documents stored in any Solid Pod that the user is allowed to access, directly or indirectly. SocialGenPod makes use of Solid access control mechanisms to give users full control of determining who has access to data stored in their Pods. SocialGenPod keeps all user data (chat history, app configuration, personal documents, etc) securely in the user’s personal Pod; separate from specific model or application providers. Besides better privacy controls, this approach also enables portability across different services and applications. Finally, we discuss challenges, posed by the large compute requirements of state-of-the-art models, that future research in this area should address. Our prototype is open-source and available at: https://github.com/Vidminas/socialgenpod/. © 2024 Copyright held by the owner/author(s).","Decentralised Web; Privacy; Retrieval Augmented Generation; Solid","Access control; Data privacy; Information retrieval; Application providers; Data store; Decentralised; Decentralized web; Privacy; Retrieval augmented generation; Social Web applications; User data; WEB application; Web applications; HTTP","","Association for Computing Machinery, Inc","English","Conference paper","Final","All Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85194498225"
"Wang Y.; Lipka N.; Rossi R.A.; Siu A.; Zhang R.; Derr T.","Wang, Yu (57225158329); Lipka, Nedim (25927367600); Rossi, Ryan A. (57197077642); Siu, Alexa (57188592424); Zhang, Ruiyi (57204807127); Derr, Tyler (57198886641)","57225158329; 25927367600; 57197077642; 57188592424; 57204807127; 57198886641","Knowledge Graph Prompting for Multi-Document Question Answering","2024","Proceedings of the AAAI Conference on Artificial Intelligence","38","17","","19206","19214","8","12","10.1609/aaai.v38i17.29889","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188263953&doi=10.1609%2faaai.v38i17.29889&partnerID=40&md5=e78bdeb37abd7b343bbf4a79ceda6a83","Vanderbilt University, Nashville, United States; Adobe Research, San Jose, United States","Wang Y., Vanderbilt University, Nashville, United States; Lipka N., Adobe Research, San Jose, United States; Rossi R.A., Adobe Research, San Jose, United States; Siu A., Adobe Research, San Jose, United States; Zhang R., Adobe Research, San Jose, United States; Derr T., Vanderbilt University, Nashville, United States","The ‘pre-train, prompt, predict’ paradigm of large language models (LLMs) has achieved remarkable success in open-domain question answering (OD-QA). However, few works explore this paradigm in multi-document question answering (MD-QA), a task demanding a thorough understanding of the logical associations among the contents and structures of documents. To fill this crucial gap, we propose a Knowledge Graph Prompting (KGP) method to formulate the right context in prompting LLMs for MD-QA, which consists of a graph construction module and a graph traversal module. For graph construction, we create a knowledge graph (KG) over multiple documents with nodes symbolizing passages or document structures (e.g., pages/tables), and edges denoting the semantic/lexical similarity between passages or document structural relations. For graph traversal, we design an LLM-based graph traversal agent that navigates across nodes and gathers supporting passages assisting LLMs in MD-QA. The constructed graph serves as the global ruler that regulates the transitional space among passages and reduces retrieval latency. Concurrently, the graph traversal agent acts as a local navigator that gathers pertinent context to progressively approach the question and guarantee retrieval quality. Extensive experiments underscore the efficacy of KGP for MD-QA, signifying the potential of leveraging graphs in enhancing the prompt design and retrieval augmented generation for LLMs. Our code: https://github.com/YuWVandy/KG-LLM-MDQA. © 2024, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.","","Air navigation; Graph theory; Semantics; Structural design; Content and structure; Document structure; Graph construction; Graph traversals; Knowledge graphs; Language model; Multidocuments; Multiple documents; Open domain question answering; Question Answering; Knowledge graph","Wooldridge M.; Dy J.; Natarajan S.","Association for the Advancement of Artificial Intelligence","English","Conference paper","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85188263953"
"Sullutrone G.; Vigliermo R.A.; Sala L.; Bergamaschi S.","Sullutrone, Giovanni (59299148800); Vigliermo, Riccardo Amerigo (57267607400); Sala, Luca (57266964300); Bergamaschi, Sonia (7006782238)","59299148800; 57267607400; 57266964300; 7006782238","Sensitive Topics Retrieval in Digital Libraries: A Case Study of ḥadīṯ collections","2024","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","15178 LNCS","","","51","62","11","0","10.1007/978-3-031-72440-4_5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206220820&doi=10.1007%2f978-3-031-72440-4_5&partnerID=40&md5=76074d852687428fac19ab2173719b9a","Università di Modena e Reggio Emilia (UNIMORE), Modena, Italy; DBGroup, UNIMORE, Modena, Italy; Fondazione per le Scienze Religiose (FSCIRE), Bologna, Italy","Sullutrone G., Università di Modena e Reggio Emilia (UNIMORE), Modena, Italy, DBGroup, UNIMORE, Modena, Italy; Vigliermo R.A., Università di Modena e Reggio Emilia (UNIMORE), Modena, Italy, Fondazione per le Scienze Religiose (FSCIRE), Bologna, Italy; Sala L., Università di Modena e Reggio Emilia (UNIMORE), Modena, Italy, DBGroup, UNIMORE, Modena, Italy; Bergamaschi S., Università di Modena e Reggio Emilia (UNIMORE), Modena, Italy, DBGroup, UNIMORE, Modena, Italy","The advent of Large Language Models (LLMs) has led to the development of new Question-Answering (QA) systems based on Retrieval-Augmented Generation (RAG) to incorporate query-specific knowledge at inference time. In this paper, the trustworthiness of RAG systems is investigated, particularly focusing on the performance of their retrieval phase when dealing with sensitive topics. This issue is particularly relevant as it could hinder a user’s ability to analyze sections of the available corpora, effectively biasing any following research. To mimic a specialised library possibly containing sensitive topics, a ḥādīṯ dataset has been curated using an ad-hoc framework called Question-Classify-Retrieve (QCR), which automatically assesses the performance of document retrieval by operating in three main steps: Question Generation, Passage Classification, and Passage Retrieval. Different sentence embedding models for document retrieval were tested showing significant performance gap between sensitive and non-sensitive topics compared to baseline. In real-world applications this would mean relevant documents placed lower in the retrieval list leading to the presence of irrelevant information or the absence of relevant one in case of a lower cut-off. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.","Bias; Digital Libraries; Islamic studies; Retrieval-Augmented Generation; Sensitive Topics; ḥadīṯ collections","Content based retrieval; Digital libraries; Modeling languages; Query languages; Real time systems; Sensitive data; Structured Query Language; Bias; Case-studies; Document Retrieval; Islamic study; Language model; Performance; Question answering systems; Retrieval-augmented generation; Sensitive topic; Ḥadīṯ collection; Question answering","Antonacopoulos A.; Hinze A.; Vanderschantz N.; Piwowarski B.; Coustaty M.; Di Nunzio G.M.; Gelati F.","Springer Science and Business Media Deutschland GmbH","English","Conference paper","Final","","Scopus","2-s2.0-85206220820"
"Cooper M.M.; Klymkowsky M.W.","Cooper, Melanie M. (35766303800); Klymkowsky, Michael W. (7004889703)","35766303800; 7004889703","Let Us Not Squander the Affordances of LLMs for the Sake of Expedience: Using Retrieval Augmented Generative AI Chatbots to Support and Evaluate Student Reasoning","2024","Journal of Chemical Education","","","","","","","0","10.1021/acs.jchemed.4c00765","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206539350&doi=10.1021%2facs.jchemed.4c00765&partnerID=40&md5=8af248fd0167e856fcf66e0024b4cc6a","Department of Chemistry, Michigan State University, 578 South Shaw Lane, East Lansing, 48824, MI, United States; Molecular, Cellular, and Developmental Biology, University of Colorado, Boulder, Boulder, 80309, CO, United States","Cooper M.M., Department of Chemistry, Michigan State University, 578 South Shaw Lane, East Lansing, 48824, MI, United States; Klymkowsky M.W., Molecular, Cellular, and Developmental Biology, University of Colorado, Boulder, Boulder, 80309, CO, United States","The use of large language model Generative AI (GenAI) systems by students and instructors is increasing rapidly, and there is little choice but to adapt to this new situation. Many, but not all, students are using GenAI for homework and assignments, which means that we need to provide equitable access for all students to AI systems that can support and enhance their learning. At the same time, we need to think carefully about just what we want teaching and learning to look like as GenAI systems become readily available. Here we propose that “business as usual” is not a responsible option. Although chatbots can readily answer questions, produce summaries of content, and make the process of education more efficient, there is scant evidence that such time saving is effective, and indeed, it is important that we not allow the use of GenAI systems to circumvent or undermine the learning process. The availability of so-called Retrieval Augmented Generative (RAG) AI systems allows us to expand what we expect students to know and do, by 1) supporting instructors in the design of more complex tasks (that can, for example, elicit evidence of three-dimensional learning (3DL)), 2) supporting students as they reason through such scaffolded tasks, and 3) by evaluating student responses, individually and in aggregate. We present examples of each of these affordances with the associated training materials and bot personas, along with caveats about their use. © 2024 The Authors. Published by American Chemical Society and Division of Chemical Education, Inc.","Curriculum; First-Year Undergraduate; General; Generative AI; Learning Theories; Student Centered Learning","","","American Chemical Society","English","Article","Article in press","All Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85206539350"
"Cherubini M.; Romano F.; Bolioli A.; De Mattei L.; Sangermano M.","Cherubini, Manola (58641898400); Romano, Francesco (55726760100); Bolioli, Andrea (7801311498); De Mattei, Lorenzo (57204921228); Sangermano, Mattia (57782892200)","58641898400; 55726760100; 7801311498; 57204921228; 57782892200","Improving the accessibility of EU laws: the Chat-EUR-Lex project","2024","CEUR Workshop Proceedings","3762","","","6","11","5","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205594793&partnerID=40&md5=fcec37c934f20ae05bd38acdbde4cbfe","Institute of Legal Informatics and Judicial Systems (IGSG-CNR), via dei Barucci 20, Florence, 50127, Italy; Aptus.AI, Largo Padre Renzo Spadoni 1, Pisa, 56126, Italy","Cherubini M., Institute of Legal Informatics and Judicial Systems (IGSG-CNR), via dei Barucci 20, Florence, 50127, Italy; Romano F., Institute of Legal Informatics and Judicial Systems (IGSG-CNR), via dei Barucci 20, Florence, 50127, Italy; Bolioli A., Aptus.AI, Largo Padre Renzo Spadoni 1, Pisa, 56126, Italy; De Mattei L., Aptus.AI, Largo Padre Renzo Spadoni 1, Pisa, 56126, Italy; Sangermano M., Aptus.AI, Largo Padre Renzo Spadoni 1, Pisa, 56126, Italy","In this article we describe the results of an ongoing research project on the use of Chat-Based Large Language Models (Chat LLMs) and Retrieval Augmented Generation (RAG) for the access to legal repositories. We are integrating Chat LLMs and RAG to access a dataset of legal acts in English and Italian (a subset of EUR-Lex collection), and interact through a chatbot. We present the state of the art, the objectives, the use cases, the methodology used in the project, and then we discuss the preliminary results. © 2024 Copyright for this paper by its authors.","Large Language Models (LLMs); Legal Informatics; Retrieval Augmented Generation (RAG)","International law; Chatbots; Language model; Large language model; Legal informatics; Retrieval augmented generation; State of the art; Modeling languages","Di Martino S.; University of Naples Federico II, Department of Electrical Engineering and Information Technology (DIETI), Via Claudio 21, Naples; Sansone C.; University of Naples Federico II, Department of Electrical Engineering and Information Technology (DIETI), Via Claudio 21, Naples; Masciari E.; University of Naples Federico II, Department of Electrical Engineering and Information Technology (DIETI), Via Claudio 21, Naples; Rossi S.; University of Naples Federico II, Department of Electrical Engineering and Information Technology (DIETI), Via Claudio 21, Naples; Gravina M.; University of Naples Federico II, Department of Electrical Engineering and Information Technology (DIETI), Via Claudio 21, Naples","CEUR-WS","English","Conference paper","Final","","Scopus","2-s2.0-85205594793"
"Arefeen M.A.; Debnath B.; Chakradhar S.","Arefeen, Md Adnan (57220584745); Debnath, Biplob (24469971600); Chakradhar, Srimat (7003995360)","57220584745; 24469971600; 7003995360","Optimizing LLM API usage costs with novel query-aware reduction of relevant enterprise data","2024","NEC Technical Journal","17","2","","102","106","4","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198139273&partnerID=40&md5=d351761dec721f9bda82b2cc22d9a49c","NEC Laboratories America, United States; University of Missouri, Kansas City, United States","Arefeen M.A., NEC Laboratories America, United States, University of Missouri, Kansas City, United States; Debnath B., NEC Laboratories America, United States; Chakradhar S., NEC Laboratories America, United States","Costs of LLM API usage rise rapidly when proprietary enterprise data is used as context for user queries to generate more accurate responses from LLMs. To reduce costs, we propose LeanContext, which generates query-aware, compact and AI model-friendly summaries of relevant enterprise data context. This is unlike traditional summarizers that produce query-unaware human-friendly summaries that are also not as compact. We first use retrieval augmented generation (RAG) to generate a query-aware enterprise data context, which includes key, query-relevant enterprise data. Then, we use reinforcement learning to further reduce the context while ensuring that a prompt consisting of the user query and the reduced context elicits an LLM response that is just as accurate as the LLM response to a prompt that uses the original enterprise data context. Our reduced context is not only query-dependent, but it is also variable-sized. Our experimental results demonstrate that LeanContext (a) reduces costs of LLM API usage by 37% to 68% (compared to RAG), while maintaining the accuracy of the LLM response, and (b) improves accuracy of responses by 26% to 38% when state-of-the-art summarizers reduce RAG context. © 2024 NEC Mediaproducts. All rights reserved.","domain-specific question-answering; generative AI; large language model; natural language processing; reinforcement learning; retrieval augmented generation; text summarization","Application programming interfaces (API); Cost reduction; Natural language processing systems; Domain specific; Domain-specific question-answering; Generative AI; Language model; Language processing; Large language model; Natural language processing; Natural languages; Question Answering; Reinforcement learnings; Retrieval augmented generation; Text Summarisation; Reinforcement learning","","NEC Mediaproducts","English","Article","Final","","Scopus","2-s2.0-85198139273"
"","","","Proceedings - 2024 International Conference on Networking and Network Applications, NaNA 2024","2024","Proceedings - 2024 International Conference on Networking and Network Applications, NaNA 2024","","","","","","564","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205951156&partnerID=40&md5=9f00f3fe8b9dc7a6c1c6320e23165279","","","The proceedings contain 89 papers. The topics discussed include: a novel multipath data transmission method with traffic obfuscation; a real-time APT attack detection scheme based on fusion provenance graph in private clouds; a service customize routing method based on software defined network using deep Q-network; CEDA-TQA: context enhancement and domain adaptation method for textbook QA based on LLM and RAG; route origin authorization emergency synchronization based on RPKI relying party cache; trajectory optimization for UAV-enabled covert communications; testing object detection models for autonomous vehicles against hazards; improving the accuracy of anomaly detection from system audit logs via heterogeneous provenance graphs; hierarchical policy learning with noisy networks based multi-round conversational recommendation; and smart garbage design based on voice recognition.","","","","Institute of Electrical and Electronics Engineers Inc.","English","Conference review","Final","","Scopus","2-s2.0-85205951156"
"Wang X.; Sun J.; Qi C.","Wang, Xiaopu (57561838700); Sun, Jianing (57221740880); Qi, Chao (36880399600)","57561838700; 57221740880; 36880399600","CEDA-TQA: Context Enhancement and Domain Adaptation Method for Textbook QA Based on LLM and RAG","2024","Proceedings - 2024 International Conference on Networking and Network Applications, NaNA 2024","","","","263","268","5","0","10.1109/NaNA63151.2024.00050","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205983320&doi=10.1109%2fNaNA63151.2024.00050&partnerID=40&md5=2592b236b56ad49b32ab04eb21dcd336","Key Laboratory of Modern Teaching Technology, Ministry of Education, Xi'an, 710062, China; Shaanxi Normal University, School of Computer Science, Xi'an, 710062, China","Wang X., Key Laboratory of Modern Teaching Technology, Ministry of Education, Xi'an, 710062, China, Shaanxi Normal University, School of Computer Science, Xi'an, 710062, China; Sun J., Key Laboratory of Modern Teaching Technology, Ministry of Education, Xi'an, 710062, China, Shaanxi Normal University, School of Computer Science, Xi'an, 710062, China; Qi C., Key Laboratory of Modern Teaching Technology, Ministry of Education, Xi'an, 710062, China, Shaanxi Normal University, School of Computer Science, Xi'an, 710062, China","Textbook Question Answering (TQA) is a specific area of Natural Language Processing (NLP) that focuses on processing and understanding the content of textbooks to generate coherent and accurate responses. Textbooks contain various types of information, such as text, diagrams, and formulas, which require the model to have abilities in reasoning, analyzing, and synthesizing information. The training of Large Language Models involves extensive corpora, enabling them to effectively process and comprehend intricate linguistic phenomena, thereby generating coherent and insightful responses. This paper utilizes instructional materials as supporting information to assist LLM in responding to questions, then fine-tunes the LLM to enhance its adaptability to specific disciplines while utilizing the RAG technique to minimize interference from irrelevant content. We conducted ablation experiments on a medium-sized LLM that demonstrated the highest accuracy of 81.91% when both finetuning and RAG techniques were employed. © 2024 IEEE.","Large Language Models; Low-Rank Adaptation; Retrieval Augmented Generation; Textbook Question Answering","Digital elevation model; Linguistics; Natural language processing systems; Adaptation methods; Domain adaptation; Language model; Large language model; Low-rank adaptation; Natural languages; Question Answering; Retrieval augmented generation; Specific areas; Textbook question answering; Question answering","","Institute of Electrical and Electronics Engineers Inc.","English","Conference paper","Final","","Scopus","2-s2.0-85205983320"
"Zhang X.; Wang H.; Sun C.","Zhang, Xin (59044771200); Wang, Huiyu (55844471600); Sun, Chunyun (57069307300)","59044771200; 55844471600; 57069307300","BiSpec Pairwise AI: guiding the selection of bispecific antibody target combinations with pairwise learning and GPT augmentation","2024","Journal of Cancer Research and Clinical Oncology","150","5","237","","","","1","10.1007/s00432-024-05740-3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192264252&doi=10.1007%2fs00432-024-05740-3&partnerID=40&md5=1890b0d161db1f31bccb0bc2a48b451a","Beijing Engineering Research Center of Protein and Antibody, Sinocelltech Ltd., Beijing, 100176, China; School of Medicine, Nankai University, Tianjin, 300071, China","Zhang X., Beijing Engineering Research Center of Protein and Antibody, Sinocelltech Ltd., Beijing, 100176, China, School of Medicine, Nankai University, Tianjin, 300071, China; Wang H., Beijing Engineering Research Center of Protein and Antibody, Sinocelltech Ltd., Beijing, 100176, China; Sun C., Beijing Engineering Research Center of Protein and Antibody, Sinocelltech Ltd., Beijing, 100176, China","Purpose: Bispecific antibodies (BsAbs), capable of targeting two antigens simultaneously, represent a significant advancement by employing dual mechanisms of action for tumor suppression. However, how to pair targets to develop effective and safe bispecific drugs is a major challenge for pharmaceutical companies. Methods: Using machine learning models, we refined the biological characteristics of currently approved or in clinical development BsAbs and analyzed hundreds of membrane proteins as bispecific targets to predict the likelihood of successful drug development for various target combinations. Moreover, to enhance the interpretability of prediction results in bispecific target combination, we combined machine learning models with Large Language Models (LLMs). Through a Retrieval-Augmented Generation (RAG) approach, we supplement each pair of bispecific targets’ machine learning prediction with important features and rationales, generating interpretable analytical reports. Results: In this study, the XGBoost model with pairwise learning was employed to predict the druggability of BsAbs. By analyzing extensive data on BsAbs and designing features from perspectives such as target activity, safety, cell type specificity, pathway mechanism, and gene embedding representation, our model is able to predict target combinations of BsAbs with high market potential. Specifically, we integrated XGBoost with the GPT model to discuss the efficacy of each bispecific target pair, thereby aiding the decision-making for drug developers. Conclusion: The novelty of this study lies in the integration of machine learning and GPT techniques to provide a novel framework for the design of BsAbs drugs. This holistic approach not only improves prediction accuracy, but also enhances the interpretability and innovativeness of drug design. © The Author(s) 2024.","Bispecific antibody; GPT; Machine learning; Pairwise learning; Target combination","Antibodies, Bispecific; Humans; Machine Learning; Neoplasms; bispecific antibody; cytotoxic T lymphocyte antigen 4; durvalumab; ipilimumab; membrane protein; programmed death 1 ligand 1; socazolimab; bispecific antibody; area under the curve; Article; binary classification; clinical trial (topic); cross validation; decision making; decision tree; discretization; drug design; feature extraction; generative pretrained transformer; large language model; machine learning; pathway enrichment analysis; predictive model; receiver operating characteristic; safety; human; immunology; neoplasm","","Springer Science and Business Media Deutschland GmbH","English","Article","Final","All Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85192264252"
"","","","Ital-IA 2024 - Proceedings of the Ital-IA Intelligenza Artificiale - Thematic Workshops, co-located with the 4th CINI National Lab AIIS Conference on Artificial Intelligence, Ital-IA 2024","2024","CEUR Workshop Proceedings","3762","","","","","545","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205588806&partnerID=40&md5=2a98e59519111a7e7b10d6c56389695d","","","The proceedings contain 93 papers. The topics discussed include: GiottoBugFixer: an effective and scalable easy-to-use framework for fixing software issues in a DevOps pipeline; GitHub copilot: a systematic study; evaluating retrieval-augmented generation for question answering with large language models; large language models for issue report classification; SAI4EO: symbiotic artificial intelligence for earth observation; explaining intimate partner violence with LLaMAntino; regulating generative ai towards the future; using large language models to support software engineering documentation in waterfall life cycles: are we there yet?; and large language models in software engineering: a focus on issue report classification and user acceptance test generation.","","","Di Martino S.; University of Naples Federico II, Department of Electrical Engineering and Information Technology (DIETI), Via Claudio 21, Naples; Sansone C.; University of Naples Federico II, Department of Electrical Engineering and Information Technology (DIETI), Via Claudio 21, Naples; Masciari E.; University of Naples Federico II, Department of Electrical Engineering and Information Technology (DIETI), Via Claudio 21, Naples; Rossi S.; University of Naples Federico II, Department of Electrical Engineering and Information Technology (DIETI), Via Claudio 21, Naples; Gravina M.; University of Naples Federico II, Department of Electrical Engineering and Information Technology (DIETI), Via Claudio 21, Naples","CEUR-WS","English","Conference review","Final","","Scopus","2-s2.0-85205588806"
"Venkatakrishnan R.; Tanyildizi E.; Canbaz M.A.","Venkatakrishnan, Radhakrishnan (58547765400); Tanyildizi, Emrah (59148380000); Canbaz, M. Abdullah (57027952600)","58547765400; 59148380000; 57027952600","Semantic interlinking of Immigration Data using LLMs for Knowledge Graph Construction","2024","WWW 2024 Companion - Companion Proceedings of the ACM Web Conference","","","","605","608","3","1","10.1145/3589335.3651557","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194462152&doi=10.1145%2f3589335.3651557&partnerID=40&md5=8fa4c8869a1051976b14b398ec6a7002","University at Albany, Albany, NY, United States","Venkatakrishnan R., University at Albany, Albany, NY, United States; Tanyildizi E., University at Albany, Albany, NY, United States; Canbaz M.A., University at Albany, Albany, NY, United States","The challenge of managing immigration data is exacerbated by its reliance on paper-based, evidence-driven records maintained by legal professionals, creating obstacles for efficient processing and analysis due to inherent trust issues with AI-based systems. This paper introduces a cutting-edge framework to surmount these hurdles by synergizing Large Language Models (LLMs) with Knowledge Graphs (KGs), revolutionizing traditional data handling methods. Our method transforms archaic, paper-based immigration records into a structured, interconnected knowledge network that intricately mirrors the legal and procedural nuances of immigration, ensuring a dynamic and trustworthy platform for data analysis. Utilizing LLMs, we extract vital entities and relationships from diverse legal documents to forge a comprehensive knowledge graph, encapsulating the complex legalities and procedural disparities in immigration processes and mapping the multifaceted interactions among stakeholders like applicants, sponsors, and legal experts. This graph not only facilitates a deep dive into the legal stipulations but also incorporates them, significantly boosting the system’s reliability and precision. With the integration of Retrieval Augmented Generation (RAG) for exact, context-aware data retrieval and Augmented Knowledge Creation for developing a conversational interface via LLMs, our framework offers a scalable, adaptable solution to immigration data management. This innovative amalgamation of LLMs, KGs, and RAG techniques marks a paradigm shift towards more informed, efficient, and trustworthy decision-making in the sphere of global migration, setting a new benchmark for legal technology and data source management. © 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.","Data Restructuring; Document Processing; Information Retrieval; Knowledge Graphs; Large Language Models; Legal Tech","Computational linguistics; Data handling; Information management; Knowledge graph; Semantics; Cutting edges; Data restructuring; Document-processing; Graph construction; Knowledge graphs; Knowledge networks; Language model; Large language model; Legal documents; Legal tech; Decision making","","Association for Computing Machinery, Inc","English","Conference paper","Final","All Open Access; Bronze Open Access","Scopus","2-s2.0-85194462152"
"Jayawardena L.; Yapa P.","Jayawardena, Lasal (58983537000); Yapa, Prasan (57053277600)","58983537000; 57053277600","Improving Quality and Domain-Relevancy of Paraphrase Generation with Graph-Based Retrieval Augmented Generation","2024","ACM International Conference Proceeding Series","","","","196","208","12","0","10.1145/3669754.3669784","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203793959&doi=10.1145%2f3669754.3669784&partnerID=40&md5=0a8f9a984baf094f886cbdd36d160bcb","School of Computing, Robert Gordon University, Aberdeen, United Kingdom; School of Computing, Informatics Institute of Technology, Colombo, Sri Lanka","Jayawardena L., School of Computing, Robert Gordon University, Aberdeen, United Kingdom; Yapa P., School of Computing, Informatics Institute of Technology, Colombo, Sri Lanka","Paraphrase generation is a fundamental area of research in Natural Language Processing (NLP) and Natural Language Generation (NLG), due to its sequence-to-sequence (Seq2Seq) nature. Paraphrasing, spanning across various domains, poses challenges for simpler model architectures due to the extensive knowledge required to generate paraphrases. The added constraint of generating diverse paraphrases further complicates the task for models trained on existing datasets. We present a methodology that leverages Graph-Based Retrieval Augmented Generation (G-RAG), capable of utilizing both entity and phrasal knowledge to address this issue. We demonstrate through experiments that this approach enables both complex models like Large Language models (LLMs) and smaller Seq2Seq models to generate more diverse paraphrases without compromising semantic similarity. Furthermore, this approach's capacity to integrate domain-specific knowledge makes it particularly effective across different domains, enhancing its applicability in varied contexts. The results are further corroborated by human evaluation and extensive quantitative analysis focusing on semantic similarity, lexical diversity, syntactic diversity, and grammatical correctness to gauge high-quality paraphrases. © 2024 ACM.","Graph-based Knowledge; Large Language Models; Natural Language Processing; Paraphrase Generation; Sequence-to-Sequence Models","Domain Knowledge; Knowledge graph; Natural language processing systems; Graph-based; Graph-based knowledge; Language model; Language processing; Large language model; Natural language processing; Natural languages; Paraphrase generation; Sequence models; Sequence-to-sequence model; Semantics","","Association for Computing Machinery","English","Conference paper","Final","","Scopus","2-s2.0-85203793959"
"Tu Q.; Guo J.; Li N.; Qi J.; Xu M.","Tu, Qingshi (57977292000); Guo, Jing (57208035905); Li, Nan (56764943700); Qi, Jianchuan (57208080766); Xu, Ming (55519747200)","57977292000; 57208035905; 56764943700; 57208080766; 55519747200","Mitigating Grand Challenges in Life Cycle Inventory Modeling through the Applications of Large Language Models","2024","Environmental Science and Technology","","","","","","","0","10.1021/acs.est.4c07634","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206920514&doi=10.1021%2facs.est.4c07634&partnerID=40&md5=a6c4d4d8aac9e7339c689a2c24ba9a5f","Sustainable Bioeconomy Research Group, Department of Wood Science, The University of British Columbia, Vancouver, V6T 1Z4, BC, Canada; School of Environment, Tsinghua University, Beijing, 100084, China","Tu Q., Sustainable Bioeconomy Research Group, Department of Wood Science, The University of British Columbia, Vancouver, V6T 1Z4, BC, Canada; Guo J., School of Environment, Tsinghua University, Beijing, 100084, China; Li N., School of Environment, Tsinghua University, Beijing, 100084, China; Qi J., School of Environment, Tsinghua University, Beijing, 100084, China; Xu M., School of Environment, Tsinghua University, Beijing, 100084, China","The accuracy of life cycle assessment (LCA) studies is often questioned due to the two grand challenges of life cycle inventory (LCI) modeling: (1) missing foreground flow data and (2) inconsistency in background data matching. Traditional mechanistic methods (e.g., process simulation) and existing machine learning (ML) methods (e.g., similarity-based selection methods) are inadequate due to their limitations in scalability and generalizability. The large language models (LLMs) are well-positioned to address these challenges, given the massive and diverse knowledge learned through the pretraining step. Incorporating LLMs into LCI modeling can lead to the automation of inventory data curation from diverse data sources and to the implementation of a multimodal analytical capacity. In this article, we delineated the mechanisms and advantages of LLMs to addressing these two grand challenges. We also discussed the future research to enhance the use of LLMs for LCI modeling, which includes the key areas such as improving retrieval augmented generation (RAG), integration with knowledge graphs, developing prompt engineering strategies, and fine-tuning pretrained LLMs for LCI-specific tasks. The findings from our study serve as a foundation for future research on scalable and automated LCI modeling methods that can provide more appropriate data for LCA calculations. © 2024 American Chemical Society.","automation; background data mapping; large language models; life cycle assessment; life cycle inventory; missing data; scalability","Background data mapping; Data mappings; Data matching; Flow data; Grand Challenge; Inventory modeling; Language model; Large language model; Life Cycle Inventory; Missing data; automation; human; information retrieval; large language model; life cycle; life cycle assessment; machine learning; process model; prompt engineering; review; therapy","","American Chemical Society","English","Review","Article in press","","Scopus","2-s2.0-85206920514"
"Tian Y.; Song H.; Wang Z.; Wang H.; Hu Z.; Wang F.; Chawla N.V.; Xu P.","Tian, Yijun (57340427000); Song, Huan (56022206900); Wang, Zichen (55650724200); Wang, Haozhu (57203400970); Hu, Ziqing (58954566800); Wang, Fang (58647261200); Chawla, Nitesh V. (35077581400); Xu, Panpan (36505244500)","57340427000; 56022206900; 55650724200; 57203400970; 58954566800; 58647261200; 35077581400; 36505244500","Graph Neural Prompting with Large Language Models","2024","Proceedings of the AAAI Conference on Artificial Intelligence","38","17","","19080","19088","8","9","10.1609/aaai.v38i17.29875","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185803457&doi=10.1609%2faaai.v38i17.29875&partnerID=40&md5=7db44360ec0406f99fd74f888e6343ff","University of Notre Dame, United States; Amazon","Tian Y., University of Notre Dame, United States; Song H., Amazon; Wang Z., Amazon; Wang H., Amazon; Hu Z., Amazon; Wang F., Amazon; Chawla N.V., University of Notre Dame, United States; Xu P., Amazon","Large language models (LLMs) have shown remarkable generalization capability with exceptional performance in various language modeling tasks. However, they still exhibit inherent limitations in precisely capturing and returning grounded knowledge. While existing work has explored utilizing knowledge graphs (KGs) to enhance language modeling via joint training and customized model architectures, applying this to LLMs is problematic owing to their large number of parameters and high computational cost. Therefore, how to enhance pre-trained LLMs using grounded knowledge, e.g., retrieval-augmented generation, remains an open question. In this work, we propose Graph Neural Prompting (GNP), a novel plug-and-play method to assist pre-trained LLMs in learning beneficial knowledge from KGs. GNP encompasses various designs, including a standard graph neural network encoder, a cross-modality pooling module, a domain projector, and a self-supervised link prediction objective. Extensive experiments on multiple datasets demonstrate the superiority of GNP on both commonsense and biomedical reasoning tasks across different LLM sizes and settings. Code is available at https://github.com/meettyj/GNP. © 2024, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.","","Computational linguistics; Knowledge graph; Modeling languages; Computational costs; Generalization capability; Graph neural networks; Inherent limitations; Knowledge graphs; Language model; Modeling architecture; Modeling task; Performance; Plug-and-play; Graph neural networks","Wooldridge M.; Dy J.; Natarajan S.","Association for the Advancement of Artificial Intelligence","English","Conference paper","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85185803457"
"Kang Z.; He Y.; Zhao B.; Qu X.; Peng J.; Xiao J.; Wang J.","Kang, Zuheng (56903626600); He, Yayun (58158286600); Zhao, Botao (57410568000); Qu, Xiaoyang (57188590785); Peng, Junqing (57218453705); Xiao, Jing (57190986110); Wang, Jianzong (57261367700)","56903626600; 58158286600; 57410568000; 57188590785; 57218453705; 57190986110; 57261367700","Retrieval-Augmented Audio Deepfake Detection","2024","ICMR 2024 - Proceedings of the 2024 International Conference on Multimedia Retrieval","","","","376","384","8","0","10.1145/3652583.3658086","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199218100&doi=10.1145%2f3652583.3658086&partnerID=40&md5=a835605c063ba1fb89b1ad398cefd7b8","Ping An Technology (Shenzhen) Co., Ltd, Shenzhen, China; Ping An Insurance (Group) Company of China, Shenzhen, China","Kang Z., Ping An Technology (Shenzhen) Co., Ltd, Shenzhen, China; He Y., Ping An Technology (Shenzhen) Co., Ltd, Shenzhen, China; Zhao B., Ping An Technology (Shenzhen) Co., Ltd, Shenzhen, China; Qu X., Ping An Technology (Shenzhen) Co., Ltd, Shenzhen, China; Peng J., Ping An Technology (Shenzhen) Co., Ltd, Shenzhen, China; Xiao J., Ping An Insurance (Group) Company of China, Shenzhen, China; Wang J., Ping An Technology (Shenzhen) Co., Ltd, Shenzhen, China","With recent advances in speech synthesis including text-to-speech (TTS) and voice conversion (VC) systems enabling the generation of ultra-realistic audio deepfakes, there is growing concern about their potential misuse. However, most deepfake (DF) detection methods rely solely on the fuzzy knowledge learned by a single model, resulting in performance bottlenecks and transparency issues. Inspired by retrieval-augmented generation (RAG), we propose a retrieval-augmented detection (RAD) framework that augments test samples with similar retrieved samples for enhanced detection. We also extend the multi-fusion attentive classifier to integrate it with our proposed RAD framework. Extensive experiments show the superior performance of the proposed RAD framework over baseline methods, achieving state-of-the-art results on the ASVspoof 2021 DF set and competitive results on the 2019 and 2021 LA sets. Further sample analysis indicates that the retriever consistently retrieves samples mostly from the same speaker with acoustic characteristics highly consistent with the query audio, thereby improving detection performance. © 2024 Copyright held by the owner/author(s).","audio deepfake; deepfake detection; LLM; retrieval-augmented detection; retrieval-augmented generation; text-to-speech; voice conversion","Audio acoustics; Audio systems; Information retrieval; Speech processing; Speech recognition; Audio deepfake; Deepfake detection; Detection framework; LLM; Retrieval-augmented detection; Retrieval-augmented generation; Text to speech; Text to voices; Text-to-speech conversion; Voice conversion; Speech synthesis","","Association for Computing Machinery, Inc","English","Conference paper","Final","All Open Access; Bronze Open Access","Scopus","2-s2.0-85199218100"
"Sharma V.; Raman V.","Sharma, Vansh (58601437200); Raman, Venkat (7101864743)","58601437200; 7101864743","A reliable knowledge processing framework for combustion science using foundation models","2024","Energy and AI","16","","100365","","","","1","10.1016/j.egyai.2024.100365","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190965118&doi=10.1016%2fj.egyai.2024.100365&partnerID=40&md5=8f2f7665cabfc329237ab21bdd32e2a8","Department of Aerospace Engineering, University of Michigan, Ann Arbor, 48109-2102, MI, United States","Sharma V., Department of Aerospace Engineering, University of Michigan, Ann Arbor, 48109-2102, MI, United States; Raman V., Department of Aerospace Engineering, University of Michigan, Ann Arbor, 48109-2102, MI, United States","This research explores the integration of large language models (LLMs) into scientific data assimilation, focusing on combustion science as a case study. Leveraging foundational models integrated with Retrieval-Augmented Generation (RAG) framework, the study introduces an approach to process diverse combustion research data, spanning experimental studies, simulations, and literature. The multifaceted nature of combustion research emphasizes the critical role of knowledge processing in navigating and extracting valuable information from a vast and diverse pool of sources. The developed approach minimizes computational and economic expenses while optimizing data privacy and accuracy. It incorporates prompt engineering and offline open-source LLMs, offering user autonomy in selecting base models. The study provides a thorough examination of text segmentation strategies, conducts comparative studies between LLMs, and explores various optimized prompts to demonstrate the effectiveness of the framework. By incorporating an external vector database, the framework outperforms a conventional LLM in generating accurate responses and constructing robust arguments. Additionally, the study delves into the investigation of optimized prompt templates for the purpose of efficient extraction of scientific literature. Furthermore, we present a targeted scaling study to quantify the algorithmic performance of the framework as the number of prompt tokens increases. The research addresses concerns related to hallucinations and false research articles by introducing a custom workflow developed with a detection algorithm to filter out inaccuracies. Despite identified areas for improvement, the framework consistently delivers accurate domain-specific responses with minimal human oversight. The prompt-agnostic approach introduced holds promise for future improvements. The study underscores the significance of integrating LLMs and knowledge processing techniques in scientific research, providing a foundation for advancements in data assimilation and utilization. © 2024 The Author(s)","Combustion; Foundation models; Knowledge processing; Large language models (LLM); Retrieval-augmented generation (RAG)","Computational linguistics; Data mining; Data privacy; Filtration; Case-studies; Combustion research; Combustion science; Data assimilation; Foundation models; Knowledge processing; Language model; Large language model; Retrieval-augmented generation; Scientific data; Combustion","","Elsevier B.V.","English","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85190965118"
"Jenq J.","Jenq, John (6701503803)","6701503803","Improving Performance of Local Chatbot with Caching","2024","Proceedings of World Multi-Conference on Systemics, Cybernetics and Informatics, WMSCI","2024-September","","","68","71","3","0","10.54808/WMSCI2024.01.68","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206632018&doi=10.54808%2fWMSCI2024.01.68&partnerID=40&md5=c8129f4b4f2089fa6ed0fd89727b2fed","School of Computing, Montclair State University, Montclair, 07043, NJ, United States","Jenq J., School of Computing, Montclair State University, Montclair, 07043, NJ, United States","Chatbots and the technology behind them are widely used in many places and in various ways. Retrieval Augmented Generation AI framework has gained its popularity by its linking of large language model with private dataset. It enables one to run AI locally and privately with the most updated information and knowledge. In this report, we aim to improve the local private chatbot response time by using a cache. From our experimental results, the majority of time spent during the query process is in the generation of the response. The response time can be significantly improved when there is a hit on the cache system which enables us to return the response to the user immediately without going through the generation step. In this report, we focus our efforts on improving the turnaround time of the generation step. The cache is organized into categories which can be used for efficient searching. User’s query information such as query string, embedding information, and its response are recorded and stored in the cache. Experiment results are presented and the issues of speed up of request response turnaround time is addressed. © 2024 by the International Institute of Informatics and Systemics. All rights reserved.","Cache; Chatbot; Embeddings; LLM; RAG; Similarity Search","Structured Query Language; Turnaround time; Cache; Chatbots; Embeddings; Improving performance; Language model; LLM; RAG; Similarity search; Turn-around time; Updated informations; Embeddings","Callaos N.C.; Gaile-Sarkane E.; Lace N.; Sanchez B.; Savoie M.","International Institute of Informatics and Cybernetics","English","Conference paper","Final","","Scopus","2-s2.0-85206632018"
"Boumber D.; Tuck B.E.; Verma R.M.; Qachfar F.Z.","Boumber, Dainis (55390789900); Tuck, Bryan E. (58872877100); Verma, Rakesh M. (57203140173); Qachfar, Fatima Zahra (57705173100)","55390789900; 58872877100; 57203140173; 57705173100","LLMs for Explainable Few-shot Deception Detection","2024","IWSPA 2024 - Proceedings of the 10th ACM International Workshop on Security and Privacy Analytics","","","","37","47","10","0","10.1145/3643651.3659898","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197548557&doi=10.1145%2f3643651.3659898&partnerID=40&md5=1c11aff1036782e3f939f8843a746107","Dept. of Computer Science, University of Houston, Houston, TX, United States","Boumber D., Dept. of Computer Science, University of Houston, Houston, TX, United States; Tuck B.E., Dept. of Computer Science, University of Houston, Houston, TX, United States; Verma R.M., Dept. of Computer Science, University of Houston, Houston, TX, United States; Qachfar F.Z., Dept. of Computer Science, University of Houston, Houston, TX, United States","This study investigates the effectiveness of Large Language Models (LLMs) in detecting deception using a Retrieval Augmented Generation (RAG) framework for few-shot learning in domain-Agnostic settings. Our approach combines the sophisticated reasoning capabilities and extensive knowledge base of LLMs to identify deceptive statements across various contexts, with a focus on the explainability of the detection process. This emphasis on explainability enables a detailed analysis of the model's methodologies in distinguishing between truthful and deceptive statements. Additionally, we examine the impact of different definitions of deception, from overt falsehoods to subtle misrepresentations, on the model's accuracy. Our main contributions include providing initial insights into the adaptability of LLMs for deception detection and highlighting the challenges faced in this endeavor, thereby encouraging further exploration in this area. © 2024 ACM.","business email compromise; explainability; fake news; job scams; language models; opinion spam; phishing; reasoning; retrieval augmented generation; sms spam; social engineering attacks","Computational linguistics; Business email compromize; Explainability; Fake news; Job scam; Language model; Opinion spam; Phishing; Reasoning; Retrieval augmented generation; Sms spam; Social engineering; Social engineering attack; Knowledge based systems","","Association for Computing Machinery, Inc","English","Conference paper","Final","","Scopus","2-s2.0-85197548557"
"Habib M.A.; Amin S.; Oqba M.; Jaipal S.; Khan M.J.; Samad A.","Habib, Mohammad Affan (59247540200); Amin, Shehryar (59247998900); Oqba, Muhammad (59247385500); Jaipal, Sameer (59247999000); Khan, Muhammad Junaid (58834676200); Samad, Abdul (57925367100)","59247540200; 59247998900; 59247385500; 59247999000; 58834676200; 57925367100","TaxTajweez: A Large Language Model-based Chatbot for Income Tax Information In Pakistan Using Retrieval Augmented Generation (RAG)","2024","Proceedings of the International Florida Artificial Intelligence Research Society Conference, FLAIRS","37","","","","","","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200483206&partnerID=40&md5=453fadad73752825bd17040f3aa21858","Habib University,, Pakistan; University of Central Florida, United States","Habib M.A., Habib University,, Pakistan; Amin S., Habib University,, Pakistan; Oqba M., Habib University,, Pakistan; Jaipal S., Habib University,, Pakistan; Khan M.J., University of Central Florida, United States; Samad A., Habib University,, Pakistan","The advent of Large Language Models (LLMs) has heralded a transformative era in natural language processing across diverse fields, igniting considerable interest in domain-specific applications. However, while proprietary models have made significant strides in sectors such as medicine, education, and law through tailored data accumulations, similar advancements have yet to emerge in the Pakistani taxation domain, hindering its digital transformation. In this paper, we introduce TaxTajweez, a specialized Retrieval Augmented Generation (RAG) system powered by the OpenAI GPT-3.5-turbo LLM, designed specifically for income taxation. Complemented by a meticulously curated dataset tailored to the intricacies of income taxation, TaxTajweez leverages the RAG pipeline to mitigate model hallucinations, enhancing the reliability of generated responses. Through a blend of qualitative and quantitative evaluation methodologies, we rigorously assess the accuracy and usability of TaxTajweez, establishing its efficacy as an income tax advisory tool. Copyright © 2024 by the authors.","","Computational linguistics; Metadata; Natural language processing systems; Chatbots; Diverse fields; Domain-specific application; Income tax; Income taxation; Language model; Language processing; Model-based OPC; Natural languages; Pakistan; Taxation","","Florida Online Journals, University of Florida","English","Conference paper","Final","","Scopus","2-s2.0-85200483206"
"Vadapalli J.; Gupta S.; Karki B.; Tsai C.-H.","Vadapalli, Jagadeesh (59160906500); Gupta, Srishti (57755135800); Karki, Bishwa (59091039700); Tsai, Chun-Hua (56277973900)","59160906500; 57755135800; 59091039700; 56277973900","Incorporating Citizen-Generated Data into Large Language Models","2024","ACM International Conference Proceeding Series","","","","1023","1025","2","0","10.1145/3657054.3659119","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195271051&doi=10.1145%2f3657054.3659119&partnerID=40&md5=c22becd1726461469a26133de24bed0e","University of Nebraska at Omaha, Omaha, NE, United States","Vadapalli J., University of Nebraska at Omaha, Omaha, NE, United States; Gupta S., University of Nebraska at Omaha, Omaha, NE, United States; Karki B., University of Nebraska at Omaha, Omaha, NE, United States; Tsai C.-H., University of Nebraska at Omaha, Omaha, NE, United States","This study investigates the use of citizen-generated data to optimize a large language model (LLM) chatbot that gives nutrition advice. By actively participating in the data collection and annotation process from FDA-approved websites, citizens provided insightful information that was essential for improving the model and addressing biases. The study highlights the difficulties in gathering and annotating data, especially in situations where nuances matter, such as pregnancy nutrition. The results show that the use of citizen-generated data improves the efficacy and efficiency of data collection procedures, providing a practical viewpoint and encouraging community involvement. In addition to guaranteeing data quality, the iterative process raises stakeholders’ awareness of and proficiency with data. Thus, citizen-generated data becomes an essential tool for creating information systems that are more reliable and inclusive. © 2024 Copyright held by the owner/author(s).","Citizen Science; Fine-tuning; Retrieval-Augmented Generation","Computational linguistics; Data acquisition; Chatbots; Citizen science; Community involvement; Data annotation; Data collection; Data quality; Fine tuning; Iterative process; Language model; Retrieval-augmented generation; Nutrition","Liao H.-C.; Cid D.D.; Macadar M.A.; Bernardini F.","Association for Computing Machinery","English","Conference paper","Final","","Scopus","2-s2.0-85195271051"
"Yang R.; Zeng Q.; You K.; Qiao Y.; Huang L.; Hsieh C.-C.; Rosand B.; Goldwasser J.; Dave A.; Keenan T.; Ke Y.; Hong C.; Liu N.; Chew E.; Radev D.; Lu Z.; Xu H.; Chen Q.; Li I.","Yang, Rui (58728071500); Zeng, Qingcheng (57681143900); You, Keen (57668759200); Qiao, Yujie (57668427900); Huang, Lucas (58506851400); Hsieh, Chia-Chun (57219764746); Rosand, Benjamin (57222502822); Goldwasser, Jeremy (57226254434); Dave, Amisha (57202279221); Keenan, Tiarnan (16686139900); Ke, Yuhe (57220660733); Hong, Chuan (55945588500); Liu, Nan (35795731300); Chew, Emily (7102013764); Radev, Dragomir (7006578526); Lu, Zhiyong (23474115300); Xu, Hua (55493876700); Chen, Qingyu (57169104000); Li, Irene (57207861716)","58728071500; 57681143900; 57668759200; 57668427900; 58506851400; 57219764746; 57222502822; 57226254434; 57202279221; 16686139900; 57220660733; 55945588500; 35795731300; 7102013764; 7006578526; 23474115300; 55493876700; 57169104000; 57207861716","Ascle—A Python Natural Language Processing Toolkit for Medical Text Generation: Development and Evaluation Study","2024","Journal of Medical Internet Research","26","","e60601","","","","0","10.2196/60601","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205605906&doi=10.2196%2f60601&partnerID=40&md5=98fff69cc9aa11e2d597bb127d0a9e03","Centre for Quantitative Medicine, Duke-NUS Medical School, Singapore, Singapore; Department of Linguistics, Northwestern University, Evanston, IL, United States; Department of Computer Science, Yale University, New Haven, CT, United States; Yale School of Public Health, Yale University, New Haven, CT, United States; Yale New Haven Hospital, Yale School of Medicine, Yale University, New Haven, CT, United States; Division of Epidemiology and Clinical Applications, National Eye Institute, National Institutes of Health, Bethesda, MD, United States; Department of Anesthesiology, Singapore General Hospital, Singapore, Singapore; Department of Biostatistics and Bioinformatics, Duke University, Durham, NC, United States; Program in Health Services and Systems Research, Duke-NUS Medical School, Singapore, Singapore; Institute of Data Science, National University of Singapore, Singapore, Singapore; National Center for Biotechnology Information, National Library of Medicine, National Institutes of Health, Bethesda, MD, United States; Department of Biomedical Informatics and Data Science, Yale School of Medicine, Yale University, New Haven, CT, United States; Information Technology Center, University of Tokyo, Kashiwa, Japan; Smartor LLC, Tokyo, Japan","Yang R., Centre for Quantitative Medicine, Duke-NUS Medical School, Singapore, Singapore; Zeng Q., Department of Linguistics, Northwestern University, Evanston, IL, United States; You K., Department of Computer Science, Yale University, New Haven, CT, United States; Qiao Y., Yale School of Public Health, Yale University, New Haven, CT, United States; Huang L., Department of Computer Science, Yale University, New Haven, CT, United States; Hsieh C.-C., Department of Computer Science, Yale University, New Haven, CT, United States; Rosand B., Department of Computer Science, Yale University, New Haven, CT, United States; Goldwasser J., Department of Computer Science, Yale University, New Haven, CT, United States; Dave A., Yale New Haven Hospital, Yale School of Medicine, Yale University, New Haven, CT, United States; Keenan T., Division of Epidemiology and Clinical Applications, National Eye Institute, National Institutes of Health, Bethesda, MD, United States; Ke Y., Department of Anesthesiology, Singapore General Hospital, Singapore, Singapore; Hong C., Department of Biostatistics and Bioinformatics, Duke University, Durham, NC, United States; Liu N., Centre for Quantitative Medicine, Duke-NUS Medical School, Singapore, Singapore, Program in Health Services and Systems Research, Duke-NUS Medical School, Singapore, Singapore, Institute of Data Science, National University of Singapore, Singapore, Singapore; Chew E., Division of Epidemiology and Clinical Applications, National Eye Institute, National Institutes of Health, Bethesda, MD, United States; Radev D., Department of Computer Science, Yale University, New Haven, CT, United States; Lu Z., National Center for Biotechnology Information, National Library of Medicine, National Institutes of Health, Bethesda, MD, United States; Xu H., Department of Biomedical Informatics and Data Science, Yale School of Medicine, Yale University, New Haven, CT, United States; Chen Q., Department of Biomedical Informatics and Data Science, Yale School of Medicine, Yale University, New Haven, CT, United States; Li I., Information Technology Center, University of Tokyo, Kashiwa, Japan, Smartor LLC, Tokyo, Japan","Background: Medical texts present significant domain-specific challenges, and manually curating these texts is a time-consuming and labor-intensive process. To address this, natural language processing (NLP) algorithms have been developed to automate text processing. In the biomedical field, various toolkits for text processing exist, which have greatly improved the efficiency of handling unstructured text. However, these existing toolkits tend to emphasize different perspectives, and none of them offer generation capabilities, leaving a significant gap in the current offerings. Objective: This study aims to describe the development and preliminary evaluation of Ascle. Ascle is tailored for biomedical researchers and clinical staff with an easy-to-use, all-in-one solution that requires minimal programming expertise. For the first time, Ascle provides 4 advanced and challenging generative functions: question-answering, text summarization, text simplification, and machine translation. In addition, Ascle integrates 12 essential NLP functions, along with query and search capabilities for clinical databases. Methods: We fine-tuned 32 domain-specific language models and evaluated them thoroughly on 27 established benchmarks. In addition, for the question-answering task, we developed a retrieval-augmented generation (RAG) framework for large language models that incorporated a medical knowledge graph with ranking techniques to enhance the reliability of generated answers. Additionally, we conducted a physician validation to assess the quality of generated content beyond automated metrics. Results: The fine-tuned models and RAG framework consistently enhanced text generation tasks. For example, the fine-tuned models improved the machine translation task by 20.27 in terms of BLEU score. In the question-answering task, the RAG framework raised the ROUGE-L score by 18% over the vanilla models. Physician validation of generated answers showed high scores for readability (4.95/5) and relevancy (4.43/5), with a lower score for accuracy (3.90/5) and completeness (3.31/5). Conclusions: This study introduces the development and evaluation of Ascle, a user-friendly NLP toolkit designed for medical text generation. All code is publicly available through the Ascle GitHub repository. All fine-tuned language models can be accessed through Hugging Face. ©Rui Yang, Qingcheng Zeng, Keen You, Yujie Qiao, Lucas Huang, Chia-Chun Hsieh, Benjamin Rosand, Jeremy Goldwasser, Amisha Dave, Tiarnan Keenan, Yuhe Ke, Chuan Hong, Nan Liu, Emily Chew, Dragomir Radev, Zhiyong Lu, Hua Xu, Qingyu Chen, Irene Li. Originally published in the Journal of Medical Internet Research (https://www.jmir.org), 03.10.2024.","deep learning; generative artificial intelligence; healthcare; large language models; machine learning; natural language processing; retrieval-augmented generation","Algorithms; Humans; Natural Language Processing; Software; algorithm; article; benchmarking; data base; deep learning; generative artificial intelligence; human; information retrieval; Internet; language model; large language model; machine learning; natural language processing; reliability; Vanilla; word processing; software","","JMIR Publications Inc.","English","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85205605906"
"Bhattacharya R.","Bhattacharya, Ranjeeta (59253194100)","59253194100","Strategies to mitigate hallucinations in large language models","2024","Applied Marketing Analytics","10","1","","62","67","5","0","10.69554/nxxb8234","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202886920&doi=10.69554%2fnxxb8234&partnerID=40&md5=ca872300412c68c70deb81a8e0219b2b","BNY Mellon AI Hub, United States; 240 Greenwich Street, New York, 10286, NY, United States","Bhattacharya R., BNY Mellon AI Hub, United States, 240 Greenwich Street, New York, 10286, NY, United States","In the world of enterprise-level applications, the construction and utilisation of large language models (LLMs) carry a paramount significance, accompanied by the crucial task of mitigating hallucinations. These instances of generating factually inaccurate information pose challenges during both the initial development phase of LLMs and the subsequent refinement process through prompt engineering. This paper delves into a variety of approaches such as retrieval augmented generation, advanced prompting methodologies, harnessing the power of knowledge graphs, construction of entirely new LLMs from scratch etc, aimed at alleviating these challenges. The paper also underscores the indispensable role of human oversight and user education in addressing this evolving issue. As the field continues to evolve, the importance of continuous vigilance and adaptation cannot be overstated, with a focus on refining strategies to effectively combat hallucinations within LLMs. © Henry Stewart Publications 2054-7544 (2024)","hallucination; large language model; LLM; prompt engineering; RAG","","","Henry Stewart Publications","English","Article","Final","","Scopus","2-s2.0-85202886920"
"Zhou Y.; Liu Z.; Jin J.; Nie J.-Y.; Dou Z.","Zhou, Yujia (57214938039); Liu, Zheng (57211759701); Jin, Jiajie (58475361200); Nie, Jian-Yun (59142334600); Dou, Zhicheng (24722777200)","57214938039; 57211759701; 58475361200; 59142334600; 24722777200","Metacognitive Retrieval-Augmented Large Language Models","2024","WWW 2024 - Proceedings of the ACM Web Conference","","","","1453","1463","10","0","10.1145/3589334.3645481","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194077649&doi=10.1145%2f3589334.3645481&partnerID=40&md5=f5021ef61a4726939f196b35f3ce7c79","School of Information, Renmin University of China, Beijing, China; Beijing Academy of Artificial Intelligence, Beijing, China; Gaoling School of Artificial Intelligence, Renmin University of China, Beijing, China; University of Montreal, Quebec, Canada","Zhou Y., School of Information, Renmin University of China, Beijing, China; Liu Z., Beijing Academy of Artificial Intelligence, Beijing, China; Jin J., Gaoling School of Artificial Intelligence, Renmin University of China, Beijing, China; Nie J.-Y., University of Montreal, Quebec, Canada; Dou Z., Gaoling School of Artificial Intelligence, Renmin University of China, Beijing, China","Retrieval-augmented generation have become central in natural language processing due to their efficacy in generating factual content. While traditional methods employ single-time retrieval, more recent approaches have shifted towards multi-time retrieval for multi-hop reasoning tasks. However, these strategies are bound by predefined reasoning steps, potentially leading to inaccuracies in response generation. This paper introduces MetaRAG, an approach that combines the retrieval-augmented generation process with metacognition. Drawing from cognitive psychology, metacognition allows an entity to self-reflect and critically evaluate its cognitive processes. By integrating this, MetaRAG enables the model to monitor, evaluate, and plan its response strategies, enhancing its introspective reasoning abilities. Through a three-step metacognitive regulation pipeline, the model can identify inadequacies in initial cognitive responses and fixes them. Empirical evaluations show that MetaRAG significantly outperforms existing methods.  © 2024 ACM.","llms; metacognition; retrieval-augmented generation","Natural language processing systems; Language model; Language processing; Llms; Metacognition; Metacognitives; Multi-hops; Natural languages; Reasoning tasks; Response generation; Retrieval-augmented generation; Cognitive systems","","Association for Computing Machinery, Inc","English","Conference paper","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85194077649"
"Rouf N.; Amin F.; Franzon P.D.","Rouf, Nirjhor (55633351500); Amin, Fin (58487052300); Franzon, Paul D. (7006752280)","55633351500; 58487052300; 7006752280","Can Low-Rank Knowledge Distillation in LLMs be Useful for Microelectronic Reasoning?","2024","2024 IEEE LLM Aided Design Workshop, LAD 2024","","","","","","","0","10.1109/LAD62341.2024.10691755","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206691799&doi=10.1109%2fLAD62341.2024.10691755&partnerID=40&md5=a3a8b2b1bfac411c646ce2301e3003a1","North Carolina State University, Ece Department, United States","Rouf N., North Carolina State University, Ece Department, United States; Amin F., North Carolina State University, Ece Department, United States; Franzon P.D., North Carolina State University, Ece Department, United States","In this work, we present empirical results regarding the feasibility of using offline large language models (LLMs) in the context of electronic design automation (EDA). The goal is to investigate and evaluate a contemporary language model's (Llama-2-7B) ability to function as a microelectronic Q&A expert as well as its reasoning, and generation capabilities in solving microelectronic-related problems. Llama-2-7B was tested across a variety of adaptation methods, including introducing a novel low-rank knowledge distillation (LoRA-KD) scheme. Our experiments produce both qualitative and quantitative results. Furthermore, we release our evaluation benchmark along with the code necessary to replicate our experiments at github.com/FinAminToastCrunch.  © 2024 IEEE.","knowledge-distillation; LLM fine-tuning; LLMs for EDA education; Low-Rank adaptation; RAG","Benchmarking; Electronics design automation; Fine tuning; Knowledge-distillation; Language model; Large language model fine-tuning; Large language model for electronic design automation education; Low-rank adaptation; Offline; RAG; Integrated circuit design","","Institute of Electrical and Electronics Engineers Inc.","English","Conference paper","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85206691799"
"Xu S.; Pang L.; Xu J.; Shen H.; Cheng X.","Xu, Shicheng (57604195300); Pang, Liang (55967159200); Xu, Jun (57148828000); Shen, Huawei (21740199800); Cheng, Xueqi (55855927900)","57604195300; 55967159200; 57148828000; 21740199800; 55855927900","List-aware Reranking-Truncation Joint Model for Search and Retrieval-augmented Generation","2024","WWW 2024 - Proceedings of the ACM Web Conference","","","","1330","1340","10","1","10.1145/3589334.3645336","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194080254&doi=10.1145%2f3589334.3645336&partnerID=40&md5=6e3bca293cc6fd5457b742ec7cbb3cb0","CAS Key Laboratory of AI Security, Institute of Computing Technology, Chinese Academy of Sciences, University of Chinese Academy of Sciences, Beijing, China; CAS Key Laboratory of AI Security, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China; Gaoling School of Artificial Intelligence, Renmin University of China, Beijing, China","Xu S., CAS Key Laboratory of AI Security, Institute of Computing Technology, Chinese Academy of Sciences, University of Chinese Academy of Sciences, Beijing, China; Pang L., CAS Key Laboratory of AI Security, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China; Xu J., Gaoling School of Artificial Intelligence, Renmin University of China, Beijing, China; Shen H., CAS Key Laboratory of AI Security, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China; Cheng X., CAS Key Laboratory of AI Security, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China","The results of information retrieval (IR) are usually presented in the form of a ranking list of candidate documents, such as web search for humans and retrieval-augmented generation for large language models (LLMs). List-aware retrieval aims to capture the list-level contextual features to return a better list, mainly including reranking and truncation. Reranking finely re-scores the documents in the list. Truncation dynamically determines the cut-off point of the ranked list to achieve the trade-off between overall relevance and avoiding misinformation from irrelevant documents. Previous studies treat them as two separate tasks and model them separately. However, the separation is not optimal. First, it is hard to share the contextual information of the ranking list between the two tasks. Second, the separate pipeline usually meets the error accumulation problem, where the small error from the reranking stage can largely affect the truncation stage. To solve these problems, we propose a Reranking-Truncation joint model (GenRT) that can perform the two tasks concurrently. GenRT integrates reranking and truncation via a generative paradigm based on an encoder-decoder architecture with novel loss functions for joint optimization to learn both tasks. Sharing parameters by the joint model is conducive to making full use of the common modeling information of the two tasks. Besides, the two tasks are performed concurrently and co-optimized to solve the error accumulation problem between separate stages. Experiments on public learning-to-rank benchmarks and open-domain Q&A tasks show that our method achieves SOTA performance on both reranking and truncation tasks for web search and retrieval-augmented LLMs. © 2024 Owner/Author.","reranking; retrieval-augmented LLMs; truncation","Benchmarking; Economic and social effects; Errors; Websites; Contextual feature; Error accumulation; Joint models; Language model; Ranking lists; Re-ranking; Retrieval-augmented large language model; Search and retrieval; Truncation; Web searches; Information retrieval","","Association for Computing Machinery, Inc","English","Conference paper","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85194080254"
"Ma T.; Han W.; Mu Y.; Wang Z.; Xu X.; Shen J.; Wang J.; Zhang J.","Ma, Tianming (59362890800); Han, Wei (59363414000); Mu, Yuzhi (59363414100); Wang, Zihao (59363152900); Xu, Xuefan (59363153000); Shen, Junyu (59362890900); Wang, Jiansheng (59363153100); Zhang, Jian (59363414200)","59362890800; 59363414000; 59363414100; 59363152900; 59363153000; 59362890900; 59363153100; 59363414200","TA-Agent: Tool Augmented Based on Iterative Ideas in Software Engineering","2024","2024 5th International Conference on Electronic Communication and Artificial Intelligence, ICECAI 2024","","","","605","609","4","0","10.1109/ICECAI62591.2024.10674851","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206100146&doi=10.1109%2fICECAI62591.2024.10674851&partnerID=40&md5=2139dc5b7cfe351ec81c99e9df94913c","The College of Information, Mechanical and Electrical Engineering, Shanghai Normal University, Shanghai, China; DataGrand Inc., Shanghai, China","Ma T., The College of Information, Mechanical and Electrical Engineering, Shanghai Normal University, Shanghai, China; Han W., DataGrand Inc., Shanghai, China; Mu Y., DataGrand Inc., Shanghai, China; Wang Z., DataGrand Inc., Shanghai, China; Xu X., DataGrand Inc., Shanghai, China; Shen J., The College of Information, Mechanical and Electrical Engineering, Shanghai Normal University, Shanghai, China; Wang J., The College of Information, Mechanical and Electrical Engineering, Shanghai Normal University, Shanghai, China; Zhang J., DataGrand Inc., Shanghai, China","Humans have long been pursuing Artificial Intelligence (AI) that equals or surpasses the human level, and AI agents are considered a promising vehicle for achieving this goal. Artificially intelligent agents are artificial entities that can perceive the environment, make decisions, and take actions. Agents can solve practical tasks based on existing tools. However, the current tools-based Agents suffer from the drawbacks of incomplete loading of tools libraries and redundancy in tools creation. To address these two issues, we introduce the Tools Augment Agent (TA-Agent) based on the iterative thinking of software engineering. Our automation paradigm uses LLM-based agents to achieve enhancement automation through reasoning and acting recall tools. It is designed to enhance existing tools according to human task requirements without creating new tools as much as possible and to continuously optimize and improve the quality of existing tools through iterations. Finally, the tools-augmented task construction and execution processes are explained in detail through experiments, proving the feasibility of TA-Agent and revealing the possibility of a new paradigm of Agent-driven automation. The code is available at https://github.com/Taurus9527/Tool_Augment. © 2024 IEEE.","LLM-based agents; ReAct; Retrieval-Augmented Generation; Software Engineering and Iteration; Tools augment","Computer aided software engineering; Requirements engineering; 'current; Agent based; Artificial intelligence agent; Human levels; LLM-based agent; React; Retrieval-augmented generation; Software engineering and iteration; Task-based; Tool augment; Software agents","","Institute of Electrical and Electronics Engineers Inc.","English","Conference paper","Final","","Scopus","2-s2.0-85206100146"
"Ordóñez-Camacho D.; Melgarejo-Heredia R.; Abbasi M.; González-Solis L.","Ordóñez-Camacho, Diego (57216416228); Melgarejo-Heredia, Rafael (57190005369); Abbasi, Mohsen (59116446700); González-Solis, Lucía (59371422600)","57216416228; 57190005369; 59116446700; 59371422600","Aurel_AI: Automating an Institutional Help Desk Using an LLM Chatbot","2024","Proceedings of World Multi-Conference on Systemics, Cybernetics and Informatics, WMSCI","2024-September","","","81","84","3","0","10.54808/WMSCI2024.01.81","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206614745&doi=10.54808%2fWMSCI2024.01.81&partnerID=40&md5=6a79d952cdc33fcf6805d45d140fa3a0","Facultad Internacional de Innovación, PUCE-Icam - Pontificia Universidad Católica del Ecuador, ICAM - Institut catholique d'arts et métiers, Quito, Ecuador","Ordóñez-Camacho D., Facultad Internacional de Innovación, PUCE-Icam - Pontificia Universidad Católica del Ecuador, ICAM - Institut catholique d'arts et métiers, Quito, Ecuador; Melgarejo-Heredia R., Facultad Internacional de Innovación, PUCE-Icam - Pontificia Universidad Católica del Ecuador, ICAM - Institut catholique d'arts et métiers, Quito, Ecuador; Abbasi M., Facultad Internacional de Innovación, PUCE-Icam - Pontificia Universidad Católica del Ecuador, ICAM - Institut catholique d'arts et métiers, Quito, Ecuador; González-Solis L., Facultad Internacional de Innovación, PUCE-Icam - Pontificia Universidad Católica del Ecuador, ICAM - Institut catholique d'arts et métiers, Quito, Ecuador","The Aurel_AI research project focuses on creating a virtual help desk for universities, delivering accurate information about academic programs, regulations, processes, and personnel to both internal and external clients. Traditional call centers often grapple with outdated data, limited knowledge, and high staff turnover, leading to inaccurate responses and long wait times. Generative AI models, particularly Large Language Models (LLMs), offer a promising solution for automated help desks. These models can comprehend poorly structured queries and generate appropriate answers. However, they may encounter “hallucinations” due to insufficient training data. Ensuring accurate and comprehensive information involves specific data collection, validation, and updating methodologies. Techniques like Fine-Tuning and Retrieval-Augmented Generation (RAG) are essential for specific use cases. While both methods have pros and cons, balancing cost-effective infrastructure is crucial for a precise, flexible, and user-friendly system. © 2024 by the International Institute of Informatics and Systemics. All rights reserved.","automated help desk; chatbot; Fine-Tuning; LLM; RAG","Information retrieval; Query languages; Academic program; Automated help desk; Automated helps; Chatbots; Fine tuning; Help Desk; Language model; Large language model; Program regulation; Retrieval-augmented generation; Structured Query Language","Callaos N.C.; Gaile-Sarkane E.; Lace N.; Sanchez B.; Savoie M.","International Institute of Informatics and Cybernetics","English","Conference paper","Final","","Scopus","2-s2.0-85206614745"
"Wang G.; Li Y.; Liu Y.; Deng G.; Li T.; Xu G.; Liu Y.; Wang H.; Wang K.","Wang, Guanyu (58913168200); Li, Yuekang (57196001970); Liu, Yi (57263997900); Deng, Gelei (57208594263); Li, Tianlin (57218764226); Xu, Guosheng (55726292200); Liu, Yang (57881803100); Wang, Haoyu (55808022700); Wang, Kailong (57189044584)","58913168200; 57196001970; 57263997900; 57208594263; 57218764226; 55726292200; 57881803100; 55808022700; 57189044584","MeTMaP: Metamorphic Testing for Detecting False Vector Matching Problems in LLM Augmented Generation","2024","Proceedings - 2024 IEEE/ACM 1st International Conference on AI Foundation Models and Software Engineering, FORGE 2024","","","","12","23","11","1","10.1145/3650105.3652297","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197264619&doi=10.1145%2f3650105.3652297&partnerID=40&md5=3ce99caef9ec827e9b3fdfbf2f7c3426","Beijing University of Posts and Telecommunications, Beijing, China; University of New South Wales, Sydney, Australia; Nanyang Technological University, Singapore, Singapore; Huazhong University of Science and Technology, Wuhan, China","Wang G., Beijing University of Posts and Telecommunications, Beijing, China; Li Y., University of New South Wales, Sydney, Australia; Liu Y., Nanyang Technological University, Singapore, Singapore; Deng G., Nanyang Technological University, Singapore, Singapore; Li T., Nanyang Technological University, Singapore, Singapore; Xu G., Beijing University of Posts and Telecommunications, Beijing, China; Liu Y., Nanyang Technological University, Singapore, Singapore; Wang H., Huazhong University of Science and Technology, Wuhan, China; Wang K., Huazhong University of Science and Technology, Wuhan, China","Augmented generation techniques such as Retrieval-Augmented Generation (RAG) and Cache-Augmented Generation (CAG) have revolutionized the field by enhancing large language model (LLM) outputs with external knowledge and cached information. However, the integration of vector databases, which serve as a backbone for these augmentations, introduces critical challenges, particularly in ensuring accurate vector matching. False vector matching in these databases can significantly compromise the integrity and reliability of LLM outputs, leading to misinformation or erroneous responses. Despite the crucial impact of these issues, there is a notable research gap in methods to effectively detect and address false vector matches in LLM-augmented generation.This paper presents MeTMaP, a metamorphic testing framework developed to identify false vector matching in LLM-augmented generation systems. We derive eight metamorphic relations (MRs) from six NLP datasets, which form our method's core, based on the idea that semantically similar texts should match and dissimilar ones should not. MeTMaP uses these MRs to create sentence triplets for testing, simulating real-world matching scenarios. Our evaluation of MeTMaP over 203 vector matching configurations, involving 29 embedding models and 7 distance metrics, uncovers significant inaccuracies. The results, showing a maximum accuracy of only 41.51% on our tests compared to the original datasets, emphasize the widespread issue of false matches in vector matching methods and the critical need for effective detection and mitigation in LLM-augmented applications.  © 2024 is held by the owner/author(s). Publication rights licensed to ACM.","augmented generation; metamorphic testing; vector matching","Augmented generation; External knowledge; Generation techniques; Language model; Matching problems; Matchings; Metamorphic relations; Metamorphic testing; Model outputs; Vector matching; Vectors","","Association for Computing Machinery, Inc","English","Conference paper","Final","All Open Access; Bronze Open Access","Scopus","2-s2.0-85197264619"
"Bernardi M.L.; Casciani A.; Cimitile M.; Marrella A.","Bernardi, Mario Luca (57195515766); Casciani, Angelo (58997870900); Cimitile, Marta (23392132800); Marrella, Andrea (23569686800)","57195515766; 58997870900; 23392132800; 23569686800","Conversing with business process-aware large language models: the BPLLM framework","2024","Journal of Intelligent Information Systems","","","","","","","1","10.1007/s10844-024-00898-1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205550548&doi=10.1007%2fs10844-024-00898-1&partnerID=40&md5=6d175bc813d813ce6862532e2ddc419b","Department of Engineering, University of Sannio, Piazza Roma 21, Benevento, 82100, Italy; Department of Computer, Control and Management Engineering, Sapienza University of Rome, Via Ariosto 25, Rome, 00185, Italy; Department of Law and Digital Society, UnitelmaSapienza, Piazza Sassari, Rome, 00185, Italy","Bernardi M.L., Department of Engineering, University of Sannio, Piazza Roma 21, Benevento, 82100, Italy; Casciani A., Department of Computer, Control and Management Engineering, Sapienza University of Rome, Via Ariosto 25, Rome, 00185, Italy; Cimitile M., Department of Law and Digital Society, UnitelmaSapienza, Piazza Sassari, Rome, 00185, Italy; Marrella A., Department of Computer, Control and Management Engineering, Sapienza University of Rome, Via Ariosto 25, Rome, 00185, Italy","Traditionally, process-aware Decision Support Systems (DSSs) have been enhanced with AI functionalities to facilitate quick and informed decision-making. In this context, AI-Augmented Business Process Management Systems have emerged as innovative human-centric information systems, blending flexibility, autonomy, and conversational capability. Large Language Models (LLMs) have significantly boosted such systems, showcasing remarkable natural language processing capabilities across various tasks. Despite the potential of LLMs to support human decisions in business contexts, empirical validations of their effectiveness for process-aware decision support are scarce in the literature. In this paper, we propose the Business Process Large Language Model (BPLLM) framework, a novel approach for enacting actionable conversations with human workers. BPLLM couples Retrieval-Augmented Generation with fine-tuning, to enrich process-specific knowledge. Additionally, a process-aware chunking approach is incorporated to enhance the BPLLM pipeline. We evaluated the approach in various experimental scenarios to assess its ability to generate accurate and contextually relevant answers to users’ questions. The empirical study shows the promising performance of the framework in identifying the presence of particular activities and sequence flows within the considered process model, offering insights into its potential for enhancing process-aware DSSs. © The Author(s) 2024.","Business process; Decision support systems; LLM; RAG","Decision making; Enterprise resource management; Information management; Man machine systems; Modeling languages; Natural language processing systems; Business Process; Business process management systems; Decision supports; Decisions makings; Informed decision; Language model; Large language model; Modelling framework; RAG; Support systems; Decision support systems","","Springer","English","Article","Article in press","All Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85205550548"
"Xu S.; Pang L.; Shen H.; Cheng X.; Chua T.-S.","Xu, Shicheng (57604195300); Pang, Liang (55967159200); Shen, Huawei (21740199800); Cheng, Xueqi (55855927900); Chua, Tat-Seng (58847166100)","57604195300; 55967159200; 21740199800; 55855927900; 58847166100","Search-in-the-Chain: Interactively Enhancing Large Language Models with Search for Knowledge-intensive Tasks","2024","WWW 2024 - Proceedings of the ACM Web Conference","","","","1362","1373","11","0","10.1145/3589334.3645363","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194069617&doi=10.1145%2f3589334.3645363&partnerID=40&md5=48abc699f6c20ebddd522b66a9a3f1ed","CAS Key Laboratory of AI Security, Institute of Computing Technology, Chinese Academy of Sciences, University of Chinese Academy of Sciences, Beijing, China; CAS Key Laboratory of AI Security, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China; Sea-NExT Joint Lab, National University of Singapore, Singapore, Singapore","Xu S., CAS Key Laboratory of AI Security, Institute of Computing Technology, Chinese Academy of Sciences, University of Chinese Academy of Sciences, Beijing, China; Pang L., CAS Key Laboratory of AI Security, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China; Shen H., CAS Key Laboratory of AI Security, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China; Cheng X., CAS Key Laboratory of AI Security, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China; Chua T.-S., Sea-NExT Joint Lab, National University of Singapore, Singapore, Singapore","Making the contents generated by Large Language Model (LLM), accurate, credible and traceable is crucial, especially in complex knowledge-intensive tasks that require multi-step reasoning and each step needs knowledge to solve. Retrieval-augmented generation is good potential to solve this problem. However, where and how to introduce Information Retrieval (IR) to LLM is a big challenge. Previous work has the problems that wrong knowledge retrieved by IR misleads the LLM and interaction between IR and LLM breaks the reasoning chain of LLM. This paper proposes a novel framework named Search-in-the-Chain (SearChain) for the interaction between LLM and IR to solve the challenges. First, LLM generates the reasoning chain named Chain-of-Query (CoQ) where each node consists of an IR-oriented query-answer pair. Second, IR verifies the answer of each node of CoQ. It corrects the answer that is not consistent with the retrieved information when IR gives high confidence, which improves the credibility. Third, LLM can indicate its missing knowledge in CoQ and rely on IR to provide this knowledge to LLM. These operations improve the accuracy in terms of reasoning and knowledge. Finally, SearChain generates the reasoning process and marks references to supporting documents for each reasoning step, which improves traceability. Interaction with IR in SearChain forms a novel reasoning path based on a tree, which enables LLM to dynamically modify the direction of reasoning. Experiments show that SearChain outperforms state-of-the-art baselines on complex knowledge-intensive tasks including multi-hop Q&A, slot filling, fact checking, and long-form Q&A. © 2024 Owner/Author.","large language models; retrieval-augmented model","Computational linguistics; High confidence; Knowledge intensive tasks; Language informations; Language model; Languages interactions; Large language model; Multisteps; Path-based; Reasoning process; Retrieval-augmented model; Query processing","","Association for Computing Machinery, Inc","English","Conference paper","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85194069617"
"Tihanyi N.; Ferrag M.A.; Jain R.; Bisztray T.; Debbah M.","Tihanyi, Norbert (55791555600); Ferrag, Mohamed Amine (56115001200); Jain, Ridhi (57198836900); Bisztray, Tamas (57202022540); Debbah, Merouane (35588784300)","55791555600; 56115001200; 57198836900; 57202022540; 35588784300","CyberMetric: A Benchmark Dataset based on Retrieval-Augmented Generation for Evaluating LLMs in Cybersecurity Knowledge","2024","Proceedings of the 2024 IEEE International Conference on Cyber Security and Resilience, CSR 2024","","","","296","302","6","0","10.1109/CSR61664.2024.10679494","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206143524&doi=10.1109%2fCSR61664.2024.10679494&partnerID=40&md5=0eb04bca2cac3d3e56024424a13cbf9e","Technology Innovation Institute (TII), Abu Dhabi, United Arab Emirates; University of Oslo, Oslo, Norway; Khalifa University, Abu Dhabi, United Arab Emirates","Tihanyi N., Technology Innovation Institute (TII), Abu Dhabi, United Arab Emirates; Ferrag M.A., Technology Innovation Institute (TII), Abu Dhabi, United Arab Emirates; Jain R., Technology Innovation Institute (TII), Abu Dhabi, United Arab Emirates; Bisztray T., University of Oslo, Oslo, Norway; Debbah M., Khalifa University, Abu Dhabi, United Arab Emirates","Large Language Models (LLMs) are increasingly used across various domains, from software development to cyber threat intelligence. Understanding all the different cybersecurity fields, including topics such as cryptography, reverse engineering, and risk assessment, poses a challenge even for human experts. The research community needs a diverse, accurate, and up-to-date dataset to test the general knowledge of LLMs in cybersecurity. To address this gap, we present CyberMetric-80, CyberMetric-500, CyberMetric-2000, and CyberMetric-10000, which are multiple-choice Q&A benchmark datasets comprising 80, 500, 2000, and 10,000 questions, respectively. By utilizing GPT-3.5 and Retrieval-Augmented Generation (RAG), we collected documents, including NIST standards, research papers, publicly accessible books, RFCs, and other publications in the cybersecurity domain, to generate questions, each with four possible answers. The results underwent several rounds of error checking and refinement. Human experts invested over 200 hours validating the questions and solutions to ensure their accuracy and relevance and to filter out any questions unrelated to cybersecurity. We have evaluated and compared 25 state-of-the-art LLM models on the CyberMetric datasets. In addition to our primary goal of evaluating LLMs, we involved 30 human participants to solve CyberMetric-80 in a closed-book scenario. The results can serve as a reference for comparing the general cybersecurity knowledge of humans and LLMs. The findings revealed that GPT-4o, GPT-4-turbo, Mixtral-8x7B-Instruct, Falcon-180B-Chat, and GEMINI-pro 1.0 were the best-performing LLMs. Additionally, the top LLMs were more accurate than humans on CyberMetric-80, although highly experienced human experts still outperformed small models such as Llama-3-8B, Phi-2 or Gemma-7b. The CyberMetric dataset is publicly available for the research community and can be downloaded from the projects' website: https://github.com/CyberMetric. © 2024 IEEE.","","Software design; Benchmark datasets; Cyber security; Cyber threats; Cybermetrics; Engineering assessments; General knowledge; Human expert; Language model; Research communities; Risks assessments; Reverse engineering","","Institute of Electrical and Electronics Engineers Inc.","English","Conference paper","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85206143524"
"Gregory J.; Liao Q.","Gregory, Jonathan (58558718300); Liao, Qi (36908488500)","58558718300; 36908488500","Autonomous Cyberattack with Security-Augmented Generative Artificial Intelligence","2024","Proceedings of the 2024 IEEE International Conference on Cyber Security and Resilience, CSR 2024","","","","270","275","5","0","10.1109/CSR61664.2024.10679470","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206191528&doi=10.1109%2fCSR61664.2024.10679470&partnerID=40&md5=966036e97e1a0a77ca8ec346947a6055","Central Michigan University, Department of Computer Science, Mount Pleasant, United States","Gregory J., Central Michigan University, Department of Computer Science, Mount Pleasant, United States; Liao Q., Central Michigan University, Department of Computer Science, Mount Pleasant, United States","Ethical hacking and penetration testing is a vital task by cybersecurity professionals to find and exploit possible vulnerabilities in a system before malicious actors do. However, system hacking has a high barrier to entry that necessitates years of experiential learning and formal education. The rapid development of generative artificial intelligence (AI) may potentially lower the barrier to entry. This research experiments with automatic penetration testing via large language models (LLMs) augmented with security information. This research uses a locally hosted Mistral 7B model with Low-Rank Adaptation (LoRA) fine-tuning and Retrieval-Augmented Generation (RAG) to improve penetration testing. When the LLMs are fine tuned with limited and unstructured security data such as privilege escalation articles from a few public web sites, the system succeeds in achieving privilege escalation on Linux hosts. The results of this research suggest that no-cost LLM-assisted penetration testing is possible even on ordinary PCs using locally hosted models. Future research is needed to achieve more diversified attacks and discover zero-day vulnerabilities, perhaps with better prompt engineering, models, and security data. © 2024 IEEE.","Attacks and Defense; Cybersecurity; Generative Artificial Intelligence; Hacking; Large Language Models; Low-Rank Adaptation; Machine Learning; Penetration Testing; Retrieval-Augmented Generation; Vulnerability","Adversarial machine learning; Generative adversarial networks; Model checking; Zero-day attack; Attack and defense; Cyber security; Generative artificial intelligence; Hacking; Language model; Large language model; Low-rank adaptation; Machine-learning; Penetration testing; Retrieval-augmented generation; Vulnerability; Cyber attacks","","Institute of Electrical and Electronics Engineers Inc.","English","Conference paper","Final","","Scopus","2-s2.0-85206191528"
"Völker T.; Pfister J.; Koopmann T.; Hotho A.","Völker, Tom (58848717600); Pfister, Jan (57526757100); Koopmann, Tobias (57211293592); Hotho, Andreas (8227931000)","58848717600; 57526757100; 57211293592; 8227931000","From Chat to Publication Management: Organizing your related work using BibSonomy & LLMs","2024","CHIIR 2024 - Proceedings of the 2024 Conference on Human Information Interaction and Retrieval","","","","386","390","4","0","10.1145/3627508.3638298","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188661197&doi=10.1145%2f3627508.3638298&partnerID=40&md5=f5007610f89acd4ce23179f85e09b75d","Center for Artificial Intelligence and Data Science (CAIDAS), Institute for Computer Science, University of Würzburg, Würzburg, Germany","Völker T., Center for Artificial Intelligence and Data Science (CAIDAS), Institute for Computer Science, University of Würzburg, Würzburg, Germany; Pfister J., Center for Artificial Intelligence and Data Science (CAIDAS), Institute for Computer Science, University of Würzburg, Würzburg, Germany; Koopmann T., Center for Artificial Intelligence and Data Science (CAIDAS), Institute for Computer Science, University of Würzburg, Würzburg, Germany; Hotho A., Center for Artificial Intelligence and Data Science (CAIDAS), Institute for Computer Science, University of Würzburg, Würzburg, Germany","The ever-growing corpus of scientific literature presents significant challenges for researchers with respect to discovery, management, and annotation of relevant publications. Traditional platforms like Semantic Scholar, BibSonomy, and Zotero offer tools for literature management, but largely require manual laborious and error-prone input of tags and metadata. Here, we introduce a novel retrieval augmented generation system that leverages chat-based large language models (LLMs) to streamline and enhance the process of publication management. It provides a unified chat-based interface, enabling intuitive interactions with various backends, including Semantic Scholar, BibSonomy, and the Zotero Webscraper. It supports two main use-cases: (1) Explorative Search & Retrieval - leveraging LLMs to search for and retrieve both specific and general scientific publications, while addressing the challenges of content hallucination and data obsolescence; and (2) Cataloguing & Management - aiding in the organization of personal publication libraries, in this case BibSonomy, by automating the addition of metadata and tags, while facilitating manual edits and updates. We compare our system to different LLM models in three different settings, including a user study, and we can show its advantages in different metrics. © 2024 Owner/Author.","Academic Search; ChatGPT; Publication Management; RAG","Metadata; Obsolescence; Publishing; Academic search; ChatGPT; Error prones; Generation systems; Intuitive interaction; Language model; Publication management; RAG; Related works; Scientific literature; Semantics","","Association for Computing Machinery, Inc","English","Conference paper","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85188661197"
"Muhlburger H.; Wotawa F.","Muhlburger, Herbert (52564145300); Wotawa, Franz (6603677377)","52564145300; 6603677377","FaultLines - Evaluating the Efficacy of Open-Source Large Language Models for Fault Detection in Cyber-Physical Systems","2024","Proceedings - 6th IEEE International Conference on Artificial Intelligence Testing, AITest 2024","","","","47","54","7","0","10.1109/AITest62860.2024.00014","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206479922&doi=10.1109%2fAITest62860.2024.00014&partnerID=40&md5=f3e111701856da0771779b2024d3b894","Institute of Software Technology, Graz University of Technology, Christian-Doppler Laboratory Qamcas, Graz, Austria","Muhlburger H., Institute of Software Technology, Graz University of Technology, Christian-Doppler Laboratory Qamcas, Graz, Austria; Wotawa F., Institute of Software Technology, Graz University of Technology, Christian-Doppler Laboratory Qamcas, Graz, Austria","Cyber-physical systems are integral to the infrastructure of global communication and transportation networks, which makes it crucial to detect faults, prevent cyber attacks, and ensure operational safety. Although machine learning techniques, including large language models (LLMs), have been explored for fault detection, the efficacy of open-source LLMs remains underexplored. In this work, we assess the capabilities of eight open-source LLMs in identifying faults in cyber-physical systems using a simulation dataset from monitoring an electrified vehicle's battery management system. By applying pretrained LLMs without fine-tuning and incorporating retrieval augmented generation (RAG) techniques alongside textual encoding methods, our study aims to explore the potential of open LLMs in fault detection. Our results show that open LLMs can effectively identify faults, with Mistral out-performing alternative models such as Mixtral, codellama, and Gemma in precision, recall, and Fl-score metrics. Furthermore, our results highlight the importance of textual encoding strategies in enhancing the fault detection capabilities of LLMs, which possess a degree of explanatory power with respect to the detected anomalies. This work demonstrates the feasibility of using open LLMs for fault detection in cyber-physical systems and opens avenues for future research to enhance fault detection and fault localization. © 2024 IEEE.","Anomaly detection; Cyber-physical systems fault detection; Open-source large language models (LLMs); Retrieval Augmented Generation (RAG) techniques; Textual encoding strategies for LLMs","Anomaly detection; Cyber attacks; Machine learning; Problem oriented languages; Anomaly detection; Cybe-physical system fault detection; Cybe-physical systems; Cyber-physical systems; Encoding strategy; Generation techniques; Language model; Open-source; Open-source large language model; Retrieval augmented generation  technique; System fault detection; Textual encoding strategy for large language model; Encoding (symbols)","","Institute of Electrical and Electronics Engineers Inc.","English","Conference paper","Final","","Scopus","2-s2.0-85206479922"
"Liu Z.; Zhou Y.; Zhu Y.; Lian J.; Li C.; Dou Z.; Lian D.; Nie J.-Y.","Liu, Zheng (57211759701); Zhou, Yujia (57214938039); Zhu, Yutao (57203388961); Lian, Jianxun (57149933900); Li, Chaozhuo (57196073466); Dou, Zhicheng (24722777200); Lian, Defu (54403324000); Nie, Jian-Yun (59142334600)","57211759701; 57214938039; 57203388961; 57149933900; 57196073466; 24722777200; 54403324000; 59142334600","Information Retrieval Meets Large Language Models","2024","WWW 2024 Companion - Companion Proceedings of the ACM Web Conference","","","","1586","1589","3","3","10.1145/3589335.3641299","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194490494&doi=10.1145%2f3589335.3641299&partnerID=40&md5=6e725f197989bb885e12c0493ed77a3f","BAAI, Beijing, China; Renmin University of China, Beijing, China; Microsoft Research Asia, Beijing, China; University of Science and Technology of China, Hefei, China; University of Montreal, Montreal, Canada","Liu Z., BAAI, Beijing, China; Zhou Y., Renmin University of China, Beijing, China; Zhu Y., Renmin University of China, Beijing, China; Lian J., Microsoft Research Asia, Beijing, China; Li C., Microsoft Research Asia, Beijing, China; Dou Z., Renmin University of China, Beijing, China; Lian D., University of Science and Technology of China, Hefei, China; Nie J.-Y., University of Montreal, Montreal, Canada","The advent of large language models (LLMs) presents both opportunities and challenges for the information retrieval (IR) community. On one hand, LLMs will revolutionize how people access information, meanwhile the retrieval techniques can play a crucial role in addressing many inherent limitations of LLMs. On the other hand, there are open problems regarding the collaboration of retrieval and generation, the potential risks of misinformation, and the concerns about cost-effectiveness. To seize the critical moment for development, it calls for the joint effort from academia and industry on many key issues, including identification of new research problems, proposal of new techniques, and creation of new evaluation protocols. It has been one year since the launch of ChatGPT in November last year, and the entire community is currently undergoing a profound transformation in techniques. Therefore, this workshop will be a timely venue to exchange ideas and forge collaborations. The organizers, committee members, and invited speakers are composed of a diverse group of researchers coming from leading institutions in the world. This event will be made up of multiple sessions, including invited talks, paper presentations, hands-on tutorials, and panel discussions. All the materials collected for this workshop will be archived and shared publicly, which will present a long-term value to the community. © 2024 Copyright held by the owner/author(s).","Information Retrieval; Large Language Models; Question Answering; Ranking; Retrieval-Augmented Generation; Search","Computational linguistics; Cost effectiveness; Critical moment; Inherent limitations; Language model; Large language model; Potential risks; Question Answering; Ranking; Retrieval techniques; Retrieval-augmented generation; Search; Information retrieval","","Association for Computing Machinery, Inc","English","Conference paper","Final","All Open Access; Bronze Open Access","Scopus","2-s2.0-85194490494"
"Chen Z.; Zou D.; Xie H.; Lou H.; Pang Z.","Chen, Zheng (58965943200); Zou, Di (56319369100); Xie, Haoran (57219619828); Lou, Huajie (59363979200); Pang, Zhiyuan (59364533900)","58965943200; 56319369100; 57219619828; 59363979200; 59364533900","Facilitating university admission using a chatbot based on large language models with retrieval-augmented generation","2024","Educational Technology and Society","27","4","","454","470","16","0","10.30191/ETS.202410_27(4).TP02","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206145029&doi=10.30191%2fETS.202410_27%284%29.TP02&partnerID=40&md5=fbb2dd2ceda2281842b56d194c9510ab","Department of Statistics and Actuarial Science, The University of Hong Kong, Hong Kong; Department of English and Communication, The Hong Kong Polytechnic University, Hong Kong; School of Data Science, Lingnan University, Hong Kong","Chen Z., Department of Statistics and Actuarial Science, The University of Hong Kong, Hong Kong; Zou D., Department of English and Communication, The Hong Kong Polytechnic University, Hong Kong; Xie H., School of Data Science, Lingnan University, Hong Kong; Lou H., Department of Statistics and Actuarial Science, The University of Hong Kong, Hong Kong; Pang Z., Department of Statistics and Actuarial Science, The University of Hong Kong, Hong Kong","University admission consultation is a professional service that assists students with the university application process. Typically, accessing this service entails exploring university websites, directly contacting faculty members and officers via phone calls or emails, and engaging educational intermediaries. University admission consultation is crucial for both students and institutions. However, conventional consultation methods face challenges such as time and spatial constraints, leading to a growing interest in utilizing chatbots for university admission consultation. In this study, we propose a novel approach that leverages generative pretrained transformer (ChatGPT 3.5) models and implements the retrieval-augmented generation technique using the LlamaIndex framework. To evaluate the effectiveness of this approach, we applied it to undergraduate admission data from three universities: a science and technology university in the United States, a comprehensive university in Kenya, and a comprehensive university in Hong Kong. We also gathered feedback from 53 high school students who tested the chatbot. The results demonstrated a significant improvement in average accuracy, from 41.4% with the ChatGPT 3.5 model to 89.5% with the proposed chatbot, with peak accuracy reaching 94.7%. User reviews also indicated a generally positive perception of the admission chatbot. This methodology has the potential to revolutionize university admissions by utilizing chatbots based on large language models with retrieval-augmented generation. © (2023), (International Forum of Educational Technology and Society). All Rights Reserved.","Chatbot; GPT; Large language models; Retrieval-augmented generation; University admissions","","","International Forum of Educational Technology and Society,National Taiwan Normal University","English","Article","Final","","Scopus","2-s2.0-85206145029"
"Nikolakopoulos A.; Evangelatos S.; Veroni E.; Chasapas K.; Gousetis N.; Apostolaras A.; Nikolopoulos C.D.; Korakis T.","Nikolakopoulos, Anastasios (59338008100); Evangelatos, Spyridon (53984089800); Veroni, Eleni (57209009755); Chasapas, Konstantinos (59337247400); Gousetis, Nikolaos (58886326300); Apostolaras, Apostolos (26657829600); Nikolopoulos, Christos D. (36246465200); Korakis, Thanasis (16030975700)","59338008100; 53984089800; 57209009755; 59337247400; 58886326300; 26657829600; 36246465200; 16030975700","Large Language Models in Modern Forensic Investigations: Harnessing the Power of Generative Artificial Intelligence in Crime Resolution and Suspect Identification","2024","EEITE 2024 - Proceedings of 2024 5th International Conference in Electronic Engineering, Information Technology and Education","","","","","","","0","10.1109/EEITE61750.2024.10654427","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204632333&doi=10.1109%2fEEITE61750.2024.10654427&partnerID=40&md5=d1818167aa318aa9a1d3b8d3dc3e0715","Netcompany-Intrasoft S.A., Research & Innovation Development Department, Luxembourg; Hellenic Mediterranean University, Department of Electronics Engineering, Crete, Greece; University of Thessaly, Department of Electrical and Computer Engineering, Volos, Greece; Centre for Research & Technology, Hellas, Volos, Greece","Nikolakopoulos A., Netcompany-Intrasoft S.A., Research & Innovation Development Department, Luxembourg; Evangelatos S., Netcompany-Intrasoft S.A., Research & Innovation Development Department, Luxembourg, Hellenic Mediterranean University, Department of Electronics Engineering, Crete, Greece; Veroni E., Netcompany-Intrasoft S.A., Research & Innovation Development Department, Luxembourg, Hellenic Mediterranean University, Department of Electronics Engineering, Crete, Greece; Chasapas K., Netcompany-Intrasoft S.A., Research & Innovation Development Department, Luxembourg; Gousetis N., Netcompany-Intrasoft S.A., Research & Innovation Development Department, Luxembourg; Apostolaras A., University of Thessaly, Department of Electrical and Computer Engineering, Volos, Greece, Centre for Research & Technology, Hellas, Volos, Greece; Nikolopoulos C.D., Hellenic Mediterranean University, Department of Electronics Engineering, Crete, Greece; Korakis T., University of Thessaly, Department of Electrical and Computer Engineering, Volos, Greece, Centre for Research & Technology, Hellas, Volos, Greece","Large Language Models (LLMs) have recently captured the attention of the scientific c ommunity. S ince t he global launch of LLM-based chatbots in late 2022, the field h as witnessed a rapid increase in interest from researchers, technology providers and citizens alike. With its wide-ranging applicability, Generative Artificial I ntelligence (GenAI) h as t he p otential to impact various aspects of society, from improving communication and accessibility to transforming industries such as healthcare, education and security. More specifically, in the field of Forensic Science, LLMs could offer significant b enefits as sisting Law Enforcement Agencies (LEAs) and Forensic Practitioners in crime investigations. This paper proposes the implementation of a Retrieval Augmented Generation (RAG) LLM, trained with criminology data, to provide swift and actionable insights into specific incidents, thereby enhancing Forensic Data Analysis and facilitating the daily operations of LEAs. © 2024 IEEE.","Biometric Data; Forensic Data Analysis; Forensics; Generative Artificial Intelligence; Large Language Models; Law Enforcement Agencies; Security","Crime; Forensic engineering; Biometric data; Forensic; Forensic data; Forensic investigation; Generative artificial intelligence; Language model; Large language model; Law-enforcement agencies; Power; Security; Forensic science","","Institute of Electrical and Electronics Engineers Inc.","English","Conference paper","Final","","Scopus","2-s2.0-85204632333"
"Li G.; Zhou X.; Zhao X.","Li, Guoliang (55800543300); Zhou, Xuanhe (57211583553); Zhao, Xinyang (57353885000)","55800543300; 57211583553; 57353885000","LLM for Data Management","2024","Proceedings of the VLDB Endowment","17","12","","4213","4216","3","0","10.14778/3685800.3685838","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205305545&doi=10.14778%2f3685800.3685838&partnerID=40&md5=2dfd4af59144feb38b54a2a15724356c","Tsinghua University, China","Li G., Tsinghua University, China; Zhou X., Tsinghua University, China; Zhao X., Tsinghua University, China","Machine learning techniques have been verified to be effective in optimizing data management systems and are widely researched in recent years. However, traditional small-sized ML models often struggle to generalize to new scenarios, and have limited context understanding ability (e.g., inputting discrete features only). The emergence of LLMs offers a promising solution to these challenges. LLMs have been trained over a vast number of scenarios and tasks and acquire human-competitive capabilities like context understanding and summarization, which can be highly beneficial for data management tasks (e.g., natural language based data analytics). In this tutorial, we present how to utilize LLMs to optimize data management systems and review new techniques for addressing these technical challenges, including hallucination of LLMs, high cost of interacting with LLMs, and low accuracy for processing complicated tasks. First, we discuss retrieval augmented generation (RAG) techniques to address the hallucination problem. Second, we present vector database techniques to improve the latency. Third, we present LLM agent techniques for processing complicated tasks by generating multi-round pipelines. We also showcase some realworld data management scenarios that can be well optimized by LLMs, including query rewrite, database diagnosis and data analytics. Finally, we summarize some open research challenges. © 2024, VLDB Endowment. All rights reserved.","","Data accuracy; Data reduction; Information management; Management information systems; Natural language processing systems; Query languages; Competitive capabilities; Data analytics; Data management system; High costs; Machine learning techniques; Management IS; Management review; Management tasks; Natural languages; Technical challenges; Data Analytics","Fan J.; Cao Y.; Ding X.","VLDB Endowment","English","Conference paper","Final","","Scopus","2-s2.0-85205305545"
"Addad B.; Kapusta K.","Addad, Boussad (25627232500); Kapusta, Katarzyna (57112239100)","25627232500; 57112239100","Homeopathic Poisoning of RAG Systems","2024","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","14989 LNCS","","","358","364","6","0","10.1007/978-3-031-68738-9_28","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204519991&doi=10.1007%2f978-3-031-68738-9_28&partnerID=40&md5=c90f831ecfef90802f2b6c5543c2a51f","CortAIx Lab, Thales Group, Saclay, France","Addad B., CortAIx Lab, Thales Group, Saclay, France; Kapusta K., CortAIx Lab, Thales Group, Saclay, France","Despite their remarkable success and wide use in many applications, large language models (LLMs) are not free from intrinsic vulnerabilities (e.g. prompt injection). They may also suffer from hallucinations and drop in performance due to lack of up-to-date knowledge. Retrieval-Augmented Generation (RAG) is currently one of the most promising techniques to mitigate such issues. In short, a RAG augments each prompt using a relevant context from an external knowledge database. Usually, the context is composed of texts that are the most similar to the request. While reducing hallucinations, RAG augments at the same time the attack surface of the whole system. Indeed, an attacker may poison the knowledge database by injecting bad or misleading information. In this paper, we introduce HOPRAG, a subtle, but very efficient, poisoning technique that consists in adding a suffix (or prefix) of only few tokens (sub-words) to any given text to raise (or decrease) its similarity with a prompt and therefore be used (or avoid being used) as context by RAG to answer. Our results show that with only three injected tokens, we manage to perform a successful attack. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.","LLM; Poisoning; RAG","External knowledge; Generation systems; Knowledge database; Language model; Large language model; Misleading informations; Performance; Poisoning; Retrieval-augmented generation; Sub words; Context free languages","Ceccarelli A.; Bondavalli A.; Trapp M.; Schoitsch E.; Gallina B.; Bitsch F.","Springer Science and Business Media Deutschland GmbH","English","Conference paper","Final","","Scopus","2-s2.0-85204519991"
"Zhang Y.; Li D.; Peng G.; Guo S.; Dou Y.; Yi R.","Zhang, Yanjun (59340844600); Li, Dapeng (57202678640); Peng, Gaojun (59340633300); Guo, Shuang (59341155900); Dou, Yu (59340949900); Yi, Ruheng (59340433300)","59340844600; 57202678640; 59340633300; 59341155900; 59340949900; 59340433300","A Dynamic Retrieval-Augmented Generation Framework for Border Inspection Legal Question Answering","2024","Proceedings of 2024 International Conference on Asian Language Processing, IALP 2024","","","","372","376","4","0","10.1109/IALP63756.2024.10661194","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204788703&doi=10.1109%2fIALP63756.2024.10661194&partnerID=40&md5=b3deb4a3ee2572e42e6f1df1c1ef6bbc","Inner Mongolia University of Technology, College of Data Science and Application, China; Hohhot Entry-Exit Frontier Inspection Station, National Immigration Administration, Hohhot, China","Zhang Y., Inner Mongolia University of Technology, College of Data Science and Application, China; Li D., Inner Mongolia University of Technology, College of Data Science and Application, China; Peng G., Inner Mongolia University of Technology, College of Data Science and Application, China; Guo S., Inner Mongolia University of Technology, College of Data Science and Application, China; Dou Y., Hohhot Entry-Exit Frontier Inspection Station, National Immigration Administration, Hohhot, China; Yi R., Hohhot Entry-Exit Frontier Inspection Station, National Immigration Administration, Hohhot, China","Border inspection legal question answering (LQA) is designed for specific legal scenarios, aiming to address legal questions related to border inspections and provide accurate and practical legal guidance to the public and border inspection departments. Current research requires a retrieval process regardless of whether the necessary knowledge already exists, and does not evaluate the legal information in the generated responses, leading to errors and low-quality content. we propose the Dynamic Retrieval-Augmented Generation framework for Border Inspection LQA (DRAG-BILQA), which generates responses first and then dynamically controls retrieval based on confidence scores. In this framework, we innovatively introduce a legal factor recognition module to ensure the legal accuracy of generated answers and improve the quality of the generation. We also present the BorderLegal-QA dataset, filling the gap in border inspection legal datasets. We conducted extensive experiments on both the BorderLegal-QA and the general LQA dataset JEC-QA. Experimental results show that DRAG-BILQA outperforms Sota models in terms of legal factor recognition accuracy and retrieval performance, achieving a METEOR score of 39.5 and improving generation quality. Case analysis also demonstrate that DRAG-BILQA effectively Augmented the legal accuracy of the generated content. © 2024 IEEE.","border inspection LQA; large language model; retrieval-augmented generation","Modeling languages; 'current; Border inspection legal question answering; Dynamic retrieval; Language model; Large language model; Legal factors; Legal questions; Question Answering; Retrieval process; Retrieval-augmented generation; Question answering","Liu R.; Wang L.; Bao F.; Lu Y.; Fan C.; Dong M.","Institute of Electrical and Electronics Engineers Inc.","English","Conference paper","Final","","Scopus","2-s2.0-85204788703"
"","","","2024 International Joint Conference on Neural Networks, IJCNN 2024 - Proceedings","2024","Proceedings of the International Joint Conference on Neural Networks","","","","","","13361","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205007948&partnerID=40&md5=efa6779dadd095623a8a674780426f72","","","The proceedings contain 1644 papers. The topics discussed include: exploring the impact of zero-cost proxies for hybrid vision transformers; QFALT: quantization and fault aware loss for training enables performance recovery with unreliable weights; CDM: text-driven image editing with composable diffusion models; AV-GAN: attention-based varifocal generative adversarial network for uneven medical image translation; continual learning for robust gate detection under dynamic lighting in autonomous drone racing; anomaly detection on attributed network based on hyperbolic radial distance; manufacturing domain QA with integrated term enhanced RAG; explaining supervisor set for machine learning methods; can shape-infused joint embeddings improve image-conditioned 3D diffusion?; seamless robot teleoperation: intuitive control through hand gestures and neural network decoding; and tinyDigiClones: a multi-modal LLM-based framework for edge-optimized personalized avatars.","","","","Institute of Electrical and Electronics Engineers Inc.","English","Conference review","Final","","Scopus","2-s2.0-85205007948"
"Galla D.; Hoda S.; Zhang M.; Quan W.; Yang T.D.; Voyles J.","Galla, Divyanshi (57203099558); Hoda, Shaz (57221835496); Zhang, Meiwei (59352237000); Quan, Wenzhe (59352006800); Yang, Tommy Dong (59352237100); Voyles, Joseph (57201737745)","57203099558; 57221835496; 59352237000; 59352006800; 59352237100; 57201737745","CoURAGE: A Framework to Evaluate RAG Systems","2024","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","14763 LNCS","","","392","407","15","0","10.1007/978-3-031-70242-6_37","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205486674&doi=10.1007%2f978-3-031-70242-6_37&partnerID=40&md5=3273c367d2770f576367598754220917","Innovation Hub, PricewaterhouseCoopers Service Delivery Centre, Bengaluru, India; Innovation Hub, PricewaterhouseCoopers, Baltimore, United States; Innovation Hub, PricewaterhouseCoopers Shanghai Acceleration Center, Shanghai, China","Galla D., Innovation Hub, PricewaterhouseCoopers Service Delivery Centre, Bengaluru, India; Hoda S., Innovation Hub, PricewaterhouseCoopers, Baltimore, United States; Zhang M., Innovation Hub, PricewaterhouseCoopers Shanghai Acceleration Center, Shanghai, China; Quan W., Innovation Hub, PricewaterhouseCoopers Shanghai Acceleration Center, Shanghai, China; Yang T.D., Innovation Hub, PricewaterhouseCoopers Shanghai Acceleration Center, Shanghai, China; Voyles J., Innovation Hub, PricewaterhouseCoopers, Baltimore, United States","In the rapidly evolving domain of Generative AI(GenAI), evaluating models’ effectiveness for a business use case remains a significant challenge, particularly due to the diverse array of available metrics, the absence of a standardized framework for their application and varied challenges in use cases. This paper proposes a structured framework de signed to assist practitioners, including new adopters, in selecting appropriate metrics for the evaluation of GenAI models, specifically within question answering (QA) systems. The framework focuses on considerations such as data availability, the nature of the dataset, and the necessity for Large Language Models (LLMs) calls for evaluation. By categorizing metrics into quantitative and qualitative types, and distinguishing between scenarios that require golden labels, this framework seeks to streamline the evaluation process. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.","Evaluation; Framework; Golden Label; LLM; Metrics; RAG; retrieval augmented generation; Validation","Structured Query Language; Evaluating models; Evaluation; Framework; Golden label; Language model; Large language model; Metric; RAG; Retrieval augmented generation; Validation; Question answering","Rapp A.; Di Caro L.; Meziane F.; Sugumaran V.","Springer Science and Business Media Deutschland GmbH","English","Conference paper","Final","","Scopus","2-s2.0-85205486674"
"Jairath N.; Manduca S.; Que S.K.T.","Jairath, Neil (57216040273); Manduca, Sophia (58562795600); Que, Syril Keena T. (34977464400)","57216040273; 58562795600; 34977464400","ReconGPT: A novel artificial intelligence tool and its potential use in post-Mohs reconstructive decision-making","2024","Journal of the American Academy of Dermatology","","","","","","","0","10.1016/j.jaad.2024.08.048","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204480354&doi=10.1016%2fj.jaad.2024.08.048&partnerID=40&md5=727ead55a32580d76e5e92e9aa051682","The Ronald O. Perelman Department of Dermatology, New York University Grossman School of Medicine, New York, New York, United States; Department of Dermatology, Indiana University School of Medicine, Carmel, Indiana, United States","Jairath N., The Ronald O. Perelman Department of Dermatology, New York University Grossman School of Medicine, New York, New York, United States; Manduca S., The Ronald O. Perelman Department of Dermatology, New York University Grossman School of Medicine, New York, New York, United States; Que S.K.T., Department of Dermatology, Indiana University School of Medicine, Carmel, Indiana, United States","[No abstract available]","artificial intelligence; large language models; Mohs surgery; reconstruction; retrieval augmented generation","","","Elsevier Inc.","English","Article","Article in press","","Scopus","2-s2.0-85204480354"
"Strich J.; Schneider F.; Nikishina I.; Biemann C.","Strich, Jan (59328717700); Schneider, Florian (57220897549); Nikishina, Irina (57203315660); Biemann, Chris (8538613800)","59328717700; 57220897549; 57203315660; 8538613800","On Improving Repository-Level Code QA for Large Language Models","2024","Proceedings of the Annual Meeting of the Association for Computational Linguistics","4","","","303","338","35","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204060724&partnerID=40&md5=7bff33303ab9ca48bb19e0bcfb49da6d","Language Technology Group Universität Hamburg, Germany","Strich J., Language Technology Group Universität Hamburg, Germany; Schneider F., Language Technology Group Universität Hamburg, Germany; Nikishina I., Language Technology Group Universität Hamburg, Germany; Biemann C., Language Technology Group Universität Hamburg, Germany","Large Language Models (LLMs) such as ChatGPT, GitHub Copilot, Llama, or Mistral assist programmers as copilots and knowledge sources to make the coding process faster and more efficient. This paper aims to improve the copilot performance by implementing different self-alignment processes and retrieval-augmented generation (RAG) pipelines, as well as their combination. To test the effectiveness of all approaches, we create a dataset and apply a model-based evaluation, using LLM as a judge. It is designed to check the model’s abilities to understand the source code semantics, the dependency between files, and the overall meta-information about the repository. We also compare our approach with other existing solutions, e.g. ChatGPT-3.5, and evaluate on the existing benchmarks. Code and dataset are available online1 ©2024 Association for Computational Linguistics.","","Benchmarking; Codes (symbols); Computational linguistics; Code semantics; Coding process; Knowledge sources; Language model; Meta information; Model-based evaluation; Performance; Self-alignment process; Source codes; Semantics","Fu X.; Fleisig E.","Association for Computational Linguistics (ACL)","English","Conference paper","Final","","Scopus","2-s2.0-85204060724"
"Barros R.N.; Arguello K.K.; Wehrmann J.","Barros, Ramiro N. (59344408700); Arguello, Kristen K. (59344260800); Wehrmann, Jônatas (57192664396)","59344408700; 59344260800; 57192664396","Anchor Your Embeddings Through the Storm: Mitigating Instance-to-Document Semantic Gap","2024","Proceedings of the International Joint Conference on Neural Networks","","","","","","","0","10.1109/IJCNN60899.2024.10650518","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205013300&doi=10.1109%2fIJCNN60899.2024.10650518&partnerID=40&md5=88da559647a91ae55b36765ab0b58459","Pontifícia Universidade Católica Do Rio Grande Do Sul, Porto Alegre, Brazil; Teia Labs, Porto Alegre, Brazil","Barros R.N., Pontifícia Universidade Católica Do Rio Grande Do Sul, Porto Alegre, Brazil, Teia Labs, Porto Alegre, Brazil; Arguello K.K., Pontifícia Universidade Católica Do Rio Grande Do Sul, Porto Alegre, Brazil, Teia Labs, Porto Alegre, Brazil; Wehrmann J., Teia Labs, Porto Alegre, Brazil","Large Language Models (LLMs) have revolutionized the field of natural language processing with their remarkable ability to generate coherent responses. Despite their impressive capabilities, LLMs grapple with the challenges of learning from private data while ensuring the relevance and timeliness of the information they provide. To overcome this challenge, retrieval-based strategies for generation have become essential, though they require clean data and a complex indexing pipeline. In this paper, we introduce Anchor Embeddings, a novel embedding enhancing technique designed to mitigate the instance-to-document semantic gap that often hinders the retrieval process. Our method proposes the usage of an anchor embedding to serve as a semantic beacon, adding more context to smaller text segments extracted from the same source. This extra embedding acts as a holistic representation regarding the original document that is merged into the instance embeddings. It can be derived based on a diversity of strategies that involve semantic representation and localization cues. Our empirical analysis on the MS MARCO dataset reveals that Anchor Embeddings can significantly outperform traditional retrieval methods, boasting up to an 14% performance improvement. The elegance of our approach lies in its simplicity and robustness, providing more specific context while maintaining the same time complexity for retrieval of the baseline approach. © 2024 IEEE.","anchor embeddings; large language models; RAG; retrieval","Content based retrieval; Embeddings; Indexing (of information); Metadata; Modeling languages; Natural language processing systems; Anchor embedding; Document semantics; Embeddings; Language model; Language processing; Large language model; Natural languages; RAG; Retrieval; Semantic gap; Semantics","","Institute of Electrical and Electronics Engineers Inc.","English","Conference paper","Final","","Scopus","2-s2.0-85205013300"
"Hwang T.; Jeong S.; Cho S.; Han S.; Park J.C.","Hwang, Taeho (59093859300); Jeong, Soyeong (56562251600); Cho, Sukmin (57552840900); Han, SeungYoon (59233391300); Park, Jong C. (18537473800)","59093859300; 56562251600; 57552840900; 59233391300; 18537473800","DSLR: Document Refinement with Sentence-Level Re-ranking and Reconstruction to Enhance Retrieval-Augmented Generation","2024","KnowledgeNLP 2024 - 3rd Workshop on Knowledge Augmented Methods for NLP, Proceedings of the Workshop","","","","73","92","19","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204869986&partnerID=40&md5=abe0b4591b224922b3b157584443372b","School of Computing, Korea Advanced Institute of Science and Technology, South Korea","Hwang T., School of Computing, Korea Advanced Institute of Science and Technology, South Korea; Jeong S., School of Computing, Korea Advanced Institute of Science and Technology, South Korea; Cho S., School of Computing, Korea Advanced Institute of Science and Technology, South Korea; Han S., School of Computing, Korea Advanced Institute of Science and Technology, South Korea; Park J.C., School of Computing, Korea Advanced Institute of Science and Technology, South Korea","Recent advancements in Large Language Models (LLMs) have significantly improved their performance across various Natural Language Processing (NLP) tasks. However, LLMs still struggle with generating non-factual responses due to limitations in their parametric memory. Retrieval-Augmented Generation (RAG) systems address this issue by incorporating external knowledge with a retrieval module. Despite their successes, however, current RAG systems face challenges with retrieval failures and the limited ability of LLMs to filter out irrelevant information. Therefore, in this work, we propose DSLR (Document Refinement with Sentence-Level Re-ranking and Reconstruction), an unsupervised framework that decomposes retrieved documents into sentences, filters out irrelevant sentences, and reconstructs them again into coherent passages. We experimentally validate DSLR on multiple open-domain QA datasets and the results demonstrate that DSLR significantly enhances the RAG performance over conventional fixed-size passage. Furthermore, our DSLR enhances performance in specific, yet realistic scenarios without the need for additional training, providing an effective and efficient solution for refining retrieved documents in RAG systems. © 2024 Association for Computational Linguistics.","","Natural language processing systems; 'current; External knowledge; Generation systems; Language model; Language processing; Natural languages; Performance; Re-ranking; Retrieved documents; Sentence level; Computational linguistics","Yu W.; Shi W.; Yasunaga M.; Jiang M.; Zhu C.; Hajishirzi H.; Zettlemoyer L.; Zhang Z.","Association for Computational Linguistics (ACL)","English","Conference paper","Final","","Scopus","2-s2.0-85204869986"
"Xu S.; Pang L.; Yu M.; Meng F.; Shen H.; Cheng X.; Zhou J.","Xu, Shicheng (57604195300); Pang, Liang (55967159200); Yu, Mo (35174012000); Meng, Fandong (55847567500); Shen, Huawei (21740199800); Cheng, Xueqi (55855927900); Zhou, Jie (57211746430)","57604195300; 55967159200; 35174012000; 55847567500; 21740199800; 55855927900; 57211746430","Unsupervised Information Refinement Training of Large Language Models for Retrieval-Augmented Generation","2024","Proceedings of the Annual Meeting of the Association for Computational Linguistics","1","","","133","145","12","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204439984&partnerID=40&md5=325406e55ec536d7d969508d01c49d4e","CAS Key Laboratory of AI Safety, Institute of Computing Technology, CAS, China; University of Chinese Academy of Sciences, China; Pattern Recognition Center, WeChat AI, China","Xu S., CAS Key Laboratory of AI Safety, Institute of Computing Technology, CAS, China, University of Chinese Academy of Sciences, China; Pang L., CAS Key Laboratory of AI Safety, Institute of Computing Technology, CAS, China; Yu M., Pattern Recognition Center, WeChat AI, China; Meng F., Pattern Recognition Center, WeChat AI, China; Shen H., CAS Key Laboratory of AI Safety, Institute of Computing Technology, CAS, China; Cheng X., CAS Key Laboratory of AI Safety, Institute of Computing Technology, CAS, China; Zhou J., Pattern Recognition Center, WeChat AI, China","Retrieval-augmented generation (RAG) enhances large language models (LLMs) by incorporating additional information from retrieval. However, studies have shown that LLMs still face challenges in effectively using the retrieved information, even ignoring it or being misled by it. The key reason is that the training of LLMs does not clearly make LLMs learn how to utilize input retrieved texts with varied quality. In this paper, we propose a novel perspective that considers the role of LLMs in RAG as “Information Refiner”, which means that regardless of correctness, completeness, or usefulness of retrieved texts, LLMs can consistently integrate knowledge within the retrieved texts and model parameters to generate the texts that are more concise, accurate, and complete than the retrieved texts. To this end, we propose an information refinement training method named INFO-RAG that optimizes LLMs for RAG in an unsupervised manner. INFO-RAG is low-cost and general across various tasks. Extensive experiments on zero-shot prediction of 11 datasets in diverse tasks including Question Answering, Slot-Filling, Language Modeling, Dialogue, and Code Generation show that INFO-RAG improves the performance of LLaMA2 by an average of 9.39% relative points. INFO-RAG also shows advantages in in-context learning and robustness of RAG. © 2024 Association for Computational Linguistics.","","Information retrieval; Modeling languages; Natural language processing systems; Codegeneration; Dialogue generations; Language model; Learn+; Low-costs; Model generation; Modeling parameters; Performance; Question Answering; Training methods; Computational linguistics","Ku L.-W.; Martins A.F.T.; Srikumar V.","Association for Computational Linguistics (ACL)","English","Conference paper","Final","","Scopus","2-s2.0-85204439984"
"Chirkova N.; Rau D.; Déjean H.; Formal T.; Clinchant S.; Nikoulina V.","Chirkova, Nadezhda (57215723560); Rau, David (57611395200); Déjean, Hervé (13007182400); Formal, Thibault (57216589351); Clinchant, Stéphane (14035112900); Nikoulina, Vassilina (55632038800)","57215723560; 57611395200; 13007182400; 57216589351; 14035112900; 55632038800","Retrieval-augmented generation in multilingual settings","2024","KnowLLM 2024 - 1st Workshop on Towards Knowledgeable Language Models, Proceedings of the Workshop","","","","177","188","11","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204908113&partnerID=40&md5=07ed92d69861310b1820fcae8d8d01e3","Naver Labs Europe, France","Chirkova N., Naver Labs Europe, France; Rau D., Naver Labs Europe, France; Déjean H., Naver Labs Europe, France; Formal T., Naver Labs Europe, France; Clinchant S., Naver Labs Europe, France; Nikoulina V., Naver Labs Europe, France","Retrieval-augmented generation (RAG) has recently emerged as a promising solution for incorporating up-to-date or domain-specific knowledge into large language models (LLMs) and improving LLM factuality, but is predominantly studied in English-only settings. In this work, we consider RAG in the multilingual setting (mRAG), i.e. with user queries and the datastore in 13 languages, and investigate which components and with which adjustments are needed to build a well-performing mRAG pipeline, that can be used as a strong baseline in future works. Our findings highlight that despite the availability of high-quality off-the-shelf multilingual retrievers and generators, task-specific prompt engineering is needed to enable generation in user languages. Moreover, current evaluation metrics need adjustments for multilingual setting, to account for variations in spelling named entities. The main limitations to be addressed in future works include frequent code-switching in non-Latin alphabet languages, occasional fluency errors, wrong reading of the provided documents, or irrelevant retrieval. We release the code for the resulting mRAG baseline pipeline at https://github.com/naver/bergen. © 2024 Association for Computational Linguistics.","","Coding errors; Pipeline codes; Query languages; Search engines; 'current; Code-switching; Domain-specific knowledge; Evaluation metrics; High quality; Language model; Named entities; User query; Computational linguistics","Li S.; Li M.; Zhang M.J.Q.; Choi E.; Geva M.; Hase P.; Ji H.","Association for Computational Linguistics (ACL)","English","Conference paper","Final","","Scopus","2-s2.0-85204908113"
"Vu T.-H.-G.; Hoang X.-B.","Vu, Thi-Huong-Giang (55203071800); Hoang, Xuan-Bach (59340531200)","55203071800; 59340531200","User Privacy Risk Analysis within Website Privacy Policies","2024","2024 International Conference on Multimedia Analysis and Pattern Recognition, MAPR 2024 - Proceedings","","","","","","","0","10.1109/MAPR63514.2024.10660854","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204806508&doi=10.1109%2fMAPR63514.2024.10660854&partnerID=40&md5=21254f50810402b8c8d9fc6038f40e4e","Hanoi University of Science and Technology, School of Information and Communication Technology, Hanoi, Viet Nam","Vu T.-H.-G., Hanoi University of Science and Technology, School of Information and Communication Technology, Hanoi, Viet Nam; Hoang X.-B., Hanoi University of Science and Technology, School of Information and Communication Technology, Hanoi, Viet Nam","The websites' privacy policies reflect how their users' personal data is collected, processed, stored, and used. This paper proposes a risk analysis method to assist users in understanding and identifying potential privacy risks in these policies. The method consists of two phases. First, we propose a transfer learning process to refine an existing large language model (LLM) to enable it to understand and answer legal questions effectively. Second, we introduce a retrieval-augmented generation (RAG) technique applied to the refined LLM to analyze risks in privacy policies. Additionally, we define a checklist to assess the compliance of privacy policies with legal regulations. This checklist is mapped to 20 queries, which are used to build prompts for the refined LLM. This allows our refined LLM to provide explanatory answers to users regarding the overall compliance level of privacy policies with relevant regulations, stating the potential risks in these privacy policies. The transfer learning process has been conducted on two existing LLMs. Experiments were performed on 200 random legal questions to compare these fine-tuned LLMs with the originals, demonstrating the efficiency of our proposed method in terms of the cosine similarity index and the F1 score.  © 2024 IEEE.","legal compliance; LLM; Privacy policy; privacy risk analysis; RAG","Anonymity; Language model; Large language model; Learning process; Legal compliance; Privacy policies; Privacy risk analyze; Privacy risks; Retrieval-augmented generation; Risk analyze; Transfer learning; Differential privacy","","Institute of Electrical and Electronics Engineers Inc.","English","Conference paper","Final","","Scopus","2-s2.0-85204806508"
"Sun Y.; Hu J.; Cheng W.; Chen H.","Sun, Yiyou (57195558086); Hu, Junjie (59325813100); Cheng, Wei (57218967449); Chen, Haifeng (35241923100)","57195558086; 59325813100; 57218967449; 35241923100","DFA-RAG: Conversational Semantic Router for Large Language Model with Definite Finite Automaton","2024","Proceedings of Machine Learning Research","235","","","47033","47055","22","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203831738&partnerID=40&md5=1ceaf0cbff569c3e5cf391bd4c7331eb","Department of Computer Science, University of Wisconsin, United States; NEC Laboratories America, inc., Princeton, United States","Sun Y., Department of Computer Science, University of Wisconsin, United States, NEC Laboratories America, inc., Princeton, United States; Hu J., Department of Computer Science, University of Wisconsin, United States; Cheng W., NEC Laboratories America, inc., Princeton, United States; Chen H., NEC Laboratories America, inc., Princeton, United States","This paper introduces the retrieval-augmented large language model with Definite Finite Automaton (DFA-RAG), a novel framework designed to enhance the capabilities of conversational agents using large language models (LLMs). Traditional LLMs face challenges in generating regulated and compliant responses in special scenarios with predetermined response guidelines, like emotional support and customer service. Our framework addresses these challenges by embedding a Definite Finite Automaton (DFA), learned from training dialogues, within the LLM. This structured approach acts as a semantic router which enables the LLM to adhere to a deterministic response pathway. The routing is achieved by the retrieval-augmentation generation (RAG) strategy, which carefully selects dialogue examples aligned with the current conversational context. The advantages of DFA-RAG include an interpretable structure through human-readable DFA, context-aware retrieval for responses in conversations, and plug-and-play compatibility with existing LLMs. Extensive benchmarks validate DFA-RAG’s effectiveness, indicating its potential as a valuable contribution to the conversational agent. Copyright 2024 by the author(s)","","Benchmarking; Chatbots; Computer system recovery; Finite automata; Modeling languages; Conversational agents; Conversational semantics; Customer-service; Deterministics; Embeddings; Emotional supports; Language model; Response pathways; Structured approach; Support services; Semantics","Salakhutdinov R.; Kolter Z.; Heller K.; Weller A.; Oliver N.; Scarlett J.; Berkenkamp F.","ML Research Press","English","Conference paper","Final","","Scopus","2-s2.0-85203831738"
"Merth T.; Fu Q.; Rastegari M.; Najibi M.","Merth, Thomas (57820198100); Fu, Qichen (58629145700); Rastegari, Mohammad (26654390900); Najibi, Mahyar (57151084000)","57820198100; 58629145700; 26654390900; 57151084000","Superposition Prompting: Improving and Accelerating Retrieval-Augmented Generation","2024","Proceedings of Machine Learning Research","235","","","35507","35527","20","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203815622&partnerID=40&md5=ec408bf3d45e285d03598e6c7698ec8e","Apple, Cupertino, CA, United States; Meta, Menlo Park, CA, United States","Merth T., Apple, Cupertino, CA, United States; Fu Q., Apple, Cupertino, CA, United States; Rastegari M., Meta, Menlo Park, CA, United States; Najibi M., Apple, Cupertino, CA, United States","Despite the successes of large language models (LLMs), they exhibit significant drawbacks, particularly when processing long contexts. Their inference cost scales quadratically with respect to sequence length, making it expensive for deployment in some real-world text processing applications, such as retrieval-augmented generation (RAG). Additionally, LLMs also exhibit the “distraction phenomenon”, where irrelevant context in the prompt degrades output quality. To address these drawbacks, we propose a novel RAG prompting methodology, superposition prompting, which can be directly applied to pre-trained transformer-based LLMs without the need for finetuning. At a high level, superposition prompting allows the LLM to process input documents in parallel prompt paths, discarding paths once they are deemed irrelevant. We demonstrate the capability of our method to simultaneously enhance time efficiency across a variety of question-answering benchmarks using multiple pre-trained LLMs. Furthermore, our technique significantly improves accuracy when the retrieved context is large relative the context the model was trained on. For example, our approach facilitates an 93× reduction in compute time while improving accuracy by 43% on the NaturalQuestions-Open dataset with the MPT-7B instruction-tuned model over naive RAG. Copyright 2024 by the author(s)","","Benchmarking; Large datasets; Modeling languages; Word processing; Cost scale; Language model; Output quality; Process inputs; Processing applications; Question Answering; Real-world; Sequence lengths; Text-processing; Time efficiencies; Open Data","Salakhutdinov R.; Kolter Z.; Heller K.; Weller A.; Oliver N.; Scarlett J.; Berkenkamp F.","ML Research Press","English","Conference paper","Final","","Scopus","2-s2.0-85203815622"
"Wan A.; Wallace E.; Klein D.","Wan, Alexander (58119471800); Wallace, Eric (57207856436); Klein, Dan (23009040500)","58119471800; 57207856436; 23009040500","What Evidence Do Language Models Find Convincing?","2024","Proceedings of the Annual Meeting of the Association for Computational Linguistics","1","","","7468","7484","16","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204447522&partnerID=40&md5=1bbd3afefc81ff39f1428832339a4eea","UC Berkeley, United States","Wan A., UC Berkeley, United States; Wallace E., UC Berkeley, United States; Klein D., UC Berkeley, United States","Retrieval-augmented language models are being increasingly tasked with subjective, contentious, and conflicting queries such as “is aspartame linked to cancer”. To resolve these ambiguous queries, one must search through a large range of websites and consider which, if any, of this evidence do I find convincing? In this work, we study how LLMs answer this question. In particular, we construct CONFLICTINGQA, a dataset that pairs controversial queries with a series of real-world evidence documents that contain different facts (e.g., quantitative results), argument styles (e.g., appeals to authority), and answers (Yes or No). We use this dataset to perform sensitivity and counterfactual analyses to explore which text features most affect LLM predictions. Overall, we find that current models rely heavily on the relevance of a website to the query, while largely ignoring stylistic features that humans find important such as whether a text contains scientific references or is written with a neutral tone. Taken together, these results highlight the importance of RAG corpus quality (e.g., the need to filter misinformation), and possibly even a shift in how LLMs are trained to better align with human judgements. © 2024 Association for Computational Linguistics.","","Computational linguistics; Counterfactuals; Current modeling; Evidence documents; Human judgments; Language model; Neutral tone; Quantitative result; Real-world; Scientific references; Text feature; Structured Query Language","Ku L.-W.; Martins A.F.T.; Srikumar V.","Association for Computational Linguistics (ACL)","English","Conference paper","Final","","Scopus","2-s2.0-85204447522"
"Bernardi M.L.; Cimitile M.","Bernardi, Mario Luca (57195515766); Cimitile, Marta (23392132800)","57195515766; 23392132800","Report Generation from X-Ray imaging by Retrieval-Augmented Generation and improved Image-Text Matching","2024","Proceedings of the International Joint Conference on Neural Networks","","","","","","","0","10.1109/IJCNN60899.2024.10650332","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204967350&doi=10.1109%2fIJCNN60899.2024.10650332&partnerID=40&md5=24caca2756b48c9a6510440656a2fc3f","University of Sannio, Dept. of Engineering, Benevento, Italy; UnitelmaSapienza University, Dept. of Law and Digital Society, Rome, Italy","Bernardi M.L., University of Sannio, Dept. of Engineering, Benevento, Italy; Cimitile M., UnitelmaSapienza University, Dept. of Law and Digital Society, Rome, Italy","Creating radiology reports is a vital but time-intensive task that involves analyzing images, consulting documents, and evaluating data. This process, heavily reliant on human effort, is prone to errors that can vary with the radiologists experience. Consequently, automating the generation of radiology reports is a key research goal due to its potential impact on medical procedures and patient care.This work proposes a multimodal approach specifically designed for generating radiological reports from chest X-rays (CXRs). Our method integrates a LLaMa large language model with Retrieval Augmented Generation (RAG), enhanced by a modified ALBEF embedding model that exploits efficient organ semantic segmentation and triple contrastive loss (called EALBEF). The combination of these two components allows radiological report generation that surpasses current state-of-the-art methods in terms of quality and accuracy. Our approach demonstrates a significant enhancement in the radiologist-specific metrics (e.g., RadCliQ), as well as across various generic lexical-based metrics (e.g., GLEU). Quantitative analyses of the models outputs reveal a notable increase in fluency and accuracy, with a marked reduction in issues such as hallucinations and source-reference divergences in the generated reports. © 2024 IEEE.","Deep Learning; Image-Text Match; Large Language Models (LLMs); Report Generation; X-Ray imaging","C (programming language); Image matching; Image retrieval; Semantics; Deep learning; Image texts; Image-text match; Language model; Large language model; Radiology reports; Report generation; Research goals; Text-matching; X-ray imaging; Semantic Segmentation","","Institute of Electrical and Electronics Engineers Inc.","English","Conference paper","Final","","Scopus","2-s2.0-85204967350"
"Liu Y.; Peng X.; Zhang X.; Liu W.; Yin J.; Cao J.; Du T.","Liu, Yanming (58953210400); Peng, Xinyue (58953210500); Zhang, Xuhong (57219174118); Liu, Weihao (58630507700); Yin, Jianwei (8249720800); Cao, Jiannan (58744887200); Du, Tianyu (57195491788)","58953210400; 58953210500; 57219174118; 58630507700; 8249720800; 58744887200; 57195491788","RA-ISF: Learning to Answer and Understand from Retrieval Augmentation via Iterative Self-Feedback","2024","Proceedings of the Annual Meeting of the Association for Computational Linguistics","","","","4730","4749","19","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205317872&partnerID=40&md5=c4037b56243556f2acfb181cc6366d9b","Zhejiang University, China; Southeast University, China; Massachusetts Institute of Technology, United States","Liu Y., Zhejiang University, China; Peng X., Southeast University, China; Zhang X., Zhejiang University, China; Liu W.; Yin J., Zhejiang University, China; Cao J., Massachusetts Institute of Technology, United States; Du T., Zhejiang University, China","Large language models (LLMs) demonstrate exceptional performance in numerous tasks but still heavily rely on knowledge stored in their parameters. Moreover, updating this knowledge incurs high training costs. Retrieval-augmented generation (RAG) methods address this issue by integrating external knowledge. The model can answer questions it couldn't previously by retrieving knowledge relevant to the query. This approach improves performance in certain scenarios for specific tasks. However, if irrelevant texts are retrieved, it may impair model performance. In this paper, we propose Retrieval Augmented Iterative Self-Feedback (RA-ISF), a framework that iteratively decomposes tasks and processes them in three submodules to enhance the model's problem-solving capabilities. Experiments show that our method outperforms existing benchmarks, performing well on models like GPT3.5, Llama2, significantly enhancing factual reasoning capabilities and reducing hallucinations. © 2024 Association for Computational Linguistics.","","Benchmarking; Contrastive Learning; Problem solving; Structured Query Language; External knowledge; Feedback learning; Generation method; Improve performance; Language model; Modeling performance; Performance; Self-feedback; Specific tasks; Training costs; Computational linguistics","Ku L.-W.; Martins A.; Srikumar V.","Association for Computational Linguistics (ACL)","English","Conference paper","Final","","Scopus","2-s2.0-85205317872"
"Wang Z.; Teo S.X.; Ouyang J.; Xu Y.; Shi W.","Wang, Zheng (35111811300); Teo, Shu Xian (59179655500); Ouyang, Jieer (59179227400); Xu, Yongjun (59179073700); Shi, Wei (58590606700)","35111811300; 59179655500; 59179227400; 59179073700; 58590606700","M-RAG: Reinforcing Large Language Model Performance through Retrieval-Augmented Generation with Multiple Partitions","2024","Proceedings of the Annual Meeting of the Association for Computational Linguistics","1","","","1966","1978","12","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204471985&partnerID=40&md5=ea4e92d345626ddc628a4a1472f07a8b","Huawei Technologies, Co., Ltd., China","Wang Z., Huawei Technologies, Co., Ltd., China; Teo S.X., Huawei Technologies, Co., Ltd., China; Ouyang J., Huawei Technologies, Co., Ltd., China; Xu Y., Huawei Technologies, Co., Ltd., China; Shi W., Huawei Technologies, Co., Ltd., China","Retrieval-Augmented Generation (RAG) enhances Large Language Models (LLMs) by retrieving relevant memories from an external database. However, existing RAG methods typically organize all memories in a whole database, potentially limiting focus on crucial memories and introducing noise. In this paper, we introduce a multiple partition paradigm for RAG (called M-RAG), where each database partition serves as a basic unit for RAG execution. Based on this paradigm, we propose a novel framework that leverages LLMs with Multi-Agent Reinforcement Learning to optimize different language generation tasks explicitly. Through comprehensive experiments conducted on seven datasets, spanning three language generation tasks and involving three distinct language model architectures, we confirm that M-RAG consistently outperforms various baseline methods, achieving improvements of 11%, 8%, and 12% for text summarization, machine translation, and dialogue generation, respectively. © 2024 Association for Computational Linguistics.","","Chatbots; Computational linguistics; Computer aided language translation; Machine translation; Modeling languages; Reinforcement learning; Speech enhancement; Baseline methods; Basic units; External database; Generation method; Language generation; Language model; Modeling architecture; Modeling performance; Multi-agent reinforcement learning; Text Summarisation; Database systems","Ku L.-W.; Martins A.F.T.; Srikumar V.","Association for Computational Linguistics (ACL)","English","Conference paper","Final","","Scopus","2-s2.0-85204471985"
"Guinet G.; Omidvar-Tehrani B.; Deoras A.; Callot L.","Guinet, Gauthier (57221112991); Omidvar-Tehrani, Behrooz (56189603100); Deoras, Anoop (35742626300); Callot, Laurent (56574299500)","57221112991; 56189603100; 35742626300; 56574299500","Automated Evaluation of Retrieval-Augmented Language Models with Task-Specific Exam Generation","2024","Proceedings of Machine Learning Research","235","","","16773","16801","28","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203814529&partnerID=40&md5=742c3516f05e3d036fb4ebdd257e2c27","AWS AI Labs, United States","Guinet G., AWS AI Labs, United States; Omidvar-Tehrani B., AWS AI Labs, United States; Deoras A., AWS AI Labs, United States; Callot L., AWS AI Labs, United States","We propose a new method to measure the task-specific accuracy of Retrieval-Augmented Large Language Models (RAG). Evaluation is performed by scoring the RAG on an automatically-generated synthetic exam composed of multiple choice questions based on the corpus of documents associated with the task. Our method is an automated, cost-efficient, interpretable, and robust strategy to select the optimal components for a RAG system. We leverage Item Response Theory (IRT) to estimate the quality of an exam and its informativeness on task-specific accuracy. IRT also provides a natural way to iteratively improve the exam by eliminating the exam questions that are not sufficiently informative about a model's ability. We demonstrate our approach on four new open-ended Question-Answering tasks based on Arxiv abstracts, StackExchange questions, AWS DevOps troubleshooting guides, and SEC filings. In addition, our experiments reveal more general insights into factors impacting RAG performance like size, retrieval mechanism, prompting and fine-tuning. Most notably, our findings show that choosing the right retrieval algorithms often leads to bigger performance gains than simply using a larger language model. Copyright 2024 by the author(s)","","Modeling languages; Search engines; Automated evaluation; Automatically generated; Cost-efficient; Efficient strategy; Exam questions; Informativeness; Item response theory; Language model; Multiple-choice questions; Robust strategy; Question answering","Salakhutdinov R.; Kolter Z.; Heller K.; Weller A.; Oliver N.; Scarlett J.; Berkenkamp F.","ML Research Press","English","Conference paper","Final","","Scopus","2-s2.0-85203814529"
"Chen Z.; Wang X.; Jiang Y.; Xie P.; Huang F.; Tu K.","Chen, Zhuo (59284481700); Wang, Xinyu (57216623716); Jiang, Yong (57195958145); Xie, Pengjun (57216619845); Huang, Fei (57210150087); Tu, Kewei (56371222100)","59284481700; 57216623716; 57195958145; 57216619845; 57210150087; 56371222100","Improving Retrieval Augmented Open-Domain Question-Answering with Vectorized Contexts","2024","Proceedings of the Annual Meeting of the Association for Computational Linguistics","","","","7683","7694","11","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205309124&partnerID=40&md5=80e641e75008c1cc98cf571e3e4804f0","School of Information Science and Technology, ShanghaiTech University, China; Shanghai Engineering Research Center of Intelligent Vision and Imaging, China; Institute for Intelligent Computing, Alibaba Group, China","Chen Z., School of Information Science and Technology, ShanghaiTech University, China, Shanghai Engineering Research Center of Intelligent Vision and Imaging, China; Wang X., Institute for Intelligent Computing, Alibaba Group, China; Jiang Y., Institute for Intelligent Computing, Alibaba Group, China; Xie P., Institute for Intelligent Computing, Alibaba Group, China; Huang F., Institute for Intelligent Computing, Alibaba Group, China; Tu K., School of Information Science and Technology, ShanghaiTech University, China","In the era of large language models, applying techniques such as Retrieval Augmented Generation can better address Open-Domain Question-Answering problems. Due to constraints including model sizes and computing resources, the length of context is often limited, and it becomes challenging to empower the model to cover overlong contexts while answering questions from open domains. This paper proposes a general and convenient method to cover longer contexts in Open-Domain Question-Answering tasks. It leverages a small encoder and cross-attention mechanism and effectively encodes contexts. With our method, the original language models can cover several times longer contexts while keeping the computing requirements close to the baseline. Our experiments demonstrate that after finetuning, there is improved performance across two held-in datasets, four held-out datasets, and also in two In Context Learning settings. Our code will be released at https://github.com/Alibaba-NLP/Vec-RA-ODQA. © 2024 Association for Computational Linguistics.","","Computational linguistics; Encoding (symbols); Attention mechanisms; Computing resource; Context learning; In contexts; Language model; Model size; Open domain question answering; Original language modeling; Performance; Question Answering Task; Question answering","Ku L.-W.; Martins A.; Srikumar V.","Association for Computational Linguistics (ACL)","English","Conference paper","Final","","Scopus","2-s2.0-85205309124"
"Liu Y.; Meng R.; Bhat M.M.; Joty S.; Xiong C.; Zhou Y.; Yavuz S.","Liu, Ye (58872166600); Meng, Rui (57191032288); Bhat, Meghana Moorthy (58029847400); Joty, Shafiq (24779447500); Xiong, Caiming (37017840800); Zhou, Yingbo (57204047196); Yavuz, Semih (57207854542)","58872166600; 57191032288; 58029847400; 24779447500; 37017840800; 57204047196; 57207854542","Modeling Uncertainty and Using Post-fusion as Fallback Improves Retrieval Augmented Generation with LLMs","2024","KnowLLM 2024 - 1st Workshop on Towards Knowledgeable Language Models, Proceedings of the Workshop","","","","69","82","13","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204876466&partnerID=40&md5=48d99861d697514fa10e73e5ce0f85b1","Salesforce Research, United States","Liu Y., Salesforce Research, United States; Meng R., Salesforce Research, United States; Bhat M.M., Salesforce Research, United States; Joty S., Salesforce Research, United States; Xiong C., Salesforce Research, United States; Zhou Y., Salesforce Research, United States; Yavuz S., Salesforce Research, United States","The integration of retrieved passages and large language models (LLMs), such as ChatGPTs, has significantly contributed to improving open-domain question answering. However, there is still a lack of exploration regarding the optimal approach for incorporating retrieved passages into the answer generation process. This paper aims to fill this gap by investigating different methods of combining retrieved passages with LLMs to enhance answer generation. We begin by examining the limitations of a commonly-used concatenation approach. Surprisingly, this approach often results in generating “unknown” outputs, even when the correct document is among the top-k retrieved passages. To address this issue, we explore four alternative strategies for integrating the retrieved passages with the LLMs. These strategies include two single-round methods that utilize chain-of-thought reasoning and two multi-round strategies that incorporate feedback loops. Through comprehensive analyses and experiments, we provide insightful observations on how to effectively leverage retrieved passages to enhance the answer generation capability of LLMs. On three open-domain question answering datesets, NQ, TriviaQA and SQuAD, our multi-round approaches outperform traditional concatenation approach, achieving over a 10% improvement in answer EM. © 2024 Association for Computational Linguistics.","","Computational linguistics; Modeling languages; Answer generation process; Comprehensive analysis; Feedback loops; Language model; Modeling uncertainties; Open domain question answering; Optimal approaches; Unknown outputs; Question answering","Li S.; Li M.; Zhang M.J.Q.; Choi E.; Geva M.; Hase P.; Ji H.","Association for Computational Linguistics (ACL)","English","Conference paper","Final","","Scopus","2-s2.0-85204876466"
"Akyon S.H.; Akyon F.C.; Camyar A.S.; Hızlı F.; Sari T.; Hızlı Ş.","Akyon, Seyma Handan (58154095700); Akyon, Fatih Cagatay (57195222735); Camyar, Ahmet Sefa (59334475400); Hızlı, Fatih (59334475500); Sari, Talha (59333812700); Hızlı, Şamil (56181474000)","58154095700; 57195222735; 59334475400; 59334475500; 59333812700; 56181474000","Evaluating the Capabilities of Generative AI Tools in Understanding Medical Papers: Qualitative Study","2024","JMIR Medical Informatics","12","","e59258","","","","0","10.2196/59258","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204381860&doi=10.2196%2f59258&partnerID=40&md5=2f1295a914a00f4b5bfab3bdda97ba64","Golpazari Family Health Center, Bilecik, Turkey; SafeVideo AI, San Francisco, CA, United States; Graduate School of Informatics, Middle East Technical University, Ankara, Turkey; Department of Internal Medicine, Ankara Etlik City Hospital, Ankara, Turkey; Faculty of Medicine, Ankara Yildirim Beyazit University, Ankara, Turkey; Department of Computer Science, Istanbul Technical University, Istanbul, Turkey; Department of Pediatric Gastroenterology, Children Hospital, Ankara Bilkent City Hospital, Ankara Yildirim Beyazit University, Ankara, Turkey","Akyon S.H., Golpazari Family Health Center, Bilecik, Turkey; Akyon F.C., SafeVideo AI, San Francisco, CA, United States, Graduate School of Informatics, Middle East Technical University, Ankara, Turkey; Camyar A.S., Department of Internal Medicine, Ankara Etlik City Hospital, Ankara, Turkey; Hızlı F., Faculty of Medicine, Ankara Yildirim Beyazit University, Ankara, Turkey; Sari T., SafeVideo AI, San Francisco, CA, United States, Department of Computer Science, Istanbul Technical University, Istanbul, Turkey; Hızlı Ş., Department of Pediatric Gastroenterology, Children Hospital, Ankara Bilkent City Hospital, Ankara Yildirim Beyazit University, Ankara, Turkey","Background: Reading medical papers is a challenging and time-consuming task for doctors, especially when the papers are long and complex. A tool that can help doctors efficiently process and understand medical papers is needed. Objective: This study aims to critically assess and compare the comprehension capabilities of large language models (LLMs) in accurately and efficiently understanding medical research papers using the STROBE (Strengthening the Reporting of Observational Studies in Epidemiology) checklist, which provides a standardized framework for evaluating key elements of observational study. Methods: The study is a methodological type of research. The study aims to evaluate the understanding capabilities of new generative artificial intelligence tools in medical papers. A novel benchmark pipeline processed 50 medical research papers from PubMed, comparing the answers of 6 LLMs (GPT-3.5-Turbo, GPT-4-0613, GPT-4-1106, PaLM 2, Claude v1, and Gemini Pro) to the benchmark established by expert medical professors. Fifteen questions, derived from the STROBE checklist, assessed LLMs’ understanding of different sections of a research paper. Results: LLMs exhibited varying performance, with GPT-3.5-Turbo achieving the highest percentage of correct answers (n=3916, 66.9%), followed by GPT-4-1106 (n=3837, 65.6%), PaLM 2 (n=3632, 62.1%), Claude v1 (n=2887, 58.3%), Gemini Pro (n=2878, 49.2%), and GPT-4-0613 (n=2580, 44.1%). Statistical analysis revealed statistically significant differences between LLMs (P<.001), with older models showing inconsistent performance compared to newer versions. LLMs showcased distinct performances for each question across different parts of a scholarly paper—with certain models like PaLM 2 and GPT-3.5 showing remarkable versatility and depth in understanding. Conclusions: This study is the first to evaluate the performance of different LLMs in understanding medical papers using the retrieval augmented generation method. The findings highlight the potential of LLMs to enhance medical research by improving efficiency and facilitating evidence-based decision-making. Further research is needed to address limitations such as the influence of question formats, potential biases, and the rapid evolution of LLM models. ©Seyma Handan Akyon, Fatih Cagatay Akyon, Ahmet Sefa Camyar, Fatih Hızlı, Talha Sari, Şamil Hızlı.","AI; answer; answers; artificial intelligence; ChatGPT; comprehension; generative; GPT; health care; language model; language models; large language models; LLM; LLMs; machine learning; medicine; natural language processing; research paper; research papers; response; responses; scientific research; Strengthening the Reporting of Observational Studies in Epidemiology; STROBE","","","JMIR Publications Inc.","English","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85204381860"
"Bei Y.; Fang Z.; Mao S.; Yu S.; Jiang Y.; Tong Y.; Cai W.","Bei, Yijun (22633605700); Fang, Zhibin (59343330100); Mao, Shenyu (59344400000); Yu, Shuyi (59344400100); Jiang, Yan (59344252100); Tong, Yining (59344400200); Cai, Weimin (59343330200)","22633605700; 59343330100; 59344400000; 59344400100; 59344252100; 59344400200; 59343330200","Manufacturing Domain QA with Integrated Term Enhanced RAG","2024","Proceedings of the International Joint Conference on Neural Networks","","","","","","","0","10.1109/IJCNN60899.2024.10649905","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204990979&doi=10.1109%2fIJCNN60899.2024.10649905&partnerID=40&md5=267f52ddc237cd5b00dcbb2659ebef93","Zhejiang University, School of Software Technology, Ningbo, China; Zhejiang Jiyun Education Technology Co., Ltd, Ningbo, China","Bei Y., Zhejiang University, School of Software Technology, Ningbo, China; Fang Z., Zhejiang University, School of Software Technology, Ningbo, China; Mao S., Zhejiang University, School of Software Technology, Ningbo, China; Yu S., Zhejiang University, School of Software Technology, Ningbo, China; Jiang Y., Zhejiang University, School of Software Technology, Ningbo, China; Tong Y., Zhejiang Jiyun Education Technology Co., Ltd, Ningbo, China; Cai W., Zhejiang Jiyun Education Technology Co., Ltd, Ningbo, China","Large Language Models (LLMs) have demonstrated powerful capabilities, yet LLMs face issues like hallucination in certain domain-specific areas. Consequently, an increasing number of domain-specific models are emerging. The current paradigm for domain-specific models involves training with domain data, followed by the employment of Retrieval-Augmented Generation (RAG) to mitigate hallucination issues. However, in precision-critical domains such as manufacturing, if the knowledge documents are of low quality or contain noise, the context retrieved through simple semantic matching by RAG may not necessarily benefit model output. Additionally, there can be issues like getting ""lost in the middle""due to irrelevant or excessive context. To overcome this, we introduce the Integrated Term Enhancement Methodology (ITEM). Inspired by Chinese educational methods focused on key term elucidation, ITEM extracts and explains critical terms precisely from knowledge documents to form a comprehensive Term Dictionary for retrieving terms and explanations to enhance query capabilities. This methodology refines query responses by providing more accurate and contextually relevant information. To assess ITEM's effectiveness, we utilize the Chinese Mould Manufacturing Dataset (CMMD) and Contextualized Adaptive Response Assessment (CARA) metric method. Our experiment demonstrates that ITEM significantly outperforms existing retrieval enhancement Dense Retrievers by over 17.0% in accuracy while requiring only 80% of their token length. Moreover, the accuracy of our method exceeded that of GPT-4 by 5.0%. This advancement represents a significant leap in context-specific retrieval in LLMs, especially beneficial for specialized domains. The results underscore ITEM's potential as a transformative method in the field, offering new perspectives on integrating domain-specific knowledge into LLMs. © 2024 IEEE.","","Manufacturing data processing; Metadata; Natural language processing systems; Query processing; Structured Query Language; 'current; Critical domain; Domain specific; Domain-specific modelling; Language model; Low qualities; Manufacturing domains; Semantic matching; Simple++; Specific areas; Semantics","","Institute of Electrical and Electronics Engineers Inc.","English","Conference paper","Final","","Scopus","2-s2.0-85204990979"
"Hu H.-W.; Lin Y.-C.; Chia C.-H.; Chuang E.; Cheng Ru Y.","Hu, Hsiang-Wei (57216762794); Lin, Yu-Chun (59325577000); Chia, Chang-Hung (59326470900); Chuang, Ethan (59325923400); Cheng Ru, Yang (59325578200)","57216762794; 59325577000; 59326470900; 59325923400; 59325578200","Leveraging Large Language Models for Generating Personalized Care Recommendations in Dementia","2024","IEEE International Workshop on Electromagnetics: Applications and Student Innovation Competition, iWEM 2024","","","","","","","0","10.1109/iWEM59914.2024.10649066","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203846284&doi=10.1109%2fiWEM59914.2024.10649066&partnerID=40&md5=104cbbfdf29d1129211edb883fab908a","Industrial Technology Research Institute, Department of Biomedical Engineering, Hsinchu county, Taiwan; Institute of Medicine, Chung Shan Medical University, Taichung, Taiwan; International Academia of Biomedical Innovation Technology, Department of Artificial Intelligence in Healthcare, Reno, United States","Hu H.-W., Industrial Technology Research Institute, Department of Biomedical Engineering, Hsinchu county, Taiwan; Lin Y.-C., Institute of Medicine, Chung Shan Medical University, Taichung, Taiwan; Chia C.-H., International Academia of Biomedical Innovation Technology, Department of Artificial Intelligence in Healthcare, Reno, United States; Chuang E., International Academia of Biomedical Innovation Technology, Department of Artificial Intelligence in Healthcare, Reno, United States; Cheng Ru Y., International Academia of Biomedical Innovation Technology, Department of Artificial Intelligence in Healthcare, Reno, United States","As dementia cases surge globally, with projections reaching 78 million by 2030, innovative care solutions are urgently needed. This study introduces a groundbreaking approach to personalized dementia care by integrating Large Language Models (LLMs) with Retrieval-Augmented Generation (RAG) technology. Our method leverages AI to enhance cognitive state assessment accuracy and generate tailored care recommendations. The system fine-tunes a GPT-4 based LLM, integrating it with a vector database using RAG to optimize care plan personalization. AI-generated diagnostic reports based on key clinical parameters achieved a 90% accuracy and 88% readability score when evaluated by clinical physicians. Personalized care plans encompassing cognitive training, music therapy, dietary control, and routine management were developed and rigorously assessed by healthcare professionals. These plans demonstrated exceptional performance, scoring between 7.66 and 8.93 out of 10 across suitability, scientific basis, operability, and comprehensiveness. This research addresses the critical need for scalable, personalized dementia care. By synergizing AI technology with clinical expertise, our approach has the potential to transform care paradigms, improve patient outcomes, and alleviate pressure on global healthcare systems. This integration of LLMs with RAG represents a significant advancement in medical AI, opening new avenues for personalized medicine in neurodegenerative disorders.  © 2024 IEEE.","Alzheimer's disease; Large Language Models (LLMs); Personalized Care; Preventative Care; Real-time Feedback Systems","Clinical research; Diagnosis; Disease control; Patient treatment; Personalized medicine; Alzheimers disease; Care solutions; Dementia cares; Feedback systems; Language model; Large language model; Personalized care; Preventative care; Real-time feedback; Real-time feedback system; Neurodegenerative diseases","","Institute of Electrical and Electronics Engineers Inc.","English","Conference paper","Final","","Scopus","2-s2.0-85203846284"
"Agarwal P.; Kumar N.; Bedathur S.","Agarwal, Prerna (59336189700); Kumar, Nishant (57760670100); Bedathur, Srikanta (22833788900)","59336189700; 57760670100; 22833788900","SymKGQA: Few-Shot Knowledge Graph Question Answering via Symbolic Program Generation and Execution","2024","Proceedings of the Annual Meeting of the Association for Computational Linguistics","1","","","10119","10140","21","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204481424&partnerID=40&md5=c2703f774177c78033468922328cbab1","Indian Institute of Technology, Delhi, India; IBM Research India, India","Agarwal P., Indian Institute of Technology, Delhi, India, IBM Research India, India; Kumar N., Indian Institute of Technology, Delhi, India; Bedathur S., Indian Institute of Technology, Delhi, India","Semantic Parsing of natural language questions into their executable logical form (LF) has shown state-of-the-art (SOTA) performance for Knowledge Graph Question Answering (KGQA). However, these methods are not applicable for real-world applications, due to lack of KG-specific training data. Recent advances in the capabilities of Large Language Models (LLMs) has led towards generating low-level LFs such as SPARQL and S-Expression in a few-shot setting. Unfortunately, these methods: (1) are limited to the knowledge of underlying LLM about the LF, (2) performs inferior for the harder complex benchmarks such as KQA Pro, (3) suffers while grounding the generated LF to a specific Knowledge Graph. Recently, a new LF called KoPL (Cao et al., 2022a) has been introduced that explicitly models complex reasoning process step-by-step in a symbolic manner and has shown SOTA on KQA Pro in fully-supervised setting. Inspired by this, we propose SymKGQA framework that generates step-by-step Symbolic LF i.e., KoPL in a few-shot in-context learning setting using LLM. Our framework is not dependent on pre-trained knowledge of LLM about KoPL. We further build a Retrieval-Augmented Generation based Question-Aware Contextual KoPL (QUACK) resolver to ground the generated LF. Our experiments with different LLMs and few-shot settings demonstrate that SymKGQA outperforms all other few-shot and even many of the fully-supervised KGQA approaches. © 2024 Association for Computational Linguistics.","","Benchmarking; Computational linguistics; Natural language processing systems; Semantics; Zero-shot learning; Executables; Knowledge graphs; Language model; Logical forms; Natural language questions; Program execution; Program generation; Question Answering; Semantic parsing; State-of-the-art performance; Knowledge graph","Ku L.-W.; Martins A.F.T.; Srikumar V.","Association for Computational Linguistics (ACL)","English","Conference paper","Final","","Scopus","2-s2.0-85204481424"
"Li W.; Li J.; Ma W.; Liu Y.","Li, Weitao (58932494000); Li, Junkai (58932044700); Ma, Weizhi (57015922800); Liu, Yang (57211088579)","58932494000; 58932044700; 57015922800; 57211088579","Citation-Enhanced Generation for LLM-based Chatbots","2024","Proceedings of the Annual Meeting of the Association for Computational Linguistics","1","","","1451","1466","15","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204427421&partnerID=40&md5=9080834737086d6b80d6d14e985887ae","Dept. of Comp. Sci. & Tech., Institute for AI, Tsinghua University, Beijing, China; Institute for AI Industry Research (AIR), Tsinghua University, Beijing, China; Jiangsu Collaborative Innovation Center for Language Competence, Jiangsu, China","Li W., Dept. of Comp. Sci. & Tech., Institute for AI, Tsinghua University, Beijing, China, Institute for AI Industry Research (AIR), Tsinghua University, Beijing, China; Li J., Dept. of Comp. Sci. & Tech., Institute for AI, Tsinghua University, Beijing, China, Institute for AI Industry Research (AIR), Tsinghua University, Beijing, China; Ma W., Institute for AI Industry Research (AIR), Tsinghua University, Beijing, China; Liu Y., Dept. of Comp. Sci. & Tech., Institute for AI, Tsinghua University, Beijing, China, Institute for AI Industry Research (AIR), Tsinghua University, Beijing, China, Jiangsu Collaborative Innovation Center for Language Competence, Jiangsu, China","Large language models (LLMs) exhibit powerful general intelligence across diverse scenarios, including their integration into chatbots. However, a vital challenge of LLM-based chatbots is that they may produce hallucinated content in responses, which significantly limits their applicability. Various efforts have been made to alleviate hallucination, such as retrieval augmented generation and reinforcement learning with human feedback, but most of them require additional training and data annotation. In this paper, we propose a novel post-hoc Citation-Enhanced Generation (CEG) approach combined with retrieval argumentation. Unlike previous studies that focus on preventing hallucinations during generation, our method addresses this issue in a post-hoc way. It incorporates a retrieval module to search for supporting documents relevant to the generated content, and employs a natural language inference-based citation generation module. Once the statements in the generated content lack of reference, our model can regenerate responses until all statements are supported by citations. Note that our method is a training-free plug-and-play plugin that is capable of various LLMs. Experiments on various hallucination-related datasets show our framework outperforms state-of-the-art methods in both hallucination detection and response regeneration on three benchmarks. Our code and datasets can be found at https://github.com/Tsinghua-dhy/CEG. © 2024 Association for Computational Linguistics.","","Benchmarking; Natural language processing systems; Reinforcement learning; Chatbots; Data annotation; General Intelligence; Language inference; Language model; Model-based OPC; Natural languages; Plug-and-play; Plug-ins; Reinforcement learnings; Computational linguistics","Ku L.-W.; Martins A.F.T.; Srikumar V.","Association for Computational Linguistics (ACL)","English","Conference paper","Final","","Scopus","2-s2.0-85204427421"
"Gupta T.K.; Goel T.; Verma I.; Dey L.; Bhardwaj S.","Gupta, Tanay Kumar (58824912100); Goel, Tushar (36999834100); Verma, Ishan (55753871900); Dey, Lipika (6603939167); Bhardwaj, Sachit (59332567900)","58824912100; 36999834100; 55753871900; 6603939167; 59332567900","Knowledge Graph aided LLM based ESG Question-Answering from News","2024","CEUR Workshop Proceedings","3753","","","65","78","13","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204312367&partnerID=40&md5=36a503e3640f5272a3c77763a15a6fe1","TCS Research, New Delhi, India","Gupta T.K., TCS Research, New Delhi, India; Goel T., TCS Research, New Delhi, India; Verma I., TCS Research, New Delhi, India; Dey L., TCS Research, New Delhi, India; Bhardwaj S., TCS Research, New Delhi, India","Organizations around the globe have acknowledged the importance of sustainability. Sustainability performance has gained traction in investing and risk management and is now an integral part of business planning. The volume and velocity of information being published on the web have made use of natural language processing evident for insight generation. With the recent advancements in language modelling and the availability of Large Language Models (LLM), conversational insight generation is increasingly becoming popular. LLM combined with advanced retrieval techniques has eased the task of question-answering over large natural language datasets. In this work, we present a novel approach that leverages Knowledge Graph-based Retrieval Augmented Generation (KG-RAG) to facilitate question-answering in the context of sustainability news articles and corporate Environmental, Social, and Governance (ESG) performance. Our methodology encompasses the creation of an ESG Knowledge Graph, retrieval techniques that identify contextually relevant information, and an LLM-based answer-generation framework. We have experimented with multiple LLM models and have shown a comparative study of their performances against several baseline algorithms. © 2024 Copyright for this paper by its authors.","ESG; Knowledge Graph; Large Language Models; Question Answering; Sustainability","Enterprise resource planning; Modeling languages; Risk management; Environmental, social, and governance; Knowledge graphs; Language model; Large language model; Model-based OPC; Natural languages; Performance; Question Answering; Retrieval techniques; Sustainability performance; Knowledge graph","Blomqvist E.; Garcia-Castro R.; Universidad Politecnica de Madrid, Ontology Engineering Group, Avda. Monteprincipe, s/nBoadilla del Monte, Madrid; Hernandez D.; University of Stuttgart, Institute for Artificial Intelligence, Universitatsstrasse 32, Stuttgart; Hitzler P.; Kansas State University, Department of Computer Science, 2184 Engineering Hall, 1701D Platt St., Manhattan, KS; Lindecrantz M.; Ragn-Sells AB, Vaderholmens Gard, Sollentuna; Poveda-Villalon M.; Universidad Politecnica de Madrid, Ontology Engineering Group, Avda. Monteprincipe, s/n Boadilla del Monte, Madrid","CEUR-WS","English","Conference paper","Final","","Scopus","2-s2.0-85204312367"
"Chen Y.; Lv A.; Lin T.-E.; Chen C.; Wu Y.; Huang F.; Li Y.; Yan R.","Chen, Yuhan (57804351200); Lv, Ang (57847729700); Lin, Ting-En (57210644805); Chen, Changyu (57331637500); Wu, Yuchuan (57362554400); Huang, Fei (57210150087); Li, Yongbin (57216693726); Yan, Rui (36723202000)","57804351200; 57847729700; 57210644805; 57331637500; 57362554400; 57210150087; 57216693726; 36723202000","Fortify the Shortest Stave in Attention: Enhancing Context Awareness of Large Language Models for Effective Tool-Use","2024","Proceedings of the Annual Meeting of the Association for Computational Linguistics","1","","","11160","11174","14","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204435721&partnerID=40&md5=7c7afc16bb3a6c74f4ff555ac428f3a1","Gaoling School of Artificial Intelligence, Renmin University of China, China; Alibaba Group, China; Engineering Research Center of Next-Generation Intelligent Search and Recommendation, Ministry of Education, China","Chen Y., Gaoling School of Artificial Intelligence, Renmin University of China, China; Lv A., Gaoling School of Artificial Intelligence, Renmin University of China, China; Lin T.-E., Alibaba Group, China; Chen C., Gaoling School of Artificial Intelligence, Renmin University of China, China; Wu Y., Alibaba Group, China; Huang F., Alibaba Group, China; Li Y., Alibaba Group, China; Yan R., Gaoling School of Artificial Intelligence, Renmin University of China, China, Engineering Research Center of Next-Generation Intelligent Search and Recommendation, Ministry of Education, China","In this paper, we demonstrate that an inherent waveform pattern in the attention allocation of large language models (LLMs) significantly affects their performance in tasks demanding a high degree of context awareness, such as utilizing LLMs for tool-use. Specifically, the crucial information in the context will be potentially overlooked by model when it is positioned in the trough zone of the attention waveform, leading to decreased performance. To address this issue, we propose a novel inference method named Attention Buckets. It allows LLMs to process their input through multiple parallel processes. Each process utilizes a distinct base angle for the rotary position embedding, thereby creating a unique attention waveform. By compensating an attention trough of a particular process with an attention peak of another process, our approach enhances LLM's awareness to various contextual positions, thus mitigating their risk of overlooking crucial information. In the largest tool-use benchmark, our method elevates a 7B model to achieve state-of-the-art performance comparable to that of GPT-4. On other benchmarks and some RAG tasks, which also demand a thorough understanding of contextual content, Attention Buckets also exhibited notable enhancements in performance. © 2024 Association for Computational Linguistics.","","Benchmarking; Context sensitive languages; Context- awareness; Effective tool; Embeddings; Inference methods; Language model; Multiple parallel process; Performance; Tool use; Waveform patterns; Waveforms; Computational linguistics","Ku L.-W.; Martins A.F.T.; Srikumar V.","Association for Computational Linguistics (ACL)","English","Conference paper","Final","","Scopus","2-s2.0-85204435721"
"Belikova J.; Beliakin E.; Konovalov V.","Belikova, Julia (59342251500); Beliakin, Evegeniy (59342389600); Konovalov, Vasily (57203316979)","59342251500; 59342389600; 57203316979","JellyBell at TextGraphs-17 Shared Task: Fusing Large Language Models with External Knowledge for Enhanced Question Answering","2024","TextGraphs at ACL 2024 - Proceedings of TextGraphs-17: Graph-Based Methods for Natural Language Processing, 62nd Annual Meeting of the Association of Computational Linguistics","","","","154","160","6","1","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204924501&partnerID=40&md5=0b8dd41365b1ff2a3865e250302497f6","Moscow Institute of Physics and Technology, Russian Federation; AIRI, Moscow, Russian Federation","Belikova J., Moscow Institute of Physics and Technology, Russian Federation; Beliakin E., Moscow Institute of Physics and Technology, Russian Federation; Konovalov V., Moscow Institute of Physics and Technology, Russian Federation, AIRI, Moscow, Russian Federation","This work describes an approach to develop Knowledge Graph Question Answering (KGQA) system for TextGraphs-17 shared task. The task focuses on the fusion of Large Language Models (LLMs) with Knowledge Graphs (KGs). The goal is to select a KG entity (out of several candidates) which corresponds to an answer given a textual question. Our approach applies LLM to identify the correct answer among the list of possible candidates. We confirm that integrating external information is particularly beneficial when the subject entities are not well-known, and using RAG can negatively impact the performance of LLM on questions related to popular entities, as the retrieved context might be misleading. With our result, we achieved 2nd place in the post-evaluation phase. © 2024 Association for Computational Linguistics.","","Computational linguistics; Knowledge graph; Evaluation phase; External informations; External knowledge; Knowledge graphs; Language model; Performance; Post evaluations; Question Answering; Question answering systems; Question answering","Ustalov D.; Gao Y.; Panchenko A.; Tutubalina E.; Nikishina I.; Ramesh A.; Sakhovskiy A.; Usbeck R.; Penn G.; Valentino M.","Association for Computational Linguistics (ACL)","English","Conference paper","Final","","Scopus","2-s2.0-85204924501"
"Eppalapally S.; Dangi D.; Bhat C.; Gupta A.; Zhang R.; Agarwal S.; Bagga K.; Yoon S.; Lipka N.; Rossi R.A.; Dernoncourt F.","Eppalapally, Swetha (59256799200); Dangi, Daksh (59256726100); Bhat, Chaithra (59256799300); Gupta, Ankita (57944412600); Zhang, Ruiyi (57204807127); Agarwal, Shubham (58141314700); Bagga, Karishma (59125330200); Yoon, Seunghyun (57201772909); Lipka, Nedim (25927367600); Rossi, Ryan A. (57197077642); Dernoncourt, Franck (55827671700)","59256799200; 59256726100; 59256799300; 57944412600; 57204807127; 58141314700; 59125330200; 57201772909; 25927367600; 57197077642; 55827671700","KaPQA: Knowledge-Augmented Product Question-Answering","2024","KnowledgeNLP 2024 - 3rd Workshop on Knowledge Augmented Methods for NLP, Proceedings of the Workshop","","","","15","29","14","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204882587&partnerID=40&md5=c3dcb5fbad820b065e00aa5aa0e3c977","University of Massachusetts Amherst, United States; Adobe Research, United States","Eppalapally S., University of Massachusetts Amherst, United States; Dangi D., University of Massachusetts Amherst, United States; Bhat C., University of Massachusetts Amherst, United States; Gupta A., University of Massachusetts Amherst, United States; Zhang R., Adobe Research, United States; Agarwal S., Adobe Research, United States; Bagga K., Adobe Research, United States; Yoon S., Adobe Research, United States; Lipka N., Adobe Research, United States; Rossi R.A., Adobe Research, United States; Dernoncourt F., Adobe Research, United States","Question-answering for domain-specific applications has recently attracted much interest due to the latest advancements in large language models (LLMs). However, accurately assessing the performance of these applications remains a challenge, mainly due to the lack of suitable benchmarks that effectively simulate real-world scenarios. To address this challenge, we introduce two product question-answering (QA) datasets focused on Adobe Acrobat and Photoshop products to help evaluate the performance of existing models on domain-specific product QA tasks. Additionally, we propose a novel knowledge-driven RAG-QA framework to enhance the performance of the models in the product QA task. Our experiments demonstrated that inducing domain knowledge through query reformulation allowed for increased retrieval and generative performance when compared to standard RAG-QA methods. This improvement, however, is slight, and thus illustrates the challenge posed by the datasets introduced. © 2024 Association for Computational Linguistics.","","Computational linguistics; Domain Knowledge; Structured Query Language; Adobe Acrobat; Adobe Photoshop; Domain specific; Domain-specific application; Language model; Performance; Question Answering; Question Answering Task; Real-world scenario; Two-product; Question answering","Yu W.; Shi W.; Yasunaga M.; Jiang M.; Zhu C.; Hajishirzi H.; Zettlemoyer L.; Zhang Z.","Association for Computational Linguistics (ACL)","English","Conference paper","Final","","Scopus","2-s2.0-85204882587"
"Dimmelmeier A.; Doll H.C.; Schierholz M.; Kormanyos E.; Fehr M.; Ma B.; Beck J.; Fraser A.; Kreuter F.","Dimmelmeier, Andreas (57199235901); Doll, Hendrik Christian (59335881300); Schierholz, Malte (57194510066); Kormanyos, Emily (59336208400); Fehr, Maurice (59335881400); Ma, Bolei (57953025400); Beck, Jacob (57802887300); Fraser, Alexander (59335881500); Kreuter, Frauke (23034899700)","57199235901; 59335881300; 57194510066; 59336208400; 59335881400; 57953025400; 57802887300; 59335881500; 23034899700","Informing climate risk analysis using textual information – A research agenda","2024","ClimateNLP 2024 - 1st Workshop on Natural Language Processing Meets Climate Change, Proceedings of the Workshop","","","","12","26","14","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204450168&partnerID=40&md5=12934b95fec86615d3c562bd5e219e3d","Ludwig-Maximilians-University Munich, Germany; Deutsche Bundesbank, Germany; Goethe University Frankfurt, Germany; Munich Center for Machine Learning (MCML), Germany; Technical University of Munich, Germany; University of Maryland, College Park, United States","Dimmelmeier A., Ludwig-Maximilians-University Munich, Germany; Doll H.C., Deutsche Bundesbank, Germany; Schierholz M., Ludwig-Maximilians-University Munich, Germany; Kormanyos E., Deutsche Bundesbank, Germany, Goethe University Frankfurt, Germany; Fehr M., Deutsche Bundesbank, Germany; Ma B., Ludwig-Maximilians-University Munich, Germany, Munich Center for Machine Learning (MCML), Germany; Beck J., Ludwig-Maximilians-University Munich, Germany, Munich Center for Machine Learning (MCML), Germany; Fraser A., Munich Center for Machine Learning (MCML), Germany, Technical University of Munich, Germany; Kreuter F., Ludwig-Maximilians-University Munich, Germany, Munich Center for Machine Learning (MCML), Germany, University of Maryland, College Park, United States","We present a research agenda focused on efficiently extracting, assuring quality, and consolidating textual company sustainability information to address urgent climate change decision-making needs. Starting from the goal to create integrated FAIR (Findable, Accessible, Interoperable, Reusable) climate-related data, we identify research needs pertaining to the technical aspects of information extraction as well as to the design of the integrated sustainability datasets that we seek to compile. Regarding extraction, we leverage technological advancements, particularly in large language models (LLMs) and Retrieval-Augmented Generation (RAG) pipelines, to unlock the underutilized potential of unstructured textual information contained in corporate sustainability reports. In applying these techniques, we review key challenges, which include the retrieval and extraction of CO2 emission values from PDF documents, especially from unstructured tables and graphs therein, and the validation of automatically extracted data through comparisons with human-annotated values. We also review how existing use cases and practices in climate risk analytics relate to choices of what textual information should be extracted and how it could be linked to existing structured data. ©2024 Association for Computational Linguistics.","","Corporate sustainability reports; Decisions makings; Language model; Research agenda; Research needs; Risk analyze; Sustainability informations; Technical aspects; Technological advancement; Textual information","Stammbach D.; Ni J.; Schimanski T.; Dutia K.; Singh A.; Bingler J.; Christiaen C.; Kushwaha N.; Muccione V.; Vaghefi S.A.; Leippold M.","Association for Computational Linguistics (ACL)","English","Conference paper","Final","","Scopus","2-s2.0-85204450168"
"Hsieh C.-Y.; Chuang Y.-S.; Li C.-L.; Wang Z.; Le L.T.; Kumar A.; Glass J.; Ratner A.; Lee C.-Y.; Krishna R.; Pfister T.","Hsieh, Cheng-Yu (57218718570); Chuang, Yung-Sung (57220723839); Li, Chun-Liang (57192255448); Wang, Zifeng (57215324239); Le, Long T. (57219794184); Kumar, Abhishek (58493374200); Glass, James (7201603693); Ratner, Alexander (57190406673); Lee, Chen-Yu (57219741997); Krishna, Ranjay (57141831300); Pfister, Tomas (36598926300)","57218718570; 57220723839; 57192255448; 57215324239; 57219794184; 58493374200; 7201603693; 57190406673; 57219741997; 57141831300; 36598926300","Found in the middle: Calibrating Positional Attention Bias Improves Long Context Utilization","2024","Proceedings of the Annual Meeting of the Association for Computational Linguistics","","","","14982","14995","13","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205313219&partnerID=40&md5=2563444da596a038ef683f7d22ee6682","University of Washington, United States; MIT, United States; Google Cloud AI Research, United States; Google, United States","Hsieh C.-Y., University of Washington, United States; Chuang Y.-S., MIT, United States; Li C.-L., Google Cloud AI Research, United States; Wang Z., Google Cloud AI Research, United States; Le L.T., Google Cloud AI Research, United States; Kumar A., Google, United States; Glass J., MIT, United States; Ratner A., University of Washington, United States; Lee C.-Y., Google Cloud AI Research, United States; Krishna R., University of Washington, United States; Pfister T., Google Cloud AI Research, United States","Large language models (LLMs), even when specifically trained to process long input contexts, struggle to capture relevant information located in the middle of their input. This phenomenon has been known as the lost-in-the-middle problem. In this work, we make three contributions. First, we set out to understand the factors that cause this phenomenon. In doing so, we establish a connection between lost-in-the-middle to LLMs' intrinsic attention bias: LLMs exhibit an U-shaped attention bias where the tokens at the beginning and at the end of its input receive higher attention, regardless of their relevance. Second, we mitigate this positional bias through a calibration mechanism, found-in-the-middle, that allows the model to attend to contexts faithfully according to their relevance, even though when they are in the middle. Third, we show found-in-the-middle not only achieves better performance in locating relevant information within a long context, but also eventually leads to improved retrieval-augmented generation (RAG) performance across various tasks, outperforming existing methods by up to 10 percentage points. These findings open up future directions in understanding LLM attention bias and its potential consequences. © 2024 Association for Computational Linguistics.","","Modeling languages; Natural language processing systems; Language model; Percentage points; Performance; U-shaped; Computational linguistics","Ku L.-W.; Martins A.; Srikumar V.","Association for Computational Linguistics (ACL)","English","Conference paper","Final","","Scopus","2-s2.0-85205313219"
"Zhang L.; Yu Y.; Wang K.; Zhang C.","Zhang, Lingxi (57221157473); Yu, Yue (57218847592); Wang, Kuan (57222982601); Zhang, Chao (56192792200)","57221157473; 57218847592; 57222982601; 56192792200","ARL2: Aligning Retrievers for Black-box Large Language Models via Self-guided Adaptive Relevance Labeling","2024","Proceedings of the Annual Meeting of the Association for Computational Linguistics","1","","","3708","3719","11","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204480629&partnerID=40&md5=91b700fc117fc49799db972b9395d4a9","Renmin University of China, Beijing, China; Georgia Institute of Technology, Atlanta, United States","Zhang L., Renmin University of China, Beijing, China; Yu Y., Georgia Institute of Technology, Atlanta, United States; Wang K., Georgia Institute of Technology, Atlanta, United States; Zhang C., Georgia Institute of Technology, Atlanta, United States","Retrieval-augmented generation enhances large language models (LLMs) by incorporating relevant information from external knowledge sources. This enables LLMs to adapt to specific domains and mitigate hallucinations in knowledge-intensive tasks. However, existing retrievers are often misaligned with LLMs due to their separate training processes and the black-box nature of LLMs. To address this challenge, we propose ARL2, a retriever learning technique that harnesses LLMs as labelers. ARL2 leverages LLMs to annotate and score relevance evidence, enabling learning the retriever from robust LLM supervision. Furthermore, ARL2 uses a adaptive self-training strategy for curating high-quality and diverse relevance data, which can effectively reduce the annotation cost. Extensive experiments demonstrate the effectiveness of ARL2, achieving accuracy improvements of 5.4% on NQ and 4.6% on MMLU compared to the state-ofthe-art methods. Additionally, ARL2 exhibits robust transfer learning capabilities and strong zero-shot generalization abilities. © 2024 Association for Computational Linguistics.","","Adversarial machine learning; Computational linguistics; Contrastive Learning; Federated learning; Modeling languages; Self-supervised learning; Transfer learning; Black boxes; External knowledge; Knowledge intensive tasks; Knowledge sources; Labelings; Language model; Learning techniques; Self-training; Training process; Training strategy; Zero-shot learning","Ku L.-W.; Martins A.F.T.; Srikumar V.","Association for Computational Linguistics (ACL)","English","Conference paper","Final","","Scopus","2-s2.0-85204480629"
"Yu J.; Zhou J.; Ding Y.; Zhang L.; Guo Y.; Sato H.","Yu, Junwei (58627185700); Zhou, Jieyu (59329255300); Ding, Yepeng (57219342107); Zhang, Lingfeng (57211678194); Guo, Yuheng (57383188700); Sato, Hiroyuki (55515628400)","58627185700; 59329255300; 57219342107; 57211678194; 57383188700; 55515628400","Textual Differential Privacy for Context-Aware Reasoning with Large Language Model","2024","Proceedings - 2024 IEEE 48th Annual Computers, Software, and Applications Conference, COMPSAC 2024","","","","988","997","9","0","10.1109/COMPSAC61105.2024.00135","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204095059&doi=10.1109%2fCOMPSAC61105.2024.00135&partnerID=40&md5=976caf22fb9ad31953bbc2cd11a228ba","The University of Tokyo, Tokyo, Japan; Tokyo, Japan; Hiroshima University, Hiroshima, Japan; National Institute of Informatics, The University of Tokyo, Tokyo, Japan","Yu J., The University of Tokyo, Tokyo, Japan; Zhou J., Tokyo, Japan; Ding Y., Hiroshima University, Hiroshima, Japan; Zhang L., The University of Tokyo, Tokyo, Japan; Guo Y., The University of Tokyo, Tokyo, Japan; Sato H., National Institute of Informatics, The University of Tokyo, Tokyo, Japan","Large language models (LLMs) have demonstrated proficiency in various language tasks but encounter difficulties in specific domain or scenario. These challenges are mitigated through prompt engineering techniques such as retrieval-augmented generation, which improves performance by integrating contextual information. However, concerns regarding the privacy implications of context-aware reasoning architectures persist, particularly regarding the transmission of sensitive data to LLMs service providers, potentially compromising personal privacy. To mitigate these challenges, this paper introduces Tex-tual Differential Privacy, a novel paradigm aimed at safeguarding user privacy in LLMs-based context-aware reasoning. The proposed Differential Embedding Hash algorithm anonymizes sensitive information while maintaining the reasoning capability of LLMs. Additionally, a quantification scheme for privacy loss is proposed to better understand the trade-off between privacy protection and loss. Through rigorous analysis and experimentation, the effectiveness and robustness of the proposed paradigm in mitigating privacy risks associated with context-aware reasoning tasks are demonstrated. This paradigm addresses privacy concerns in context-aware reasoning architectures, enhancing the trust and utility of LLMs in various applications.  © 2024 IEEE.","Context-Aware Reasoning; Differential Privacy; Large Language Model; Named -Entity Recognition; Retrieval-Augmented Generation","Anonymity; Context-Aware; Context-aware reasoning; Contextual information; Differential privacies; Engineering techniques; Improve performance; Language model; Large language model; Named entity recognition; Retrieval-augmented generation; Differential privacy","Shahriar H.; Ohsaki H.; Sharmin M.; Towey D.; Majumder AKM.J.A.; Hori Y.; Yang J.-J.; Takemoto M.; Sakib N.; Banno R.; Ahamed S.I.","Institute of Electrical and Electronics Engineers Inc.","English","Conference paper","Final","","Scopus","2-s2.0-85204095059"
"Chen X.; He B.; Lin H.; Han X.; Wang T.; Cao B.; Sun L.; Sun Y.","Chen, Xiaoyang (57218700905); He, Ben (8845565100); Lin, Hongyu (57207858382); Han, Xianpei (35302334000); Wang, Tianshu (57219898920); Cao, Boxi (57225220772); Sun, Le (55453689000); Sun, Yingfei (56174853700)","57218700905; 8845565100; 57207858382; 35302334000; 57219898920; 57225220772; 55453689000; 56174853700","Spiral of Silence: How is Large Language Model Killing Information Retrieval?-A Case Study on Open Domain Question Answering","2024","Proceedings of the Annual Meeting of the Association for Computational Linguistics","1","","","14930","14951","21","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204441168&partnerID=40&md5=0aec379790420c4ea0344a319a3b47ea","University of Chinese Academy of Sciences, China; Chinese Information Processing Laboratory, Institute of Software, Chinese Academy of Sciences, China; Hangzhou Institute for Advanced Study, University of Chinese Academy of Sciences, China","Chen X., University of Chinese Academy of Sciences, China, Chinese Information Processing Laboratory, Institute of Software, Chinese Academy of Sciences, China; He B., University of Chinese Academy of Sciences, China; Lin H., Chinese Information Processing Laboratory, Institute of Software, Chinese Academy of Sciences, China; Han X., Chinese Information Processing Laboratory, Institute of Software, Chinese Academy of Sciences, China; Wang T., Chinese Information Processing Laboratory, Institute of Software, Chinese Academy of Sciences, China, Hangzhou Institute for Advanced Study, University of Chinese Academy of Sciences, China; Cao B., University of Chinese Academy of Sciences, China, Chinese Information Processing Laboratory, Institute of Software, Chinese Academy of Sciences, China; Sun L., Chinese Information Processing Laboratory, Institute of Software, Chinese Academy of Sciences, China; Sun Y., University of Chinese Academy of Sciences, China","The practice of Retrieval-Augmented Generation (RAG), which integrates Large Language Models (LLMs) with retrieval systems, has become increasingly prevalent. However, the repercussions of LLM-derived content infiltrating the web and influencing the retrieval-generation feedback loop are largely uncharted territories. In this study, we construct and iteratively run a simulation pipeline to deeply investigate the short-term and long-term effects of LLM text on RAG systems. Taking the trending Open Domain Question Answering (ODQA) task as a point of entry, our findings reveal a potential digital “Spiral of Silence” effect, with LLM-generated text consistently outperforming human-authored content in search rankings, thereby diminishing the presence and impact of human contributions online. This trend risks creating an imbalanced information ecosystem, where the unchecked proliferation of erroneous LLM-generated content may result in the marginalization of accurate information. We urge the academic community to take heed of this potential issue, ensuring a diverse and authentic digital information landscape. © 2024 Association for Computational Linguistics.","","Computational linguistics; Content based retrieval; Digital elevation model; Modeling languages; Case-studies; Feedback loops; Generation systems; Information ecosystems; Language model; Long-term effects; Open domain question answering; Point of entries; Question Answering Task; Retrieval systems; Question answering","Ku L.-W.; Martins A.F.T.; Srikumar V.","Association for Computational Linguistics (ACL)","English","Conference paper","Final","","Scopus","2-s2.0-85204441168"
"Maged S.; Elmaghraby A.; Marzban A.; Essawey M.; Ahmed A.; Negm E.; Gomaa W.H.","Maged, Samaa (59334173000); Elmaghraby, Asmaa (58991370400); Marzban, Ali (59334045100); Essawey, Mohamed (59334173100); Ahmed, Amira (59334173200); Negm, Esraa (59333768500); Gomaa, Wael H. (55847606700)","59334173000; 58991370400; 59334045100; 59334173100; 59334173200; 59333768500; 55847606700","HistoryQuest: Arabic Question Answering in Egyptian History with LLM Fine-Tuning and Transformer Models","2024","2nd International Conference of Intelligent Methods, Systems and Applications, IMSA 2024","","","","135","140","5","0","10.1109/IMSA61967.2024.10652824","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204365140&doi=10.1109%2fIMSA61967.2024.10652824&partnerID=40&md5=47624099ddc6fbfdca685e795edc3c39","School of Information Technology and Computer Science (ITCS), Nile University, Artificial Intelligence Program, Giza, Egypt; Beni-Suef University, Faculty of Computers and Artificial Intelligence, Egypt","Maged S., School of Information Technology and Computer Science (ITCS), Nile University, Artificial Intelligence Program, Giza, Egypt; Elmaghraby A., School of Information Technology and Computer Science (ITCS), Nile University, Artificial Intelligence Program, Giza, Egypt; Marzban A., School of Information Technology and Computer Science (ITCS), Nile University, Artificial Intelligence Program, Giza, Egypt; Essawey M., School of Information Technology and Computer Science (ITCS), Nile University, Artificial Intelligence Program, Giza, Egypt; Ahmed A., School of Information Technology and Computer Science (ITCS), Nile University, Artificial Intelligence Program, Giza, Egypt; Negm E., School of Information Technology and Computer Science (ITCS), Nile University, Artificial Intelligence Program, Giza, Egypt; Gomaa W.H., Beni-Suef University, Faculty of Computers and Artificial Intelligence, Egypt","Question answering (QA) in Egyptian history presents a unique and complex challenge for Arabic natural language processing (NLP). This study aims to explore and assess how large language models (LLMs) can enhance the accuracy and performance of Arabic question answering (QA), specifically in this domain. To conduct this investigation, we utilize two comprehensive datasets: the Arabic History-QA dataset and the Contextual Articles Dataset, which cover pivotal historical periods. We evaluate transformer-based models, including AraBERTv2, BERT-large-Arabic with Retrieval-Augmented Generation (RAG), fine-tuned LLaMa-2, and zero-shot LLaMa-3 with Retrieval-Augmented Generation (RAG). Through a rigorous and detailed evaluation process, we analyze how these models address various questions related to Egyptian history. This research contributes valuable insights into advancing the capabilities of Arabic NLP in specialized domains such as historical question answering. Our best results, summarized as the superiority of LLMs, beat those with transformers; additionally, the RAG significantly raised the performance level overall.  © 2024 IEEE.","Arabic Question Answering(AQA); Large Language Models(LLMs); Natural Language Processing(NLP); Question Answering(QA); Retrieval Augmented Generation (RAG)","Large datasets; Natural language processing systems; Arabic question answering; Egyptians; Language model; Language processing; Large language model; Natural language processing; Natural languages; Question Answering; Retrieval augmented generation; Question answering","","Institute of Electrical and Electronics Engineers Inc.","English","Conference paper","Final","","Scopus","2-s2.0-85204365140"
"","","","Proceedings of the 2024 AAAI Conference on Artificial Intelligence","2024","Proceedings of Machine Learning Research","257","","","","","169","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203829053&partnerID=40&md5=03c425dfd05b375a2763743c28f0c36b","","","The proceedings contain 17 papers. The topics discussed include: learning to compare hints: combining insights from student logs and large language models; current evaluation methods are a bottleneck in automatic question generation; challenges and opportunities of moderating usage of large language models in education; evaluation of the instance weighting strategy for transfer learning of educational predictive models; exploring the relationship between feature attribution methods and model performance; concept prerequisite relation prediction by using permutation-equivariant directed graph neural networks; problem-solving guide (PSG): predicting the algorithm tags and difficulty for competitive programming problems; and improving assessment of tutoring practices using retrieval-augmented generation.","","","Ananda M.; Malick D.B.; Burstein J.; Liu L.T.; Liu Z.; Sharpnack J.; Wang Z.; Wang S.","ML Research Press","English","Conference review","Final","","Scopus","2-s2.0-85203829053"
"","","","KnowLLM 2024 - 1st Workshop on Towards Knowledgeable Language Models, Proceedings of the Workshop","2024","KnowLLM 2024 - 1st Workshop on Towards Knowledgeable Language Models, Proceedings of the Workshop","","","","","","211","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204904251&partnerID=40&md5=dfebedd156b2fd9e9827b3c0f7da4388","","","The proceedings contain 16 papers. The topics discussed include: PhonologyBench: evaluating phonological skills of large language models; is your large language model knowledgeable or a choices-only cheater?; reassess summary factual inconsistency detection with large language model; retrieval-augmented knowledge integration into language models: a survey; modeling uncertainty and using post-fusion as fallback improves retrieval augmented generation with LLMs; AcKnowledge: acquired knowledge representation by small language model without pre-training; beyond probabilities: unveiling the misalignment in evaluating large language models; patent response system optimized for faithfulness: procedural knowledge embodiment with knowledge graph and retrieval augmented generation; and retrieve, generate, evaluate: a case study for medical paraphrases generation with small language models.","","","Li S.; Li M.; Zhang M.J.Q.; Choi E.; Geva M.; Hase P.; Ji H.","Association for Computational Linguistics (ACL)","English","Conference review","Final","","Scopus","2-s2.0-85204904251"
"","","","LLM4Eval 2024 - Proceedings of the 1st Workshop on Large Language Models for Evaluation in Information Retrieval, co-located with 10th International Conference on Online Publishing, SIGIR 2024","2024","CEUR Workshop Proceedings","3752","","","","","126","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203819017&partnerID=40&md5=f0618222b7993c464e7d9f0a2f1d13bf","","","The proceedings contain 8 papers. The topics discussed include: the challenges of evaluating LLM applications: an analysis of automated, human, and LLM-based approaches; exploring large language models for relevance judgments in Tetun; EXAM++: LLM-based answerability metrics for IR evaluation; a novel evaluation framework for image2text generation; using LLMs to investigate correlations of conversational follow-up queries with user satisfaction; evaluating RAG-fusion with RAGElo: an automated Elo-based framework; and toward automatic relevance judgment using vision-language models for image-text retrieval evaluation.","","","Siro C.; Aliannejadi M.; Rahmani H.A.; Craswell N.; Clarke C.L.A.; Faggioli G.; Mitra B.; Thomas P.; Yilmaz E.; Yilmaz E.","CEUR-WS","English","Conference review","Final","","Scopus","2-s2.0-85203819017"
"Zhao X.; Zhou X.; Li G.","Zhao, Xinyang (57353885000); Zhou, Xuanhe (57211583553); Li, Guoliang (55800543300)","57353885000; 57211583553; 55800543300","Chat2Data: An Interactive Data Analysis System with RAG, Vector Databases and LLMs","2024","Proceedings of the VLDB Endowment","17","12","","4481","4484","3","1","10.14778/3685800.3685905","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205322046&doi=10.14778%2f3685800.3685905&partnerID=40&md5=c404ee0a60965b706bd8e6328a7cb6e5","Tsinghua University, Beijing, China","Zhao X., Tsinghua University, Beijing, China; Zhou X., Tsinghua University, Beijing, China; Li G., Tsinghua University, Beijing, China","Traditional data analysis methods require users to write programming codes or issue SQL queries to analyze the data, which are inconvenient for ordinary users. Large language models (LLMs) can alleviate these limitations by enabling users to interact with the data with natural language (NL), e.g., result retrieval and summarization for unstructured data and transforming the NL text to SQL queries or codes for structured data. However, existing LLMs have three limitations: hallucination (due to lacking domain knowledge for vertical domains), high cost for LLM reasoning, and low accuracy for complicated tasks. To address these problems, we propose a prototype, Chat2Data, to interactively analyze the data with natural language. Chat2Data adopts a three-layer method, where the first layer uses Retrieval-Augmented Generation (RAG) to embed domain knowledge in order to address the hallucination problem, the second layer utilizes vector databases to reduce the number of interactions with LLMs so as to improve the performance, and the third layer designs a pipeline agent to decompose a complex task to multiple subtasks and use multiple round reasoning to generate the results in order to improve the accuracy of LLMs. We demonstrate Chat2Data with two real scenarios, unstructured data retrieval and summarization, and natural language-based structured data analysis. The online demo is available at http://vdemo.dbmind.cn. © 2024, VLDB Endowment. All rights reserved.","","Data accuracy; Data Analytics; Data assimilation; Modeling languages; Natural language processing systems; Pipeline codes; Problem oriented languages; Query languages; Data analysis system; Data analysis-methods; Domain knowledge; Interactive data analysis; Language model; Natural languages; Programming codes; SQL query; Structured data; Unstructured data; Structured Query Language","Fan J.; Cao Y.; Ding X.","VLDB Endowment","English","Conference paper","Final","","Scopus","2-s2.0-85205322046"
"Nai R.; Sulis E.; Fatima I.; Meo R.","Nai, Roberto (57889262400); Sulis, Emilio (56611749600); Fatima, Ishrat (57220115545); Meo, Rosa (7005599926)","57889262400; 56611749600; 57220115545; 7005599926","Large Language Models and Recommendation Systems: A Proof-of-Concept Study on Public Procurements","2024","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","14763 LNCS","","","280","290","10","0","10.1007/978-3-031-70242-6_27","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205480566&doi=10.1007%2f978-3-031-70242-6_27&partnerID=40&md5=0b7d5361fa84b56d54af20b077b95c6f","Computer Science Department, University of Turin, Turin, Italy","Nai R., Computer Science Department, University of Turin, Turin, Italy; Sulis E., Computer Science Department, University of Turin, Turin, Italy; Fatima I., Computer Science Department, University of Turin, Turin, Italy; Meo R., Computer Science Department, University of Turin, Turin, Italy","In legal informatics research, decision support systems can be a valuable tool for practitioners facing a growing volume of data. An expert system based on information retrieval and a recommender system can benefit from the application of Large Language Models to improve the quality of results. This paper proposes a general framework based on Retrieval-Augmented Generation for addressing integrated recommendation systems with generative models in public procurement. Moreover, we addressed a practical application by adopting real datasets in the legal domain. To illustrate the feasibility of the approach, a proof-of-concept has been presented in the context of public procurement management within an Italian case study. The study and evaluation phases have been supervised by domain experts in the legal field to ensure robust analysis and relevance.  © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.","Information Retrevial; Large Language Models applications; Public Procurements","Recommender systems; Concept studies; Decision supports; Informatics research; Information retrevial; Language model; Large language model application; Legal informatics; Model application; Proof of concept; Public procurement; Expert systems","Rapp A.; Di Caro L.; Meziane F.; Sugumaran V.","Springer Science and Business Media Deutschland GmbH","English","Conference paper","Final","","Scopus","2-s2.0-85205480566"
"Guo R.; Farnan G.; McLaughlin N.; Devereux B.","Guo, Rui (59196857700); Farnan, Greg (59196857800); McLaughlin, Niall (55311476600); Devereux, Barry (10044388300)","59196857700; 59196857800; 55311476600; 10044388300","QUB-Cirdan at “Discharge Me!”: Zero shot discharge letter generation by open-source LLM","2024","BioNLP 2024 - 23rd Meeting of the ACL Special Interest Group on Biomedical Natural Language Processing, Proceedings of the Workshop and Shared Tasks","","","","664","674","10","1","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204459806&partnerID=40&md5=a6e7e4f84a7f1500fe768ac86374cc5c","Queen’s University Belfast, United Kingdom; Cirdan","Guo R., Queen’s University Belfast, United Kingdom, Cirdan; Farnan G., Cirdan; McLaughlin N., Queen’s University Belfast, United Kingdom; Devereux B., Queen’s University Belfast, United Kingdom","The BioNLP ACL’24 Shared Task on Streamlining Discharge Documentation aims to reduce the administrative burden on clinicians by automating the creation of critical sections of patient discharge letters. This paper presents our approach using the Llama3 8B quantized model to generate the “Brief Hospital Course” and “Discharge Instructions” sections. We employ a zero-shot method combined with Retrieval-Augmented Generation (RAG) to produce concise, contextually accurate summaries. Our contributions include the development of a curated template-based approach to ensure reliability and consistency, as well as the integration of RAG for word count prediction. We also describe several unsuccessful experiments to provide insights into our pathway for the competition. Our results demonstrate the effectiveness and efficiency of our approach, achieving high scores across multiple evaluation metrics.. ©2024 Association for Computational Linguistics.","","Open source software; Open systems; Administrative burdens; Critical sections; Discharge letters; Effectiveness and efficiencies; Evaluation metrics; Open-source; Patient discharge; Quantized models; Template-based approaches; Computational linguistics","Demner-Fushman D.; Ananiadou S.; Miwa M.; Roberts K.; Tsujii J.","Association for Computational Linguistics (ACL)","English","Conference paper","Final","","Scopus","2-s2.0-85204459806"
"Ang Y.; Bao Y.; Huang Q.; Tung A.K.H.; Huang Z.","Ang, Yihao (57219663845); Bao, Yifan (58620327900); Huang, Qiang (57704521600); Tung, Anthony K. H. (57204929410); Huang, Zhiyong (9269381800)","57219663845; 58620327900; 57704521600; 57204929410; 9269381800","TSGAssist: An Interactive Assistant Harnessing LLMs and RAG for Time Series Generation Recommendations and Benchmarking","2024","Proceedings of the VLDB Endowment","17","12","","4309","4312","3","0","10.14778/3685800.3685862","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205316567&doi=10.14778%2f3685800.3685862&partnerID=40&md5=de53c60c6464fe15b9ccf82f7f8a6fd9","National University of Singapore, Singapore; NUS Research Institute in Chongqing, China","Ang Y., National University of Singapore, Singapore, NUS Research Institute in Chongqing, China; Bao Y., National University of Singapore, Singapore; Huang Q., National University of Singapore, Singapore; Tung A.K.H., National University of Singapore, Singapore; Huang Z., National University of Singapore, Singapore, NUS Research Institute in Chongqing, China","Time Series Generation (TSG) is essential in many industries for generating synthetic data that mirrors real-world characteristics. TSGBench has advanced the field by offering comprehensive evaluations and unique insights for selecting suitable TSG methods. However, translating these advancements to industry applications is hindered by a cognitive gap among professionals and the absence of a dynamic platform for method comparison and evaluation. To address these issues, we introduce TSGAssist, an interactive assistant that integrates the strengths of TSGBench and harnesses Large Language Models (LLMs) and Retrieval-Augmented Generation (RAG) for TSG recommendations and benchmarking. Our demonstration highlights its effectiveness in (1) enhancing TSG understanding, (2) providing industry-specific recommendations, and (3) offering a comprehensive benchmarking platform, illustrating its potential to ease industry professionals’ navigation through the TSG landscape and encourage broader application across industries. © 2024, VLDB Endowment. All rights reserved.","","Cognitive gap; Comprehensive evaluation; Generation method; Industry applications; Language model; Method comparison; Method evaluation; Real-world; Synthetic data; Time-series generation; Benchmarking","Fan J.; Cao Y.; Ding X.","VLDB Endowment","English","Conference paper","Final","","Scopus","2-s2.0-85205316567"
"Fernandez N.; Scarlatos A.; Lan A.","Fernandez, Nigel (57219754915); Scarlatos, Alexander (57221354237); Lan, Andrew (55967012900)","57219754915; 57221354237; 55967012900","SYLLABUSQA: A Course Logistics Question Answering Dataset","2024","Proceedings of the Annual Meeting of the Association for Computational Linguistics","1","","","10344","10369","25","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204472440&partnerID=40&md5=64a8937101788eda5653e67525600345","University of Massachusetts Amherst, United States","Fernandez N., University of Massachusetts Amherst, United States; Scarlatos A., University of Massachusetts Amherst, United States; Lan A., University of Massachusetts Amherst, United States","Automated teaching assistants and chatbots have significant potential to reduce the workload of human instructors, especially for logistics-related question answering, which is important to students yet repetitive for instructors. However, due to privacy concerns, there is a lack of publicly available datasets. We introduce SYLLABUSQA, an open-source dataset with 63 real course syllabi covering 36 majors, containing 5, 078 open-ended course logistics-related question-answer pairs that are diverse in both question types and answer formats. Since many logistics-related questions contain critical information like the date of an exam, it is important to evaluate the factuality of answers. We benchmark several strong baselines on this task, from large language model prompting to retrieval-augmented generation. We introduce Fact-QA, an LLM-based (GPT-4) evaluation metric to evaluate the factuality of predicted answers. We find that despite performing close to humans on traditional metrics of textual similarity, there remains a significant gap between automated approaches and humans in terms of fact precision. © 2024 Association for Computational Linguistics.","","Curricula; Teaching; Chatbots; Evaluation metrics; Language model; Open-source; Privacy concerns; Question Answering; Question type; Question-answer pairs; Teaching assistants; Textual similarities; Computational linguistics","Ku L.-W.; Martins A.F.T.; Srikumar V.","Association for Computational Linguistics (ACL)","English","Conference paper","Final","","Scopus","2-s2.0-85204472440"
"Nguyen V.; Karimi S.; Hallgren W.; Harkin A.; Prakash M.","Nguyen, Vincent (57203492979); Karimi, Sarvnaz (35302172500); Hallgren, Willow (55131452100); Harkin, Ashley (59335879300); Prakash, Mahesh (7101767972)","57203492979; 35302172500; 55131452100; 59335879300; 7101767972","My Climate Advisor: An Application of NLP in Climate Adaptation for Agriculture","2024","ClimateNLP 2024 - 1st Workshop on Natural Language Processing Meets Climate Change, Proceedings of the Workshop","","","","27","45","18","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204439657&partnerID=40&md5=77ba849127c1ef47344eef4bc5e39a70","CSIRO Data61, Australia; CSIRO Agriculture and Food, Australia; Bureau of Meteorology, Australia","Nguyen V., CSIRO Data61, Australia; Karimi S., CSIRO Data61, Australia; Hallgren W., CSIRO Agriculture and Food, Australia; Harkin A., Bureau of Meteorology, Australia; Prakash M., CSIRO Data61, Australia","Climate adaptation in the agricultural sector necessitates tools that equip farmers and farm advisors with relevant and trustworthy information to help increase their resilience to climate change. We introduce My Climate Advisor, a question-answering (QA) prototype that synthesises information from different data sources, such as peer-reviewed scientific literature and high-quality, industry-relevant grey literature to generate answers, with references, to a given user’s question. Our prototype uses open-source generative models for data privacy and intellectual property protection, and retrieval augmented generation for answer generation, grounding and provenance. While there are standard evaluation metrics for QA systems, no existing evaluation framework suits our LLM-based QA application in the climate adaptation domain. We design an evaluation framework with seven metrics based on the requirements of the domain experts to judge the generated answers from 12 different LLM-based models. Our initial evaluations through a user study via domain experts show promising usability results. ©2024 Association for Computational Linguistics.","","Agricultural sector; Data-source; Domain experts; Evaluation framework; Generative model; Grey literature; High quality; Open-source; Question Answering prototypes; Scientific literature","Stammbach D.; Ni J.; Schimanski T.; Dutia K.; Singh A.; Bingler J.; Christiaen C.; Kushwaha N.; Muccione V.; Vaghefi S.A.; Leippold M.","Association for Computational Linguistics (ACL)","English","Conference paper","Final","","Scopus","2-s2.0-85204439657"
"Rogiers A.; Buyl M.; Kang B.; De Bie T.","Rogiers, Alexander (59137140800); Buyl, Maarten (57219760714); Kang, Bo (55925980400); De Bie, Tijl (57203775071)","59137140800; 57219760714; 55925980400; 57203775071","KamerRaad: Enhancing Information Retrieval in Belgian National Politics Through Hierarchical Summarization and Conversational Interfaces","2024","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","14948 LNAI","","","409","412","3","0","10.1007/978-3-031-70371-3_30","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203873484&doi=10.1007%2f978-3-031-70371-3_30&partnerID=40&md5=9aca1b0cd865bda0151dc6fb4927a60a","Ghent University, Ghent, Belgium","Rogiers A., Ghent University, Ghent, Belgium; Buyl M., Ghent University, Ghent, Belgium; Kang B., Ghent University, Ghent, Belgium; De Bie T., Ghent University, Ghent, Belgium","KamerRaad is an AI tool that leverages large language models to help citizens interactively engage with Belgian political information. The tool extracts and concisely summarizes key excerpts from parliamentary proceedings, followed by the potential for interaction based on generative AI that allows users to steadily build up their understanding. KamerRaad’s front-end, built with Streamlit, facilitates easy interaction, while the back-end employs open-source models for text embedding and generation to ensure accurate and relevant responses. By collecting feedback, we intend to enhance the relevancy of our source retrieval and the quality of our summarization, thereby enriching the user experience with a focus on source-driven dialogue. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.","Information Retrieval; Large Language Models; Retrieval-Augmented Generation","Conversational interface; Embeddings; Front end; Hierarchical summarization; Language model; Large language model; Open-source model; Parliamentary proceedings; Political information; Retrieval-augmented generation; Open systems","Bifet A.; Daniušis P.; Davis J.; Krilavičius T.; Kull M.; Ntoutsi E.; Puolamäki K.; Žliobaitė I.","Springer Science and Business Media Deutschland GmbH","English","Conference paper","Final","","Scopus","2-s2.0-85203873484"
"Wu R.; Chen S.; Su X.; Zhu Y.; Liao Y.; Wu J.","Wu, Ridong (59181328800); Chen, Shuhong (36670848600); Su, Xiangbiao (59181478500); Zhu, Yuankai (59181627000); Liao, Yifei (59181527000); Wu, Jianming (58940067700)","59181328800; 36670848600; 59181478500; 59181627000; 59181527000; 58940067700","A Multi-Source Retrieval Question Answering Framework Based on RAG","2024","2024 5th International Conference on Information Science, Parallel and Distributed Systems, ISPDS 2024","","","","644","647","3","0","10.1109/ISPDS62779.2024.10667535","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205245471&doi=10.1109%2fISPDS62779.2024.10667535&partnerID=40&md5=bd8c782c1e02f688e06bef066d18da19","Guangzhou University, School of Computer Science and Network Engineering, Guangzhou, China","Wu R., Guangzhou University, School of Computer Science and Network Engineering, Guangzhou, China; Chen S., Guangzhou University, School of Computer Science and Network Engineering, Guangzhou, China; Su X., Guangzhou University, School of Computer Science and Network Engineering, Guangzhou, China; Zhu Y., Guangzhou University, School of Computer Science and Network Engineering, Guangzhou, China; Liao Y., Guangzhou University, School of Computer Science and Network Engineering, Guangzhou, China; Wu J., Guangzhou University, School of Computer Science and Network Engineering, Guangzhou, China","With the rapid development of large-scale language models, Retrieval-Augmented Generation (RAG) has been widely adopted. However, existing RAG paradigms are inevitably influenced by erroneous retrieval information, thereby reducing the reliability and correctness of generated results. Therefore, to improve the relevance of retrieval information, this study proposes a method that replaces traditional retrievers with GPT-3.5, leveraging its vast corpus knowledge to generate retrieval information. We also propose a web retrieval based method to implement fine-grained knowledge retrieval, Utilizing the powerful reasoning capability of GPT-3.5 to realize semantic partitioning of problem. In order to mitigate the illusion of GPT retrieval and reduce noise in Web retrieval, we proposes a multi-source retrieval framework, named MSRAG, which combines GPT retrieval with web retrieval. Experiments on multiple knowledge-intensive QA datasets demonstrate that the proposed framework in this study performs better than existing RAG framework in enhancing the overall efficiency and accuracy of QA systems.  © 2024 IEEE.","GPT Retrieval; Large Language Models; Question-Answering (QA); Retrieval-Augmented Generation; Web Retrieval","Content based retrieval; Semantics; Fine grained; GPT retrieval; Language model; Large language model; Large-scales; Multi-Sources; Question Answering; Question-answering; Retrieval-augmented generation; Web retrieval; Question answering","","Institute of Electrical and Electronics Engineers Inc.","English","Conference paper","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85205245471"
"Ardimento P.; Bernardi M.L.; Cimitile M.","Ardimento, Pasquale (12797261100); Bernardi, Mario Luca (57195515766); Cimitile, Marta (23392132800)","12797261100; 57195515766; 23392132800","Teaching UML using a RAG-based LLM","2024","Proceedings of the International Joint Conference on Neural Networks","","","","","","","0","10.1109/IJCNN60899.2024.10651492","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204965639&doi=10.1109%2fIJCNN60899.2024.10651492&partnerID=40&md5=2508dc5da451cf4309fd1f3dc56313a2","University of Bari Aldo Moro, Dept. of Computer Science, Bari, Italy; University of Sannio, Dept. of Engineering, Benevento, Italy; UnitelmaSapienza University, Dept. of Law and Economics, Rome, Italy","Ardimento P., University of Bari Aldo Moro, Dept. of Computer Science, Bari, Italy; Bernardi M.L., University of Sannio, Dept. of Engineering, Benevento, Italy; Cimitile M., UnitelmaSapienza University, Dept. of Law and Economics, Rome, Italy","Teaching the Unified Modelling Language (UML) is a critical task in the frame of Software Engineering courses. Teachers need to understand the students' behavior along with their modeling activities to provide suggestions and feedback to avoid more frequent mistakes and improve their capabilities. This paper presents a novel approach for teaching the UML in Software Engineering courses, focusing on understanding and improving student behavior and capabilities during modeling activities. It introduces a cloud-based tool that captures and analyzes UML diagrams created by students during their interactions with a UML modeling tool. The key aspect of the proposal is the integration of a Retrieval Augmented Generation Large Language Model (RAG-based LLM), which generates insightful feedback for students by leveraging knowledge acquired during the modeling process.The effectiveness of this method is demonstrated through an experiment involving a substantial dataset comprising 5,120 labeled UML models. The validation process confirms the performance of the UML RAG-based LLM in providing relevant feedback related to entities and relationships in the students' models. Additionally, a qualitative analysis highlights the user satisfaction, underscoring its potential as a valuable tool in enhancing the learning experience in software modeling education. © 2024 IEEE.","Computing Education; Deep Learning; Generative AI; LLMs; Software Modelling; UML","Behavioral research; Computer aided software engineering; Curricula; Students; Teaching; Unified Modeling Language; Computing education; Critical tasks; Deep learning; Generative AI; Language model; LLM; Software engineering course; Software modeling; Students' behaviors; Unified Modeling; Knowledge acquisition","","Institute of Electrical and Electronics Engineers Inc.","English","Conference paper","Final","","Scopus","2-s2.0-85204965639"
"Ying J.; Cao Y.; Xiong K.; He Y.; Cui L.; Liu Y.","Ying, Jiahao (58494129000); Cao, Yixin (57015851100); Xiong, Kai (57331610200); He, Yidong (58662511500); Cui, Long (58662460500); Liu, Yongbin (56496782000)","58494129000; 57015851100; 57331610200; 58662511500; 58662460500; 56496782000","Intuitive or Dependent? Investigating LLMs' Behavior Style to Conflicting Prompts","2024","Proceedings of the Annual Meeting of the Association for Computational Linguistics","1","","","4221","4246","25","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204440140&partnerID=40&md5=a563be6fb5339b6530ce96b32c50787b","Singapore Management University, Singapore; Harbin Institute of Technology, China; University of South China, China","Ying J., Singapore Management University, Singapore; Cao Y., Singapore Management University, Singapore; Xiong K., Harbin Institute of Technology, China; He Y., University of South China, China; Cui L., University of South China, China; Liu Y., University of South China, China","This study investigates the behaviors of Large Language Models (LLMs) when faced with conflicting prompts versus their internal memory. This will not only help to understand LLMs' decision mechanism but also benefit real-world applications, such as retrieval-augmented generation (RAG). Drawing on cognitive theory, we target the first scenario of decision-making styles where there is no superiority in the conflict and categorize LLMs' preference into dependent, intuitive, and rational/irrational styles. Another scenario of factual robustness considers the correctness of prompt and memory in knowledge-intensive tasks, which can also distinguish if LLMs behave rationally or irrationally in the first scenario. To quantify them, we establish a complete benchmarking framework including a dataset, a robustness evaluation pipeline, and corresponding metrics. Extensive experiments with seven LLMs reveal their varying behaviors. And, with role play intervention, we can change the styles, but different models present distinct adaptivity and upper-bound. One of our key takeaways is to optimize models or the prompts according to the identified style. For instance, RAG models with high role play adaptability may dynamically adjust the interventions according to the quality of retrieval results - being dependent to better leverage informative context; and, being intuitive when the external prompt is noisy. Our dataset can be found at https://github.com/yingjiahao14/KRE. © 2024 Association for Computational Linguistics.","","Benchmarking; Decision making; Cognitive theory; Decision mechanism; Decisions makings; Internal memory; Knowledge intensive tasks; Language model; Modeling behaviour; Modeling decisions; Real-world; Role-plays; Computational linguistics","Ku L.-W.; Martins A.F.T.; Srikumar V.","Association for Computational Linguistics (ACL)","English","Conference paper","Final","","Scopus","2-s2.0-85204440140"
"Naeem Z.A.; Ahmad M.S.; Eltabakh M.; Ouzzani M.; Tang N.","Naeem, Zan Ahmad (58179776300); Ahmad, Mohammad Shahmeer (58179911500); Eltabakh, Mohamed (14832475600); Ouzzani, Mourad (8717429400); Tang, Nan (55570310100)","58179776300; 58179911500; 14832475600; 8717429400; 55570310100","RetClean: Retrieval-Based Data Cleaning Using LLMs and Data Lakes","2024","Proceedings of the VLDB Endowment","17","12","","4421","4424","3","0","10.14778/3685800.3685890","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205304772&doi=10.14778%2f3685800.3685890&partnerID=40&md5=b847d723a9ffda47f9f254f834c37750","QCRI, HBKU, Doha, Qatar; HKUST(GZ)/HKUST, China","Naeem Z.A., QCRI, HBKU, Doha, Qatar; Ahmad M.S., QCRI, HBKU, Doha, Qatar; Eltabakh M., QCRI, HBKU, Doha, Qatar; Ouzzani M., QCRI, HBKU, Doha, Qatar; Tang N., HKUST(GZ)/HKUST, China","Large language models (LLMs) have shown great potential in data cleaning, which is a fundamental task in all modern applications. In this demo proposal, we demonstrate that indeed LLMs can assist in data cleaning, e.g., filling in missing values in a data table, through different approaches. For example, cloud-based non-private LLMs, e.g., OpenAI GPT family or Google Gemini, can assist in cleaning non-private datasets that encompass world-knowledge information (Scenario 1). However, such LLMs may struggle with datasets that they have never encountered before, e.g., local enterprise data, or when the user requires an explanation of the source of the suggested clean values. In that case, retrieval-based methods using RAG (Retrieval Augmented Generation) that complements the LLM power with a user-provided data source, e.g., a data lake, are a must. The data lake is indexed, and each time a new request comes, we retrieve the top-k relevant tuples to the user’s query tuple to be cleaned and leverage LLM inference power to infer the correct value (Scenario 2). Nevertheless, even in Scenario 2, sharing enterprise data with public LLMs (an externally hosted model) might not be feasible for privacy reasons. In this scenario, we showcase the practicality of locally hosted small LLMs in the cleaning process, especially after fine-tuning them on a small number of examples (Scenario 3). Our proposed system, RetClean, seamlessly supports all three scenarios and provides a user-friendly GUI that enables the VLDB audience to explore and experiment with different LLMs and investigate their trade-offs. © 2024, VLDB Endowment. All rights reserved.","","Data Sharing; Modeling languages; Network security; Spatio-temporal data; Cloud-based; Data cleaning; Data tables; Enterprise data; Filling in; Google+; Language model; Missing values; Modern applications; World knowledge; Data privacy","Fan J.; Cao Y.; Ding X.","VLDB Endowment","English","Conference paper","Final","","Scopus","2-s2.0-85205304772"
"Sun V.H.; Heemelaar J.C.; Hadzic I.; Raghu V.K.; Wu C.-Y.; Zubiri L.; Ghamari A.; Leboeuf N.R.; Abu-Shawer O.; Kehl K.L.; Grover S.; Singh P.; Suero-Abreu G.A.; Wu J.; Falade A.S.; Grealish K.; Thomas M.F.; Hathaway N.; Medoff B.D.; Gilman H.K.; Villani A.-C.; Ho J.S.; Mooradian M.J.; Sise M.E.; Zlotoff D.A.; Blum S.M.; Dougan M.; Sullivan R.J.; Neilan T.G.; Reynolds K.L.","Sun, Virginia H. (57470871500); Heemelaar, Julius C. (57194206931); Hadzic, Ibrahim (57222118251); Raghu, Vineet K. (56335925700); Wu, Chia-Yun (57426771700); Zubiri, Leyre (55986432700); Ghamari, Azin (59328670200); Leboeuf, Nicole R. (22934810500); Abu-Shawer, Osama (57201356474); Kehl, Kenneth L. (56403026100); Grover, Shilpa (15843658700); Singh, Prabhsimranjot (37027093700); Suero-Abreu, Giselle A. (55386040000); Wu, Jessica (58914600900); Falade, Ayo S. (57642607300); Grealish, Kelley (59328670300); Thomas, Molly F. (57202533387); Hathaway, Nora (59328809100); Medoff, Benjamin D. (6603109662); Gilman, Hannah K. (57220124749); Villani, Alexandra-Chloe (8513045400); Ho, Jor Sam (58524217900); Mooradian, Meghan J. (57194901718); Sise, Meghan E. (24339494200); Zlotoff, Daniel A. (57217159702); Blum, Steven M. (57201505594); Dougan, Michael (59094965200); Sullivan, Ryan J. (14061073900); Neilan, Tomas G. (12141383200); Reynolds, Kerry L. (55757848700)","57470871500; 57194206931; 57222118251; 56335925700; 57426771700; 55986432700; 59328670200; 22934810500; 57201356474; 56403026100; 15843658700; 37027093700; 55386040000; 58914600900; 57642607300; 59328670300; 57202533387; 59328809100; 6603109662; 57220124749; 8513045400; 58524217900; 57194901718; 24339494200; 57217159702; 57201505594; 59094965200; 14061073900; 12141383200; 55757848700","Enhancing Precision in Detecting Severe Immune-Related Adverse Events: Comparative Analysis of Large Language Models and International Classification of Disease Codes in Patient Records","2024","Journal of Clinical Oncology","","","10.1200/JCO.24.00326","","","","1","10.1200/JCO.24.00326","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204051494&doi=10.1200%2fJCO.24.00326&partnerID=40&md5=371eb118a8ea45620d4bddd5e52c4fc9","Harvard Medical School, Boston, MA, United States; Cardiovascular Imaging Research Center, Massachusetts General Hospital, Boston, MA, United States; Leiden University Medical Center, Leiden, Netherlands; Artificial Intelligence in Medicine (AIM) Program, Mass General Brigham, Boston, MA, United States; Brigham and Women's Hospital, Boston, MA, United States; Maastricht University, Maastricht, Netherlands; Division of Hematology and Oncology, Department of Medicine, Massachusetts General Hospital, Boston, MA, United States; Far Eastern Memorial Hospital, New Taipei City, Taiwan; Department of Dermatology, Brigham and Women's Hospital, Boston, MA, United States; Center for Cutaneous Oncology, Dana-Farber Cancer Institute, Boston, MA, United States; Department of Internal Medicine, Cleveland Clinic, Cleveland, OH, United States; Division of Population Sciences, Dana-Farber Cancer Institute, Boston, MA, United States; Department of Medical Oncology, Dana-Farber Cancer Institute, Boston, MA, United States; Division of Gastroenterology, Hepatology, and Endoscopy, Brigham and Women's Hospital, Boston, MA, United States; Division of Cardiology, Massachusetts General Hospital, Boston, MA, United States; Internal Medicine Department, Massachusetts General Brigham Salem Hospital, Salem, MA, United States; Division of Gastroenterology, Oregon Health and Science University, Portland, OR, United States; Department of Medicine, Oregon Health and Science University, Portland, OR, United States; Department of Cell, Developmental, and Cancer Biology, Oregon Health and Science University, Portland, OR, United States; Division of Pulmonary and Critical Care Medicine, Massachusetts General Hospital, Boston, MA, United States; Center for Immunology and Inflammatory Diseases (CIID), Massachusetts General Hospital Krantz Family Center for Cancer Research, Boston, MA, United States; Broad Institute of MIT and Harvard, Cambridge, MA, United States; Division of Nephrology, Massachusetts General Hospital, Boston, MA, United States; Division of Gastroenterology, Massachusetts General Hospital, Boston, MA, United States","Sun V.H., Harvard Medical School, Boston, MA, United States, Cardiovascular Imaging Research Center, Massachusetts General Hospital, Boston, MA, United States; Heemelaar J.C., Harvard Medical School, Boston, MA, United States, Cardiovascular Imaging Research Center, Massachusetts General Hospital, Boston, MA, United States, Leiden University Medical Center, Leiden, Netherlands; Hadzic I., Harvard Medical School, Boston, MA, United States, Artificial Intelligence in Medicine (AIM) Program, Mass General Brigham, Boston, MA, United States, Brigham and Women's Hospital, Boston, MA, United States, Maastricht University, Maastricht, Netherlands; Raghu V.K., Harvard Medical School, Boston, MA, United States, Cardiovascular Imaging Research Center, Massachusetts General Hospital, Boston, MA, United States; Wu C.-Y., Division of Hematology and Oncology, Department of Medicine, Massachusetts General Hospital, Boston, MA, United States, Far Eastern Memorial Hospital, New Taipei City, Taiwan; Zubiri L., Harvard Medical School, Boston, MA, United States, Division of Hematology and Oncology, Department of Medicine, Massachusetts General Hospital, Boston, MA, United States; Ghamari A., Harvard Medical School, Boston, MA, United States, Cardiovascular Imaging Research Center, Massachusetts General Hospital, Boston, MA, United States; Leboeuf N.R., Harvard Medical School, Boston, MA, United States, Department of Dermatology, Brigham and Women's Hospital, Boston, MA, United States, Center for Cutaneous Oncology, Dana-Farber Cancer Institute, Boston, MA, United States; Abu-Shawer O., Department of Internal Medicine, Cleveland Clinic, Cleveland, OH, United States; Kehl K.L., Harvard Medical School, Boston, MA, United States, Division of Population Sciences, Dana-Farber Cancer Institute, Boston, MA, United States, Department of Medical Oncology, Dana-Farber Cancer Institute, Boston, MA, United States; Grover S., Harvard Medical School, Boston, MA, United States, Division of Gastroenterology, Hepatology, and Endoscopy, Brigham and Women's Hospital, Boston, MA, United States; Singh P., Harvard Medical School, Boston, MA, United States, Department of Medical Oncology, Dana-Farber Cancer Institute, Boston, MA, United States; Suero-Abreu G.A., Harvard Medical School, Boston, MA, United States, Cardiovascular Imaging Research Center, Massachusetts General Hospital, Boston, MA, United States, Division of Cardiology, Massachusetts General Hospital, Boston, MA, United States; Wu J., Harvard Medical School, Boston, MA, United States, Cardiovascular Imaging Research Center, Massachusetts General Hospital, Boston, MA, United States; Falade A.S., Internal Medicine Department, Massachusetts General Brigham Salem Hospital, Salem, MA, United States; Grealish K., Division of Hematology and Oncology, Department of Medicine, Massachusetts General Hospital, Boston, MA, United States; Thomas M.F., Division of Gastroenterology, Oregon Health and Science University, Portland, OR, United States, Department of Medicine, Oregon Health and Science University, Portland, OR, United States, Department of Cell, Developmental, and Cancer Biology, Oregon Health and Science University, Portland, OR, United States; Hathaway N., Division of Hematology and Oncology, Department of Medicine, Massachusetts General Hospital, Boston, MA, United States; Medoff B.D., Harvard Medical School, Boston, MA, United States, Division of Pulmonary and Critical Care Medicine, Massachusetts General Hospital, Boston, MA, United States; Gilman H.K., Harvard Medical School, Boston, MA, United States, Cardiovascular Imaging Research Center, Massachusetts General Hospital, Boston, MA, United States; Villani A.-C., Harvard Medical School, Boston, MA, United States, Division of Hematology and Oncology, Department of Medicine, Massachusetts General Hospital, Boston, MA, United States, Center for Immunology and Inflammatory Diseases (CIID), Massachusetts General Hospital Krantz Family Center for Cancer Research, Boston, MA, United States, Broad Institute of MIT and Harvard, Cambridge, MA, United States; Ho J.S., Harvard Medical School, Boston, MA, United States, Cardiovascular Imaging Research Center, Massachusetts General Hospital, Boston, MA, United States; Mooradian M.J., Harvard Medical School, Boston, MA, United States, Division of Hematology and Oncology, Department of Medicine, Massachusetts General Hospital, Boston, MA, United States; Sise M.E., Harvard Medical School, Boston, MA, United States, Division of Nephrology, Massachusetts General Hospital, Boston, MA, United States; Zlotoff D.A., Harvard Medical School, Boston, MA, United States, Division of Cardiology, Massachusetts General Hospital, Boston, MA, United States; Blum S.M., Harvard Medical School, Boston, MA, United States, Division of Hematology and Oncology, Department of Medicine, Massachusetts General Hospital, Boston, MA, United States, Center for Immunology and Inflammatory Diseases (CIID), Massachusetts General Hospital Krantz Family Center for Cancer Research, Boston, MA, United States, Broad Institute of MIT and Harvard, Cambridge, MA, United States; Dougan M., Harvard Medical School, Boston, MA, United States, Division of Gastroenterology, Massachusetts General Hospital, Boston, MA, United States; Sullivan R.J., Harvard Medical School, Boston, MA, United States, Division of Hematology and Oncology, Department of Medicine, Massachusetts General Hospital, Boston, MA, United States; Neilan T.G., Harvard Medical School, Boston, MA, United States, Cardiovascular Imaging Research Center, Massachusetts General Hospital, Boston, MA, United States, Division of Cardiology, Massachusetts General Hospital, Boston, MA, United States; Reynolds K.L., Harvard Medical School, Boston, MA, United States, Division of Hematology and Oncology, Department of Medicine, Massachusetts General Hospital, Boston, MA, United States","PURPOSECurrent approaches to accurately identify immune-related adverse events (irAEs) in large retrospective studies are limited. Large language models (LLMs) offer a potential solution to this challenge, given their high performance in natural language comprehension tasks. Therefore, we investigated the use of an LLM to identify irAEs among hospitalized patients, comparing its performance with manual adjudication and International Classification of Disease (ICD) codes.METHODSHospital admissions of patients receiving immune checkpoint inhibitor (ICI) therapy at a single institution from February 5, 2011, to September 5, 2023, were individually reviewed and adjudicated for the presence of irAEs. ICD codes and an LLM with retrieval-augmented generation were applied to detect frequent irAEs (ICI-induced colitis, hepatitis, and pneumonitis) and the most fatal irAE (ICI-myocarditis) from electronic health records. The performance between ICD codes and LLM was compared via sensitivity and specificity with an α =.05, relative to the gold standard of manual adjudication. External validation was performed using a data set of hospital admissions from June 1, 2018, to May 31, 2019, from a second institution.RESULTSOf the 7,555 admissions for patients on ICI therapy in the initial cohort, 2.0% were adjudicated to be due to ICI-colitis, 1.1% ICI-hepatitis, 0.7% ICI-pneumonitis, and 0.8% ICI-myocarditis. The LLM demonstrated higher sensitivity than ICD codes (94.7% v 68.7%), achieving significance for ICI-hepatitis (P <.001), myocarditis (P <.001), and pneumonitis (P =.003) while yielding similar specificities (93.7% v 92.4%). The LLM spent an average of 9.53 seconds/chart in comparison with an estimated 15 minutes for adjudication. In the validation cohort (N = 1,270), the mean LLM sensitivity and specificity were 98.1% and 95.7%, respectively.CONCLUSIONLLMs are a useful tool for the detection of irAEs, outperforming ICD codes in sensitivity and adjudication in efficiency.  © American Society of Clinical Oncology.","","","","Lippincott Williams and Wilkins","English","Article","Article in press","","Scopus","2-s2.0-85204051494"
"Shlyk D.; Groza T.; Montanelli S.; Cavalleri E.; Mesiti M.","Shlyk, Darya (58634172400); Groza, Tudor (19638535200); Montanelli, Stefano (6506356009); Cavalleri, Emanuele (58489593900); Mesiti, Marco (7003431065)","58634172400; 19638535200; 6506356009; 58489593900; 7003431065","REAL: A Retrieval-Augmented Entity Linking Approach for Biomedical Concept Recognition","2024","BioNLP 2024 - 23rd Meeting of the ACL Special Interest Group on Biomedical Natural Language Processing, Proceedings of the Workshop and Shared Tasks","","","","380","389","9","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204426361&partnerID=40&md5=add561ad3e2397b0ec15ef41855d1983","Università degli Studi di Milano, Via Giovanni Celoria 19, Milan, 20133, Italy; School of Electrical Engineering, Computing and Mathematical Sciences, Curtin University, Kent St, Bentley, 6102, WA, Australia","Shlyk D., Università degli Studi di Milano, Via Giovanni Celoria 19, Milan, 20133, Italy; Groza T., School of Electrical Engineering, Computing and Mathematical Sciences, Curtin University, Kent St, Bentley, 6102, WA, Australia; Montanelli S., Università degli Studi di Milano, Via Giovanni Celoria 19, Milan, 20133, Italy; Cavalleri E., Università degli Studi di Milano, Via Giovanni Celoria 19, Milan, 20133, Italy; Mesiti M., Università degli Studi di Milano, Via Giovanni Celoria 19, Milan, 20133, Italy","Large Language Models (LLMs) offer an appealing alternative to training dedicated models for many Natural Language Processing (NLP) tasks. However, outdated knowledge and hallucination issues can be major obstacles in their application in knowledge-intensive biomedical scenarios. In this study, we consider the task of biomedical concept recognition (CR) from unstructured scientific literature and explore the use of Retrieval Augmented Generation (RAG) to improve accuracy and reliability of the LLM-based biomedical CR. Our approach, named REAL (Retrieval Augmented Entity Linking), combines the generative capabilities of LLMs with curated knowledge bases to automatically annotate natural language texts with concepts from bio-ontologies. By applying REAL to benchmark corpora on phenotype concept recognition, we show its effectiveness in improving LLM-based CR performance. This research highlights the potential of combining LLMs with external knowledge sources to advance biomedical text processing. Source code is available at: https://github.com/dash-ka/REAL-BioCR.. ©2024 Association for Computational Linguistics.","","Benchmarking; Natural language processing systems; Bio-ontologies; Concept recognition; External knowledge; Language model; Language processing; Model-based OPC; Natural languages; Natural languages texts; Performance; Scientific literature; Computational linguistics","Demner-Fushman D.; Ananiadou S.; Miwa M.; Roberts K.; Tsujii J.","Association for Computational Linguistics (ACL)","English","Conference paper","Final","","Scopus","2-s2.0-85204426361"
"Han Z.F.; Lin J.; Gurung A.; Thomas D.R.; Chen E.; Borchers C.; Gupta S.; Koedinger K.R.","Han, Zifei FeiFei (58913149300); Lin, Jionghao (57211753281); Gurung, Ashish (57222732463); Thomas, Danielle R. (58126296700); Chen, Eason (57673053100); Borchers, Conrad (57224723719); Gupta, Shivang (57391369900); Koedinger, Kenneth R. (6603678234)","58913149300; 57211753281; 57222732463; 58126296700; 57673053100; 57224723719; 57391369900; 6603678234","Improving Assessment of Tutoring Practices using Retrieval-Augmented Generation","2024","Proceedings of Machine Learning Research","257","","","66","76","10","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203842530&partnerID=40&md5=153e0790aa4f52ed2c9aa79d5f39eb99","Human-Computer Interaction Institute, Carnegie Mellon University, 5000 Forbes Ave, Pittsburgh, 15213, PA, United States","Han Z.F., Human-Computer Interaction Institute, Carnegie Mellon University, 5000 Forbes Ave, Pittsburgh, 15213, PA, United States; Lin J., Human-Computer Interaction Institute, Carnegie Mellon University, 5000 Forbes Ave, Pittsburgh, 15213, PA, United States; Gurung A., Human-Computer Interaction Institute, Carnegie Mellon University, 5000 Forbes Ave, Pittsburgh, 15213, PA, United States; Thomas D.R., Human-Computer Interaction Institute, Carnegie Mellon University, 5000 Forbes Ave, Pittsburgh, 15213, PA, United States; Chen E., Human-Computer Interaction Institute, Carnegie Mellon University, 5000 Forbes Ave, Pittsburgh, 15213, PA, United States; Borchers C., Human-Computer Interaction Institute, Carnegie Mellon University, 5000 Forbes Ave, Pittsburgh, 15213, PA, United States; Gupta S., Human-Computer Interaction Institute, Carnegie Mellon University, 5000 Forbes Ave, Pittsburgh, 15213, PA, United States; Koedinger K.R., Human-Computer Interaction Institute, Carnegie Mellon University, 5000 Forbes Ave, Pittsburgh, 15213, PA, United States","One-on-one tutoring is an effective instructional method for enhancing learning, yet its efficacy hinges on tutor competencies. Novice math tutors often prioritize content-specific guidance, neglecting aspects such as social-emotional learning. Social-emotional learning promotes equity and inclusion and nurtures relationships with students, which is crucial for holistic student development. Assessing the competencies of tutors accurately and efficiently can drive the development of tailored tutor training programs. However, evaluating novice tutor ability during real-time tutoring remains challenging as it typically requires experts-in-the-loop. To address this challenge, this study harnesses Generative Pre-trained Transformers (GPT), such as GPT-3.5 and GPT-4, to automatically assess tutors’ ability of using social-emotional tutoring strategies. Moreover, this study also reports on the financial dimensions and considerations of employing these models in real-time and at scale for automated assessment. Four prompting strategies were assessed: two basic Zero-shot prompt strategies, Tree of Thought prompting, and Retrieval-Augmented Generator (RAG) prompting. The results indicate that RAG prompting demonstrated the most accurate performance (assessed by the level of hallucination and correctness in the generated assessment texts) and the lowest financial costs. These findings inform the development of personalized tutor training interventions to enhance the the educational effectiveness of tutored learning. © 2024 Z.F. Han, J. Lin, A. Gurung, D.R. Thomas, E. Chen, C. Borchers, S. Gupta & K.R. Koedinger.","Automatic Assessment; Large Language Model; Personalized Tutor Training","Adversarial machine learning; Federated learning; Finance; Self-supervised learning; Social psychology; Students; Teaching; Zero-shot learning; Automatic assessment; Emotional learning; Instructional methods; Language model; Large language model; One-on-one tutoring; Personalized tutor training; Real- time; Student development; Training program; Contrastive Learning","Ananda M.; Malick D.B.; Burstein J.; Liu L.T.; Liu Z.; Sharpnack J.; Wang Z.; Wang S.","ML Research Press","English","Conference paper","Final","","Scopus","2-s2.0-85203842530"
"Saha B.; Saha U.","Saha, Binita (59332809700); Saha, Utsha (58753467700)","59332809700; 58753467700","Enhancing International Graduate Student Experience through AI-Driven Support Systems: A LLM and RAG-Based Approach","2024","2024 International Conference on Data Science and Its Applications, ICoDSA 2024","","","","300","304","4","0","10.1109/ICoDSA62899.2024.10651944","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204281990&doi=10.1109%2fICoDSA62899.2024.10651944&partnerID=40&md5=1206d6d401ac62e96a45284a84c15fca","North Dakota State University, Dept. of Computer Science, Fargo, ND, United States","Saha B., North Dakota State University, Dept. of Computer Science, Fargo, ND, United States; Saha U., North Dakota State University, Dept. of Computer Science, Fargo, ND, United States","International graduate students encounter unique challenges that impede their academic and personal success. This paper introduces an AI-powered chatbot designed specifically for these students, utilizing advanced language models and Retrieval-Augmented Generation (RAG). Unlike generic solutions, our chatbot is tailored with a dataset curated from Reddit communi-ties frequented by international students, enabling it to provide highly relevant and actionable advice. The system combines GPT-3.5's generative capabilities with precise information retrieval to effectively guide students through academic procedures, cul-tural adjustments, and personal challenges. An evaluation shows that our RAG-enhanced model outperforms standard GPT-3.5, demonstrating significant improvements in response accuracy and relevance. This research not only advances AI applications in student support but also offers practical, real-time aid to enhance international students' educational experiences.  © 2024 IEEE.","Chatbot; GPT-3.5-turbo; International students; Natural language processing (NLP); Personalized support systems; Retrieval-Augmented Generation (RAG)","Modeling languages; Natural language processing systems; Online searching; Search engines; Chatbots; GPT-3.5-turbo; Graduate students; International students; Language processing; Natural language processing; Natural languages; Personalized support system; Retrieval-augmented generation; Support systems; Students","","Institute of Electrical and Electronics Engineers Inc.","English","Conference paper","Final","","Scopus","2-s2.0-85204281990"
"Yang J.; Shu L.; Duan H.; Li H.","Yang, Jian (57222155873); Shu, Liqi (57204555568); Duan, Huilong (7102630467); Li, Haomin (35795854300)","57222155873; 57204555568; 7102630467; 35795854300","RDguru: A Conversational Intelligent Agent for Rare Diseases","2024","IEEE Journal of Biomedical and Health Informatics","","","","","","","0","10.1109/JBHI.2024.3464555","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204691982&doi=10.1109%2fJBHI.2024.3464555&partnerID=40&md5=2b167ec78ebe4748d2634a6c672da784","Zhejiang University School of Medicine, National Clinical Research Center for Child Health, Clinical Data Center, The Children's Hospital, Hangzhou, 310052, China; Zhejiang University, College of Biomedical Engineering and Instrument Science, Hangzhou, 310027, China; Warren Alpert Medical School of Brown University, Rhode Island Hospital, 02903, RI, United States","Yang J., Zhejiang University School of Medicine, National Clinical Research Center for Child Health, Clinical Data Center, The Children's Hospital, Hangzhou, 310052, China, Zhejiang University, College of Biomedical Engineering and Instrument Science, Hangzhou, 310027, China; Shu L., Warren Alpert Medical School of Brown University, Rhode Island Hospital, 02903, RI, United States; Duan H., Zhejiang University, College of Biomedical Engineering and Instrument Science, Hangzhou, 310027, China; Li H., Zhejiang University School of Medicine, National Clinical Research Center for Child Health, Clinical Data Center, The Children's Hospital, Hangzhou, 310052, China","Large language models (LLMs) hold significant promise in clinical practice, yet their real-world adoption is constrained by their propensity to produce erroneous and occasionally harmful outputs, particularly in the intricate domain of rare diseases (RDs). This study introduces RDguru, a conversational intelligent agent leveraging the LangChain framework and powered by GPT-3.5-turbo. RDguru offers a comprehensive suite of functionalities, encompassing evidence-traceable knowledge Q&A and professional medical consultations for differential diagnosis (DDX), integrating authoritative knowledge sources and reliable tools. A novel multi-source fusion diagnostic model, rooted in deep Q-network, amalgamates three diagnostic recommendation strategies (GPT-4, PheLR, and phenotype matching) to enhance diagnostic recall during medical consultations. Through tailored tools and advanced algorithms for retrieval-augmented generation, RDguru excels in knowledge Q&A, automated phenotype annotation, and RD DDX. A multi-aspect Q&A analysis demonstrates RDguru outperforms ChatGPT in generating descriptions aligned with authoritative knowledge, quantified by ROUGE scores, GPT-4-based automatic rating, and RAGAs evaluation metrics. Testing on 238 published RD cases reveals that RDguru's top 5 multi-source fusion diagnoses recapture 63.87% of actual diagnoses, marking a 5.47% improvement over the state-of-the-art diagnostic method PheLR. Furthermore, RDguru's consultation strategy proves effective in eliciting diagnostically beneficial phenotypes and refining the prioritization of genuine diagnoses through multi-round phenotype-orient questioning. Evaluations against established benchmarks and real-world patient data demonstrate RDguru's efficacy and reliability, highlighting its potential to enhance clinical decision-making in the realm of RDs.  © 2013 IEEE.","Conversational AI; deep Q-network; knowledge Q&A; large language model; medical consultation; rare diseases","Benchmarking; Diagnosis; Hospital data processing; Clinical practices; Conversational AI; Deep Q-network; Knowledge Q&A; Language model; Large language model; Medical consultation; Multi-source fusion; Rare disease; Real-world; Diseases","","Institute of Electrical and Electronics Engineers Inc.","English","Article","Article in press","All Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85204691982"
"Zhang Z.; Shi Y.; Zhu J.; Zhou W.; Qi X.; Zhang P.; Li H.","Zhang, Zongmeng (58317503300); Shi, Yufeng (58577592700); Zhu, Jinhua (57202399808); Zhou, Wengang (8979446000); Qi, Xiang (59325443800); Zhang, Peng (59325443900); Li, Houqiang (35956273100)","58317503300; 58577592700; 57202399808; 8979446000; 59325443800; 59325443900; 35956273100","Trustworthy Alignment of Retrieval-Augmented Large Language Models via Reinforcement Learning","2024","Proceedings of Machine Learning Research","235","","","59827","59850","23","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203826205&partnerID=40&md5=4df19b55392ac0a1c4fd77a5f8c9ac89","University of Science and Technology of China, China; Institute of Artificial Intelligence, Hefei Comprehensive Nation Science Center, China; Ant Group, China","Zhang Z., University of Science and Technology of China, China; Shi Y., University of Science and Technology of China, China; Zhu J., University of Science and Technology of China, China; Zhou W., University of Science and Technology of China, China, Institute of Artificial Intelligence, Hefei Comprehensive Nation Science Center, China; Qi X., Ant Group, China; Zhang P., Ant Group, China; Li H., University of Science and Technology of China, China, Institute of Artificial Intelligence, Hefei Comprehensive Nation Science Center, China","Trustworthiness is an essential prerequisite for the real-world application of large language models.In this paper, we focus on the trustworthiness of language models with respect to retrieval augmentation.Despite being supported with external evidence, retrieval-augmented generation still suffers from hallucinations, one primary cause of which is the conflict between contextual and parametric knowledge.We deem that retrieval-augmented language models have the inherent capabilities of supplying response according to both contextual and parametric knowledge.Inspired by aligning language models with human preference, we take the first step towards aligning retrieval-augmented language models to a status where it responds relying merely on the external evidence and disregards the interference of parametric knowledge.Specifically, we propose a reinforcement learning based algorithm TRUSTWORTHY-ALIGNMENT, theoretically and experimentally demonstrating large language models' capability of reaching a trustworthy status without explicit supervision on how to respond.Our work highlights the potential of large language models on exploring its intrinsic abilities by its own and expands the application scenarios of alignment from fulfilling human preference to creating trustworthy agents.Our code is available at https://github.com/zmzhang2000/trustworthy-alignment. Copyright 2024 by the author(s)","","Adversarial machine learning; Contrastive Learning; Application scenario; Language model; Learning-based algorithms; Real-world; Reinforcement learnings; Reinforcement learning","Salakhutdinov R.; Kolter Z.; Heller K.; Weller A.; Oliver N.; Scarlett J.; Berkenkamp F.","ML Research Press","English","Conference paper","Final","","Scopus","2-s2.0-85203826205"
"Hu X.; Li X.; Chen J.; Li Y.; Li Y.; Li X.; Wang Y.; Liu Q.; Wen L.; Yu P.S.; Guo Z.","Hu, Xuming (57219742451); Li, Xiaochuan (58662333500); Chen, Junzhe (58547232700); Li, Yinghui (57221320203); Li, Yangning (57545898600); Li, Xiaoguang (57219591018); Wang, Yasheng (57211255040); Liu, Qun (56181387900); Wen, Lijie (14030649200); Yu, Philip S. (59338237700); Guo, Zhijiang (57215715235)","57219742451; 58662333500; 58547232700; 57221320203; 57545898600; 57219591018; 57211255040; 56181387900; 14030649200; 59338237700; 57215715235","Evaluating Robustness of Generative Search Engine on Adversarial Factoid Questions","2024","Proceedings of the Annual Meeting of the Association for Computational Linguistics","","","","10650","10671","21","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205324373&partnerID=40&md5=f510b005e05e4b4c8c758283e748033b","HKUST(GZ), Hong Kong; Tsinghua University, China; Huawei Noah's Ark Lab, Canada; University of Illinois, Chicago, United States","Hu X., HKUST(GZ), Hong Kong; Li X., Tsinghua University, China; Chen J., Tsinghua University, China; Li Y., Tsinghua University, China; Li Y., Tsinghua University, China; Li X., Huawei Noah's Ark Lab, Canada; Wang Y., Huawei Noah's Ark Lab, Canada; Liu Q., Huawei Noah's Ark Lab, Canada; Wen L., Tsinghua University, China; Yu P.S., University of Illinois, Chicago, United States; Guo Z., Huawei Noah's Ark Lab, Canada","Generative search engines have the potential to transform how people seek information online, but generated responses from existing large language models (LLMs)-backed generative search engines may not always be accurate. Nonetheless, retrieval-augmented generation exacerbates safety concerns, since adversaries may successfully evade the entire system by subtly manipulating the most vulnerable part of a claim. To this end, we propose evaluating the robustness of generative search engines in the realistic and high-risk setting, where adversaries have only black-box system access and seek to deceive the model into returning incorrect responses. Through a comprehensive human evaluation of various generative search engines, such as Bing Chat, PerplexityAI, and YouChat across diverse queries, we demonstrate the effectiveness of adversarial factual questions in inducing incorrect responses. Moreover, retrieval-augmented generation exhibits a higher susceptibility to factual errors compared to LLMs without retrieval. These findings highlight the potential security risks of these systems and emphasize the need for rigorous evaluation before deployment. Our constructed dataset and codes are available at: https://github.com/HKUSTGZNLP/Adversarial-Attack. © 2024 Association for Computational Linguistics.","","Adversarial machine learning; Computational linguistics; Black box system; Entire system; Factoid questions; Human evaluation; Language model; Rigorous evaluation; Safety concerns; Security risks; System access; Generative adversarial networks","Ku L.-W.; Martins A.; Srikumar V.","Association for Computational Linguistics (ACL)","English","Conference paper","Final","","Scopus","2-s2.0-85205324373"
"Pedro Jose Gonzalez D.; Orjuela Duarte A.; Rojas W.M.; Luz Marina Santos J.","Pedro Jose Gonzalez, D. (59343030700); Orjuela Duarte, Ailin (59343048000); Rojas, William Mauricio (59342996200); Luz Marina Santos, J. (59342962700)","59343030700; 59343048000; 59342996200; 59342962700","Performance tests of LLMs in the context of answers on Industry 4.0","2024","2024 IEEE Colombian Conference on Applications of Computational Intelligence, ColCACI 2024 - Proceedings","","","","","","","0","10.1109/ColCACI63187.2024.10666552","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204939991&doi=10.1109%2fColCACI63187.2024.10666552&partnerID=40&md5=3407e953f280903d91b7043fca665ba4","Universidad de Pamplona, Ingeniería de Sistemas, Pamplona, Colombia; Ingeniería de Sistemas Universidad de Pamplona, Grupo Cicom, Pamplona, Colombia","Pedro Jose Gonzalez D., Universidad de Pamplona, Ingeniería de Sistemas, Pamplona, Colombia; Orjuela Duarte A., Ingeniería de Sistemas Universidad de Pamplona, Grupo Cicom, Pamplona, Colombia; Rojas W.M., Ingeniería de Sistemas Universidad de Pamplona, Grupo Cicom, Pamplona, Colombia; Luz Marina Santos J., Ingeniería de Sistemas Universidad de Pamplona, Grupo Cicom, Pamplona, Colombia","Large Language Models (LLMs) are a type of artificial intelligence capable of processing and generating natural language. These models are trained on vast amounts of data, such as text and code, which enables them to perform various tasks like text generation, language translation, question answering, text summarization, etc. The purpose of this research was to find an LLM that meets the following requirements: 1)easy to implement with an understanding of the Spanish language, and 2)accurately answers diagnostic questions and action plans related to Industry 4.0 (I4.0). Three open-source LLMs were selected: Llama2, Mistral and Gemma, each one of them with 7B parameters and quantizations of Q2-Q4 for the application of a first set of tests. The results showed that the model with the best performance in the Spanish language was Mistral, achieving an accuracy rate of 82.3% compared to Gemma's 51.7%. A second set of tests was then conducted with and without Retrieval-Augmented Generation (RAG), using three documents related to the topic of I4.0. The results demonstrated Mistral's capability with RAG to answer questions on the studied context with 95% accuracy. © 2024 IEEE.","Accuracy; Gemma; Industry 4.0; LLM; Mistral; RAG","Natural language processing systems; Open source software; Accuracy; Gemma; Language model; Large language model; Mistral; Natural languages; Performance tests; Retrieval-augmented generation; Spanish language; Text generations; Translation (languages)","Orjuela-Canon A.D.","Institute of Electrical and Electronics Engineers Inc.","Spanish","Conference paper","Final","","Scopus","2-s2.0-85204939991"
"Rackauckas Z.; Câmara A.; Zavrel J.","Rackauckas, Zackary (58898429600); Câmara, Arthur (57210429436); Zavrel, Jakub (58196821700)","58898429600; 57210429436; 58196821700","Evaluating RAG-Fusion with RAGElo: an Automated Elo-based Framework","2024","CEUR Workshop Proceedings","3752","","","92","112","20","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203831093&partnerID=40&md5=d3ffec746e98cb0c5ecd920d890e3489","Columbia University, New York, NY, United States; Zeta Alpha, Amsterdam, Netherlands","Rackauckas Z., Columbia University, New York, NY, United States; Câmara A., Zeta Alpha, Amsterdam, Netherlands; Zavrel J., Zeta Alpha, Amsterdam, Netherlands","Challenges in the automated evaluation of Retrieval-Augmented Generation (RAG) Question-answering (QA) systems include hallucination problems in domain-specific knowledge and the lack of gold standard benchmarks for company-internal tasks. This results in difficulties in evaluating RAG variations, like RAG-Fusion (RAGF) in the context of a product QA task at Infineon Technologies. To solve these problems, we propose a comprehensive evaluation framework, which leverages Large Language Models (LLMs) to generate large datasets of synthetic queries based on real user queries and in-domain documents, uses LLM-as-a-judge to rate retrieved documents and answers, evaluates the quality of answers, and ranks different variants of Retrieval-Augmented Generation (RAG) agents with RAGElo’s automated Elo-based competition. LLM-as-a-judge rating of a random sample of synthetic queries shows a moderate, positive correlation with domain expert scoring in relevance, accuracy, completeness, and precision. While RAGF outperformed RAG in Elo score, a significance analysis against expert annotations also shows that RAGF significantly outperforms RAG in completeness, but underperforms in precision. In addition, Infineon’s RAGF assistant demonstrated slightly higher performance in document relevance based on MRR@5 scores. We find that RAGElo positively aligns with the preferences of human annotators, though due caution is still required. Finally, RAGF’s approach leads to more complete answers based on expert annotations and better answers overall based on RAGElo’s evaluation criteria. © 2024 Copyright for this paper by its authors.","Elo-based evaluation; LLM-as-a-judge; RAG-Fusion; Retrieval-augmented generation","Large datasets; Metadata; Modeling languages; Query languages; Automated evaluation; Domain-specific knowledge; Elo-based evaluation; Expert annotations; Gold standards; Language model; Large language model-as-a-judge; Question answering systems; Retrieval-augmented generation; Retrieval-augmented generation-fusion; Benchmarking","Siro C.; Aliannejadi M.; Rahmani H.A.; Craswell N.; Clarke C.L.A.; Faggioli G.; Mitra B.; Thomas P.; Yilmaz E.; Yilmaz E.","CEUR-WS","English","Conference paper","Final","","Scopus","2-s2.0-85203831093"
"Schmidt W.J.; Rincon-Yanez D.; Kharlamov E.; Paschke A.","Schmidt, Wilma Johanna (59339036500); Rincon-Yanez, Diego (59339659800); Kharlamov, Evgeny (34979864600); Paschke, Adrian (24724965300)","59339036500; 59339659800; 34979864600; 24724965300","Scaling Scientific Knowledge Discovery with Neuro-Symbolic AI and Large Language Models","2024","CEUR Workshop Proceedings","3759","","","","","","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204727190&partnerID=40&md5=996a09e6a534d56571251a2a78ee1213","Bosch Center for AI, Robert Bosch GmbH, Renningen, Germany; University of Salerno, Fisciano, Italy; AG Corporate Semantic Web, Freie Universität Berlin, Berlin, Germany; SIRIUS, Centre for Scalable Data Access, University of Oslo, Oslo, Norway; Data Analytics Center, Fraunhofer FOKUS, Berlin, Germany; Universidad de Santander, Facultad de Ingenierías y Tecnologías, Cucuta, Colombia","Schmidt W.J., Bosch Center for AI, Robert Bosch GmbH, Renningen, Germany, SIRIUS, Centre for Scalable Data Access, University of Oslo, Oslo, Norway; Rincon-Yanez D., University of Salerno, Fisciano, Italy, Universidad de Santander, Facultad de Ingenierías y Tecnologías, Cucuta, Colombia; Kharlamov E., Bosch Center for AI, Robert Bosch GmbH, Renningen, Germany, SIRIUS, Centre for Scalable Data Access, University of Oslo, Oslo, Norway; Paschke A., AG Corporate Semantic Web, Freie Universität Berlin, Berlin, Germany, Data Analytics Center, Fraunhofer FOKUS, Berlin, Germany","The increasing amount of available research data leads to the need to scale scientific knowledge discovery, e.g., the conduction of systematic literature reviews (SLRs), to keep up with fast developments in research and further support decision-making in the industry.AI-based methods are gaining importance in these tasks and have been integrated into many SLR tools.Yet, several challenges are still open on applying especially neural methods on scientific knowledge discovery tasks.To address this, we evaluate various neural and neuro-symbolic scenarios on a specific generative writing task.While confirming existing concerns on pure Large Language Model (LLM) approaches for these tasks, we obtain a heterogeneous picture of Retrieval-Augmented Generation (RAG) approaches.The most promising candidate is a Knowledge Graph (KG) based context-enhanced LLM approach for Knowledge Discovery. © 2022 Copyright for this paper by its authors.","Knowledge Graph; Large Language Model; Neuro-Symbolic AI; Retrieval-Augmented Generation (RAG); Systematic Literature Review","Knowledge graphs; Language model; Large language model; Modeling approach; Neuro-symbolic AI; Research data; Retrieval-augmented generation; Scalings; Scientific knowledge; Systematic literature review; Knowledge graph","Garijo D.; Gentile A.L.; Kurteva A.; Mannocci A.; Osborne F.; Vahdati S.","CEUR-WS","English","Conference paper","Final","","Scopus","2-s2.0-85204727190"
"Naseem T.; Xu G.; Swaminathan S.; Yehudai A.; Chaudhury S.; Florian R.; Astudillo R.F.; Munawar A.","Naseem, Tahira (22958080800); Xu, Guangxuan (57221690079); Swaminathan, Sarathkrishna (57191283725); Yehudai, Asaf (57271313800); Chaudhury, Subhajit (56134754000); Florian, Radu (35487184700); Astudillo, Ramón Fernandez (24464805600); Munawar, Asim (57190413949)","22958080800; 57221690079; 57191283725; 57271313800; 56134754000; 35487184700; 24464805600; 57190413949","A Grounded Preference Model for LLM Alignment","2024","Proceedings of the Annual Meeting of the Association for Computational Linguistics","","","","151","162","11","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205308687&partnerID=40&md5=7a0fb952fc78035a3395bd6c8c87c39d","IBM Research, United States","Naseem T., IBM Research, United States; Xu G., IBM Research, United States; Swaminathan S., IBM Research, United States; Yehudai A., IBM Research, United States; Chaudhury S., IBM Research, United States; Florian R., IBM Research, United States; Astudillo R.F., IBM Research, United States; Munawar A., IBM Research, United States","Despite LLMs' recent advancements, they still suffer from factual inconsistency and hallucination. An often-opted remedy is retrieval-augmented generation - however, there is no guarantee that the model will strictly adhere to retrieved grounding. Fundamentally, LLMs need to be aligned to be more faithful to grounding, which will require high-quality preference annotations. This paper investigates whether we can create high-quality grounded preference data for model alignment without using annotations from humans or large proprietary models. We experimented with existing entailment data and proposed approaches to generate synthetic grounded preference data, with which we train a Grounded Preference Model(GPM). We demonstrate through Proximal Policy Optimization(PPO) training of Mistral-7B-Instruct that our GPM model can successfully align powerful LLMs to generate much better grounded responses as judged by GPT4. Moreover, we show that our GPM is also a great faithfulness classifier, achieving SoTA in dialogue sub-tasks of the TRUE faithfulness Benchmark. We release GPM under the Apache 2.0 license. © 2024 Association for Computational Linguistics.","","Metadata; High quality; Policy optimization; Preference data; Preference models; Subtask; Computational linguistics","Ku L.-W.; Martins A.; Srikumar V.","Association for Computational Linguistics (ACL)","English","Conference paper","Final","","Scopus","2-s2.0-85205308687"
"Pang T.; Tan K.; Yao Y.; Liu X.; Meng F.; Fan C.; Zhang X.","Pang, Tianqi (58281871200); Tan, Kehui (58303358400); Yao, Yujun (59343657300); Liu, Xiangyang (58141314500); Meng, Fanlong (59344112400); Fan, Chenyou (57191411277); Zhang, Xiaofan (56352677000)","58281871200; 58303358400; 59343657300; 58141314500; 59344112400; 57191411277; 56352677000","REMED: Retrieval-Augmented Medical Document Query Responding with Embedding Fine-Tuning","2024","Proceedings of the International Joint Conference on Neural Networks","","","","","","","2","10.1109/IJCNN60899.2024.10651011","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204990829&doi=10.1109%2fIJCNN60899.2024.10651011&partnerID=40&md5=52b35bc3841f8b95f59446168e61c22c","South China Normal University, China; Shanghai AI Lab, China; Bytedance Inc., China; Shanghai Jiao Tong University, China","Pang T., South China Normal University, China, Shanghai AI Lab, China; Tan K., South China Normal University, China, Shanghai AI Lab, China; Yao Y., Shanghai AI Lab, China; Liu X., South China Normal University, China; Meng F., Bytedance Inc., China; Fan C., South China Normal University, China, Shanghai AI Lab, China; Zhang X., Shanghai AI Lab, China, Shanghai Jiao Tong University, China","While advanced Large Language Models (LLMs) exhibit considerable promise, their tendency to generate unreliable information poses significant challenges, particularly in high-risk domains like healthcare. However, the advent of Retrieval-Augmented Generation (RAG) offers a novel solution tailored for the medical realm. This study further enhances retrieval accuracy by introducing REMED, a specialized medical document retrieval framework designed to address the hallucination problem prevalent in LLMs. The REMED framework integrates dataset construction, an efficient embedding fine-tuning EM-FT model, retrieval-augmented generation, and human evaluation of LLM responses. The EM-FT model can end-to-end fine-tune the medical sentence representations in large pre-trained models through an efficient embedding fine-tuning method, thereby enhancing the performance of medical retrieval. We adopt contrastive learning as the loss function to optimize the performance of the EM-FT model, enabling it to accurately capture the similarity between query and relevant documents. This approach not only improves the retrieval accuracy of positively related contents but also effectively reduces the matching with negatively related contents. Compared to direct dense vector retrieval, fine-tuning query and content vectors first and then performing dense retrieval tasks significantly improved the performance. Through validation on two datasets, we demonstrate that our EM-FT method improves recall and precision on MMD by 3.2%-6.0% and on MPD by 14.4%-42.6% compared to using the embedding model directly for retrieval. Furthermore, through human evaluation on the PULSE-7Bv5 model, we further confirm the effectiveness of our retrieval results in improving the quality of generated text. © 2024 IEEE.","Contrastive Learning; Large Language Models; Medical Dataset; Medical Document Retrieval","Query languages; Structured Query Language; Document Retrieval; Embeddings; Fine tuning; Language model; Large language model; Medical data sets; Medical document retrieval; Medical documents; Performance; Retrieval accuracy; Embeddings","","Institute of Electrical and Electronics Engineers Inc.","English","Conference paper","Final","","Scopus","2-s2.0-85204990829"
"Zyskind G.; South T.; Pentland A.","Zyskind, Guy (56497185600); South, Tobin (57215202143); Pentland, Alex (7102755925)","56497185600; 57215202143; 7102755925","Don’t forget private retrieval: distributed private similarity search for large language models","2024","PrivateNLP 2024 - 5th Workshop on Privacy in Natural Language Processing, Proceedings of the Workshop","","","","7","19","12","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204427732&partnerID=40&md5=6775cb48ce8e9dd77fb8b732963b290c","MIT Media Lab, MIT Connection Science, United States","Zyskind G., MIT Media Lab, MIT Connection Science, United States; South T., MIT Media Lab, MIT Connection Science, United States; Pentland A., MIT Media Lab, MIT Connection Science, United States","While the flexible capabilities of large language models (LLMs) allow them to answer a range of queries based on existing learned knowledge, information retrieval to augment generation is an important tool to allow LLMs to answer questions on information not included in pre-training data. Such private information is increasingly being generated in a wide array of distributed contexts by organizations and individuals. Performing such information retrieval using neural embeddings of queries and documents always leaked information about queries and database content unless both were stored locally. We present Private Retrieval Augmented Generation (PRAG), an approach that uses multi-party computation (MPC) to securely transmit queries to a distributed set of servers containing a privately constructed database to return top-k and approximate top-k documents. This is a first-of-its-kind approach to dense information retrieval that ensures no server observes a client’s query or can see the database content. The approach introduces a novel MPC friendly protocol for inverted file approximate search (IVF) that allows for fast document search over distributed and private data in sublinear communication complexity. This work presents new avenues through which data for use in LLMs can be accessed and used without needing to centralize or forgo privacy. © 2024 Association for Computational Linguistics.","","Computational linguistics; Information retrieval; Modeling languages; Praseodymium alloys; Query languages; Database contents; Embeddings; Inverted files; Knowledge information; Language model; Multiparty computation; Pre-training; Private information; Similarity search; Training data; Structured Query Language","Habernal I.; Ghanavati S.; Ravichander A.; Jain V.; Thaine P.; Igamberdiev T.; Mireshghallah N.; Feyisetan O.","Association for Computational Linguistics (ACL)","English","Conference paper","Final","","Scopus","2-s2.0-85204427732"
"Maharana A.; Lee D.-H.; Tulyakov S.; Bansal M.; Barbieri F.; Fang Y.","Maharana, Adyasha (57194338660); Lee, Dong-Ho (57216623177); Tulyakov, Sergey (57213004407); Bansal, Mohit (16466939600); Barbieri, Francesco (56828967300); Fang, Yuwei (58904366400)","57194338660; 57216623177; 57213004407; 16466939600; 56828967300; 58904366400","Evaluating Very Long-Term Conversational Memory of LLM Agents","2024","Proceedings of the Annual Meeting of the Association for Computational Linguistics","1","","","13851","13870","19","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204424742&partnerID=40&md5=af25df813870a0f18c85e5f93e2bbc31","University of North Carolina, Chapel Hill, United States; University of Southern California, United States; Snap Inc.","Maharana A., University of North Carolina, Chapel Hill, United States; Lee D.-H., University of Southern California, United States; Tulyakov S., Snap Inc.; Bansal M., University of North Carolina, Chapel Hill, United States; Barbieri F.; Fang Y., Snap Inc.","Existing works on long-term open-domain dialogues focus on evaluating model responses within contexts spanning no more than five chat sessions. Despite advancements in long-context large language models (LLMs) and retrieval augmented generation (RAG) techniques, their efficacy in very long-term dialogues remains unexplored. To address this research gap, we introduce a machine-human pipeline to generate high-quality, very long-term dialogues by leveraging LLM-based agent architectures and grounding their dialogues on personas and temporal event graphs. Moreover, we equip each agent with the capability of sharing and reacting to images. The generated conversations are verified and edited by human annotators for long-range consistency and grounding to the event graphs. Using this pipeline, we collect LOCOMO, a dataset of very long-term conversations, each encompassing approx. 600 turns and 16K tokens on avg., over up to 32 sessions. Based on LOCOMO, we present a comprehensive evaluation benchmark to measure long-term memory in models, encompassing question answering, event summarization, and multi-modal dialogue generation tasks. Our experimental results indicate that LLMs exhibit challenges in understanding lengthy conversations and comprehending long-range temporal and causal dynamics within dialogues. Employing strategies like long-context LLMs or RAG can offer improvements but these models still substantially lag behind human performance. © 2024 Association for Computational Linguistics.","","Associative storage; Benchmarking; Chatbots; Context free languages; Context sensitive languages; Memory architecture; Agent architectures; Evaluating models; Event graphs; Generation techniques; High quality; Language model; Model agents; Model response; Model-based OPC; Research gaps; Computational linguistics","Ku L.-W.; Martins A.F.T.; Srikumar V.","Association for Computational Linguistics (ACL)","English","Conference paper","Final","","Scopus","2-s2.0-85204424742"
"Garigliotti D.","Garigliotti, Darío (57016811700)","57016811700","SDG target detection in environmental reports using Retrieval-augmented Generation with LLMs","2024","ClimateNLP 2024 - 1st Workshop on Natural Language Processing Meets Climate Change, Proceedings of the Workshop","","","","241","250","9","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204483678&partnerID=40&md5=d356b6c380a4b817d4b1fd199e17b8e4","University of Bergen, Norway","Garigliotti D., University of Bergen, Norway","With the consolidation of Large Language Models (LLM) as a dominant component in approaches for multiple linguistic tasks, the interest in these technologies has greatly increased within a variety of areas and domains. A particular scenario of information needs where to exploit these approaches is climate-aware NLP. Paradigmatically, the vast manual labour of inspecting long, heterogeneous documents to find environment-relevant expressions and claims suits well within a recently established Retrieval-augmented Generation (RAG) framework. In this paper, we tackle dual problems within environment analysis dealing with the common goal of detecting a Sustainable Developmental Goal (SDG) target being addressed in a textual passage of an environmental assessment report. We develop relevant test collections, and propose and evaluate a series of methods within the general RAG pipeline, in order to assess the current capabilities of LLMs for the tasks of SDG target evidence identification and SDG target detection. ©2024 Association for Computational Linguistics.","","Computational linguistics; Direct air capture; Environmental monitoring; Sustainable development; Developmental goals; Dual problem; Environment analysis; Environmental assessment; Environmental report; Heterogeneous documents; Language model; Manual labors; Targets detection; Test Collection","Stammbach D.; Ni J.; Schimanski T.; Dutia K.; Singh A.; Bingler J.; Christiaen C.; Kushwaha N.; Muccione V.; Vaghefi S.A.; Leippold M.","Association for Computational Linguistics (ACL)","English","Conference paper","Final","","Scopus","2-s2.0-85204483678"
"Vatsal S.; Singh A.","Vatsal, Shubham (57216413814); Singh, Ayush (57817040300)","57216413814; 57817040300","Can GPT Redefine Medical Understanding? Evaluating GPT on Biomedical Machine Reading Comprehension","2024","BioNLP 2024 - 23rd Meeting of the ACL Special Interest Group on Biomedical Natural Language Processing, Proceedings of the Workshop and Shared Tasks","","","","256","265","9","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204481377&partnerID=40&md5=6c88701ad7f734ec569fe41c7d0c65b6","inQbator AI, eviCore Healthcare Evernorth Health Services","Vatsal S., inQbator AI, eviCore Healthcare Evernorth Health Services; Singh A., inQbator AI, eviCore Healthcare Evernorth Health Services","Large language models (LLMs) have shown remarkable performance on many tasks in different domains. However, their performance in contextual biomedical machine reading comprehension (MRC) has not been evaluated in depth. In this work, we evaluate GPT on four contextual biomedical MRC benchmarks. We experiment with different conventional prompting techniques as well as introduce our own novel prompting method. To solve some of the retrieval problems inherent to LLMs, we propose a prompting strategy named Implicit Retrieval Augmented Generation (RAG) that alleviates the need for using vector databases to retrieve important chunks in traditional RAG setups. Moreover, we report qualitative assessments on the natural language generation outputs from our approach. The results show that our new prompting technique is able to get the best performance in two out of four datasets and ranks second in rest of them. Experiments show that modern-day LLMs like GPT even in a zero-shot setting can outperform supervised models, leading to new state-of-the-art (SoTA) results on two of the benchmarks.. ©2024 Association for Computational Linguistics.","","Benchmarking; Natural language processing systems; Different domains; Language model; Natural language generation; Performance; Qualitative assessments; Reading comprehension; State of the art; Computational linguistics","Demner-Fushman D.; Ananiadou S.; Miwa M.; Roberts K.; Tsujii J.","Association for Computational Linguistics (ACL)","English","Conference paper","Final","","Scopus","2-s2.0-85204481377"
"Mandikal P.","Mandikal, Priyanka (57206484940)","57206484940","Ancient Wisdom, Modern Tools: Exploring Retrieval-Augmented LLMs for Ancient Indian Philosophy","2024","ML4AL 2024 - 1st Workshop on Machine Learning for Ancient Languages, Proceedings of the Workshop","","","","224","250","26","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204786704&partnerID=40&md5=947bfca6c4f6c0d46b27129e72ea7098","Department of Computer Science, UT Austin, United States","Mandikal P., Department of Computer Science, UT Austin, United States","LLMs have revolutionized the landscape of information retrieval and knowledge dissemination. However, their application in specialized areas is often hindered by limitations such as factual inaccuracies and hallucinations, especially in long-tail knowledge distributions. In this work, we explore the potential of retrieval-augmented generation (RAG) models in performing long-form question answering (LFQA) on a specially curated niche and custom knowledge domain. We present VedantaNY-10M, a dataset curated from extensive public discourses on the ancient Indian philosophy of Advaita Vedanta. We develop and benchmark a RAG model against a standard, non-RAG LLM, focusing on transcription, retrieval, and generation performance. A human evaluation involving computational linguists and domain experts, shows that the RAG model significantly outperforms the standard model in producing factual, comprehensive responses having fewer hallucinations. In addition, we find that a keyword-based hybrid retriever that focuses on unique low-frequency words further improves results. Our study provides insights into meaningfully integrating modern large language models with ancient knowledge systems. © 2024 Association for Computational Linguistics.","","Benchmarking; Content based retrieval; Natural language processing systems; Question answering; Domain experts; Human evaluation; Knowledge dissemination; Knowledge distribution; Knowledge domains; Long tail; Modern tools; Performance; Question Answering; The standard model; Computational linguistics","Pavlopoulos J.; Sommerschield T.; Assael Y.; Gordin S.; Cho K.; Passarotti M.; Sprugnoli R.; Liu Y.; Li B.; Anderson A.","Association for Computational Linguistics (ACL)","English","Conference paper","Final","","Scopus","2-s2.0-85204786704"
"Fang F.; Bai Y.; Ni S.; Yang M.; Chen X.; Xu R.","Fang, Feiteng (58547131100); Bai, Yuelin (58978768500); Ni, Shiwen (57220185331); Yang, Min (56349712700); Chen, Xiaojun (55739099100); Xu, Ruifeng (56048299800)","58547131100; 58978768500; 57220185331; 56349712700; 55739099100; 56048299800","Enhancing Noise Robustness of Retrieval-Augmented Language Models with Adaptive Adversarial Training","2024","Proceedings of the Annual Meeting of the Association for Computational Linguistics","1","","","10028","10039","11","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204493908&partnerID=40&md5=e70067f8023683dacf1a51763a0dd8eb","University of Science and Technology of China, China; Shenzhen Institute of Advanced Technology, Chinese Academy of Sciences, China; Shenzhen University, China; Harbin Institute of Technology, Shenzhen, China","Fang F., University of Science and Technology of China, China, Shenzhen Institute of Advanced Technology, Chinese Academy of Sciences, China; Bai Y., Shenzhen Institute of Advanced Technology, Chinese Academy of Sciences, China; Ni S., Shenzhen Institute of Advanced Technology, Chinese Academy of Sciences, China; Yang M., Shenzhen Institute of Advanced Technology, Chinese Academy of Sciences, China; Chen X., Shenzhen University, China; Xu R., Harbin Institute of Technology, Shenzhen, China","Large Language Models (LLMs) exhibit substantial capabilities yet encounter challenges, including hallucination, outdated knowledge, and untraceable reasoning processes. Retrieval-augmented generation (RAG) has emerged as a promising solution, integrating knowledge from external databases to mitigate these challenges. However, inappropriate retrieved passages can potentially hinder the LLMs' capacity to generate comprehensive and high-quality responses. Prior RAG studies on the robustness of retrieval noises often confine themselves to a limited set of noise types, deviating from real-world retrieval environments and limiting practical applicability. In this study, we initially investigate retrieval noises and categorize them into three distinct types, reflecting real-world environments. We analyze the impact of these various retrieval noises on the robustness of LLMs. Subsequently, we propose a novel RAG approach known as Retrieval-augmented Adaptive Adversarial Training (RAAT). RAAT leverages adaptive adversarial training to dynamically adjust the model's training process in response to retrieval noises. Concurrently, it employs multi-task learning to ensure the model's capacity to internally recognize noisy contexts. Extensive experiments demonstrate that the LLaMA-2 7B model trained using RAAT exhibits significant improvements in F1 and EM scores under diverse noise conditions. For reproducibility, we release our code and data at: https://github.com/calubkk/RAAT. © 2024 Association for Computational Linguistics.","","Adversarial machine learning; Generative adversarial networks; Modeling languages; Multi-task learning; Comprehensive qualities; External database; High quality; Language model; Model training; Noise robustness; Noise types; Real world environments; Real-world; Reasoning process; Computational linguistics","Ku L.-W.; Martins A.F.T.; Srikumar V.","Association for Computational Linguistics (ACL)","English","Conference paper","Final","","Scopus","2-s2.0-85204493908"
"Yokoyama H.; Tsuchida R.; Buma K.; Miyakawa S.; Utsuro T.; Yoshioka M.","Yokoyama, Hibiki (59341854100); Tsuchida, Rikuto (59342539400); Buma, Kosei (59342821100); Miyakawa, Sho (59342264400); Utsuro, Takehito (6506562478); Yoshioka, Masaharu (7402480542)","59341854100; 59342539400; 59342821100; 59342264400; 6506562478; 7402480542","Aggregating Impressions on Celebrities and their Reasons from Microblog Posts and Web Search Pages by LLMs","2024","KnowledgeNLP 2024 - 3rd Workshop on Knowledge Augmented Methods for NLP, Proceedings of the Workshop","","","","59","72","13","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204884253&partnerID=40&md5=6da87cea93f74b845eb50be2047f06b0","University of Tsukuba, Japan; Hokkaido University, Japan","Yokoyama H., University of Tsukuba, Japan; Tsuchida R., University of Tsukuba, Japan; Buma K., University of Tsukuba, Japan; Miyakawa S., University of Tsukuba, Japan; Utsuro T., University of Tsukuba, Japan; Yoshioka M., Hokkaido University, Japan","This paper aims to augment fans' ability to critique and explore information related to celebrities of interest. First, we collect posts from X (formerly Twitter) that discuss matters related to specific celebrities. For the collection of major impressions from these posts, we employ ChatGPT as a large language model (LLM) to analyze and summarize key sentiments. Next, based on collected impressions, we search for Web pages and collect the content of the top 30 ranked pages as the source for exploring the reasons behind those impressions. Once the Web page content collection is complete, we collect and aggregate detailed reasons for the impressions on the celebrities from the content of each page. For this part, we continue to use ChatGPT, enhanced by the retrieval augmented generation (RAG) framework, to ensure the reliability of the collected results compared to relying solely on the prior knowledge of the LLM. Evaluation results by comparing a reference that is manually collected and aggregated reasons with those predicted by ChatGPT revealed that ChatGPT achieves high accuracy in reason collection and aggregation. Furthermore, we compared the performance of ChatGPT with an existing model of mT5 in reason collection and confirmed that ChatGPT exhibits superior performance. © 2024 Association for Computational Linguistics.","","Computational linguistics; Websites; Evaluation results; High-accuracy; Language model; Micro-blog; Performance; Prior-knowledge; Search page; Web searches; Web-page; Tweets","Yu W.; Shi W.; Yasunaga M.; Jiang M.; Zhu C.; Hajishirzi H.; Zettlemoyer L.; Zhang Z.","Association for Computational Linguistics (ACL)","English","Conference paper","Final","","Scopus","2-s2.0-85204884253"
"Srinivasagan G.; Georges M.","Srinivasagan, Gokul (58779227800); Georges, Munir (48061199300)","58779227800; 48061199300","Retrieval Augmented Spoken Language Generation for Transport Domain","2024","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","15049 LNAI","","","3","12","9","0","10.1007/978-3-031-70566-3_1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204392487&doi=10.1007%2f978-3-031-70566-3_1&partnerID=40&md5=a3c142b100468eb07869fbb21d12d424","AImotion Bavaria, Technische Hochschule Ingolstadt, Ingolstadt, Germany","Srinivasagan G., AImotion Bavaria, Technische Hochschule Ingolstadt, Ingolstadt, Germany; Georges M., AImotion Bavaria, Technische Hochschule Ingolstadt, Ingolstadt, Germany","RAG-based models have gained significant attention in recent times mainly due to their ability to address some of the key challenges like mitigation hallucination, incorporation of knowledge from external sources and traceability in the reasoning process. While numerous works in the textual domain leverage additional knowledge to enhance performance, the adaptability of RAG-based models in the speech domain remains largely unexplored. This approach is particularly well-suited for transport applications, where there is a constant change in the schedule and the model needs to be aware of these changes to provide updated information to users. The datasets for such tasks are lacking, and the applicability of language models in the transport domain remains underexplored. In this work, we try to address these problems by exploiting pretrained large language models to generate a synthetic dataset for transport applications. We also utilize the pretrained language models to evaluate the performance of our cascaded RAG system. The experimental results revealed that our approach is less prone to hallucination and can generate grammatically correct responses to user queries. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.","Language models; Retrieval Augmented Generation (RAG); Spoken Language Generation (SLG); Spoken Language Understanding (SLU); Transport domain","Large datasets; Modeling languages; Problem oriented languages; Language generation; Language model; Performance; Retrieval augmented generation; Spoken language generation; Spoken language understanding; Spoken languages; Transport applications; Transport domain; Speech enhancement","Nöth E.; Horák A.; Sojka P.","Springer Science and Business Media Deutschland GmbH","English","Conference paper","Final","","Scopus","2-s2.0-85204392487"
"Scotti V.; Carman M.J.","Scotti, Vincenzo (57222517186); Carman, Mark James (10240340400)","57222517186; 10240340400","LLM Support for Real-Time Technical Assistance","2024","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","14948 LNAI","","","388","393","5","0","10.1007/978-3-031-70371-3_26","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203878594&doi=10.1007%2f978-3-031-70371-3_26&partnerID=40&md5=6b3c21ec14acb2be833a725e6e23577e","DEIB, Politecnico di Milano, Via Ponzio 34/5, MI, Milan, 20133, Italy","Scotti V., DEIB, Politecnico di Milano, Via Ponzio 34/5, MI, Milan, 20133, Italy; Carman M.J., DEIB, Politecnico di Milano, Via Ponzio 34/5, MI, Milan, 20133, Italy","In this paper, we present a demo web application that adopts Large Language Models (LLMs) to enhance user support across various fields. Its primary goal is to enable experts, like technicians, to deliver remote assistance more effectively by leveraging LLM capabilities. The application permits experts to browse through a database of documents, including past support chats and manuals, and suggests responses based on previous interactions. We developed the demo using publicly available data sets from technical support and tutoring domains to showcase its adaptability. Key features include search functionality, response suggestions, and automatic information extraction. The demo highlights the potential of LLMs in improving technical support workflows by streamlining knowledge retrieval and aiding technicians in resolving queries, leading to enhanced efficiency and user satisfaction in support interactions. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.","Few-Shots Learning; LLM; RAG; Semantic Search","Adversarial machine learning; Contrastive Learning; Information retrieval; Metadata; Modeling languages; Search engines; Few-shot learning; Language model; Large language model; RAG; Real- time; Semantic search; Technical assistance; Technical support; WEB application; Web applications; Semantics","Bifet A.; Daniušis P.; Davis J.; Krilavičius T.; Kull M.; Ntoutsi E.; Puolamäki K.; Žliobaitė I.","Springer Science and Business Media Deutschland GmbH","English","Conference paper","Final","","Scopus","2-s2.0-85203878594"
"Fore M.; Singh S.; Lee C.; Pandey A.; Anastasopoulos A.; Stamoulis D.","Fore, Michael (59090433700); Singh, Simranjit (58843061200); Lee, Chaehong (59188886700); Pandey, Amritanshu (57191526454); Anastasopoulos, Antonios (56349759500); Stamoulis, Dimitrios (57077035100)","59090433700; 58843061200; 59188886700; 57191526454; 56349759500; 57077035100","Unlearning Climate Misinformation in Large Language Models","2024","ClimateNLP 2024 - 1st Workshop on Natural Language Processing Meets Climate Change, Proceedings of the Workshop","","","","178","192","14","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204448847&partnerID=40&md5=c5ecf9d1c0656b00a191da6157277b6d","Microsoft Corporation, United States; Dept. of Electrical and Biomedical Engineering, University of Vermont, United States; Dept. of Computer Science, George Mason University, United States; Archimedes AI Unit, RC Athena, Athens, Greece","Fore M., Microsoft Corporation, United States; Singh S., Microsoft Corporation, United States; Lee C., Microsoft Corporation, United States; Pandey A., Dept. of Electrical and Biomedical Engineering, University of Vermont, United States; Anastasopoulos A., Dept. of Computer Science, George Mason University, United States, Archimedes AI Unit, RC Athena, Athens, Greece; Stamoulis D., Microsoft Corporation, United States","Misinformation regarding climate change is a key roadblock in addressing one of the most serious threats to humanity. This paper investigates factual accuracy in large language models (LLMs) regarding climate information. Using true/false labeled Q&A data for finetuning and evaluating LLMs on climate-related claims, we compare open-source models, assessing their ability to generate truthful responses to climate change questions. We investigate the detectability of models intentionally poisoned with false climate information, finding that such poisoning may not affect the accuracy of a model’s responses in other domains. Furthermore, we compare the effectiveness of unlearning algorithms, fine-tuning, and Retrieval-Augmented Generation (RAG) for factually grounding LLMs on climate change topics. Our evaluation reveals that unlearning algorithms can be effective for nuanced conceptual claims, despite previous findings suggesting their inefficacy in privacy contexts. These insights aim to guide the development of more factually reliable LLMs and highlight the need for additional work to secure LLMs against misinformation attacks.1 ©2024 Association for Computational Linguistics.","","Computational linguistics; Differential privacy; Open systems; Climate information; Detectability; Fine tuning; Language model; Open-source model; Climate models","Stammbach D.; Ni J.; Schimanski T.; Dutia K.; Singh A.; Bingler J.; Christiaen C.; Kushwaha N.; Muccione V.; Vaghefi S.A.; Leippold M.","Association for Computational Linguistics (ACL)","English","Conference paper","Final","","Scopus","2-s2.0-85204448847"
"Wang H.; Hu K.; Dong H.; Gao L.","Wang, Haochen (59008631300); Hu, Kai (57221913797); Dong, Haoyu (59325186200); Gao, Liangcai (25924927000)","59008631300; 57221913797; 59325186200; 25924927000","DocTabQA: Answering Questions from Long Documents Using Tables","2024","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","14804 LNCS","","","470","487","17","0","10.1007/978-3-031-70533-5_27","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204526985&doi=10.1007%2f978-3-031-70533-5_27&partnerID=40&md5=7e8633dda29a714c69000e11ffe8909d","Peking University, Beijing, China; University of Science and Technology of China, Hefei, China; Microsoft Corporation, Chennai, India","Wang H., Peking University, Beijing, China; Hu K., University of Science and Technology of China, Hefei, China; Dong H., Microsoft Corporation, Chennai, India; Gao L., Peking University, Beijing, China","We study a new problem setting of question answering (QA), referred to as DocTabQA. Within this setting, given a long document, the goal is to respond to questions by organizing the answers into structured tables derived directly from the document’s content. Unlike traditional QA approaches which predominantly rely on unstructured text to formulate responses, DocTabQA aims to leverage structured tables as answers to convey information clearly and systematically, thereby enhancing user comprehension and highlighting relationships between data points. To the best of our knowledge, this problem has not been previously explored. In this paper, we introduce the QTabA dataset, encompassing 300 financial documents, accompanied by manually annotated 1.5k question-table pairs. Initially, we leverage Large Language Models (LLMs) such as GPT-4 to establish a baseline. However, it is widely acknowledged that LLMs encounter difficulties when tasked with generating intricate, structured outputs from long input sequences. To overcome these challenges, we present a two-stage framework, called DocTabTalk, which initially retrieves relevant sentences from extensive documents and subsequently generates hierarchical tables based on these identified sentences. DocTabTalk incorporates two key technological innovations: AlignLLaMA and TabTalk, which are specifically tailored to assist GPT-4 in tackling DocTabQA, enabling it to generate well-structured, hierarchical tables with improved organization and clarity. Comprehensive experimental evaluations conducted on both QTabA and RotoWire datasets demonstrate that our DocTabTalk significantly enhances the performances of the GPT-4 in our proposed DocTabQA task and the table generation task. The code and dataset are available at https://github.com/SmileWHC/DocTabQA for further research. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.","Dataset; Large Language Model; Question Answering; Retrieval Augmented Generation; Table Generation","Large datasets; Modeling languages; Structured Query Language; Datapoints; Dataset; Input sequence; Language model; Large language model; Question Answering; Retrieval augmented generation; Table generation; Technological innovation; Unstructured texts; Question answering","Barney Smith E.H.; Liwicki M.; Peng L.","Springer Science and Business Media Deutschland GmbH","English","Conference paper","Final","","Scopus","2-s2.0-85204526985"
"Bernardi M.L.; Cimitile M.; Pecori R.","Bernardi, Mario Luca (57195515766); Cimitile, Marta (23392132800); Pecori, Riccardo (35186369500)","57195515766; 23392132800; 35186369500","Automatic Job Safety Report Generation using RAG-based LLMs","2024","Proceedings of the International Joint Conference on Neural Networks","","","","","","","0","10.1109/IJCNN60899.2024.10651320","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205028222&doi=10.1109%2fIJCNN60899.2024.10651320&partnerID=40&md5=bd8dc82a274450ae623c4bed59983aff","University of Sannio, Department of Engineering, Benevento, Italy; Unitelma Sapienza University, Department of Law and Digital Society, Rome, Italy; ECampus University & National Research Council of Italy, SMARTEST Research Centre, Institute of Materials for Electronics and Magnetism, Parma, Italy","Bernardi M.L., University of Sannio, Department of Engineering, Benevento, Italy; Cimitile M., Unitelma Sapienza University, Department of Law and Digital Society, Rome, Italy; Pecori R., ECampus University & National Research Council of Italy, SMARTEST Research Centre, Institute of Materials for Electronics and Magnetism, Parma, Italy","This study introduces an innovative approach to safety report generation using a Retrieval-Augmented Generation (RAG) framework, tailored to synthesize comprehensive reports from descriptions and logs of work sessions. The core contribution of our study is the comparison and optimization of various Large Language Model variants (based on LLaMA) and embedding models, aiming to identify the most effective combination for accurately capturing and reflecting the intricacies of safety-related data in a given domain. Our RAG-based system leverages the strengths of different LLaMA models and embedding techniques to process and contextualize the input data, which include detailed session descriptions and operational logs. By integrating these models, we aim to automate the generation of safety reports that are not only coherent and contextually relevant, but also adhere to the stringent requirements of safety documentation in professional environments. The validation of our approach is performed using an aviation safety dataset and classic metrics in the field, such as Recall@5, GLEU, METEOR, and BERTscore. Our findings demonstrate the potential of RAG-based systems in streamlining the process of safety report generation, offering significant improvements in efficiency and accuracy over traditional methods and non domain-specific tailored models. © 2024 IEEE.","decision support systems; Job safety; LLMs; RAG; reporting; risk assessment","Artificial intelligence; Decision support systems; Problem oriented languages; Decision supports; Innovative approaches; Job safeties; LLM; Report generation; Reporting; Retrieval-augmented generation; Risks assessments; Safety reports; Support systems; Risk assessment","","Institute of Electrical and Electronics Engineers Inc.","English","Conference paper","Final","","Scopus","2-s2.0-85205028222"
"Enouen J.; Nakhost H.; Ebrahimi S.; Arik S.Ö.; Liu Y.; Pfister T.","Enouen, James (57212196313); Nakhost, Hootan (58580432700); Ebrahimi, Sayna (57008797400); Arik, Sercan Ö. (57201791321); Liu, Yan (59130443200); Pfister, Tomas (36598926300)","57212196313; 58580432700; 57008797400; 57201791321; 59130443200; 36598926300","TextGenSHAP: Scalable Post-hoc Explanations in Text Generation with Long Documents","2024","Proceedings of the Annual Meeting of the Association for Computational Linguistics","","","","13984","14011","27","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205306339&partnerID=40&md5=b5df33d87ae486cf5e1dba8375ed8d0d","University of Southern California, Los Angeles, CA, United States; Google Cloud AI Research, Sunnyvale, CA, United States","Enouen J., University of Southern California, Los Angeles, CA, United States; Nakhost H., Google Cloud AI Research, Sunnyvale, CA, United States; Ebrahimi S., Google Cloud AI Research, Sunnyvale, CA, United States; Arik S.Ö., Google Cloud AI Research, Sunnyvale, CA, United States; Liu Y., University of Southern California, Los Angeles, CA, United States; Pfister T., Google Cloud AI Research, Sunnyvale, CA, United States","Large language models (LLMs) have attracted great interest in many real-world applications; however, their ""black-box"" nature necessitates scalable and faithful explanations. Shapley values have matured as an explainability method for deep learning, but extending them to LLMs is difficult due to long input contexts and autoregressive output generation. We introduce TextGenSHAP, an efficient post-hoc explanation method incorporating LLM-specific techniques, which leads to significant runtime improvements: token-level explanations in minutes not hours, and document-level explanations within seconds. We demonstrate how such explanations can improve end-to-end performance of retrieval augmented generation by localizing important words within long documents and reranking passages collected by retrieval systems. On various open-domain question answering benchmarks, we show TextGenSHAP improves the retrieval recall and prediction accuracy significantly. © 2024 Association for Computational Linguistics.","","Benchmarking; Deep learning; Modeling languages; Open systems; Auto-regressive; Black boxes; End-to-end performance; Language model; Re-ranking; Real-world; Retrieval systems; Runtimes; Shapley value; Text generations; Computational linguistics","Ku L.-W.; Martins A.; Srikumar V.","Association for Computational Linguistics (ACL)","English","Conference paper","Final","","Scopus","2-s2.0-85205306339"
"Li D.; Yan J.; Zhang T.; Wang C.; He X.; Huang L.; Xue H.; Huang J.","Li, Dongyang (57223824282); Yan, Junbing (57219229616); Zhang, Taolin (57221142663); Wang, Chengyu (55926354300); He, Xiaofeng (55641972700); Huang, Longtao (37121905700); Xue, Hui (57209881434); Huang, Jun (57199287007)","57223824282; 57219229616; 57221142663; 55926354300; 55641972700; 37121905700; 57209881434; 57199287007","On the Role of Long-tail Knowledge in Retrieval Augmented Large Language Models","2024","Proceedings of the Annual Meeting of the Association for Computational Linguistics","2","","","120","126","6","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203814566&partnerID=40&md5=1f2bc1e36f437103333bad201c229ea7","School of Computer Science and Technology, East China Normal University, China; Alibaba Group, China; NPPA Key Laboratory of Publishing Integration Development, ECNUP, China","Li D., School of Computer Science and Technology, East China Normal University, China, Alibaba Group, China; Yan J., School of Computer Science and Technology, East China Normal University, China, Alibaba Group, China; Zhang T., Alibaba Group, China; Wang C., Alibaba Group, China; He X., School of Computer Science and Technology, East China Normal University, China, NPPA Key Laboratory of Publishing Integration Development, ECNUP, China; Huang L., Alibaba Group, China; Xue H., Alibaba Group, China; Huang J., Alibaba Group, China","Retrieval augmented generation (RAG) exhibits outstanding performance in promoting the knowledge capabilities of large language models (LLMs) with retrieved documents related to user queries. However, RAG only focuses on improving the response quality of LLMs via enhancing queries indiscriminately with retrieved information, paying little attention to what type of knowledge LLMs really need to answer original queries more accurately. In this paper, we suggest that long-tail knowledge is crucial for RAG as LLMs have already remembered common world knowledge during large-scale pre-training. Based on our observation, we propose a simple but effective long-tail knowledge detection method for LLMs. Specifically, the novel Generative Expected Calibration Error (GECE) metric is derived to measure the “long-tailness” of knowledge based on both statistics and semantics. Hence, we retrieve relevant documents and infuse them into the model for patching knowledge loopholes only when the input query relates to long-tail knowledge. Experiments show that, compared to existing RAG pipelines, our method achieves over 4x speedup in average inference time and consistent performance improvement in downstream tasks. © 2024 Association for Computational Linguistics.","","Computational linguistics; Error statistics; Modeling languages; Natural language processing systems; Query languages; Structured Query Language; Knowledge capabilities; Language model; Large-scales; Long tail; Performance; Pre-training; Retrieved documents; Simple++; User query; World knowledge; Semantics","Ku L.-W.; Martins A.F.T.; Srikumar V.","Association for Computational Linguistics (ACL)","English","Conference paper","Final","","Scopus","2-s2.0-85203814566"
"Wendelken S.; Antony A.; Korutla R.; Pachipala B.; Mahajan D.; Shanahan J.G.; Saba W.","Wendelken, S. (58822125000); Antony, A. (59335688400); Korutla, R. (59335203500); Pachipala, B. (59336361800); Mahajan, D. (59336193800); Shanahan, J.G. (59336193900); Saba, W. (59340098100)","58822125000; 59335688400; 59335203500; 59336361800; 59336193800; 59336193900; 59340098100","Roux-lette at “Discharge Me!”: Reducing EHR Chart Burden with a Simple, Scalable, Clinician-Driven AI Approach","2024","BioNLP 2024 - 23rd Meeting of the ACL Special Interest Group on Biomedical Natural Language Processing, Proceedings of the Workshop and Shared Tasks","","","","719","723","4","1","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204422297&partnerID=40&md5=7d2a93cbf33b6b7877f0f82e5d0463ad","The Roux Institute, Northeastern University, United States; The Institute for Experiential AI, Northeastern University, United States","Wendelken S., The Roux Institute, Northeastern University, United States; Antony A., The Institute for Experiential AI, Northeastern University, United States; Korutla R., The Roux Institute, Northeastern University, United States; Pachipala B., The Roux Institute, Northeastern University, United States; Mahajan D., The Institute for Experiential AI, Northeastern University, United States; Shanahan J.G., The Institute for Experiential AI, Northeastern University, United States; Saba W., The Institute for Experiential AI, Northeastern University, United States","Healthcare providers spend a significant amount of time reading and synthesizing electronic health records (EHRs), negatively impacting patient outcomes and causing provider burnout. Traditional supervised machine learning approaches using large language models (LLMs) to summarize clinical text have struggled due to hallucinations and lack of relevant training data. Here, we present a novel, simplified solution for the “Discharge Me!” shared task. Our solution uses a question-based approach to treat this summarization task as a context-aware and domain-specific question-answering process. Our pipeline prompts an LLM answer specific questions posed by subject-matter experts (SMEs) using only patient specific context data. This method (i) avoids hallucinations through hybrid RAG/zero-shot contextualized prompting; (ii) requires no extensive training or fine-tuning; and (iii) is adaptable to various clinical tasks.. ©2024 Association for Computational Linguistics.","","Records management; Self-supervised learning; Context-Aware; Domain specific; Electronic health; Health care providers; Health records; Language model; Machine learning approaches; Simple++; Supervised machine learning; Training data; Electronic health record","Demner-Fushman D.; Ananiadou S.; Miwa M.; Roberts K.; Tsujii J.","Association for Computational Linguistics (ACL)","English","Conference paper","Final","","Scopus","2-s2.0-85204422297"
"Ghassel A.; Zhu X.; Thomas S.W.","Ghassel, Abdellah (59343861100); Zhu, Xiaodan (55696698900); Thomas, Stephen W. (57878829200)","59343861100; 55696698900; 57878829200","Are Large Language Models General-Purpose Solvers for Dialogue Breakdown Detection? An Empirical Investigation","2024","Canadian Conference on Electrical and Computer Engineering","","","","674","679","5","0","10.1109/CCECE59415.2024.10667232","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204969533&doi=10.1109%2fCCECE59415.2024.10667232&partnerID=40&md5=367923cb428f0269d26ffe9780959837","Ingenuity Labs Research Institute, Canada; Queen's University, Department of Electrical and Computer Engineering, Kingston, ON, Canada; Queen's University, Smith School of Business, Kingston, ON, Canada","Ghassel A., Ingenuity Labs Research Institute, Canada, Queen's University, Department of Electrical and Computer Engineering, Kingston, ON, Canada; Zhu X., Ingenuity Labs Research Institute, Canada, Queen's University, Department of Electrical and Computer Engineering, Kingston, ON, Canada; Thomas S.W., Queen's University, Smith School of Business, Kingston, ON, Canada","This study addresses the challenge of dialogue breakdown - characterized as incoherence, irrelevance, or any disruption that significantly hampers the flow of the conversation. The impact of dialogue breakdowns has become critical with the adoption of large language models in various industries for companies with dialogue-based systems, such as Salesforce, Amazon, and Microsoft. Leveraging the Dialogue Breakdown Detection Challenge Dataset, we investigate the performance of generalist large language models, including ChatGPT, GPT-4, and Mistral-Medium, in identifying instances of dialogue breakdown without domain-specific fine-tuning. Through a series of experiments employing zero-shot and few-shot prompting techniques combined with chain-of-thought reasoning, this research sets a new benchmark in the field. Our findings reveal that GPT-4 outperforms both specialized models previously considered state-of-the-art and other generalist models in detecting dialogue breakdowns by over a 3% margin, achieving an accuracy of 82.0%. To our knowledge, this study is the first to demonstrate the enhanced capability of generalist large language models in this domain. Our experiments found that when detecting dialogue breakdowns, larger models like GPT-4 are less sensitive to how they are prompted. In contrast, smaller models like ChatGPT and Mistral-Medium can improve their performance by using prompting techniques that combine few-shot learning with the chain-of-thought method. This work proposes future research directions, including enhanced error analysis and developing an Ensemble RAG approach for improved generalization in dialogue breakdown detection.  © 2024 IEEE.","conversational artificial intelligence; dialogue breakdown; large language models","Speech enhancement; Speech recognition; Breakdown detection; Conversational artificial intelligence; Dialog breakdown; Empirical investigation; General-purpose solvers; Language model; Large language model; MicroSoft; Performance; Salesforce; Zero-shot learning","","Institute of Electrical and Electronics Engineers Inc.","English","Conference paper","Final","","Scopus","2-s2.0-85204969533"
"Mudassar Yamin M.; Hashmi E.; Ullah M.; Katt B.","Mudassar Yamin, Muhammad (57205121104); Hashmi, Ehtesham (58922146700); Ullah, Mohib (7006278145); Katt, Basel (25824984500)","57205121104; 58922146700; 7006278145; 25824984500","Applications of LLMs for Generating Cyber Security Exercise Scenarios","2024","IEEE Access","12","","","143806","143822","16","0","10.1109/ACCESS.2024.3468914","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205455626&doi=10.1109%2fACCESS.2024.3468914&partnerID=40&md5=63a5c492552b3877679b7bbd77117cde","Norwegian University of Science and Technology (NTNU), Department of Information Security and Communication Technology (IIK), Gjovik, 2815, Norway; Norwegian University of Science and Technology (NTNU), Department of Computer Science (IDI), Gjovik, 2815, Norway","Mudassar Yamin M., Norwegian University of Science and Technology (NTNU), Department of Information Security and Communication Technology (IIK), Gjovik, 2815, Norway; Hashmi E., Norwegian University of Science and Technology (NTNU), Department of Information Security and Communication Technology (IIK), Gjovik, 2815, Norway; Ullah M., Norwegian University of Science and Technology (NTNU), Department of Computer Science (IDI), Gjovik, 2815, Norway; Katt B., Norwegian University of Science and Technology (NTNU), Department of Information Security and Communication Technology (IIK), Gjovik, 2815, Norway","This study proposes a novel approach leveraging Large Language Models (LLMs) to generate dynamic and complex adaptable cybersecurity exercise scenarios. Motivated by Turing's seminal exploration into machine cognition, which questions the ability of machines to mimic human thought and intelligence. By exploiting the generative potential of LLMs, our methodology simulates a wide range of cyber threats, both known and novel, thereby enhancing cybersecurity training and awareness. This approach transforms the potential for 'hallucination' inherent in LLMs into a potential advantage, enabling the creation of complex exercise scenarios that push the boundaries of traditional cybersecurity training. The innovation lies in the sophisticated application of AI, aiming to advance the preparedness of security professionals against diverse cyber threats. The scenarios generated through this method were subject to meticulous testing and a rigorous evaluation process involving (Generated Pre-Trained Transformer) GPT models and expert review to ensure their realism and applicability. In this paper, we introduce 'CyExec,' a novel approach leveraging GPT to dynamically generate cybersecurity training scenarios. Furthermore, the prompts provided to the LLMs were meticulously designed to adopt a Retrieval-Augmented Generation (RAG) approach, enriching the complexity and relevance of the scenarios. This incorporation of RAG, alongside the inspiration drawn from Turing's exploration of machine intelligence, showcases an advanced application of AI in cybersecurity training, reflecting a deep understanding of how machines can augment our capabilities to anticipate and mitigate cyber threats.  © 2013 IEEE.","bounded rationality; Cyber security exercise scenarios; generative configurations; Halluciation in LLMs; large language models","Computer crime; Electric transformer testing; Network intrusion; Bounded rationality; Cybe security exercise scenario; Cyber security; Cyber security exercise; Cyber threats; Generative configuration; Halluciation in large language model; Language model; Large language model; Cyber attacks","","Institute of Electrical and Electronics Engineers Inc.","English","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85205455626"
"Bašaragin B.; Ljajić A.; Medvecki D.; Cassano L.; Košprdić M.; Milošević N.","Bašaragin, Bojana (57974146600); Ljajić, Adela (57188983598); Medvecki, Darija (57974146500); Cassano, Lorenzo (59230581300); Košprdić, Miloš (58064916700); Milošević, Nikola (57189331118)","57974146600; 57188983598; 57974146500; 59230581300; 58064916700; 57189331118","How do you know that? Teaching Generative Language Models to Reference Answers to Biomedical Questions","2024","BioNLP 2024 - 23rd Meeting of the ACL Special Interest Group on Biomedical Natural Language Processing, Proceedings of the Workshop and Shared Tasks","","","","536","547","11","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204109013&partnerID=40&md5=d920b3fcb8ffcc97abd036d73568b0e7","The Institute for AI of Serbia, Fruškogorska 1, Novi Sad, Serbia; Bayer A.G., Müllerstraße 178, Berlin, Germany","Bašaragin B., The Institute for AI of Serbia, Fruškogorska 1, Novi Sad, Serbia; Ljajić A., The Institute for AI of Serbia, Fruškogorska 1, Novi Sad, Serbia; Medvecki D., The Institute for AI of Serbia, Fruškogorska 1, Novi Sad, Serbia; Cassano L., Bayer A.G., Müllerstraße 178, Berlin, Germany; Košprdić M., The Institute for AI of Serbia, Fruškogorska 1, Novi Sad, Serbia; Milošević N., Bayer A.G., Müllerstraße 178, Berlin, Germany","Large language models (LLMs) have recently become the leading source of answers for users’ questions online. Despite their ability to offer eloquent answers, their accuracy and reliability can pose a significant challenge. This is especially true for sensitive domains such as biomedicine, where there is a higher need for factually correct answers. This paper introduces a biomedical retrieval-augmented generation (RAG) system designed to enhance the reliability of generated responses. The system is based on a fine-tuned LLM for the referenced question-answering, where retrieved relevant abstracts from PubMed are passed to LLM’s context as input through a prompt. Its output is an answer based on PubMed abstracts, where each statement is referenced accordingly, allowing the users to verify the answer. Our retrieval system achieves an absolute improvement of 23% compared to the PubMed search engine. Based on the manual evaluation on a small sample, our fine-tuned LLM component achieves comparable results to GPT-4 Turbo in referencing relevant abstracts. We make the dataset used to fine-tune the models and the fine-tuned models based on Mistral-7B-instruct-v0.1 and v0.2 publicly available.. ©2024 Association for Computational Linguistics.","","Question answering; Generation systems; Know-that; Language model; Language model components; Model-based OPC; Question Answering; Retrieval systems; Small samples; Computational linguistics","Demner-Fushman D.; Ananiadou S.; Miwa M.; Roberts K.; Tsujii J.","Association for Computational Linguistics (ACL)","English","Conference paper","Final","","Scopus","2-s2.0-85204109013"
"Soliman H.; Kravcik M.; Neumann A.T.; Yin Y.; Pengel N.; Haag M.","Soliman, Hassan (59224480800); Kravcik, Milos (55887919900); Neumann, Alexander Tobias (57215417992); Yin, Yue (58624177700); Pengel, Norbert (57205566883); Haag, Maike (59348445400)","59224480800; 55887919900; 57215417992; 58624177700; 57205566883; 59348445400","Scalable Mentoring Support with a Large Language Model Chatbot","2024","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","15160 LNCS","","","260","266","6","0","10.1007/978-3-031-72312-4_37","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205323742&doi=10.1007%2f978-3-031-72312-4_37&partnerID=40&md5=81732c5fe3d2e4d5da60471739501fdc","DFKI, Berlin, Germany; RWTH Aachen University, Aachen, Germany; Leipzig University, Leipzig, Germany","Soliman H., DFKI, Berlin, Germany; Kravcik M., DFKI, Berlin, Germany; Neumann A.T., RWTH Aachen University, Aachen, Germany; Yin Y., RWTH Aachen University, Aachen, Germany; Pengel N., Leipzig University, Leipzig, Germany; Haag M., Leipzig University, Leipzig, Germany","Education students engage in diverse learning activities requiring appropriate assistance and timely feedback. As their numbers grow, providing them with scalable support is an important challenge. Here, we focus on the development of a didactic chatbot based on a Large Language Model (LLM). The potential of LLMs is enhanced by existing materials and pedagogical course descriptions. Using Retrieval Augmented Generation (RAG), the bot can retrieve and analyse course materials, in order to provide comprehensive answers to specific questions. Preliminary results indicate that it is possible to distinguish between different student contexts and to generate a prompt answer, taking into account the relevant materials. The evaluation results achieved 84.78% accuracy in providing correct answers for seminar materials. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.","Chatbot; Large Language Model; Scalable Mentoring","Students; Chatbots; Course material; Evaluation results; Language model; Large language model; Learning Activity; Pedagogical course; Scalable mentoring; Students' contexts; Timely feedback; Bot (Internet)","Ferreira Mello R.; Rummel N.; Jivet I.; Pishtari G.; Ruipérez Valiente J.A.","Springer Science and Business Media Deutschland GmbH","English","Conference paper","Final","","Scopus","2-s2.0-85205323742"
"Sung C.-W.; Lee Y.-K.; Tsai Y.-T.","Sung, Chih-Wei (59305863900); Lee, Yu-Kai (58205532600); Tsai, Yin-Te (7402627942)","59305863900; 58205532600; 7402627942","A New Pipeline for Generating Instruction Dataset via RAG and Self Fine-Tuning","2024","Proceedings - 2024 IEEE 48th Annual Computers, Software, and Applications Conference, COMPSAC 2024","","","","2308","2312","4","0","10.1109/COMPSAC61105.2024.00371","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204050669&doi=10.1109%2fCOMPSAC61105.2024.00371&partnerID=40&md5=c59b7a51854081f5920629f935948be3","Computer Scicence and Communication Engineering, Providence University, Taichung, Taiwan","Sung C.-W., Computer Scicence and Communication Engineering, Providence University, Taichung, Taiwan; Lee Y.-K., Computer Scicence and Communication Engineering, Providence University, Taichung, Taiwan; Tsai Y.-T., Computer Scicence and Communication Engineering, Providence University, Taichung, Taiwan","With the rapid development of large language models (LLMs) in recent years, there has been an increasing demand for domain-specific Agents that can cater to the unique needs of enterprises and organizations. Unlike general models, which strive for broad coverage, these specialized Agents rely on focused datasets tailored to their intended applications. This research proposes a pipeline that leverages the power of LLMs and the Retrieval-Augmented Generation (RAG) related framework to construct high-quality instruction datasets for finetuning on specific domains using custom document collections. By ingesting domain-specific documents, the pipeline generates relevant and contextually appropriate instructions, thus effectively creating a comprehensive dataset for fine-tuning LLMs on the target domain. This approach overcomes the limitations of traditional dataset creation methods, which often rely on manual curation or web-scraping techniques that may introduce noise and irrelevant data. Notably, our pipeline offers a dynamic solution that can quickly adapt to updates or modifications in the domainspecific document collection, eliminating the need for complete retraining. Additionally, it addresses the challenge of data scarcity by enabling the generation of instruction datasets from a limited set of initial documents, rendering it suitable for unpopular or specialized domains where comprehensive datasets are scarce. As a case study, we apply this approach to the domain of psychiatry, a field requiring specialized knowledge and sensitive handling of patient information. The resulting fine-tuned LLM demonstrates showcases the viability of the proposed approach and underscores its potential for widespread adoption across various industries and domains where tailored, accurate, and contextually relevant language models are indispensable.  © 2024 IEEE.","Instruction Tuning; Large Language Model; Psychiatry; Retrieval-Augmented Generation","Hospital data processing; Medical information systems; Document collection; Domain specific; Fine tuning; General model; Instruction tuning; Language model; Large language model; Power; Psychiatry; Retrieval-augmented generation; Data curation","Shahriar H.; Ohsaki H.; Sharmin M.; Towey D.; Majumder AKM.J.A.; Hori Y.; Yang J.-J.; Takemoto M.; Sakib N.; Banno R.; Ahamed S.I.","Institute of Electrical and Electronics Engineers Inc.","English","Conference paper","Final","","Scopus","2-s2.0-85204050669"
"Zhu K.; Feng X.; Du X.; Gu Y.; Yu W.; Wang H.; Chen Q.; Chu Z.; Chen J.; Qin B.","Zhu, Kun (58198603500); Feng, Xiaocheng (57193240486); Du, Xiyuan (58548971700); Gu, Yuxuan (57933717600); Yu, Weijiang (57211681215); Wang, Haotian (57938248200); Chen, Qianglong (57220892222); Chu, Zheng (57657372100); Chen, Jingchang (58335823600); Qin, Bing (8575883100)","58198603500; 57193240486; 58548971700; 57933717600; 57211681215; 57938248200; 57220892222; 57657372100; 58335823600; 8575883100","An Information Bottleneck Perspective for Effective Noise Filtering on Retrieval-Augmented Generation","2024","Proceedings of the Annual Meeting of the Association for Computational Linguistics","1","","","1044","1069","25","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204474135&partnerID=40&md5=dd504a806fa053081319b1c9137a6652","Harbin Institute of Technology, China; Peng Cheng Laboratory, China; Sun Yat-sen University, China; Zhejiang University, China","Zhu K., Harbin Institute of Technology, China; Feng X., Harbin Institute of Technology, China, Peng Cheng Laboratory, China; Du X., Harbin Institute of Technology, China; Gu Y., Harbin Institute of Technology, China; Yu W., Sun Yat-sen University, China; Wang H., Harbin Institute of Technology, China; Chen Q., Zhejiang University, China; Chu Z., Harbin Institute of Technology, China; Chen J., Harbin Institute of Technology, China; Qin B., Harbin Institute of Technology, China, Peng Cheng Laboratory, China","Retrieval-augmented generation integrates the capabilities of large language models with relevant information retrieved from an extensive corpus, yet encounters challenges when confronted with real-world noisy data. One recent solution is to train a filter module to find relevant content but only achieve suboptimal noise compression. In this paper, we propose to introduce the information bottleneck theory into retrieval-augmented generation. Our approach involves the filtration of noise by simultaneously maximizing the mutual information between compression and ground output, while minimizing the mutual information between compression and retrieved passage. In addition, we derive the formula of information bottleneck to facilitate its application in novel comprehensive evaluations, the selection of supervised fine-tuning data, and the construction of reinforcement learning rewards. Experimental results demonstrate that our approach achieves significant improvements across various question answering datasets, not only in terms of the correctness of answer generation but also in the conciseness with 2.5% compression rate. © 2024 Association for Computational Linguistics.","","Information filtering; Question answering; Reinforcement learning; Wiener filtering; Filter module; Information bottleneck; Information bottleneck theories; ITS applications; Language model; Mutual informations; Noise compression; Noise filtering; Noisy data; Real-world; Computational linguistics","Ku L.-W.; Martins A.F.T.; Srikumar V.","Association for Computational Linguistics (ACL)","English","Conference paper","Final","","Scopus","2-s2.0-85204474135"
"Niu C.; Wu Y.; Zhu J.; Xu S.; Shum K.; Zhong R.; Song J.; Zhang T.","Niu, Cheng (58817136900); Wu, Yuanhao (59181496100); Zhu, Juno (59181648200); Xu, Siliang (59181533100); Shum, Kashun (57437930900); Zhong, Randy (57219627663); Song, Juntong (58817260000); Zhang, Tong (59214338900)","58817136900; 59181496100; 59181648200; 59181533100; 57437930900; 57219627663; 58817260000; 59214338900","RAGTruth: A Hallucination Corpus for Developing Trustworthy Retrieval-Augmented Language Models","2024","Proceedings of the Annual Meeting of the Association for Computational Linguistics","1","","","10862","10878","16","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204451216&partnerID=40&md5=3091d19ccf03056e5de179887b8f6e56","NewsBreak; University of Illinois Urbana-Champaign, United States","Niu C., NewsBreak; Wu Y., NewsBreak; Zhu J., NewsBreak; Xu S., NewsBreak; Shum K., NewsBreak; Zhong R., NewsBreak; Song J., NewsBreak; Zhang T., University of Illinois Urbana-Champaign, United States","Retrieval-augmented generation (RAG) has become a main technique for alleviating hallucinations in large language models (LLMs). Despite the integration of RAG, LLMs may still present unsupported or contradictory claims to the retrieved contents. In order to develop effective hallucination prevention strategies under RAG, it is important to create benchmark datasets that can measure the extent of hallucination. This paper presents RAGTruth, a corpus tailored for analyzing word-level hallucinations in various domains and tasks within the standard RAG frameworks for LLM applications. RAGTruth comprises nearly 18,000 naturally generated responses from diverse LLMs using RAG. These responses have undergone meticulous manual annotations at both the individual case and word levels, incorporating evaluations of hallucination intensity. We not only benchmark hallucination frequencies across different LLMs, but also critically assess the effectiveness of several existing hallucination detection methodologies. We show that using a high-quality dataset such as RAGTruth, it is possible to finetune a relatively small LLM and achieve a competitive hallucination detection performance when compared to the existing prompt-based approaches using state-of-the-art LLMs such as GPT-4. Furthermore, the finetuned model can effectively mitigate hallucination in LLM responses. © 2024 Association for Computational Linguistics.","","Benchmarking; Large datasets; Modeling languages; Benchmark datasets; Detection performance; High quality; Language model; Manual annotation; Model application; Model response; Prevention strategies; State of the art; Word level; Computational linguistics","Ku L.-W.; Martins A.F.T.; Srikumar V.","Association for Computational Linguistics (ACL)","English","Conference paper","Final","","Scopus","2-s2.0-85204451216"
"Anh-Khoa N.-H.; Anh-Khoi N.-H.; Khuong-Duy V.","Anh-Khoa, Ngo-Ho (59341176900); Anh-Khoi, Ngo-Ho (59340655000); Khuong-Duy, Vo (59340452400)","59341176900; 59340655000; 59340452400","GVEC: A Generative Vietnamese Chatbot for Economy, Using Vietnamese Economy Information Database from VnEconomy Community","2024","2024 International Conference on Multimedia Analysis and Pattern Recognition, MAPR 2024 - Proceedings","","","","","","","0","10.1109/MAPR63514.2024.10660907","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204771798&doi=10.1109%2fMAPR63514.2024.10660907&partnerID=40&md5=89fde98e77c058139c266edcd3db18f2","Quantmetry, France, France; Nam Can Tho University, Faculty of Information Technology, Viet Nam; Adhightech Ltd., Viet Nam","Anh-Khoa N.-H., Quantmetry, France, France; Anh-Khoi N.-H., Nam Can Tho University, Faculty of Information Technology, Viet Nam; Khuong-Duy V., Adhightech Ltd., Viet Nam","Currently, the problem of automatic question answering (Q/A) with applications in chatbot services has become essential, addressing various issues in daily life. There are many approaches to solving this problem, but each presents its own challenges. The generative AI approach has recently gained widespread attention due to its ability to provide smooth, human-like responses. However, it has the drawback of producing coherent-sounding but inaccurate or fabricated content, known as ""hallucinations"". In this study, we aim to find a solution for the question-answering task in the context of the Vietnamese economy. We propose the Generative Vietnamese Economy Chatbot (GVEC), based on the Vietnam Economy Information Database (VEID) retrieved from VnEconomy systems. Our proposition is to apply Retrieval-Augmented Generation (RAG) to various LLM systems and test them on our specially designed benchmark, called the Vietnamese Numeric Economy Information Question/Answer Datasets (VNEIQAD), generated by our Question/Answers Generating with Numerical Information (QAGwNI) algorithm. This will help better evaluate the solution in the economic context.  © 2024 IEEE.","automatic question answering; chatbot; generative AI; Vietnamese language","Automatic question answering; Chatbots; Daily lives; Generative AI; Human like; Information database; Question Answering Task; Viet Nam; Vietnamese; Vietnamese language","","Institute of Electrical and Electronics Engineers Inc.","English","Conference paper","Final","","Scopus","2-s2.0-85204771798"
"Xiong G.; Jin Q.; Lu Z.; Zhang A.","Xiong, Guangzhi (58549503500); Jin, Qiao (57219779717); Lu, Zhiyong (23474115300); Zhang, Aidong (7402772796)","58549503500; 57219779717; 23474115300; 7402772796","Benchmarking Retrieval-Augmented Generation for Medicine","2024","Proceedings of the Annual Meeting of the Association for Computational Linguistics","","","","6233","6251","18","1","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205307651&partnerID=40&md5=9bc8ad5ae3ec9eedae6c327ab7a96388","Univeristy of Virginia, United States; National Library of Medicine, National Institutes of Health, United States","Xiong G., Univeristy of Virginia, United States; Jin Q., National Library of Medicine, National Institutes of Health, United States; Lu Z., National Library of Medicine, National Institutes of Health, United States; Zhang A., Univeristy of Virginia, United States","While large language models (LLMs) have achieved state-of-the-art performance on a wide range of medical question answering (QA) tasks, they still face challenges with hallucinations and outdated knowledge. Retrieval-augmented generation (RAG) is a promising solution and has been widely adopted. However, a RAG system can involve multiple flexible components, and there is a lack of best practices regarding the optimal RAG setting for various medical purposes. To systematically evaluate such systems, we propose the Medical Information Retrieval-Augmented Generation Evaluation (MIRAGE), a first-of-its-kind benchmark including 7,663 questions from five medical QA datasets. Using MIRAGE, we conducted large-scale experiments with over 1.8 trillion prompt tokens on 41 combinations of different corpora, retrievers, and backbone LLMs through the MEDRAG toolkit introduced in this work. Overall, MEDRAG improves the accuracy of six different LLMs by up to 18% over chain-of-thought prompting, elevating the performance of GPT-3.5 and Mixtral to GPT-4level. Our results show that the combination of various medical corpora and retrievers achieves the best performance. In addition, we discovered a log-linear scaling property and the “lost-in-the-middle” effects in medical RAG. We believe our comprehensive evaluations can serve as practical guidelines for implementing RAG systems for medicine. © 2024 Association for Computational Linguistics.","","Benchmarking; Information retrieval; Large datasets; Medical informatics; Medical information systems; Modeling languages; Question answering; Best practices; Flexible components; Generation systems; Language model; Large scale experiments; Medical information; Medical question answering; Performance; Question Answering Task; State-of-the-art performance; Computational linguistics","Ku L.-W.; Martins A.; Srikumar V.","Association for Computational Linguistics (ACL)","English","Conference paper","Final","","Scopus","2-s2.0-85205307651"
"Chen T.; Li L.; Zhu L.; Li Z.; Liu X.; Liang G.; Wang Q.; Xie T.","Chen, Tianyu (58520072600); Li, Lin (58520222200); Zhu, Liuchuan (59181635400); Li, Zongyang (57764681900); Liu, Xueqing (56354784200); Liang, Guangtai (36661190100); Wang, Qianxiang (57208587889); Xie, Tao (55574210063)","58520072600; 58520222200; 59181635400; 57764681900; 56354784200; 36661190100; 57208587889; 55574210063","VulLibGen: Generating Names of Vulnerability-Affected Packages via a Large Language Model","2024","Proceedings of the Annual Meeting of the Association for Computational Linguistics","1","","","9767","9780","13","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204442295&partnerID=40&md5=43563fc405346914c0b77c572c1c3c13","Key Lab of HCST (PKU), MOE, SCS, Peking University, China; Huawei Cloud Computing Technologies Co., Ltd., China; Stevens Institute of Technology, United States","Chen T., Key Lab of HCST (PKU), MOE, SCS, Peking University, China; Li L., Huawei Cloud Computing Technologies Co., Ltd., China; Zhu L., Huawei Cloud Computing Technologies Co., Ltd., China; Li Z., Key Lab of HCST (PKU), MOE, SCS, Peking University, China; Liu X., Stevens Institute of Technology, United States; Liang G., Huawei Cloud Computing Technologies Co., Ltd., China; Wang Q., Huawei Cloud Computing Technologies Co., Ltd., China; Xie T., Key Lab of HCST (PKU), MOE, SCS, Peking University, China","Security practitioners maintain vulnerability reports (e.g., GitHub Advisory) to help developers mitigate security risks. An important task for these databases is automatically extracting structured information mentioned in the report, e.g., the affected software packages, to accelerate the defense of the vulnerability ecosystem. However, it is challenging for existing work on affected package identification to achieve high precision. One reason is that all existing work focuses on relatively smaller models, thus they cannot harness the knowledge and semantic capabilities of large language models. To address this limitation, we propose VulLibGen, the first method to use LLM for affected package identification. In contrast to existing work, VulLibGen proposes the novel idea to directly generate the affected package. To improve the precision, VulLibGen employs supervised fine-tuning (SFT), retrieval augmented generation (RAG) and a local search algorithm. The local search algorithm is a novel post-processing algorithm we introduce for reducing the hallucination of the generated packages. Our evaluation results show that VulLibGen has an average precision of 0.806 for identifying vulnerable packages in the four most popular ecosystems in GitHub Advisory (Java, JS, Python, Go) while the best average precision in previous work is 0.721. Additionally, VulLibGen has high value to security practice: we submitted 60 <vulnerability, affected package> pairs to GitHub Advisory (covers four ecosystems) and 34 of them have been accepted and merged. © 2024 Association for Computational Linguistics.","","Java programming language; Search engines; Software packages; Evaluation results; Fine tuning; High-precision; Language model; Local search algorithm; Postprocessing algorithms; Security Practice; Security practitioners; Security risks; Structured information; Semantics","Ku L.-W.; Martins A.F.T.; Srikumar V.","Association for Computational Linguistics (ACL)","English","Conference paper","Final","","Scopus","2-s2.0-85204442295"
"Buhnila I.; Sinha A.; Constant M.","Buhnila, Ioana (58655808400); Sinha, Aman (57221318485); Constant, Mathieu (55111619400)","58655808400; 57221318485; 55111619400","Retrieve, Generate, Evaluate: A Case Study for Medical Paraphrases Generation with Small Language Models","2024","KnowLLM 2024 - 1st Workshop on Towards Knowledgeable Language Models, Proceedings of the Workshop","","","","189","203","14","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204905785&partnerID=40&md5=01d079dcca16b43a1d1944fcd2058b7d","ATILF, CNRS, Université de Lorraine, Nancy, France; Institut de Cancérologie, Strasbourg, France","Buhnila I., ATILF, CNRS, Université de Lorraine, Nancy, France; Sinha A., ATILF, CNRS, Université de Lorraine, Nancy, France, Institut de Cancérologie, Strasbourg, France; Constant M., ATILF, CNRS, Université de Lorraine, Nancy, France","Recent surge in the accessibility of large language models (LLMs) to the general population can lead to untrackable use of such models for medical-related recommendations. Language generation via LLMs models has two key problems: firstly, they are prone to hallucination and therefore, for any medical purpose they require scientific and factual grounding; secondly, LLMs pose tremendous challenge to computational resources due to their gigantic model size. In this work, we introduce pRAGe, a pipeline for Retrieval Augmented Generation and evaluation of medical paraphrases generation using Small Language Models (SLM). We study the effectiveness of SLMs and the impact of external knowledge base for medical paraphrase generation in French. © 2024 Association for Computational Linguistics.","","Medical problems; Case-studies; Computational resources; External knowledge; General population; Language generation; Language model; Model size; Computational linguistics","Li S.; Li M.; Zhang M.J.Q.; Choi E.; Geva M.; Hase P.; Ji H.","Association for Computational Linguistics (ACL)","English","Conference paper","Final","","Scopus","2-s2.0-85204905785"
"Zhang Z.; Cao Y.; Ye C.; Ma Y.; Liao L.; Chua T.-S.","Zhang, Zhihan (59188788200); Cao, Yixin (57015851100); Ye, Chenchen (57822650300); Ma, Yunshan (57204979967); Liao, Lizi (56369584100); Chua, Tat-Seng (58847166100)","59188788200; 57015851100; 57822650300; 57204979967; 56369584100; 58847166100","Analyzing Temporal Complex Events with Large Language Models? A Benchmark towards Temporal, Long Context Understanding","2024","Proceedings of the Annual Meeting of the Association for Computational Linguistics","1","","","1588","1606","18","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204422349&partnerID=40&md5=687e7b6335b82d886359bfafafe22e83","School of Computer Science, Fudan University, China; University of California, Los Angeles, United States; National University of Singapore, Singapore; Singapore Management University, Singapore","Zhang Z., School of Computer Science, Fudan University, China; Cao Y., School of Computer Science, Fudan University, China; Ye C., University of California, Los Angeles, United States; Ma Y., National University of Singapore, Singapore; Liao L., Singapore Management University, Singapore; Chua T.-S., National University of Singapore, Singapore","The digital landscape is rapidly evolving with an ever-increasing volume of online news, emphasizing the need for swift and precise analysis of complex events. We refer to the complex events composed of many news articles over an extended period as Temporal Complex Event (TCE). This paper proposes a novel approach using Large Language Models (LLMs) to systematically extract and analyze the event chain within TCE, characterized by their key points and timestamps. We establish a benchmark, named TCELongBench, to evaluate the proficiency of LLMs in handling temporal dynamics and understanding extensive text. This benchmark encompasses three distinct tasks - reading comprehension, temporal sequencing, and future event forecasting. In the experiment, we leverage retrieval-augmented generation (RAG) method and LLMs with long context window to deal with lengthy news articles of TCE. Our findings indicate that models with suitable retrievers exhibit comparable performance with those utilizing long context window. © 2024 Association for Computational Linguistics.","","Complex events; Context window; Keypoints; Language model; News articles; Online news; Precise analysis; Reading comprehension; Temporal dynamics; Time-stamp; Computational linguistics","Ku L.-W.; Martins A.F.T.; Srikumar V.","Association for Computational Linguistics (ACL)","English","Conference paper","Final","","Scopus","2-s2.0-85204422349"
"Zhang R.; Du H.; Liu Y.; Niyato D.; Kang J.; Xiong Z.; Jamalipour A.; Kim D.I.","Zhang, Ruichen (57221800822); Du, Hongyang (57211884589); Liu, Yinqiu (57209318696); Niyato, Dusit (8919714700); Kang, Jiawen (55960988400); Xiong, Zehui (57201881045); Jamalipour, Abbas (7003564684); Kim, Dong In (35476060100)","57221800822; 57211884589; 57209318696; 8919714700; 55960988400; 57201881045; 7003564684; 35476060100","Generative AI Agents with Large Language Model for Satellite Networks via a Mixture of Experts Transmission","2024","IEEE Journal on Selected Areas in Communications","","","","","","","0","10.1109/JSAC.2024.3459037","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204181188&doi=10.1109%2fJSAC.2024.3459037&partnerID=40&md5=8ddd0279bae7c7ab198a10a21d057848","Nanyang Technological University, College of Computing and Data Science, Singapore; University of Hong Kong, Department of Electrical and Electronic Engineering, Pok Fu Lam, Hong Kong; Guangdong University of Technology, School of Automation, China; Singapore University of Technology and Design, Pillar of Information Systems Technology and Design, Singapore; The University of Sydney, Sydney, 2006, NSW, Australia; Sungkyunkwan University, Department of Electrical and Computer Engineering, Suwon, 16419, South Korea","Zhang R., Nanyang Technological University, College of Computing and Data Science, Singapore; Du H., University of Hong Kong, Department of Electrical and Electronic Engineering, Pok Fu Lam, Hong Kong; Liu Y., Nanyang Technological University, College of Computing and Data Science, Singapore; Niyato D., Nanyang Technological University, College of Computing and Data Science, Singapore; Kang J., Guangdong University of Technology, School of Automation, China; Xiong Z., Singapore University of Technology and Design, Pillar of Information Systems Technology and Design, Singapore; Jamalipour A., The University of Sydney, Sydney, 2006, NSW, Australia; Kim D.I., Sungkyunkwan University, Department of Electrical and Computer Engineering, Suwon, 16419, South Korea","In response to the needs of 6G global communications, satellite communication networks have emerged as a key solution. However, the large-scale development of satellite communication networks is constrained by complex system models, whose modeling is challenging for massive users. Moreover, transmission interference between satellites and users seriously affects communication performance. To solve these problems, this paper develops generative artificial intelligence (AI) agents for model formulation and then applies a mixture of experts (MoE) approach to design transmission strategies. Specifically, we leverage large language models (LLMs) to build an interactive modeling paradigm and utilize retrieval-augmented generation (RAG) to extract satellite expert knowledge that supports mathematical modeling. Afterward, by integrating the expertise of multiple specialized components, we propose an MoE-proximal policy optimization (PPO) approach to solve the formulated problem. Each expert can optimize the optimization variables at which it excels through specialized training through its own network and then aggregate them through the gating network to perform joint optimization. The simulation results validate the accuracy and effectiveness of employing a generative agent for problem formulation. Furthermore, the superiority of the proposed MoE-ppo approach over other benchmarks is confirmed in solving the formulated problem. The adaptability of MoE-PPO to various customized modeling problems has also been demonstrated. © 1983-2012 IEEE.","generative AI agent; LLM; MoE; network design; PPO; Satellite communications","","","Institute of Electrical and Electronics Engineers Inc.","English","Article","Article in press","All Open Access; Green Open Access","Scopus","2-s2.0-85204181188"
"Kambhamettu H.; Huang Y.; Johnson K.; Bradbury A.","Kambhamettu, Hita (58062260300); Huang, Yidi (59349529700); Johnson, Kevin (8744561900); Bradbury, Angela (16237821400)","58062260300; 59349529700; 8744561900; 16237821400","Knowledge-Grounded Medical Dialogue Generation","2024","Studies in Computational Intelligence","1164 SCI","","","209","218","9","1","10.1007/978-3-031-63592-2_16","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205351738&doi=10.1007%2f978-3-031-63592-2_16&partnerID=40&md5=c57ed3f895742ba7c1a53a307b76e8ee","University of Pennsylvania, Philadelphia, PA, United States","Kambhamettu H., University of Pennsylvania, Philadelphia, PA, United States; Huang Y., University of Pennsylvania, Philadelphia, PA, United States; Johnson K., University of Pennsylvania, Philadelphia, PA, United States; Bradbury A., University of Pennsylvania, Philadelphia, PA, United States","With the introduction of the first FDA-approved treatment for Alzheimer’s disease (AD), genetic testing for APOE, a major genetic risk factor for AD, has become a critical step to assess treatment eligibility. In order to address the increasing volume of APOE testing, tools to help patients understand genetic risk factors and their implications are urgently needed. Conversational agents powered by large language models (LLMs) can help triage patients and supplement human counselors. However, deploying such agents poses challenges: institutional barriers prevent the input of clinical data, including protected health information (PHI), into commercial LLMs, LLMs potentially hallucinate critical medical facts, and LLMs should mimic the communication style of clinicians in order to be trusted supplements. We introduce a dual-method approach to enhance LLMs’ accuracy and clinical communication effectiveness. First, we build a knowledge bank of recorded patient-provider genetic counseling sessions and leverage an open-source LLM to extract and summarize relevant information. We leverage this knowledge bank to develop a retrieval-augmented system for answering patient questions. We find that responses generated from our pipeline are more readable and better resemble human responses compared to those directly from GPT-4, suggesting that this pipeline enhances both accuracy and a clinician-like tone of communication. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.","Alzheimer’s risk; Genetic counseling; Large language models; Retrieval-augmented generation","","Shaban-Nejad A.; Michalowski M.; Bianco S.","Springer Science and Business Media Deutschland GmbH","English","Conference paper","Final","","Scopus","2-s2.0-85205351738"
"Shi Z.; Zhang S.; Sun W.; Gao S.; Ren P.; Chen Z.; Ren Z.","Shi, Zhengliang (58034629900); Zhang, Shuo (57194090904); Sun, Weiwei (57218714016); Gao, Shen (57204472647); Ren, Pengjie (56181249600); Chen, Zhumin (15749859500); Ren, Zhaochun (53985046100)","58034629900; 57194090904; 57218714016; 57204472647; 56181249600; 15749859500; 53985046100","Generate-then-Ground in Retrieval-Augmented Generation for Multi-hop Question Answering","2024","Proceedings of the Annual Meeting of the Association for Computational Linguistics","1","","","7339","7353","14","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204436747&partnerID=40&md5=f2991777e6ea52a2d8ee4ce309ec73bc","Shandong University, Qingdao, China; Bloomberg, London, United Kingdom; University of Electronic Science and Technology of China, Chengdu, China; Leiden University, Leiden, Netherlands","Shi Z., Shandong University, Qingdao, China; Zhang S., Bloomberg, London, United Kingdom; Sun W., Shandong University, Qingdao, China; Gao S., University of Electronic Science and Technology of China, Chengdu, China; Ren P., Shandong University, Qingdao, China; Chen Z., Shandong University, Qingdao, China; Ren Z., Leiden University, Leiden, Netherlands","Multi-Hop Question Answering (MHQA) tasks present a significant challenge for large language models (LLMs) due to the intensive knowledge required. Current solutions, like Retrieval-Augmented Generation, typically retrieve potential documents from an external corpus to read an answer. However, the performance of this retrieve-then-read paradigm is constrained by the retriever and the inevitable noise in the retrieved documents. To mitigate these challenges, we introduce a novel generate-then-ground (GenGround) framework, synergizing the parametric knowledge of LLMs and external documents to solve a multi-hop question. GenGround empowers LLMs to alternate two phases until the final answer is derived: (1) formulate a simpler, single-hop question and directly generate the answer; (2) ground the question-answer pair in retrieved documents, amending any wrong predictions in the answer. We also propose an instructional grounding distillation method to generalize our method into smaller models. Extensive experiments conducted on four datasets illustrate the superiority of our method. © 2024 Association for Computational Linguistics.","","Computational linguistics; 'current; Language model; Multi-hops; Performance; Question Answering; Question Answering Task; Retrieved documents; Simple++; Single hop; Two phase; Question answering","Ku L.-W.; Martins A.F.T.; Srikumar V.","Association for Computational Linguistics (ACL)","English","Conference paper","Final","","Scopus","2-s2.0-85204436747"
"Chu J.-M.; Lo H.-C.; Hsiang J.; Cho C.-C.","Chu, Jung-Mei (57568189200); Lo, Hao-Cheng (57210832232); Hsiang, Jieh (7003585886); Cho, Chun-Chieh (58893945700)","57568189200; 57210832232; 7003585886; 58893945700","Patent Response System Optimised for Faithfulness: Procedural Knowledge Embodiment with Knowledge Graph and Retrieval Augmented Generation","2024","KnowLLM 2024 - 1st Workshop on Towards Knowledgeable Language Models, Proceedings of the Workshop","","","","146","155","9","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204918162&partnerID=40&md5=0ee730886a4380a0c00ae2074002599c","National Taiwan University, Taiwan; JCIPRNET","Chu J.-M., National Taiwan University, Taiwan, JCIPRNET; Lo H.-C., National Taiwan University, Taiwan, JCIPRNET; Hsiang J., National Taiwan University, Taiwan; Cho C.-C., JCIPRNET","A successful response to Office Action is crucial for an invention to obtain a patent. While previous attempts have applied generalised LLMs, such as GPT-4, in the response process, there remains significant room for improvement in generating faithful, unbiased, and practically valuable responses. To address this issue, we propose the Patent Response System Optimised for Faithfulness (PRO). PRO explicitly incorporates procedural knowledge used by patent agents during drafting arguments in response. This framework comprises several key components: (1) Our proposed PRLLM is a LLM tailored for patent responses, designed to have comprehensive patent domain-specific knowledge. (2) Our proposed PPNet encodes legal interpretations and relationships between technical components from judicial sources through a knowledge graph. (3) The augmented generation processes retrieve relevant information from both the patent text and PPNet to augment the PRLLM's input and generate faithful responses. Results show that PRO significantly reduces unfaithfulness across six error types compared to several settings. For instance, PRO outperforms GPT-4 by an average of 39% in terms of faithfulness. This demonstrates the effectiveness of our domain-specific approach in improving the quality of automated patent responses. © 2024 Association for Computational Linguistics.","","Patents and inventions; Domain specific; Domain-specific knowledge; Error types; Generation process; Knowledge graphs; Knowledge retrieval; Procedural knowledge; Response process; Response systems; Knowledge graph","Li S.; Li M.; Zhang M.J.Q.; Choi E.; Geva M.; Hase P.; Ji H.","Association for Computational Linguistics (ACL)","English","Conference paper","Final","","Scopus","2-s2.0-85204918162"
"Hsu A.; Laney M.; Manya D.; Zhang J.; Farczadi L.","Hsu, Angel (55243402000); Laney, Mason (59335878600); Manya, Diego (57216650294); Zhang, Ji (59335545900); Farczadi, Linda (59336206600)","55243402000; 59335878600; 57216650294; 59335545900; 59336206600","Evaluating ChatNetZero, an LLM-Chatbot to Demystify Climate Pledges","2024","ClimateNLP 2024 - 1st Workshop on Natural Language Processing Meets Climate Change, Proceedings of the Workshop","","","","82","92","10","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204424090&partnerID=40&md5=aecfe434baeac2deda5bbed5ea80ed96","The University of North Carolina, Chapel Hill, United States; Data-Driven EnviroLab; Arboretica","Hsu A., The University of North Carolina, Chapel Hill, United States, Data-Driven EnviroLab; Laney M., The University of North Carolina, Chapel Hill, United States, Data-Driven EnviroLab; Manya D., The University of North Carolina, Chapel Hill, United States, Data-Driven EnviroLab; Zhang J., Arboretica; Farczadi L., Arboretica","This paper introduces and evaluates ChatNetZero, a large-language model (LLM) chatbot developed through Retrieval-Augmented Generation (RAG), which uses generative AI to produce answers grounded in verified, climate-domain specific information. We describe ChatNetZero’s design, particularly the innovation of anti-hallucination and reference modules designed to enhance the accuracy and credibility of generated responses. To evaluate ChatNetZero’s performance against other LLMs, including GPT-4, Gemini, Coral, and ChatClimate, we conduct two types of validation: comparing LLMs’ generated responses to original source documents to verify their factual accuracy, and employing an expert survey to evaluate the overall quality, accuracy and relevance of each response. We find that while ChatNetZero responses show higher factual accuracy when compared to original source data, experts surveyed prefer lengthier responses that provide more context. Our results highlight the importance of prioritizing information presentation in the design of domain-specific LLMs to ensure that scientific information is effectively communicated, especially as even expert audiences find it challenging to assess the credibility of AI-generated content. ©2024 Association for Computational Linguistics.","","Chatbots; Domain specific; Domain-specific information; Expert survey; Information presentation; Language model; Overall quality; Performance; Scientific information; Source data; Computational linguistics","Stammbach D.; Ni J.; Schimanski T.; Dutia K.; Singh A.; Bingler J.; Christiaen C.; Kushwaha N.; Muccione V.; Vaghefi S.A.; Leippold M.","Association for Computational Linguistics (ACL)","English","Conference paper","Final","","Scopus","2-s2.0-85204424090"
"Sui Y.; Ren J.; Tan H.; Chen H.; Li Z.; Wang J.","Sui, Yize (59326884300); Ren, Jing (57222416329); Tan, Huibin (57190412284); Chen, Huan (58938356300); Li, Zhaoye (59326953000); Wang, Ji (56259417500)","59326884300; 57222416329; 57190412284; 58938356300; 59326953000; 56259417500","Enhancing LLM’s Reliability by Iterative Verification Attributions with Keyword Fronting","2024","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","14946 LNAI","","","251","268","17","0","10.1007/978-3-031-70365-2_15","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203873207&doi=10.1007%2f978-3-031-70365-2_15&partnerID=40&md5=c3748156bb356ff0963c48a37bdb3f26","Department of Intelligent Data Science, College of Computer Science and Technology, National University of Defense Technology, Changsha, 410073, China","Sui Y., Department of Intelligent Data Science, College of Computer Science and Technology, National University of Defense Technology, Changsha, 410073, China; Ren J., Department of Intelligent Data Science, College of Computer Science and Technology, National University of Defense Technology, Changsha, 410073, China; Tan H., Department of Intelligent Data Science, College of Computer Science and Technology, National University of Defense Technology, Changsha, 410073, China; Chen H., Department of Intelligent Data Science, College of Computer Science and Technology, National University of Defense Technology, Changsha, 410073, China; Li Z., Department of Intelligent Data Science, College of Computer Science and Technology, National University of Defense Technology, Changsha, 410073, China; Wang J., Department of Intelligent Data Science, College of Computer Science and Technology, National University of Defense Technology, Changsha, 410073, China","Retrieval-augmented text generation attribution is of great significance for knowledge-intensive tasks as it can enhance the credibility and verifiability of large language models (LLMs). However, existing research often ignores the adverse effect of “Middle Loss” in lengthy input contexts on answer correctness, and the potential negative impact of unverified citations on the quality of attribution. To address these challenges, we propose a framework IVAKF (Iterative Verified Attribution with Keyword Fronting), which better utilizes long context information and integrates attribution verification throughout the whole process of response generation. Specifically, for the “Middle Loss” issue, we employ a keyword fronting strategy with Named Entity Recognition (NER), guiding the model’s attention to focus on key entities and their relationship with other parts. As for the issue of poor attribution quality, we design a verification-based iterative optimization algorithm, which continuously updates candidate statements and citations until it produces a satisfactory output result. Experiments on three public knowledge-intensive datasets demonstrate that the proposed framework significantly improves the quality of the final response. It improved answer correctness by 6.4%, and citation quality by 9.1% than the baselines. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.","Large Language Models; Retrieval Augmented Generation; Text Generation Attribution","Adverse effect; Context information; Knowledge intensive tasks; Language model; Large language model; Retrieval augmented generation; Text generation attribution; Text generations; Verifiability; Whole process; Modeling languages","Bifet A.; Davis J.; Krilavičius T.; Kull M.; Ntoutsi E.; Žliobaitė I.","Springer Science and Business Media Deutschland GmbH","English","Conference paper","Final","","Scopus","2-s2.0-85203873207"
"Jacobs S.; Jaschke S.","Jacobs, Sven (57226720708); Jaschke, Steffen (54891442800)","57226720708; 54891442800","Leveraging Lecture Content for Improved Feedback: Explorations with GPT-4 and Retrieval Augmented Generation","2024","Software Engineering Education Conference, Proceedings","","","","","","","0","10.1109/CSEET62301.2024.10663001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204482680&doi=10.1109%2fCSEET62301.2024.10663001&partnerID=40&md5=706c62207c46a5f2df1db7f1cbc27142","Computer Science Education, University of Siegen, Siegen, Germany","Jacobs S., Computer Science Education, University of Siegen, Siegen, Germany; Jaschke S., Computer Science Education, University of Siegen, Siegen, Germany","This paper presents the use of Retrieval Augmented Generation (RAG) to improve the feedback generated by Large Language Models for programming tasks. For this purpose, corresponding lecture recordings were transcribed and made available to the Large Language Model GPT-4 as external knowledge source together with timestamps as metainformation by using RAG. The purpose of this is to prevent hallucinations and to enforce the use of the technical terms and phrases from the lecture. In an exercise platform developed to solve programming problems for an introductory programming lecture, students can request feedback on their solutions generated by GPT-4. For this task GPT-4 receives the students' code solution, the compiler output, the result of unit tests and the relevant passages from the lecture notes available through the use of RAG as additional context. The feedback generated by GPT-4 should guide students to solve problems independently and link to the lecture content, using the time stamps of the transcript as meta-information. In this way, the corresponding lecture videos can be viewed immediately at the corresponding positions. For the evaluation, students worked with the tool in a workshop and decided for each feedback whether it should be extended by RAG or not. First results based on a questionnaire and the collected usage data show that the use of RAG can improve feedback generation and is preferred by students in some situations. Due to the slower speed of feedback generation, the benefits are situation dependent.  © 2024 IEEE.","Feedback; GPT-4; Large language Models; Programming Education; Retrieval Augmented Generation","Distributed computer systems; Problem solving; Program compilers; Report generators; Search engines; Systems analysis; Teaching; External knowledge; GPT-4; Language model; Large language model; Lecture recording; Meta information; Programming education; Programming tasks; Retrieval augmented generation; Time-stamp; Students","Bollin A.; Bosnic I.; Brings J.; Daun M.; Manjunath M.","Institute of Electrical and Electronics Engineers Inc.","English","Conference paper","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85204482680"
"Ke Z.; Kong W.; Li C.; Zhang M.; Mei Q.; Bendersky M.","Ke, Zixuan (57222576029); Kong, Weize (55837760300); Li, Cheng (56285243300); Zhang, Mingyang (57203400211); Mei, Qiaozhu (12241600600); Bendersky, Michael (23994792700)","57222576029; 55837760300; 56285243300; 57203400211; 12241600600; 23994792700","Bridging the Preference Gap between Retrievers and LLMs","2024","Proceedings of the Annual Meeting of the Association for Computational Linguistics","1","","","10438","10451","13","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204464629&partnerID=40&md5=c1e71f27acfd74333b98749fb3be4a84","Google Research, United States; University of Illinois, Chicago, United States; University of Michigan, United States","Ke Z., University of Illinois, Chicago, United States; Kong W., Google Research, United States; Li C., Google Research, United States; Zhang M., Google Research, United States; Mei Q., University of Michigan, United States; Bendersky M., Google Research, United States","Large Language Models (LLMs) have demonstrated superior results across a wide range of tasks, and Retrieval-augmented Generation (RAG) is an effective way to enhance the performance by locating relevant information and placing it into the context window of the LLM. However, the relationship between retrievers and LLM in a RAG is still under-investigated. Most existing work treats the retriever and the LLM as independent components and leaves a gap between retrieving human-“friendly” information and assembling a LLM-“friendly” context. In this work, we examine a novel bridge mechanism. We validate the ranking and selection assumptions of retrievers in the context of RAG and propose a framework that chains together supervised and reinforcement learning to train a bridge model that optimizes the connection between the retriever and the LLM. Empirical results demonstrate the effectiveness of our method in both question-answering and personalized generation tasks. © 2024 Association for Computational Linguistics.","","Learning to rank; Reinforcement learning; Self-supervised learning; Supervised learning; Bridge model; Context window; Human-friendly; Independent components; Language model; Performance; Question Answering; Ranking and selection; Reinforcement learnings; Computational linguistics","Ku L.-W.; Martins A.F.T.; Srikumar V.","Association for Computational Linguistics (ACL)","English","Conference paper","Final","","Scopus","2-s2.0-85204464629"
"Koontz J.; Oronoz M.; Pérez A.","Koontz, Jordan (58754641800); Oronoz, Maite (59330935900); Pérez, Alicia (57208931888)","58754641800; 59330935900; 57208931888","Ixa-Med at Discharge Me! Retrieval-Assisted Generation for Streamlining Discharge Documentation","2024","BioNLP 2024 - 23rd Meeting of the ACL Special Interest Group on Biomedical Natural Language Processing, Proceedings of the Workshop and Shared Tasks","","","","658","663","5","1","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204483093&partnerID=40&md5=26e2421661f7937f30910994010d368b","HiTZ Center - Ixa UPV/EHU","Koontz J., HiTZ Center - Ixa UPV/EHU; Oronoz M., HiTZ Center - Ixa UPV/EHU; Pérez A., HiTZ Center - Ixa UPV/EHU","In this paper we present our system for the BioNLP ACL’24 ""Discharge Me!"" task on automating discharge summary section generation. Using Retrieval-Augmented Generation, we combine a Large Language Model (LLM) with external knowledge to guide the generation of the target sections. Our approach generates structured patient summaries from discharge notes using an instructed LLM, retrieves relevant ""Brief Hospital Course"" and ""Discharge Instructions"" examples via BM25 and SentenceBERT, and provides this context to a frozen LLM for generation. Our top system using SentenceBERT retrieval achieves an overall score of 0.183, outperforming zero-shot baselines. We analyze performance across different aspects, discussing limitations and future research directions.. ©2024 Association for Computational Linguistics.","","Modeling languages; Discharge summary; External knowledge; Future research directions; Language model; Patient Summary; Performance; Computational linguistics","Demner-Fushman D.; Ananiadou S.; Miwa M.; Roberts K.; Tsujii J.","Association for Computational Linguistics (ACL)","English","Conference paper","Final","","Scopus","2-s2.0-85204483093"
"Tang W.; Cao Y.; Ying J.; Wang B.; Zhao Y.; Liao Y.; Zhou P.","Tang, Wei (57740615200); Cao, Yixin (57015851100); Ying, Jiahao (58494129000); Wang, Bo (59348377600); Zhao, Yuyue (57216908863); Liao, Yong (55213719400); Zhou, Pengyuan (57192977951)","57740615200; 57015851100; 58494129000; 59348377600; 57216908863; 55213719400; 57192977951","A + B: A General Generator-Reader Framework for Optimizing LLMs to Unleash Synergy Potential","2024","Proceedings of the Annual Meeting of the Association for Computational Linguistics","","","","3670","3685","15","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205323691&partnerID=40&md5=2f8ed1ddb50771b575524c0aae00e976","University of Science and Technology of China, China; CCCD Key Lab of Ministry of Culture and Tourism, China; School of Computer Science, Fudan University, China; Singapore Management University, Singapore; Beijing Institute of Technology, China; Aarhus University, Denmark","Tang W., University of Science and Technology of China, China, CCCD Key Lab of Ministry of Culture and Tourism, China; Cao Y., School of Computer Science, Fudan University, China; Ying J., Singapore Management University, Singapore; Wang B., Beijing Institute of Technology, China; Zhao Y., University of Science and Technology of China, China, CCCD Key Lab of Ministry of Culture and Tourism, China; Liao Y., University of Science and Technology of China, China, CCCD Key Lab of Ministry of Culture and Tourism, China; Zhou P., Aarhus University, Denmark","Retrieval-Augmented Generation (RAG) is an effective solution to supplement necessary knowledge to large language models (LLMs). Targeting its bottleneck of retriever performance, “generate-then-read” pipeline is proposed to replace the retrieval stage with generation from the LLM itself. Although promising, this research direction is underexplored and still cannot work in the scenario when source knowledge is given. In this paper, we formalize a general “A + B” framework with varying combinations of foundation models and types for systematic investigation. We explore the efficacy of the base and chat versions of LLMs and found their different functionalities suitable for generator A and reader B, respectively. Their combinations consistently outperform single models, especially in complex scenarios. Furthermore, we extend the application of the “A + B” framework to scenarios involving source documents through continuous learning, enabling the direct integration of external knowledge into LLMs. This approach not only facilitates effective acquisition of new knowledge but also addresses the challenges of safety and helpfulness post-adaptation. The paper underscores the versatility of the “A + B” framework, demonstrating its potential to enhance the practical application of LLMs across various domains. © 2024 Association for Computational Linguistics.","","Natural language processing systems; B framework; Continuous learning; Direct integration; Effective solution; External knowledge; Foundation models; Foundation types; Language model; Performance; Single models; Computational linguistics","Ku L.-W.; Martins A.; Srikumar V.","Association for Computational Linguistics (ACL)","English","Conference paper","Final","","Scopus","2-s2.0-85205323691"
"Kang M.; Gürel N.M.; Yu N.; Song D.; Li B.","Kang, Mintong (57223083423); Gürel, Nezihe Merve (57201581479); Yu, Ning (59326138900); Song, Dawn (7402443870); Li, Bo (57188689924)","57223083423; 57201581479; 59326138900; 7402443870; 57188689924","C-RAG: Certified Generation Risks for Retrieval-Augmented Language Models","2024","Proceedings of Machine Learning Research","235","","","22963","23000","37","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203794057&partnerID=40&md5=be819af657841a5f2ce8c99a206e7488","University of Illinois, Urbana-Champaign, United States; Delft University of Technology, Netherlands; Netflix Eyeline Studios, United States; University of California, Berkeley, United States; University of Chicago, United States","Kang M., University of Illinois, Urbana-Champaign, United States; Gürel N.M., Delft University of Technology, Netherlands; Yu N., Netflix Eyeline Studios, United States; Song D., University of California, Berkeley, United States; Li B., University of Illinois, Urbana-Champaign, United States, University of Chicago, United States","Despite the impressive capabilities of large language models (LLMs) across diverse applications, they still suffer from trustworthiness issues, such as hallucinations and misalignments. Retrieval-augmented language models (RAG) have been proposed to enhance the credibility of generations by grounding external knowledge, but the theoretical understandings of their generation risks remains unexplored. In this paper, we answer: 1) whether RAG can indeed lead to low generation risks, 2) how to provide provable guarantees on the generation risks of RAG and vanilla LLMs, and 3) what sufficient conditions enable RAG models to reduce generation risks. We propose C-RAG, a novel framework to certify generation risks for RAG models. Specifically, we provide conformal risk analysis for RAG models and certify an upper confidence bound of generation risks, which we refer to as conformal generation risk. We also provide theoretical guarantees on conformal generation risks for general bounded risk functions under test distribution shifts. We prove that RAG achieves a lower conformal generation risk than that of a single LLM when the quality of the retrieval model and transformer is non-trivial. Our intensive empirical results demonstrate the soundness and tightness of our conformal generation risk guarantees across four widely-used NLP datasets on four state-of-the-art retrieval models. Copyright 2024 by the author(s)","","C (programming language); Distributed computer systems; Distribution functions; Modeling languages; Risk analysis; Condition; Diverse applications; External knowledge; Language model; Non-trivial; Retrieval models; Risk analyze; Risk function; Theoretical guarantees; Upper confidence bound; Risk assessment","Salakhutdinov R.; Kolter Z.; Heller K.; Weller A.; Oliver N.; Scarlett J.; Berkenkamp F.","ML Research Press","English","Conference paper","Final","","Scopus","2-s2.0-85203794057"
"Cao D.; Jun W.","Cao, Daipeng (59302023500); Jun, W. (59301896800)","59302023500; 59301896800","LLM-CloudSec: Large Language Model Empowered Automatic and Deep Vulnerability Analysis for Intelligent Clouds","2024","IEEE INFOCOM 2024 - IEEE Conference on Computer Communications Workshops, INFOCOM WKSHPS 2024","","","","","","","0","10.1109/INFOCOMWKSHPS61880.2024.10620804","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202353629&doi=10.1109%2fINFOCOMWKSHPS61880.2024.10620804&partnerID=40&md5=31c5ce71841e5db087782e8ee29e2a4d","Graduate School of Information, Production and Systems, Waseda University, Japan","Cao D., Graduate School of Information, Production and Systems, Waseda University, Japan; Jun W., Graduate School of Information, Production and Systems, Waseda University, Japan","The advance of intelligent cloud applications has brought attention to potential security vulnerabilities. Vulnerability detection is a critical step in ensuring the security of cloud applications. However, traditional techniques for vulnerability detection, such as static and dynamic analysis, are challenging to apply in heterogeneous cloud environments. Using data-driven methods such as Machine Learning (ML) to automate vulnerability detection in cloud applications shows promise. However, current ML solutions are limited to coarse-grained vulnerability categorization and function-level analysis. Therefore, we propose LLM-CloudSec, an unsupervised approach to fine-grained vulnerability analysis based on the Large Language Model (LLM). LLM-CloudSec uses Retrieval Augmented Generation (RAG) and the Common Weakness Enumeration (CWE) as an external knowledge base to improve its ability to detect and analyze vulnerabilities. We conduct experiments on the Juliet C++ test suite, and the results show that LLM-CloudSec enables CWE-based vulnerability classification and line-level vulnerability analysis. Additionally, we applied LLM-CloudSec to the D2A dataset, which was collected from real-world scenarios. We obtained 1230 data entries labelled with CWE and detailed vulnerability analysis. To foster related research, we publish our work on https://github.com/DPCa0/LLM-CloudSec. © 2024 IEEE.","Cloud Application; Common Weakness Enumeration; Large Language Model; Vulnerability Detection","C++ (programming language); Cloud platforms; Cloud applications; Common weakness enumeration; Critical steps; Language model; Large language model; Machine-learning; Security vulnerabilities; Traditional techniques; Vulnerability analysis; Vulnerability detection; Cloud security","","Institute of Electrical and Electronics Engineers Inc.","English","Conference paper","Final","","Scopus","2-s2.0-85202353629"
"Zhu P.; Chen W.; Chen D.; Liu J.; Liu Z.; Liu Y.; Lin G.","Zhu, Pengcheng (59257780200); Chen, Wei (57171121800); Chen, Dufeng (57224466071); Liu, Jueting (57215220843); Liu, Zemeng (58725969100); Liu, Yingchun (58726155900); Lin, Guoyuan (7401699945)","59257780200; 57171121800; 57224466071; 57215220843; 58725969100; 58726155900; 7401699945","An Efficient Query System for Coal Mine Safety Information Based on Retrieval-Augmented Language Model","2024","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","14876 LNAI","","","235","243","8","0","10.1007/978-981-97-5666-7_20","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201240172&doi=10.1007%2f978-981-97-5666-7_20&partnerID=40&md5=fb559fc49b32d885e8d72f315c5ebb08","School of Computer Science and Technology, China University of Mining and Technology, Jiangsu, Xuzhou, 221116, China; Ministry of Emergency Management Big Data Center, Beijing, 100010, China; Beijing Geotechnical and Investigation Engineering Institute, Beijing, 100080, China; Jiangsu Novolion Technology Company, Jiangsu, Xuzhou, 221116, China","Zhu P., School of Computer Science and Technology, China University of Mining and Technology, Jiangsu, Xuzhou, 221116, China; Chen W., School of Computer Science and Technology, China University of Mining and Technology, Jiangsu, Xuzhou, 221116, China, Ministry of Emergency Management Big Data Center, Beijing, 100010, China; Chen D., Beijing Geotechnical and Investigation Engineering Institute, Beijing, 100080, China; Liu J., School of Computer Science and Technology, China University of Mining and Technology, Jiangsu, Xuzhou, 221116, China; Liu Z., Jiangsu Novolion Technology Company, Jiangsu, Xuzhou, 221116, China; Liu Y., School of Computer Science and Technology, China University of Mining and Technology, Jiangsu, Xuzhou, 221116, China; Lin G., School of Computer Science and Technology, China University of Mining and Technology, Jiangsu, Xuzhou, 221116, China","Large Language Models (LLMs) and Retrieval Augmented Generation (RAG) systems hold immense potential for application in industry. In the coal mining, the process of querying and retrieving safety information for dispatchers often consumes considerable time, leading to delays in response to incidents. This paper proposes efficient safety information query system for coal mine safety information. It presents an improvement in the retrieval and generation stages, and establishes a coal mine safety question-answering dataset based on prompt engineering. Various metrics were employed to comprehensively evaluate the RAG framework. The experimental results demonstrate that this work significantly outperform the traditional RAG framework, offering guidelines for RAG implementation in coal mine technical domains. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2024.","Coal Mine Safety Information; Large Language Models; Retrieval-Augmented Generation","Coal; Computational linguistics; Information retrieval; Safety engineering; Search engines; Coal mine safety information; Coal-mine safeties; Coal-mining; Generation systems; Information query systems; Language model; Large language model; Query systems; Retrieval-augmented generation; Safety information; Coal mines","Huang D.-S.; Pan Y.; Zhang C.","Springer Science and Business Media Deutschland GmbH","English","Conference paper","Final","","Scopus","2-s2.0-85201240172"
"Parmanto B.; Aryoyudanta B.; Soekinto T.W.; Setiawan I.M.A.; Wang Y.; Hu H.; Saptono A.; Choi Y.K.","Parmanto, Bambang (6602904022); Aryoyudanta, Bayu (57193812077); Soekinto, Timothius Wilbert (59259888500); Setiawan, I Made Agus (55396194200); Wang, Yuhan (58957540800); Hu, Haomin (58118930600); Saptono, Andi (12760195700); Choi, Yong Kyung (57734324600)","6602904022; 57193812077; 59259888500; 55396194200; 58957540800; 58118930600; 12760195700; 57734324600","A Reliable and Accessible Caregiving Language Model (CaLM) to Support Tools for Caregivers: Development and Evaluation Study","2024","JMIR Formative Research","8","","e54633","","","","0","10.2196/54633","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201209010&doi=10.2196%2f54633&partnerID=40&md5=e985bd2eaada2ab41d72a57c8c2c1270","Department of Health Information Management, University of Pittsburgh, Pittsburgh, PA, United States","Parmanto B., Department of Health Information Management, University of Pittsburgh, Pittsburgh, PA, United States; Aryoyudanta B., Department of Health Information Management, University of Pittsburgh, Pittsburgh, PA, United States; Soekinto T.W., Department of Health Information Management, University of Pittsburgh, Pittsburgh, PA, United States; Setiawan I.M.A., Department of Health Information Management, University of Pittsburgh, Pittsburgh, PA, United States; Wang Y., Department of Health Information Management, University of Pittsburgh, Pittsburgh, PA, United States; Hu H., Department of Health Information Management, University of Pittsburgh, Pittsburgh, PA, United States; Saptono A., Department of Health Information Management, University of Pittsburgh, Pittsburgh, PA, United States; Choi Y.K., Department of Health Information Management, University of Pittsburgh, Pittsburgh, PA, United States","Background: In the United States, 1 in 5 adults currently serves as a family caregiver for an individual with a serious illness or disability. Unlike professional caregivers, family caregivers often assume this role without formal preparation or training. Thus, there is an urgent need to enhance the capacity of family caregivers to provide quality care. Leveraging technology as an educational tool or an adjunct to care is a promising approach that has the potential to enhance the learning and caregiving capabilities of family caregivers. Large language models (LLMs) can potentially be used as a foundation technology for supporting caregivers. An LLM can be categorized as a foundation model (FM), which is a large-scale model trained on a broad data set that can be adapted to a range of different domain tasks. Despite their potential, FMs have the critical weakness of ""hallucination,"" where the models generate information that can be misleading or inaccurate. Information reliability is essential when language models are deployed as front-line help tools for caregivers. Objective: This study aimed to (1) develop a reliable caregiving language model (CaLM) by using FMs and a caregiving knowledge base, (2) develop an accessible CaLM using a small FM that requires fewer computing resources, and (3) evaluate the model's performance compared with a large FM. Methods: We developed a CaLM using the retrieval augmented generation (RAG) framework combined with FM fine-tuning for improving the quality of FM answers by grounding the model on a caregiving knowledge base. The key components of the CaLM are the caregiving knowledge base, a fine-tuned FM, and a retriever module. We used 2 small FMs as candidates for the foundation of the CaLM (LLaMA [large language model Meta AI] 2 and Falcon with 7 billion parameters) and adopted a large FM (GPT-3.5 with an estimated 175 billion parameters) as a benchmark. We developed the caregiving knowledge base by gathering various types of documents from the internet. We focused on caregivers of individuals with Alzheimer disease and related dementias. We evaluated the models' performances using the benchmark metrics commonly used in evaluating language models and their reliability for providing accurate references with their answers. Results: The RAG framework improved the performance of all FMs used in this study across all measures. As expected, the large FM performed better than the small FMs across all metrics. Interestingly, the small fine-tuned FMs with RAG performed significantly better than GPT 3.5 across all metrics. The fine-tuned LLaMA 2 with a small FM performed better than GPT 3.5 (even with RAG) in returning references with the answers. Conclusions: The study shows that a reliable and accessible CaLM can be developed using small FMs with a knowledge base specific to the caregiving domain. © 2024 JMIR Publications Inc.. All rights reserved.","aging; caregiver; caregiving; carer; ChatGPT; elderly; GPT; informal care; language model; large language model; LLM; machine learning; natural language processing; NLP","","","JMIR Publications Inc.","English","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85201209010"
"Arora C.; Herda T.; Homm V.","Arora, Chetan (55848706400); Herda, Tomas (58678912100); Homm, Verena (59091621000)","55848706400; 58678912100; 59091621000","Generating Test Scenarios from NL Requirements Using Retrieval-Augmented LLMs: An Industrial Study","2024","Proceedings of the IEEE International Conference on Requirements Engineering","","","","240","251","11","0","10.1109/RE59067.2024.00031","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202782130&doi=10.1109%2fRE59067.2024.00031&partnerID=40&md5=270d40e949bba76cb02755d0c136ffcb","Monash University, Melbourne, Australia; Austrian Post Group It, Vienna, Austria","Arora C., Monash University, Melbourne, Australia; Herda T., Austrian Post Group It, Vienna, Austria; Homm V., Austrian Post Group It, Vienna, Austria","Test scenarios are specific instances of test cases that describe a sequence of actions to validate a particular software functionality. By outlining the conditions under which the software operates and the expected outcomes, test scenarios ensure that the software functionality is tested in an integrated manner. Test scenarios are crucial for systematically testing an application under various conditions, including edge cases, to identify potential issues and guarantee overall performance and reliability. Manually specifying test scenarios is tedious and requires a deep understanding of software functionality and the underlying domain. It further demands substantial effort and investment from already time- and budget-constrained requirements engineers and testing teams. This paper presents an automated approach (RAGTAG) for test scenario generation using Retrieval-Augmented Generation (RAG) with Large Language Models (LLMs). RAG allows the integration of specific domain knowledge with LLMs' generation capabilities. We evaluate RAGTAG on two industrial projects from Austrian Post with bilingual requirements in German and English. Our results from an interview survey conducted with four experts on five dimensions - relevance, coverage, correctness, coherence and feasibility, affirm the potential of RAGTAG in automating test scenario generation. Specifically, our results indicate that, despite the difficult task of analyzing bilingual requirements, RAGTAG is able to produce scenarios that are well-aligned with the underlying requirements and provide coverage of different aspects of the intended functionality. The generated scenarios are easily understandable to experts and feasible for testing in the project environment. The overall correctness is deemed satisfactory; however, gaps in capturing exact action sequences and domain nuances remain, underscoring the need for domain expertise when applying LLMs.  © 2024 IEEE.","Industry Study; Large Language Models (LLMs); Requirements Engineering; Requirements-driven Testing; Test Scenarios","Integration testing; Investments; Petroleum products; Requirements engineering; Condition; Industry study; Language model; Large language model; Requirement engineering; Requirement-driven; Requirement-driven testing; Scenarios generation; Software functionality; Test scenario; Budget control","Liebel G.; Hadar I.; Spoletini P.","IEEE Computer Society","English","Conference paper","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85202782130"
"Merker J.H.; Bondarenko A.; Hagen M.; Viehweger A.","Merker, Jan Heinrich (59278316000); Bondarenko, Alexander (57207881008); Hagen, Matthias (16309692700); Viehweger, Adrian (55547487000)","59278316000; 57207881008; 16309692700; 55547487000","MiBi at BioASQ 2024: Retrieval-Augmented Generation for Answering Biomedical Questions","2024","CEUR Workshop Proceedings","3740","","","176","187","11","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201633784&partnerID=40&md5=f07f373a85c5b39770cdd8cda884eaaf","Friedrich-Schiller-Universität Jena, Germany; Leipzig University, Germany; Institute of Medical Microbiology and Virology, University Hospital Leipzig, Germany","Merker J.H., Friedrich-Schiller-Universität Jena, Germany; Bondarenko A., Friedrich-Schiller-Universität Jena, Germany, Leipzig University, Germany; Hagen M., Friedrich-Schiller-Universität Jena, Germany; Viehweger A., Institute of Medical Microbiology and Virology, University Hospital Leipzig, Germany","In this paper, we describe the MiBi team's participation in the BioASQ 2024 Task 12b on biomedical semantic question answering. Our RAG-based systems (retrieval-augmented generation) use GPT-3.5, GPT-4, or Mixtral to generate an answer from some retrieved context. For the retrieval, we use PubMed's search API or a local BM25 index of PubMed abstracts and potentially re-rank the initially retrieved abstracts/snippets with different neural bi-encoder and cross-encoder re-rankers. We test five different retrieval-augmented generation schemes with different orders of generation and retrieval stages. The evaluation results for our submitted systems-although partially inconsistent over different test batches-show three general trends. First, combining BM25-based lexical retrieval with neural re-rankers seems to be a good retrieval setup. Second, answers generated from retrieved snippets as context seem more accurate than answers generated from complete abstracts. Third, GPT-4 generates more accurate answers than GPT-3.5, but Mixtral is on par with GPT-4 when employing a generation-then-retrieve-then-generation scheme. © 2024 Copyright for this paper by its authors.","biomedical question answering; information retrieval; large language models; Retrieval-augmented generation","Encoding (symbols); Information retrieval; Modeling languages; Semantics; Biomedical question answering; Evaluation results; General trends; Language model; Large language model; Question Answering; Retrieval-augmented generation; Search API; Question answering","Faggioli G.; Ferro N.; Galuscakova P.; de Herrera A.G.S.","CEUR-WS","English","Conference paper","Final","","Scopus","2-s2.0-85201633784"
"Chen X.; Wang L.; You M.; Liu W.; Fu Y.; Xu J.; Zhang S.; Chen G.; Li K.; Li J.","Chen, Xi (57195074772); Wang, Li (58697411000); You, MingKe (57991840300); Liu, WeiZhi (58112904500); Fu, Yu (58857719700); Xu, Jie (57800543800); Zhang, Shaoting (13605200100); Chen, Gang (56923895700); Li, Kang (57445059900); Li, Jian (57574492100)","57195074772; 58697411000; 57991840300; 58112904500; 58857719700; 57800543800; 13605200100; 56923895700; 57445059900; 57574492100","Evaluating and Enhancing Large Language Models’ Performance in Domain-Specific Medicine: Development and Usability Study With DocOA","2024","Journal of Medical Internet Research","26","","e58158","","","","0","10.2196/58158","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199451996&doi=10.2196%2f58158&partnerID=40&md5=4dd5702dbe55e2502ccd6f906dfae82a","Sports Medicine Center, West China Hospital, Sichuan University, Chengdu, China; Department of Orthopedics, Orthopedic Research Institute, West China Hospital, Sichuan University, Chengdu, China; West China Hospital, West China School of Medicine, Sichuan University, Chengdu, China; Shanghai Artificial Intelligence Laboratory, OpenMedLab, Shanghai, China; West China Biomedical Big Data Center, West China Hospital, Sichuan University, Chengdu, China; Med-X Center for Informatics, Sichuan University, Chengdu, China","Chen X., Sports Medicine Center, West China Hospital, Sichuan University, Chengdu, China, Department of Orthopedics, Orthopedic Research Institute, West China Hospital, Sichuan University, Chengdu, China; Wang L., Sports Medicine Center, West China Hospital, Sichuan University, Chengdu, China, Department of Orthopedics, Orthopedic Research Institute, West China Hospital, Sichuan University, Chengdu, China; You M., Sports Medicine Center, West China Hospital, Sichuan University, Chengdu, China, Department of Orthopedics, Orthopedic Research Institute, West China Hospital, Sichuan University, Chengdu, China; Liu W., Sports Medicine Center, West China Hospital, Sichuan University, Chengdu, China, Department of Orthopedics, Orthopedic Research Institute, West China Hospital, Sichuan University, Chengdu, China; Fu Y., West China Hospital, West China School of Medicine, Sichuan University, Chengdu, China; Xu J., Shanghai Artificial Intelligence Laboratory, OpenMedLab, Shanghai, China; Zhang S., Shanghai Artificial Intelligence Laboratory, OpenMedLab, Shanghai, China; Chen G., Sports Medicine Center, West China Hospital, Sichuan University, Chengdu, China, Department of Orthopedics, Orthopedic Research Institute, West China Hospital, Sichuan University, Chengdu, China; Li K., Shanghai Artificial Intelligence Laboratory, OpenMedLab, Shanghai, China, West China Biomedical Big Data Center, West China Hospital, Sichuan University, Chengdu, China, Med-X Center for Informatics, Sichuan University, Chengdu, China; Li J., Sports Medicine Center, West China Hospital, Sichuan University, Chengdu, China, Department of Orthopedics, Orthopedic Research Institute, West China Hospital, Sichuan University, Chengdu, China","Background: The efficacy of large language models (LLMs) in domain-specific medicine, particularly for managing complex diseases such as osteoarthritis (OA), remains largely unexplored. Objective: This study focused on evaluating and enhancing the clinical capabilities and explainability of LLMs in specific domains, using OA management as a case study. Methods: A domain-specific benchmark framework was developed to evaluate LLMs across a spectrum from domain-specific knowledge to clinical applications in real-world clinical scenarios. DocOA, a specialized LLM designed for OA management integrating retrieval-augmented generation and instructional prompts, was developed. It can identify the clinical evidence upon which its answers are based through retrieval-augmented generation, thereby demonstrating the explainability of those answers. The study compared the performance of GPT-3.5, GPT-4, and a specialized assistant, DocOA, using objective and human evaluations. Results: Results showed that general LLMs such as GPT-3.5 and GPT-4 were less effective in the specialized domain of OA management, particularly in providing personalized treatment recommendations. However, DocOA showed significant improvements. Conclusions: This study introduces a novel benchmark framework that assesses the domain-specific abilities of LLMs in multiple aspects, highlights the limitations of generalized LLMs in clinical contexts, and demonstrates the potential of tailored approaches for developing domain-specific medical LLMs. ©Xi Chen, Li Wang, MingKe You, WeiZhi Liu, Yu Fu, Jie Xu, Shaoting Zhang, Gang Chen, Kang Li, Jian Li.","domain-specific benchmark framework; large language model; osteoarthritis management; retrieval-augmented generation","Humans; Osteoarthritis; Article; case study; clinical evaluation; evidence based medicine; human; information retrieval; large language model; osteoarthritis; therapy","","JMIR Publications Inc.","English","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85199451996"
"Liu T.; Tian Q.; Ye J.; Fu L.; Su S.; Li J.; Wan G.-W.; Zhang L.; Wong S.-Z.; Wang X.; Yang J.","Liu, Tianyang (59291795400); Tian, Qi (59291864500); Ye, Jianmin (59291864600); Fu, LikTung (59291898800); Su, Shengchu (59291898900); Li, Junyan (59291914600); Wan, Gwok-Waa (59210542000); Zhang, Layton (59291914700); Wong, Sam-Zaak (59210717200); Wang, Xi (57191963930); Yang, Jun (54581955400)","59291795400; 59291864500; 59291864600; 59291898800; 59291898900; 59291914600; 59210542000; 59291914700; 59210717200; 57191963930; 54581955400","ChatChisel: Enabling Agile Hardware Design with Large Language Models","2024","2024 International Symposium of Electronics Design Automation, ISEDA 2024","","","","710","716","6","0","10.1109/ISEDA62518.2024.10618053","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201733282&doi=10.1109%2fISEDA62518.2024.10618053&partnerID=40&md5=87f65a3cab0b5e53511b971653d2eaae","School of Integrate Circuits, Southeast University, National Asic Center, Nanjing, 210096, China; National Center of Technology Innovation for Electronic Design Automation (EDA), Nanjing, 211800, China","Liu T., School of Integrate Circuits, Southeast University, National Asic Center, Nanjing, 210096, China; Tian Q., School of Integrate Circuits, Southeast University, National Asic Center, Nanjing, 210096, China; Ye J., School of Integrate Circuits, Southeast University, National Asic Center, Nanjing, 210096, China; Fu L., School of Integrate Circuits, Southeast University, National Asic Center, Nanjing, 210096, China; Su S., School of Integrate Circuits, Southeast University, National Asic Center, Nanjing, 210096, China; Li J., School of Integrate Circuits, Southeast University, National Asic Center, Nanjing, 210096, China; Wan G.-W., National Center of Technology Innovation for Electronic Design Automation (EDA), Nanjing, 211800, China; Zhang L., National Center of Technology Innovation for Electronic Design Automation (EDA), Nanjing, 211800, China; Wong S.-Z., National Center of Technology Innovation for Electronic Design Automation (EDA), Nanjing, 211800, China; Wang X., School of Integrate Circuits, Southeast University, National Asic Center, Nanjing, 210096, China, National Center of Technology Innovation for Electronic Design Automation (EDA), Nanjing, 211800, China; Yang J., School of Integrate Circuits, Southeast University, National Asic Center, Nanjing, 210096, China, National Center of Technology Innovation for Electronic Design Automation (EDA), Nanjing, 211800, China","With the increasing complexity of integrated circuits, agile hardware design methodologies are crucial. Modern HDLs like Chisel enhance design quality, but manual implementations remain error-prone and time-consuming. Large language models (LLMs) offer potential for design automation through natural language but face challenges in generating large circuits using Verilog. We evaluate LLM capabilities for Chisel and Verilog generation, demonstrating superior Chisel generation ability. We introduce ChatChisel, the first language-based agile hardware design workflow that generates Chisel from language specifications. ChatChisel utilizes four LLM-based modules for decomposing, generating, error-correcting, and composing hardware designs. Techniques like LLM collaboration and RAG enhance ChatChisel's performance. Using GPT-3.5-turbo, we implemented an RV32I RISC-V CPU with 5-stage pipeline and dynamic branch prediction. We also validate our approach with extensive evaluations. Our experimental results reveal that ChatChisel can outperform LLM-based hardware design with Verilog by an average of 31.86%, implying a significant design capability enhancement and design process acceleration with ChatChisel. © 2024 IEEE.","Agile Hardware Design; Chisel; LLM; RISC-V","Agile manufacturing systems; Hardware-software codesign; Problem oriented languages; Agile hardware design; Chisel; Design Methodology; Design Quality; Error prones; Hardware design; Language model; Large language model; Model-based OPC; RISC-V; Integrated circuit design","","Institute of Electrical and Electronics Engineers Inc.","English","Conference paper","Final","","Scopus","2-s2.0-85201733282"
"Monea G.; Peyrard M.; Josifoski M.; Chaudhary V.; Eisner J.; Kiciman E.; Palangi H.; Patra B.; West R.","Monea, Giovanni (58755158200); Peyrard, Maxime (57193221729); Josifoski, Martin (57203986360); Chaudhary, Vishrav (57216693372); Eisner, Jason (57206503633); Kiciman, Emre (6507547008); Palangi, Hamid (26647742200); Patra, Barun (57216617419); West, Robert (57217665120)","58755158200; 57193221729; 57203986360; 57216693372; 57206503633; 6507547008; 26647742200; 57216617419; 57217665120","A Glitch in the Matrix? Locating and Detecting Language Model Grounding with Fakepedia","2024","Proceedings of the Annual Meeting of the Association for Computational Linguistics","1","","","6828","6844","16","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203093668&partnerID=40&md5=b1095b9d0a4982bc28789df6ac50f026","EPFL, Switzerland; Univ. Grenoble Alpes, CNRS, Grenoble INP, LIG, France; Microsoft Corporation, United States","Monea G., EPFL, Switzerland; Peyrard M., Univ. Grenoble Alpes, CNRS, Grenoble INP, LIG, France; Josifoski M., EPFL, Switzerland; Chaudhary V., Microsoft Corporation, United States; Eisner J., Microsoft Corporation, United States; Kiciman E., Microsoft Corporation, United States; Palangi H., Microsoft Corporation, United States; Patra B., Microsoft Corporation, United States; West R., EPFL, Switzerland","Large language models (LLMs) have an impressive ability to draw on novel information supplied in their context. Yet the mechanisms underlying this contextual grounding remain unknown, especially in situations where contextual information contradicts factual knowledge stored in the parameters, which LLMs also excel at recalling. Favoring the contextual information is critical for retrieval-augmented generation methods, which enrich the context with up-to-date information, hoping that grounding can rectify outdated or noisy stored knowledge. We present a novel method to study grounding abilities using Fakepedia, a novel dataset of counterfactual texts constructed to clash with a model's internal parametric knowledge. We benchmark various LLMs with Fakepedia and conduct a causal mediation analysis of LLM components when answering Fakepedia queries, based on our Masked Grouped Causal Tracing (MGCT) method. Through this analysis, we identify distinct computational patterns between grounded and ungrounded responses. We finally demonstrate that distinguishing grounded from ungrounded responses is achievable through computational analysis alone. Our results, together with existing findings about factual recall mechanisms, provide a coherent narrative of how grounding and factual recall mechanisms interact within LLMs. © 2024 Association for Computational Linguistics.","","Fake detection; Structured Query Language; Contextual information; Counterfactuals; Excel; Factual knowledge; Generation method; Language model; matrix; Mediation analysis; Novel information; Novel methods; Computational linguistics","Ku L.-W.; Martins A.F.T.; Srikumar V.","Association for Computational Linguistics (ACL)","English","Conference paper","Final","","Scopus","2-s2.0-85203093668"
"Gao Y.; Zong L.; Li Y.","Gao, Yichen (59214660500); Zong, Licheng (57226608044); Li, Yu (57221627042)","59214660500; 57226608044; 57221627042","Enhancing Biomedical Question Answering with Parameter-Efficient Fine-Tuning and Hierarchical Retrieval Augmented Generation","2024","CEUR Workshop Proceedings","3740","","","117","129","12","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201625259&partnerID=40&md5=e653e92745247da7eab46f5d58fb102a","The Chinese University of Hong Kong, 999077, Hong Kong; The CUHK Shenzhen Research Institute, Hi-Tech Park, Shenzhen, 518057, China","Gao Y., The Chinese University of Hong Kong, 999077, Hong Kong; Zong L., The Chinese University of Hong Kong, 999077, Hong Kong; Li Y., The Chinese University of Hong Kong, 999077, Hong Kong, The CUHK Shenzhen Research Institute, Hi-Tech Park, Shenzhen, 518057, China","This paper reports the work done by the CUHK-AIH team in the 12th BioASQ Challenge task 12b, which involves Phases A, A+, and B. In Phase A, we build BM25 indexes for all documents from PubMed Central (PMC). When an input question is received, the system uses the question as a keyword to retrieve relevant documents from PMC via the BM25 retriever, obtaining a list of targeted documents. For Phase A+, we construct a hierarchical Retrieval-Augmented Generation (RAG) pipeline based on the Llama2-chat-7B model. The model is fine-tuned on the BioASQ training set using a Parameter-efficient Fine-Tuning (PEFT) method called Low-Rank Adaptation (LoRA). The system further refines the search results from Phase A by employing an ensemble retriever that combines sparse and dense retrievers to identify the most relevant chunks. Finally, the system feeds the question and the most relevant chunks into the base model to generate the answer using appropriate prompts. In Phase B, the answer generation pipeline is similar to Phase A+, with the main difference being that we directly build indexes for the questions and their relevant snippets, treating snippets as the basic retrieval unit. We conducted detailed ablation studies and analyses on the model types and retrieval techniques, which indicate that PEFT and RAG can significantly improve the performance in biomedical Question Answering (QA) tasks. © 2024 Copyright for this paper by its authors.","BioASQ; Biomedical Question-Answering; Large Language Model; Parameter-Efficient Fine-Tuning; Retrieval-Augmented Generation","Search engines; BioASQ; Biomedical question answering; Fine tuning; Hierarchical retrieval; In-phase; Language model; Large language model; Parameter-efficient fine-tuning; Phase A; Retrieval-augmented generation; Question answering","Faggioli G.; Ferro N.; Galuscakova P.; de Herrera A.G.S.","CEUR-WS","English","Conference paper","Final","","Scopus","2-s2.0-85201625259"
"Bernardo H.-S.; Terven J.; Chavez-Urbiola E.A.; Cordova-Esparza D.-M.; Romero-Gonzalez J.-A.; Arguelles A.; Cervantes I.","Bernardo, Hernandez-Salinas (59367439200); Terven, Juan (59013477200); Chavez-Urbiola, E.A. (54382876300); Cordova-Esparza, Diana-Margarita (55320950200); Romero-Gonzalez, Julio-Alejandro (57207571983); Arguelles, Amadeo (58701633500); Cervantes, Ilse (6603690871)","59367439200; 59013477200; 54382876300; 55320950200; 57207571983; 58701633500; 6603690871","IDAS: Intelligent Driving Assistance System Using RAG","2024","IEEE Open Journal of Vehicular Technology","5","","","1139","1165","26","0","10.1109/OJVT.2024.3447449","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201778170&doi=10.1109%2fOJVT.2024.3447449&partnerID=40&md5=becea478d313246de9dbaa71d9a1e9c4","Cicata, Instituto Politecnico Nacional, Querétaro, 76090, Mexico; Universidad Autónoma de Queretaro, Facultad de Informatica, Queretaro, 76230, Mexico; Centro de Investigacion en Computacion, Instituto Politecnico Nacional, Mexico City, 07738, Mexico","Bernardo H.-S., Cicata, Instituto Politecnico Nacional, Querétaro, 76090, Mexico; Terven J., Cicata, Instituto Politecnico Nacional, Querétaro, 76090, Mexico; Chavez-Urbiola E.A., Cicata, Instituto Politecnico Nacional, Querétaro, 76090, Mexico; Cordova-Esparza D.-M., Universidad Autónoma de Queretaro, Facultad de Informatica, Queretaro, 76230, Mexico; Romero-Gonzalez J.-A., Universidad Autónoma de Queretaro, Facultad de Informatica, Queretaro, 76230, Mexico; Arguelles A., Centro de Investigacion en Computacion, Instituto Politecnico Nacional, Mexico City, 07738, Mexico; Cervantes I., Cicata, Instituto Politecnico Nacional, Querétaro, 76090, Mexico","In the fast-growing automotive technology sector, it has become increasingly clear that there is a need for cars with smarter and more interactive systems. This article presents the Intelligent Driving Assistance System (IDAS), an artificial intelligence system that enables the driver to use voice commands to access various features of a car. The primary component of IDAS is a Large Language Model (LLM), which, through retrieval augmented generation (RAG), can efficiently read and understand the car manual for immediate context-based aid. In addition, this system incorporates speech recognition and speech synthesis capabilities, it can understand commands given in multiple languages, improving user experiences among diverse driver communities. Our results show a minimum response time of one second for the pipeline using GPT-4o-mini and Mistral Nemo. © 2020 IEEE.","Artificial intelligence; human-computer interaction; intelligent agents; large language models; retrieval augmented generation (RAG)","Advanced driver assistance systems; Automobile drivers; Automobiles; Context sensitive languages; Embedded systems; Fast response computer systems; Intelligent systems; Interactive computer systems; Modeling languages; Problem oriented languages; Real time systems; Response time (computer systems); Speech enhancement; Systems analysis; Automotive technology; Computer interaction; Driving assistance systems; Interactive system; Language model; Large language model; Manual; Real - Time system; Retrieval augmented generation; Technology sectors; Human computer interaction","","Institute of Electrical and Electronics Engineers Inc.","English","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85201778170"
"Mensah P.B.; Quao N.S.; Dagadu S.; Mensah J.K.; Darkwah J.D.","Mensah, Paulina Boadiwaa (58995728800); Quao, Nana Serwaa (57195593185); Dagadu, Sesinam (57194125474); Mensah, James Kwabena (59152441600); Darkwah, Jude Domfeh (59152441700)","58995728800; 57195593185; 57194125474; 59152441600; 59152441700","All You Need Is Context: Clinician Evaluations of various iterations of a Large Language Model-Based First Aid Decision Support Tool in Ghana","2024","Proceedings - 2024 IEEE 12th International Conference on Healthcare Informatics, ICHI 2024","","","","580","585","5","0","10.1109/ICHI61247.2024.00093","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203678251&doi=10.1109%2fICHI61247.2024.00093&partnerID=40&md5=a32af70c448a7e179a5bad25866e63f7","SnooCODE RED, SnooCODE, Accra, Ghana; Accident and Emergency Centre, Korle Bu Teaching Hospital SnooCODE RED, Accra, Ghana; Volta Regional Government Hospital, Hohoe, Ghana; University Hospital, Kwame Nkrumah, University of Science and Technology, Kumasi, Ghana; Evaluation Group (1), Ghana","Mensah P.B., SnooCODE RED, SnooCODE, Accra, Ghana, Evaluation Group (1), Ghana; Quao N.S., Accident and Emergency Centre, Korle Bu Teaching Hospital SnooCODE RED, Accra, Ghana, Evaluation Group (1), Ghana; Dagadu S., SnooCODE RED, SnooCODE, Accra, Ghana, Evaluation Group (1), Ghana; Mensah J.K., Volta Regional Government Hospital, Hohoe, Ghana, Evaluation Group (1), Ghana; Darkwah J.D., University Hospital, Kwame Nkrumah, University of Science and Technology, Kumasi, Ghana, Evaluation Group (1), Ghana","As advancements in research and development expand the capabilities of Large Language Models (LLMs), there is a growing focus on their applications within the healthcare sector, driven by the large volume of data generated in healthcare. There are a few medicine-oriented evaluation datasets and benchmarks for assessing the performance of various LLMs in clinical scenarios; however, there is a paucity of information on the real-world usefulness of LLMs in context-specific scenarios in resource-constrained settings. In this work, 5 iterations of a decision support tool for medical emergencies using 5 distinct generalized LLMs were constructed, alongside a combination of Prompt Engineering and Retrieval Augmented Generation techniques. 50 responses were generated from the LLMs. Quantitative and qualitative evaluations of the LLM responses were provided by 13 physicians (general practitioners) with an average of 3 years of practice experience managing medical emergencies in resource-constrained settings in Ghana. Machine evaluations of the LLM responses were also computed and compared with the expert evaluations. © 2024 IEEE.","Claude Sonnet; Clinical Context; Clinical Decision Support; Clinician Evaluation; Emergency Medical Services; First Aid; Gemini 1.5 Pro; GPT 4; Large Language Models; Medical Emergencies; Resource-Constrained Settings; SnooCODE","Decision support systems; Claude sonnet; Clinical context; Clinical decision support; Clinician evaluation; Emergency medical services; First aids; Geminus 1.5 pro; GPT 4; Language model; Large language model; Medical emergency; Resource-constrained setting; SnooCODE; Benchmarking","","Institute of Electrical and Electronics Engineers Inc.","English","Conference paper","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85203678251"
"Joshi P.; Gupta A.; Kumar P.; Sisodia M.","Joshi, Pankaj (59222441500); Gupta, Aditya (59221876500); Kumar, Pankaj (59222303300); Sisodia, Manas (59222158600)","59222441500; 59221876500; 59222303300; 59222158600","Robust Multi Model RAG Pipeline For Documents Containing Text, Table & Images","2024","Proceedings of the 3rd International Conference on Applied Artificial Intelligence and Computing, ICAAIC 2024","","","","993","999","6","0","10.1109/ICAAIC60222.2024.10574972","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198701241&doi=10.1109%2fICAAIC60222.2024.10574972&partnerID=40&md5=4b963e221a1bf69cd324880e4f21fc08","Avasant Advisory India Pvt. Ltd., Avasant Intern Software Engineer (Labs), Delhi, India; Avasant Advisory India Pvt. Ltd., Avasant Technical Lead (Labs), Delhi, India; Avasant Advisory India Pvt. Ltd., Avasant Associate Software Engineer (Labs), Delhi, India","Joshi P., Avasant Advisory India Pvt. Ltd., Avasant Intern Software Engineer (Labs), Delhi, India; Gupta A., Avasant Advisory India Pvt. Ltd., Avasant Intern Software Engineer (Labs), Delhi, India; Kumar P., Avasant Advisory India Pvt. Ltd., Avasant Technical Lead (Labs), Delhi, India; Sisodia M., Avasant Advisory India Pvt. Ltd., Avasant Associate Software Engineer (Labs), Delhi, India","RAG (Retrieval Augmented Generation) is generally used for generating results from the existing knowledge-base. RAG refers to finding references (R), Adding references (A) and improving generation(i.e, answers to the question) (G). MultiModel-RAGs are used for generation of results over the documents which contain images and texts. There exists multiple different Multimodel-RAGs but these are not still efficient in generation of the results from the documents which contain relationships between images and texts. This study has proposed the solution to enable effective retrieval and generation of results, which includes the relationship between images and texts. The comparison of proposed Multimodal RAG with four different datasets (i.e., Short-form-type-QA, Long-form-type-QA, MCQ-type-QA, True-False-type-QA) shows the proposed solution improves the effectiveness of the existing Multimodal RAGs. Testing of proposed Multimodal RAG over two different other multimodal LLM i.e, Open-AI & Gemini helps in deciding whether the proposed solution fits best with LLM in different cases. © 2024 IEEE.","GenAI(Generative AI); LLM(Large Language Models); MuRAG(Multimodal Retrieval Augmented Generation); RAG(Retrieval Augmented Generation)","Information retrieval; Generative AI; Language model; Large language model; Multi-modal; Multi-modelling; Multimodal retrieval augmented generation; Retrieval augmented generation; Knowledge based systems","","Institute of Electrical and Electronics Engineers Inc.","English","Conference paper","Final","","Scopus","2-s2.0-85198701241"
"Chih B.-C.; Han J.-C.; Tsai R.T.-H.","Chih, Bing-Chen (59281954700); Han, Jen-Chieh (57212190520); Tsai, Richard Tzong-Han (59257218800)","59281954700; 57212190520; 59257218800","NCU-IISR: Enhancing Biomedical Question Answering with GPT-4 and Retrieval Augmented Generation in BioASQ 12b Phase B","2024","CEUR Workshop Proceedings","3740","","","99","105","6","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201608224&partnerID=40&md5=774f36b24c6aa78af8f1d4dc18ac39e2","Department of Computer Science and Information Engineering, National Central University, Taiwan; Research Center for Humanities and Social Sciences, Academia Sinica, Taiwan","Chih B.-C., Department of Computer Science and Information Engineering, National Central University, Taiwan; Han J.-C., Department of Computer Science and Information Engineering, National Central University, Taiwan; Tsai R.T.-H., Department of Computer Science and Information Engineering, National Central University, Taiwan, Research Center for Humanities and Social Sciences, Academia Sinica, Taiwan","In this paper, we introduce our system and submissions in BioASQ 12b phase b [1], highlighting a significant improvement with GPT-4 and the integration of Retrieval Augmented Generation (RAG) techniques. We describe our prompt engineering methods and the experimental procedures followed. Because GPT-4 has proven effectiveness in generating answers and its ability in the biological domain, our system utilizes GPT-4 to address biomedical question-answering (QA). Leveraging OpenAI's ChatCompletions API, we refined previous prompt engineering approaches [2] for BioASQ 11b phase b. This year, the addition of RAG techniques significantly improved the information retrieval capabilities of our system. Consequently, our latest submission employed what we experimented to be the most effective prompts and techniques, achieving excellent performance across multiple metrics in the fourth batch. © 2024 Copyright for this paper by its authors.","Biomedical Question Answer; Generative Pre-trained Transformer; Large Language Models (LLMs); Retrieval Augmented Generation","Information retrieval; Modeling languages; Biological domain; Biomedical question answer; Biomedical question answering; Engineering methods; Experimental procedure; Generation techniques; Generative pre-trained transformer; Language model; Large language model; Retrieval augmented generation; Question answering","Faggioli G.; Ferro N.; Galuscakova P.; de Herrera A.G.S.","CEUR-WS","English","Conference paper","Final","","Scopus","2-s2.0-85201608224"
"Li S.; Lee I.; Park S.; Bastani O.","Li, Shuo (57215558130); Lee, Insup (56876051600); Park, Sangdon (57194173235); Bastani, Osbert (56786340300)","57215558130; 56876051600; 57194173235; 56786340300","TRAQ: Trustworthy Retrieval Augmented Question Answering via Conformal Prediction","2024","Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL 2024","1","","","3799","3821","22","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200008192&partnerID=40&md5=cbe9a4b6f6cb5f3dd9e90a1e923bd3b8","University of Pennsylvania, United States; Pohang University of Science and Technology, South Korea","Li S., University of Pennsylvania, United States; Lee I., University of Pennsylvania, United States; Park S., Pohang University of Science and Technology, South Korea; Bastani O., University of Pennsylvania, United States","When applied to open-domain question answering, large language models (LLMs) frequently generate incorrect responses based on made-up facts, which are called hallucinations. Retrieval augmented generation (RAG) is a promising strategy to avoid hallucinations, but it does not provide guarantees on its correctness. To address this challenge, we propose the Trustworthy Retrieval Augmented Question Answering, or TRAQ, which provides the first end-to-end statistical correctness guarantee for RAG. TRAQ uses conformal prediction, a statistical technique for constructing prediction sets that are guaranteed to contain the semantically correct response with high probability. Additionally, TRAQ leverages Bayesian optimization to minimize the size of the constructed sets. In an extensive experimental evaluation, we demonstrate that TRAQ provides the desired correctness guarantee while reducing prediction set size by 16.2% on average compared to an ablation. The implementation is available: https://github.com/shuoli90/TRAQ. ©2024 Association for Computational Linguistics.","","Computational linguistics; Bayesian optimization; Conformal predictions; End to end; Experimental evaluation; High probability; Language model; Open domain question answering; Question Answering; Statistical techniques; Forecasting","Duh K.; Gomez H.; Bethard S.","Association for Computational Linguistics (ACL)","English","Conference paper","Final","","Scopus","2-s2.0-85200008192"
"Chang T.-J.; Lin L.H.-M.; Tsai R.T.-H.","Chang, Ting-Jui (59260193800); Lin, Lydia Hsiao-Mei (59260078000); Tsai, Richard Tzong-Han (59257218800)","59260193800; 59260078000; 59257218800","Conversational Product Recommendation using LLM","2024","2024 IEEE 4th International Conference on Electronic Communications, Internet of Things and Big Data, ICEIB 2024","","","","340","343","3","0","10.1109/ICEIB61477.2024.10602608","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201205614&doi=10.1109%2fICEIB61477.2024.10602608&partnerID=40&md5=4b89f72fe06822ac9b326f97a1082c0e","National Central University, Department of Computer Science and Information Engineering, Taoyuan, Taiwan; National Taipei University of Technology, Department of Interaction Design, Taipei, Taiwan; Research Center for Humanities and Social Sciences Academia Sinica, Taipei, Taiwan","Chang T.-J., National Central University, Department of Computer Science and Information Engineering, Taoyuan, Taiwan; Lin L.H.-M., National Taipei University of Technology, Department of Interaction Design, Taipei, Taiwan; Tsai R.T.-H., Research Center for Humanities and Social Sciences Academia Sinica, Taipei, Taiwan","It is expected to deploy chatbots as sales assistants on e-commerce platforms soon. In recent years, the capabilities demonstrated by large language models (LLMs) indicate their suitability for this role. However, a dialogue process is not fully established. Most existing works concentrate on searching for ideal products, such as Retrieval-Augmented Generation (RAG) and product search. Many proposed methods rely on product reviews. However, in the case of some e-commerce platform products, valuable reviews are often lacking, rendering these approaches impractical. Thus, we studied how to assist users and select a set of candidate products. Accordingly, we simulated sales conversations based on the product features provided by the seller, using LLM and reliable content while addressing the cold-start problem. Specifically, we used product features to generate customer persona for user simulation. LLM was used to play the role of sales assistant in giving recommendations. The experimental results showed that practical conversation was created between customers and chatbots in Traditional Chinese. The code and results are available at: https://github.com/terryobe-ncu/CPR_LLM  © 2024 IEEE.","conversational AI; dialog systems; eCommerce; large language model (LLM)","Computational linguistics; Electronic commerce; Chatbots; Commerce platforms; Conversational AI; Dialogue systems; E- commerces; Ecommerce; Language model; Large language model; Product feature; Sales assistants; Sales","Meen T.-H.","Institute of Electrical and Electronics Engineers Inc.","English","Conference paper","Final","","Scopus","2-s2.0-85201205614"
"Richard R.P.; Veemaraj E.; Thomas J.M.; Mathew J.; Stephen C.; Koshy R.S.","Richard, Rohan Paul (59174073600); Veemaraj, Ebenezer (56607413500); Thomas, Juanith Mathew (59173339700); Mathew, Joel (59045906700); Stephen, Caleb (59045906800); Koshy, Richie Suresh (59047003100)","59174073600; 56607413500; 59173339700; 59045906700; 59045906800; 59047003100","A Client-Server Based Educational Chatbot for Academic Institutions","2024","2024 4th International Conference on Intelligent Technologies, CONIT 2024","","","","","","","0","10.1109/CONIT61985.2024.10627567","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202705232&doi=10.1109%2fCONIT61985.2024.10627567&partnerID=40&md5=bd15be8ff4bc619f461f4c7bc13562e6","Karunya Institute of Technology and Sciences, Department of Computer Science and Engineering, Coimbatore, India","Richard R.P., Karunya Institute of Technology and Sciences, Department of Computer Science and Engineering, Coimbatore, India; Veemaraj E., Karunya Institute of Technology and Sciences, Department of Computer Science and Engineering, Coimbatore, India; Thomas J.M., Karunya Institute of Technology and Sciences, Department of Computer Science and Engineering, Coimbatore, India; Mathew J., Karunya Institute of Technology and Sciences, Department of Computer Science and Engineering, Coimbatore, India; Stephen C., Karunya Institute of Technology and Sciences, Department of Computer Science and Engineering, Coimbatore, India; Koshy R.S., Karunya Institute of Technology and Sciences, Department of Computer Science and Engineering, Coimbatore, India","The use of Generative AI applications in academia, such as ChatGPT, Bard and Perplexity among others is growing at a rapid pace. With its rise, certain ramifications are being felt in regards to the quality and correctness of knowledge and output of these apps. This is detrimental to the process of learning and understanding subject matter in relevant context. In order to stop this issue in its tracks, a solution must be identified, built, tested and deployed so that students will get reliable outputs from trusted sources. This research analyses and describes a sample architecture as well as implementation for such a solution. It incorporates the latest in AI research and development, such as the Large Language Model Mixture of Experts (MoE) architecture as well as a Retrieval Augmented Generation (RAG) with a vector store to use trusted documents such as presentation files, PDF handouts and more from instructors. This is used to add context to the request to the Large Language Model and enrich the understanding as well as response of the model. Apart from this, the application is packaged into a server that can be run on the intranet, as well as deployed for public access. A frontend client page is served to the user, and communicates with the server for all its functioning. © 2024 IEEE.","Generative AI; LangChain; Large Language Model (LLM); Mixture of Experts; Retrieval Augmented Generation (RAG)","Academic institutions; Chatbots; Client /server; Generative AI; Langchain; Language model; Large language model; Mixture of experts; Retrieval augmented generation; Server-based","","Institute of Electrical and Electronics Engineers Inc.","English","Conference paper","Final","","Scopus","2-s2.0-85202705232"
"Aboukacem A.; Berrada I.; Bergou E.H.; Iraqi Y.; Mekouar L.","Aboukacem, Abdelghafour (59244196400); Berrada, Ismail (8963275500); Bergou, El Houcine (56380631500); Iraqi, Youssef (6603845850); Mekouar, Loubna (10144716400)","59244196400; 8963275500; 56380631500; 6603845850; 10144716400","Investigating the Predictive Potential of Large Language Models in Student Dropout Prediction","2024","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","14830 LNAI","","","381","388","7","0","10.1007/978-3-031-64299-9_34","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200267265&doi=10.1007%2f978-3-031-64299-9_34&partnerID=40&md5=2a156d544f70b4161c29d5af1290fa5d","College of Computing, Mohammed VI Polytechnic University, Ben Guerir, Morocco","Aboukacem A., College of Computing, Mohammed VI Polytechnic University, Ben Guerir, Morocco; Berrada I., College of Computing, Mohammed VI Polytechnic University, Ben Guerir, Morocco; Bergou E.H., College of Computing, Mohammed VI Polytechnic University, Ben Guerir, Morocco; Iraqi Y., College of Computing, Mohammed VI Polytechnic University, Ben Guerir, Morocco; Mekouar L., College of Computing, Mohammed VI Polytechnic University, Ben Guerir, Morocco","In the landscape of educational analytics, the usage of Machine Learning (ML), Deep Learning (DL), and Survival Analysis (SA), for student dropout prediction often encounters challenges in effectively detecting dropout cases and explaining dropout reasons. This is due to many challenges such as data imbalance, data processing issues, cold start problem, and the limited explainability of the predictive models. This paper explores the usage of Large Language Models (LLMs) for dropout prediction to tackle the previous challenges. We introduce an approach that leverages the adaptability and contextual understanding of LLMs to discern subtle indicators of potential dropout risks. In particular, we employ a Retrieval Augmented Generation (RAG)-assisted few-shot learning paradigm and prompt engineering to transfer the knowledge of LLMs. An intensive experimentation of our approach has been conducted using real-life Moroccan student data containing academic, demographic, and socio-economic information, to predict yearly school dropouts. Our findings highlight that LLMs outperform baseline ML models while showing the ability to produce textual analysis of students’ data. Thus, LLMs have a promising potential to be employed as student dropout prediction assistants in educational institutions hoping to mitigate this phenomenon. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.","Few-shot learning; Large Language Models; Retrieval Augmented Generation; Student dropout prediction","Computational linguistics; Data handling; Deep learning; Learning systems; Students; Cold start problems; Data imbalance; Few-shot learning; Imbalance datum; Language model; Large language model; Machine-learning; Retrieval augmented generation; Student dropout prediction; Survival analysis; Forecasting","Olney A.M.; Chounta I.-A.; Liu Z.; Santos O.C.; Bittencourt I.I.","Springer Science and Business Media Deutschland GmbH","English","Conference paper","Final","","Scopus","2-s2.0-85200267265"
"Gao M.; Xiong J.; Zong Y.; Li S.","Gao, Min (59124878000); Xiong, Jize (58912893700); Zong, Yanqi (58924837000); Li, Shulin (58826571200)","59124878000; 58912893700; 58924837000; 58826571200","Science Exam Question Answering based on Retrieval-Augmented Generation","2024","Proceedings - 2024 3rd International Conference on Computer Technologies, ICCTech 2024","","","","55","58","3","0","10.1109/ICCTech61708.2024.00020","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198902352&doi=10.1109%2fICCTech61708.2024.00020&partnerID=40&md5=e77750e86d93d085c35c29dff22b2ff5","Trine University, Phoenix, United States; Northern Arizona University, Flagstaff, United States","Gao M., Trine University, Phoenix, United States; Xiong J., Northern Arizona University, Flagstaff, United States; Zong Y., Trine University, Phoenix, United States; Li S., Trine University, Phoenix, United States","With the increasing capabilities of large language models (LLMs), researchers are exploring novel ways to leverage them in various domains. This competition explores the potential of large language models in answering challenging science-based questions. In response to the inherent limitations of scant training data, our proposed solution introduces a pioneering Retrieval-Augmented Generation (RAG) approach, incorporating the expansive Wikipedia6.5M dataset. Our innovation centers on skillfully incorporating external knowledge, a crucial factor in improving question-answering in limited computational settings. The synergy of vector similarity retrieval and Platypus2-70B LLM broadens perspectives, enhancing comprehension of STEM subjects and overcoming data scarcity by utilizing external knowledge repositories. © 2024 IEEE.","component; Large Language Models (LLMs); Retrieval-Augmented Generation (RAG); Science Exam Question Answering","Component; Exam questions; External knowledge; Inherent limitations; Language model; Large language model; Question Answering; Retrieval-augmented generation; Science exam question answering; Training data; Computational linguistics","","Institute of Electrical and Electronics Engineers Inc.","English","Conference paper","Final","","Scopus","2-s2.0-85198902352"
"Otto W.; Upadhyaya S.; Dietze S.","Otto, Wolfgang (57210636145); Upadhyaya, Sharmila (57897669800); Dietze, Stefan (19638604400)","57210636145; 57897669800; 19638604400","Enhancing Software-Related Information Extraction via Single-Choice Question Answering with Large Language Models","2024","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","14770 LNAI","","","289","306","17","0","10.1007/978-3-031-65794-8_21","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202215320&doi=10.1007%2f978-3-031-65794-8_21&partnerID=40&md5=ad9eb715bc5ac9e57283c0c99ee5938a","GESIS - Leibniz Institute for the Social Sciences, Cologne, Germany; Heinrich Heine University Düsseldorf, Düsseldorf, Germany","Otto W., GESIS - Leibniz Institute for the Social Sciences, Cologne, Germany; Upadhyaya S., GESIS - Leibniz Institute for the Social Sciences, Cologne, Germany; Dietze S., GESIS - Leibniz Institute for the Social Sciences, Cologne, Germany, Heinrich Heine University Düsseldorf, Düsseldorf, Germany","This paper describes our participation in the Shared Task on Software Mentions Disambiguation (SOMD), with a focus on improving relation extraction in scholarly texts through generative Large Language Models (LLMs) using single-choice question-answering. The methodology prioritises the use of in-context learning capabilities of LLMs to extract software-related entities and their descriptive attributes, such as distributive information. Our approach uses Retrieval-Augmented Generation (RAG) techniques and LLMs for Named Entity Recognition (NER) and Attributive NER to identify relationships between extracted software entities, providing a structured solution for analysing software citations in academic literature. The paper provides a detailed description of our approach, demonstrating how using LLMs in a single-choice QA paradigm can greatly enhance IE methodologies. Our participation in the SOMD shared task highlights the importance of precise software citation practices and showcases our system’s ability to overcome the challenges of disambiguating and extracting relationships between software mentions. This sets the groundwork for future research and development in this field. © The Author(s) 2024.","Generative Large Language Models; Information Extraction; Named Entity Recognition; Relation Extraction; Retrieval-Augmented Generation; Single-Choice Question Answering; Software Citation; Software Mentions Disambiguation Task","Generative adversarial networks; Information retrieval; Generative large language model; Information extraction; Language model; Named entity recognition; Question Answering; Relation extraction; Retrieval-augmented generation; Single-choice question answering; Software citation; Software mention disambiguation task; Question answering","Rehm G.; Dietze S.; Schimmler S.; Krüger F.","Springer Science and Business Media Deutschland GmbH","English","Conference paper","Final","All Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85202215320"
"Kukreja S.; Kumar T.; Bharate V.; Purohit A.; Dasgupta A.; Guha D.","Kukreja, Sanjay (58979019500); Kumar, Tarun (59120383400); Bharate, Vishal (57191620541); Purohit, Amit (58103305700); Dasgupta, Abhijit (57222612400); Guha, Debashis (57221493288)","58979019500; 59120383400; 57191620541; 58103305700; 57222612400; 57221493288","Performance Evaluation of Vector Embeddings with Retrieval-Augmented Generation","2024","2024 9th International Conference on Computer and Communication Systems, ICCCS 2024","","","","333","340","7","0","10.1109/ICCCS61882.2024.10603291","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201264040&doi=10.1109%2fICCCS61882.2024.10603291&partnerID=40&md5=d3971f7da050c6112ee570d4da797e38","SP Jain School of Global Management, Department of Machine Learning, Mumbai, India; COE AI-ML EClerx Services Ltd., Chandigarh, India; COE AI-ML EClerx Services Ltd., Pune, India; COE AI-ML EClerx Services Ltd., Mumbai, India; SP Jain School of Global Management, Department of Data Science, Mumbai, India","Kukreja S., SP Jain School of Global Management, Department of Machine Learning, Mumbai, India; Kumar T., COE AI-ML EClerx Services Ltd., Chandigarh, India; Bharate V., COE AI-ML EClerx Services Ltd., Pune, India; Purohit A., COE AI-ML EClerx Services Ltd., Mumbai, India; Dasgupta A., SP Jain School of Global Management, Department of Data Science, Mumbai, India; Guha D., SP Jain School of Global Management, Department of Machine Learning, Mumbai, India","Vector embeddings form the basis of sophisticated language models. These language models were developed with the advent of developments in natural language processing (NLP) and aid in a variety of downstream tasks. Contextually relevant responses are improved using a combination of generation-based models and information retrieval, which is combined in the Retrieval-Augmented Generation (RAG) framework. The state-of-the-art research focuses on the RAG framework. Performance evaluation of vector embeddings in context with the RAG framework for data querying from documents is presented in this paper. The research encompasses a comparative analysis of various vector embeddings and their average, weighted average ensemble, evaluating their effectiveness in easing information retrieval and subsequent generation activities. The investigations focus on the impact of alternative embedding approaches on the overall performance of context generation across the NCERT books dataset using a systematic evaluation. The capabilities of ChatGPT and Llama2 are employed for evaluating the performance of embedding models. NCERT books form the underlying database, and LLM models are used to rank the contexts derived from the database. The optimized prompt is utilized to achieve ranking of the results. The same LLM is also utilized to generate the response for all the embedding models employing generated contexts. The variety in vector embedding approaches is exhibited by the experimental results. © 2024 IEEE.","Data querying; Ensemble embedding; Information Retrieval; Natural Language Processing; Performance Evaluation; Response Generation; Retrieval-Augmented Generation; Vector Embeddings","Natural language processing systems; Query languages; Data querying; Embeddings; Ensemble embedding; Language processing; Natural language processing; Natural languages; Performances evaluation; Response generation; Retrieval-augmented generation; Vector embedding; Structured Query Language","","Institute of Electrical and Electronics Engineers Inc.","English","Conference paper","Final","","Scopus","2-s2.0-85201264040"
"Liu C.; Hoang L.; Stolman A.; Wu B.","Liu, Chang (58845465400); Hoang, Loc (57202859301); Stolman, Andrew (59242749400); Wu, Bo (57734918200)","58845465400; 57202859301; 59242749400; 57734918200","HiTA: A RAG-Based Educational Platform that Centers Educators in the Instructional Loop","2024","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","14830 LNAI","","","405","412","7","0","10.1007/978-3-031-64299-9_37","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200217163&doi=10.1007%2f978-3-031-64299-9_37&partnerID=40&md5=15a8bad91d042cdddbbbb76ba66686ef","Colorado School of Mines, Golden, 80401, United States; HiTA AI Inc., Santa Clara, United States","Liu C., Colorado School of Mines, Golden, 80401, United States; Hoang L., HiTA AI Inc., Santa Clara, United States; Stolman A., HiTA AI Inc., Santa Clara, United States; Wu B., Colorado School of Mines, Golden, 80401, United States, HiTA AI Inc., Santa Clara, United States","Large Language Models (LLMs) have the potential to influence the current educational framework by providing answers to students without educators’ involvement. Herein, we have developed a new system, called HiTA, that places educators at the center of AI-assisted learning loops. The key concept involves using LLMs as teaching assistants to amplify educators’ expertise with their pedagogical supervision. Built on retrieval-augmented generation, HiTA incorporates advanced features such as a user-friendly interface, a multi-mode prompt processing subsystem, and a customization subsystem that provides course-specific support. Compared to general LLMs, HiTA provides pedagogically oriented and course-adherent responses. Our system has been deployed to 6 educators and 400 students spanning entry-level to advanced courses at the Colorado School of Mines for two semesters. In the Fall 2023 semester, 270 students posted over 14,000 questions within approximately two months. From the 47 feedback forms collected post-semester, over 97% of survey respondents found HiTA helpful, and more than 80% considered it more beneficial than ChatGPT.  © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.","ChatGPT; Education; LLM","Education computing; 'current; ChatGPT; Colorado School of Mines; Customisation; Educational platforms; Language model; Large language model; Multimodes; Teaching assistants; User friendly interface; Students","Olney A.M.; Chounta I.-A.; Liu Z.; Santos O.C.; Bittencourt I.I.","Springer Science and Business Media Deutschland GmbH","English","Conference paper","Final","","Scopus","2-s2.0-85200217163"
"","","","20th IFIP WG 12.5 International Conference on Artificial Intelligence Applications and Innovations, AIAI 2024","2024","IFIP Advances in Information and Communication Technology","713 IFIPAICT","","","","","1497","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199215552&partnerID=40&md5=e94c57a5a5279c6c480113e7e198a6fe","","","The proceedings contain 108 papers. The special focus in this conference is on Artificial Intelligence Applications and Innovations. The topics include: Strategizing the Shallows: Leveraging Multi-Agent Reinforcement Learning for Enhanced Tactical Decision-Making in Littoral Naval Warfare; multi-dimensional Classification on Social Media Data for Detailed Reporting with Large Language Models; LLM Prompting Versus Fine-Tuning PLMs: A Comparative Study on Keyword Generation from Customer Feedback; greekT5: Sequence-to-Sequence Models for Greek News Summarization; generating Profiles of News Commentators with Language Models; enhancing Financial Market Prediction with Reinforcement Learning and Ensemble Learning; AI-Driven Sentiment Trend Analysis: Enhancing Topic Modeling Interpretation with ChatGPT; preface; detecting Illicit Data Leaks on Android Smartphones Using an Artificial Intelligence Models; an Algorithmic Data Pipeline Architecture for the Production of Personalized Telecom Product Offers; improving Agricultural Image Classification by Mining Images; enhancing Predictive Process Monitoring with Conformal Prediction; online Reinforcement Learning for Designing Automotive Hybrid Assembly Sequence: A Task Clustering-Guided Approach; SMT: Self-supervised Approach for Multiple Animal Detection and Tracking; Improved NO2 Prediction Using Machine Learning Algorithms; benign Paroxysmal Positional Vertigo Disorders Classification Using Eye Tracking Data; Improving RAG Quality for Large Language Models with Topic-Enhanced Reranking; the Impact of Augmentation Techniques on Icon Detection Using Machine Learning Techniques; unlocking User Privacy: A Systematic Survey of Factors and Methods in Predicting App Permission Decisions; toward Unsupervised Energy Consumption Anomaly Detection; simulation Study for Evaluating Efficiency of McPhail Traps in Olive Groves; predictive Maintenance Under Absence of Sensor Data; pollutant Concentration Prediction by Random Forest to Estimate a Contaminant Source Position; Machine Learning Models for Electricity Generation Forecasting from a PV Farm.","","","Maglogiannis I.; Iliadis L.; Macintyre J.; Avlonitis M.; Papaleonidas A.","Springer Science and Business Media Deutschland GmbH","English","Conference review","Final","","Scopus","2-s2.0-85199215552"
"Rorseth J.; Godfrey P.; Golab L.; Srivastava D.; Szlichta J.","Rorseth, Joel (57204246939); Godfrey, Parke (7005052485); Golab, Lukasz (8224502200); Srivastava, Divesh (58161615400); Szlichta, Jaroslaw (37082075800)","57204246939; 7005052485; 8224502200; 58161615400; 37082075800","Towards Explainability in Retrieval-Augmented LLMs","2024","Proceedings - International Conference on Data Engineering","","","","5669","5670","1","0","10.1109/ICDE60146.2024.00466","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200444910&doi=10.1109%2fICDE60146.2024.00466&partnerID=40&md5=4c037229be422a75084c7216cbe8609d","University of Waterloo, Canada; York University, Canada; AT&T Chief Data Office","Rorseth J., University of Waterloo, Canada; Godfrey P., York University, Canada; Golab L., University of Waterloo, Canada; Srivastava D., AT&T Chief Data Office; Szlichta J., York University, Canada","In an era where artificial intelligence (AI) is re-shaping countless aspects of society, we present a forward-looking perspective for enhancing the explainability of large language models (LLMs), with a particular focus on the retrieval-augmented generation (RAG) prompting technique. We motivate the urgency for developing techniques to explain LLM decision-making behaviour, especially as these models are deployed in critical sectors. Central to this effort is RAGE, our novel explain-ability tool that can trace the provenance of an LLM's answer back to external knowledge sources provided via RAG. RAGE builds upon established explainability techniques to recover citations for LLM answers, identify context biases, and mine answer rules. Through our novel explainability formulations and practical use cases, we chart a course toward more transparent and trustworthy AI technologies.  © 2024 IEEE.","Explainable AI; Large Language Models; Retrieval-Augmented Generation","Computational linguistics; Decision-making behaviors; Explainable artificial intelligence; External knowledge; Forward looking; Knowledge sources; Language model; Large language model; Modeling decision makings; Practical use; Retrieval-augmented generation; Decision making","","IEEE Computer Society","English","Conference paper","Final","","Scopus","2-s2.0-85200444910"
"Panou D.; Dimopoulos A.C.; Reczko M.","Panou, Dimitra (57221248976); Dimopoulos, Alexandros C. (57216891632); Reczko, Martin (6602121632)","57221248976; 57216891632; 6602121632","Farming Open LLMs for Biomedical Question Answering","2024","CEUR Workshop Proceedings","3740","","","188","196","8","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201585886&partnerID=40&md5=ccdaa72b0570c0990c220d79846e29da","Institute for Fundamental Biomedical Science, Biomedical Sciences Research Center ""Alexander Fleming"", 34 Fleming Street, Vari, 16672, Greece; Department of Informatics and Telecommunications, National and Kapodistrian University of Athens, Athens, 15784, Greece; Hellenic Naval Academy, Piraeus, 18539, Greece","Panou D., Institute for Fundamental Biomedical Science, Biomedical Sciences Research Center ""Alexander Fleming"", 34 Fleming Street, Vari, 16672, Greece, Department of Informatics and Telecommunications, National and Kapodistrian University of Athens, Athens, 15784, Greece; Dimopoulos A.C., Institute for Fundamental Biomedical Science, Biomedical Sciences Research Center ""Alexander Fleming"", 34 Fleming Street, Vari, 16672, Greece, Hellenic Naval Academy, Piraeus, 18539, Greece; Reczko M., Institute for Fundamental Biomedical Science, Biomedical Sciences Research Center ""Alexander Fleming"", 34 Fleming Street, Vari, 16672, Greece","A large number of performant, open Large Language Models (LLMs) are continuously appearing. Here we deploy a selection of these for embedding and retrieval of documents and snippets as well as retrieval-augmented generators to answer biomedical questions within the BioASQ competition. Dense retrieval based on distances between dense representations obtained by LLM embeddings of the corpus and the question and hybrid sparse/dense methods result in higher mean average precisions compared to traditional sparse retrieval methods. In the exact answer category, which is processed using open LLMs in a zero-shot approach, our submission shares one first place in the last batch of the BioASQ 12b competition. © 2024 Copyright for this paper by its authors.","BioASQ; Biomedical Question Answering; Large Language Models; Retrieval-augmented generation","Embeddings; BioASQ; Biomedical question answering; Embeddings; Language model; Large language model; Model embedding; Retrieval methods; Retrieval-augmented generation; Question answering","Faggioli G.; Ferro N.; Galuscakova P.; de Herrera A.G.S.","CEUR-WS","English","Conference paper","Final","","Scopus","2-s2.0-85201585886"
"Shaik K.; Wang D.; Zheng W.; Cao Q.; Fan H.; Schwartz P.; Feng Y.","Shaik, Kareem (58960496200); Wang, Dali (55713364700); Zheng, Weijian (57194060354); Cao, Qinglei (58960703100); Fan, Heng (56085688000); Schwartz, Peter (57806931500); Feng, Yunhe (57195902826)","58960496200; 55713364700; 57194060354; 58960703100; 56085688000; 57806931500; 57195902826","S3LLM: Large-Scale Scientific Software Understanding with LLMs Using Source, Metadata, and Document","2024","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","14834 LNCS","","","222","230","8","0","10.1007/978-3-031-63759-9_27","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199586809&doi=10.1007%2f978-3-031-63759-9_27&partnerID=40&md5=21ca356b0508cf53fd0eb12d418ffb6b","University of North Texas, Denton, 76207, TX, United States; Oak Ridge National Laboratory, Oak Ridge, 37830, TN, United States; Argonne National Laboratory, Lemont, 60439, IL, United States; Saint Louis University, St. Louis, 63103, MO, United States","Shaik K., University of North Texas, Denton, 76207, TX, United States; Wang D., Oak Ridge National Laboratory, Oak Ridge, 37830, TN, United States; Zheng W., Argonne National Laboratory, Lemont, 60439, IL, United States; Cao Q., Saint Louis University, St. Louis, 63103, MO, United States; Fan H., University of North Texas, Denton, 76207, TX, United States; Schwartz P., Oak Ridge National Laboratory, Oak Ridge, 37830, TN, United States; Feng Y., University of North Texas, Denton, 76207, TX, United States","The understanding of large-scale scientific software is a significant challenge due to its diverse codebase, extensive code length, and target computing architectures. The emergence of generative AI, specifically large language models (LLMs), provides novel pathways for understanding such complex scientific codes. This paper presents S3LLM, an LLM-based framework designed to enable the examination of source code, code metadata, and summarized information in conjunction with textual technical reports in an interactive, conversational manner through a user-friendly interface. S3LLM leverages open-source LLaMA-2 models to enhance code analysis through the automatic transformation of natural language queries into domain-specific language (DSL) queries. In addition, S3LLM is equipped to handle diverse metadata types, including DOT, SQL, and customized formats. Furthermore, S3LLM incorporates retrieval-augmented generation (RAG) and LangChain technologies to directly query extensive documents. S3LLM demonstrates the potential of using locally deployed open-source LLMs for the rapid understanding of large-scale scientific computing software, eliminating the need for extensive coding expertise and thereby making the process more efficient and effective. S3LLM is available at https://github.com/ResponsibleAILab/s3llm. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.","ChatGPT; E3SM Land Model; Large-Scale Scientific Software; LLaMA; LLM; Research Software Analysis; Retrieval Augmented Generation (RAG)","Codes (symbols); Computer architecture; Information retrieval; Natural language processing systems; Open source software; Open systems; Problem oriented languages; ChatGPT; E3SM land model; Land model; Language model; Large language model; Large-scale scientific software; Large-scales; LLaMA; Research software analyse; Retrieval augmented generation; Scientific softwares; Software analysis; Metadata","Franco L.; de Mulatier C.; Paszynski M.; Krzhizhanovskaya V.V.; Dongarra J.J.; Sloot P.M.A.","Springer Science and Business Media Deutschland GmbH","English","Conference paper","Final","","Scopus","2-s2.0-85199586809"
"Devi S.; Dhar G.; Bharadwaj C.; Abdussamad M.","Devi, Sharmila (58547765200); Dhar, Gopala (59259351000); Bharadwaj, Chaitanya (58547265500); Abdussamad, M. (59259351100)","58547765200; 59259351000; 58547265500; 59259351100","Retrieval Augmented MedLM","2024","Proceedings - 2024 IEEE Conference on Artificial Intelligence, CAI 2024","","","","1220","1221","1","0","10.1109/CAI59869.2024.00217","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201224740&doi=10.1109%2fCAI59869.2024.00217&partnerID=40&md5=19f20cde09ba0754bc8cd0e136836fbc","Ai Services, Google Cloud Consulting (GCC), Google, Bengaluru, India; Ai Services, Google Cloud Consulting (GCC), Google, Mumbai, India; Apollo247, Bengaluru, India; Apollo247, Bengaluru, India","Devi S., Ai Services, Google Cloud Consulting (GCC), Google, Bengaluru, India; Dhar G., Ai Services, Google Cloud Consulting (GCC), Google, Mumbai, India; Bharadwaj C., Apollo247, Bengaluru, India; Abdussamad M., Apollo247, Bengaluru, India","This paper presents a novel approach to leverage large language models (LLMs) for medical question answering (QA) by integrating them with external knowledge sources. We utilize de-identified clinical discharge notes from MIMIC-IV and Apollo Hospitals as our data source. We propose a novel summarization technique that extracts and condenses the core medical information from the discharge notes, eliminating unnecessary verbosity. This results in concise ""medical summaries""that effectively inform the LLM while reducing context overload. We evaluate our approach using RAGAS, a novel framework for label-free evaluation of Retrieval-Augmented Generation (RAG) pipelines. Clinician validation further confirms the effectiveness of our approach, highlighting its potential to enhance medical QA systems. © 2024 IEEE.","Discharge Notes; Embeddings; GenAL; LLM; Medical QA systems; MedLM; MedPaLM; PaLM; PaLM2; RAG","Natural language processing systems; Discharge note; Embeddings; GenAL; Language model; Large language model; Medical question answering; Medical question answering system; MedLM; MedPaLM; PaLM; PaLM2; Question answering systems; Retrieval-augmented generation; Knowledge management","","Institute of Electrical and Electronics Engineers Inc.","English","Conference paper","Final","","Scopus","2-s2.0-85201224740"
"Wang J.; Wang Z.; Zhu Z.; Xie J.; Yu Y.; Fei Y.; Huang Y.; Cheng D.; Zhao H.","Wang, Jinyuan (58462664200); Wang, Zhong (58618218400); Zhu, Zeyang (58616580300); Xie, Jinhao (58617389700); Yu, Yong (58617389800); Fei, Yongjian (58616855600); Huang, Yue (58617938400); Cheng, Dawei (57191748068); Zhao, Hai (55715822700)","58462664200; 58618218400; 58616580300; 58617389700; 58617389800; 58616855600; 58617938400; 57191748068; 55715822700","CSPRD: A Financial Policy Retrieval Dataset for Chinese Stock Market","2024","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","14910 LNCS","","","3","17","14","0","10.1007/978-3-031-68309-1_1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202157198&doi=10.1007%2f978-3-031-68309-1_1&partnerID=40&md5=c121fe57073496d030356db27e5eb4af","Shanghai Jiao Tong University, Shanghai, China; Shanghai Stock Exchange Technology Co., Ltd., Shanghai, China; Tongji University, Shanghai, China","Wang J., Shanghai Jiao Tong University, Shanghai, China; Wang Z., Shanghai Stock Exchange Technology Co., Ltd., Shanghai, China; Zhu Z., Shanghai Stock Exchange Technology Co., Ltd., Shanghai, China; Xie J., Shanghai Stock Exchange Technology Co., Ltd., Shanghai, China; Yu Y., Shanghai Stock Exchange Technology Co., Ltd., Shanghai, China; Fei Y., Shanghai Stock Exchange Technology Co., Ltd., Shanghai, China; Huang Y., Shanghai Stock Exchange Technology Co., Ltd., Shanghai, China; Cheng D., Tongji University, Shanghai, China; Zhao H., Shanghai Jiao Tong University, Shanghai, China","Recently, Large language models (LLMs) have demonstrated formidable capabilities, yet challenges persist in real-world applications, particularly in aspects of hallucination, misinformation and outdated knowledge. Retrieval-Augmented Generation (RAG) addresses these challenges by pre-retrieving pertinent information from external knowledge bases prior to utilizing LLMs for answering queries. Although RAG has been empirically validated to enhance response accuracy and reduce error rates, the paucity of domain-specific datasets hampers the development of proficient retrievers, therefore becoming a bottleneck in deploying RAG pipelines within professional fields. In this work, we propose a novel task termed stock policy retrieval and introduce the Chinese Stock Policy Retrieval Dataset (CSPRD), comprising 700+ prospectus excerpts annotated by seasoned experts, correlated with relevant articles from a collection of more than 10,000 entries in our amassed Chinese policy corpus. Our experiments with lexical, embedding, and fine-tuned bi-encoder models not only attests to the efficacy of our proposed CSPRD but also indicates considerable potential for enhancement. To capitalize on high quality encodings, we proposed CSPR-MQA, a retrieval-oriented pre-training paradigm that amalgamates various supervised natural language processing (NLP) tasks into an unsupervised framework for masked question-answering (MQA). Our CSPR-MQA model, after pre-training on 61GB Chinese corpus and fine-tuning on CSPRD, achieves the best performance on the CSPRD development set, with metrics including 57.9% MRR@10, 29.1% NDCG@10 and 39.3% Recall@10. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.","Decision Support Systems; Information Retrieval; Retrieval Augmented Generation","Commerce; Decentralized finance; Electronic trading; Error statistics; Large datasets; Marketplaces; Modeling languages; Natural language processing systems; Online searching; Question answering; Chinese stock market; Decision supports; External knowledge; Language model; Pre-training; Question Answering; Real-world; Retrieval augmented generation; Stock policy; Support systems; Financial markets","Strauss C.; Amagasa T.; Manco G.; Kotsis G.; Khalil I.; Tjoa A.M.","Springer Science and Business Media Deutschland GmbH","English","Conference paper","Final","","Scopus","2-s2.0-85202157198"
"Takano K.; Nakagawa K.; Fujimoto Y.","Takano, Kaito (57211290449); Nakagawa, Kei (57202888921); Fujimoto, Yugo (57984817100)","57211290449; 57202888921; 57984817100","Generation of Market Comments and Outlooks in Mutual Fund Disclosure Documents Using LLM","2024","Transactions of the Japanese Society for Artificial Intelligence","39","4","FIN23-B_1-13","","","","0","10.1527/tjsai.39-4_FIN23-B","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198106337&doi=10.1527%2ftjsai.39-4_FIN23-B&partnerID=40&md5=b3149f740d661eb94b63af8057d9de96","Nomura Asset Management Co., Ltd, Japan","Takano K., Nomura Asset Management Co., Ltd, Japan; Nakagawa K.; Fujimoto Y.","The number of funds remains high and the amount of economic and social news information increases rapidly, increasing the burden on asset management companies in preparing disclosure documents. These disclosure documents are important for mutual fund holders, and in particular, market comments and outlooks are essential to understanding the current and future investment environment. Writing these documents takes a lot of time, adding to the workload of asset management companies. Recently, advancements in Large Language Models (LLMs) have expanded their use in various tasks. However, LLMs struggle to easily learn new information due to computational resources and costs, making it challenging to generate market comments and outlooks reflecting the latest economic data. Retrieval Augmented Generation (RAG) is a solution to this problem. In this study, we use ChatGPT, a type of LLM, to develop a tool that automatically generates market comments and outlooks. This tool can incorporate the latest news information and generate comments based on the information while suppressing hallucinations. We propose two methods: few-shot learning, which uses past market comments as examples, and zero-shot learning, which does not use past market comments. We collected actual market comments from publicly available mutual fund disclosure documents and conducted both qualitative and quantitative evaluations in comparison with the generated comments. © 2024, Japanese Society for Artificial Intelligence. All rights reserved.","few-shot learning; large language model (LLM); mutual fund disclosure document; retrieval augmented generation; zero-shot learning","Asset management; Commerce; Computational linguistics; Learning systems; Zero-shot learning; 'current; Asset management company; Few-shot learning; Language model; Large language model; Mutual fund disclosure document; Mutual funds; News information; Retrieval augmented generation; Social news; Investments","","Japanese Society for Artificial Intelligence","Japanese","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85198106337"
"Ko H.-T.; Liu Y.-K.; Tsai Y.-C.; Suen S.","Ko, Hsing-Tzu (59247248100); Liu, Yen-Ku (59248017100); Tsai, Yun-Cheng (57217994558); Suen, Summit (59247406000)","59247248100; 59248017100; 57217994558; 59247406000","Enhancing Python Learning Through Retrieval-Augmented Generation: A Theoretical and Applied Innovation in Generative AI Education","2024","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","14786 LNCS","","","164","173","9","0","10.1007/978-3-031-65884-6_17","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200515117&doi=10.1007%2f978-3-031-65884-6_17&partnerID=40&md5=b5dd23fee0cb7cda9a0c82f03abe72d0","Department of Technology Application and Human Resource Development, National Taiwan Normal University, No.162, He-Ping East Road Sec1, Taipei, 10610, Taiwan; Kadokawa Corporation, No. 13-3, Fujimi 2-chome, Chiyoda-ku, Tokyo, Japan","Ko H.-T., Department of Technology Application and Human Resource Development, National Taiwan Normal University, No.162, He-Ping East Road Sec1, Taipei, 10610, Taiwan; Liu Y.-K., Department of Technology Application and Human Resource Development, National Taiwan Normal University, No.162, He-Ping East Road Sec1, Taipei, 10610, Taiwan; Tsai Y.-C., Department of Technology Application and Human Resource Development, National Taiwan Normal University, No.162, He-Ping East Road Sec1, Taipei, 10610, Taiwan; Suen S., Kadokawa Corporation, No. 13-3, Fujimi 2-chome, Chiyoda-ku, Tokyo, Japan","Our study presents an innovative learning tool that leverages the synergy between Retrieval-Augmented Generation (RAG) and Large Language Models (LLMs) to redefine Python programming skill acquisition. This research explores how integrating RAG with LLMs like ChatGPT can overcome traditional learning barriers by providing precise, contextually relevant responses, streamlining learning, and boosting learner confidence. Implementing RAG-enhanced LLMs resulted in decreased cognitive load and enhanced grasp and application of complex programming concepts. Our findings suggest that this RAG-based tool improves information reliability and enriches learning experiences, fostering more profound understanding and robust confidence in tackling programming challenges. This study contributes to the discourse on AI-assisted learning by showcasing RAG’s potential to enhance programming learning efficacy and satisfy learners ethically and at scale. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.","AI-assisted learning; Cognitive load reduction; Large Language Models (LLMs); Learner confidence; Retrieval-Augmented Generation (RAG)","Computational linguistics; Learning systems; Python; AI-assisted learning; Cognitive load reduction; Cognitive loads; Innovative learning; Language model; Large language model; Learner confidence; Learning tool; Load reduction; Retrieval-augmented generation; High level languages","Cheng Y.-P.; Pedaste M.; Bardone E.; Huang Y.-M.","Springer Science and Business Media Deutschland GmbH","English","Conference paper","Final","","Scopus","2-s2.0-85200515117"
"Sofat A.; Sodhi B.","Sofat, Aashna (59300206300); Sodhi, Balwinder (37020331700)","59300206300; 37020331700","Speeding up Government Procurement Workflows with LLMs","2024","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","14913 LNCS","","","27","33","6","0","10.1007/978-3-031-68211-7_3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202205397&doi=10.1007%2f978-3-031-68211-7_3&partnerID=40&md5=c13b9619dce516d195ed6400f33f27c0","Independent Researcher, Bengaluru, 560071, India; Indian Institute of Technology Ropar, Rupnagar, 140001, India","Sofat A., Independent Researcher, Bengaluru, 560071, India; Sodhi B., Indian Institute of Technology Ropar, Rupnagar, 140001, India","Public procurement requires careful preparation of tender documents that must comply with regulatory requirements and the tendered items’ specifications. Later, when the bids are received, they need to be diligently evaluated for compliance. All these steps involve significant manual effort from the subject matter experts (SME). The bid evaluation alone takes several days to complete, often leading to delays and cost overruns. We present a system design that leverages LLMs to significantly reduce the bid analysis and evaluation effort. Traditional methods often struggle with extracting nuanced information and understanding complex relationships within bid documents. Our proposed system addresses these challenges by integrating LLMs for contextual understanding and retrieval-augmented generation for precise query answering. We present a comprehensive system design, highlighting its innovative features and potential for advancing information analysis tasks in tender bid evaluation. We have evaluated our system on diverse tenders data available through Indian e-procurement portals [2]. Our experiments show that our system is able to reduce the bid compliance check time from hours to seconds. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.","e-procurement; Large Language models; Retrieval-augmented generation; tender bids","Natural language processing systems; Search engines; Specifications; Bid evaluation; e-Procurement; Government procurement; Language model; Large language model; Public procurement; Retrieval-augmented generation; Tender bid; Tender documents; Work-flows; Modeling languages","Kö A.; Kotsis G.; Khalil I.; Tjoa A.M.","Springer Science and Business Media Deutschland GmbH","English","Conference paper","Final","","Scopus","2-s2.0-85202205397"
"Su W.; Tang Y.; Ai Q.; Wu Z.; Liu Y.","Su, Weihang (57271831700); Tang, Yichen (58964324800); Ai, Qingyao (57119155600); Wu, Zhijing (57195630929); Liu, Yiqun (35327597400)","57271831700; 58964324800; 57119155600; 57195630929; 35327597400","DRAGIN: Dynamic Retrieval Augmented Generation based on the Information Needs of Large Language Models","2024","Proceedings of the Annual Meeting of the Association for Computational Linguistics","1","","","12991","13013","22","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199344397&partnerID=40&md5=0e7719b291d2c7a24f021e74e385b216","Department of Computer Science and Technology, Tsinghua University, China; School of Computer Science and Technology, Beijing Institute of Technology, China","Su W., Department of Computer Science and Technology, Tsinghua University, China; Tang Y., Department of Computer Science and Technology, Tsinghua University, China; Ai Q., Department of Computer Science and Technology, Tsinghua University, China; Wu Z., School of Computer Science and Technology, Beijing Institute of Technology, China; Liu Y., Department of Computer Science and Technology, Tsinghua University, China","Dynamic retrieval augmented generation (RAG) paradigm actively decides when and what to retrieve during the text generation process of Large Language Models (LLMs). There are two key elements of this paradigm: identifying the optimal moment to activate the retrieval module (deciding when to retrieve) and crafting the appropriate query once retrieval is triggered (determining what to retrieve). However, current dynamic RAG methods fall short in both aspects. Firstly, the strategies for deciding when to retrieve often rely on static rules. Moreover, the strategies for deciding what to retrieve typically limit themselves to the LLM's most recent sentence or the last few tokens, while the LLM's information needs may span across the entire context. To overcome these limitations, we introduce a new framework, DRAGIN, i.e., Dynamic Retrieval Augmented Generation based on the Information Needs of LLMs. Our framework is specifically designed to make decisions on when and what to retrieve based on the LLM's information needs during the text generation process. We evaluate DRAGIN along with existing methods comprehensively over 4 knowledge-intensive generation datasets. Experimental results show that DRAGIN achieves superior performance on all tasks, demonstrating the effectiveness of our method. © 2024 Association for Computational Linguistics.","","Structured Query Language; Current dynamics; Dynamic retrieval; Generation method; Generation process; Key elements; Language model; Performance; Text generations; Computational linguistics","Ku L.-W.; Martins A.F.T.; Srikumar V.","Association for Computational Linguistics (ACL)","English","Conference paper","Final","","Scopus","2-s2.0-85199344397"
"Babaei Giglou H.; Taffa T.A.; Abdullah R.; Usmanova A.; Usbeck R.; D’Souza J.; Auer S.","Babaei Giglou, Hamed (57203265595); Taffa, Tilahun Abedissa (58749762200); Abdullah, Rana (58656026400); Usmanova, Aida (58783809200); Usbeck, Ricardo (43661711000); D’Souza, Jennifer (55489533700); Auer, Sören (23391879500)","57203265595; 58749762200; 58656026400; 58783809200; 43661711000; 55489533700; 23391879500","Scholarly Question Answering Using Large Language Models in the NFDI4DataScience Gateway","2024","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","14770 LNAI","","","3","18","15","0","10.1007/978-3-031-65794-8_1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202151417&doi=10.1007%2f978-3-031-65794-8_1&partnerID=40&md5=569e8eb1d5c22f4eff7b90b18ef00a2e","TIB Leibniz Information Centre for Science and Technology, Hannover, Germany; Artificial Intelligence and Explainability, Leuphana Universität Lüneburg, Lüneburg, Germany; Semantic Systems, Universität Hamburg, Hamburg, Germany","Babaei Giglou H., TIB Leibniz Information Centre for Science and Technology, Hannover, Germany; Taffa T.A., Artificial Intelligence and Explainability, Leuphana Universität Lüneburg, Lüneburg, Germany, Semantic Systems, Universität Hamburg, Hamburg, Germany; Abdullah R., Semantic Systems, Universität Hamburg, Hamburg, Germany; Usmanova A., Artificial Intelligence and Explainability, Leuphana Universität Lüneburg, Lüneburg, Germany; Usbeck R., Artificial Intelligence and Explainability, Leuphana Universität Lüneburg, Lüneburg, Germany; D’Souza J., TIB Leibniz Information Centre for Science and Technology, Hannover, Germany; Auer S., TIB Leibniz Information Centre for Science and Technology, Hannover, Germany","This paper introduces a scholarly Question Answering (QA) system on top of the NFDI4DataScience Gateway, employing a Retrieval Augmented Generation-based (RAG) approach. The NFDI4DS Gateway, as a foundational framework, offers a unified and intuitive interface for querying various scientific databases using federated search. The RAG-based scholarly QA, powered by a Large Language Model (LLM), facilitates dynamic interaction with search results, enhancing filtering capabilities and fostering a conversational engagement with the Gateway search. The effectiveness of both the Gateway and the scholarly QA system is demonstrated through experimental analysis. © The Author(s) 2024.","Federated Search; Large Language Models; NFDI4DS Gateway; Retrieval Augmented Generation; Scholarly Question Answering","Computer simulation languages; Gateways (computer networks); Query languages; Structured Query Language; Federated search; Intuitive interfaces; Language model; Large language model; NFDI4DS gateway; Question Answering; Question answering systems; Retrieval augmented generation; Scholarly question answering; Scientific database; Question answering","Rehm G.; Dietze S.; Schimmler S.; Krüger F.","Springer Science and Business Media Deutschland GmbH","English","Conference paper","Final","All Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85202151417"
"Tevissen Y.; Guetari K.; Petitpont F.","Tevissen, Yannis (58079784400); Guetari, Khalil (59144485000); Petitpont, Frederic (58078267300)","58079784400; 59144485000; 58078267300","Towards Retrieval Augmented Generation over Large Video Libraries","2024","International Conference on Human System Interaction, HSI","","","","","","","0","10.1109/HSI61632.2024.10613524","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201538969&doi=10.1109%2fHSI61632.2024.10613524&partnerID=40&md5=0c086f8117a4b1a0b9227f68a7743a2d","Moments Lab Research, Boulogne-Billancourt, France","Tevissen Y., Moments Lab Research, Boulogne-Billancourt, France; Guetari K., Moments Lab Research, Boulogne-Billancourt, France; Petitpont F., Moments Lab Research, Boulogne-Billancourt, France","Video content creators need efficient tools to repurpose content, a task that often requires complex manual or automated searches. Crafting a new video from large video libraries remains a challenge. In this paper we introduce the task of Video Library Question Answering (VLQA) through an interoperable architecture that applies Retrieval Augmented Generation (RAG) to video libraries. We propose a system that uses large language models (LLMs) to generate search queries, retrieving relevant video moments indexed by speech and visual metadata. An answer generation module then integrates user queries with this metadata to produce responses with specific video timestamps. This approach shows promise in multimedia content retrieval, and AI-assisted video content creation.  © 2024 IEEE.","retrieval augmented generation; video library question answering; video retrieval","Interoperability; Metadata; Modeling languages; Video analysis; Automated searches; Content creators; Language model; Question Answering; Retrieval augmented generation; Search queries; Video contents; Video libraries; Video library question answering; Video retrieval; Question answering","","IEEE Computer Society","English","Conference paper","Final","","Scopus","2-s2.0-85201538969"
"Ateia S.; Kruschwitz U.","Ateia, Samy (58485237800); Kruschwitz, Udo (6603505459)","58485237800; 6603505459","Can Open-Source LLMs Compete with Commercial Models? Exploring the Few-Shot Performance of Current GPT Models in Biomedical Tasks","2024","CEUR Workshop Proceedings","3740","","","78","98","20","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201624420&partnerID=40&md5=2a93df0680ab0ad5b29f2579322d3b4b","University of Regensburg, Universitätsstraße 31, Regensburg, 93053, Germany","Ateia S., University of Regensburg, Universitätsstraße 31, Regensburg, 93053, Germany; Kruschwitz U., University of Regensburg, Universitätsstraße 31, Regensburg, 93053, Germany","Commercial large language models (LLMs), like OpenAI's GPT-4 powering ChatGPT and Anthropic's Claude 3 Opus, have dominated natural language processing (NLP) benchmarks across different domains. New competing Open-Source alternatives like Mixtral 8x7B or Llama 3 have emerged and seem to be closing the gap while often offering higher throughput and being less costly to use. Open-Source LLMs can also be self-hosted, which makes them interesting for enterprise and clinical use cases where sensitive data should not be processed by third parties. We participated in the 12th BioASQ challenge, which is a retrieval augmented generation (RAG) setting, and explored the performance of current GPT models Claude 3 Opus, GPT-3.5-turbo and Mixtral 8x7b with in-context learning (zero-shot, few-shot) and QLoRa fine-tuning. We also explored how additional relevant knowledge from Wikipedia added to the context-window of the LLM might improve their performance. Mixtral 8x7b was competitive in the 10-shot setting, both with and without fine-tuning, but failed to produce usable results in the zero-shot setting. QLoRa fine-tuning and Wikipedia context did not lead to measurable performance gains. Our results indicate that the performance gap between commercial and open-source models in RAG setups exists mainly in the zero-shot setting and can be closed by simply collecting few-shot examples for domain-specific use cases. The code needed to rerun these experiments is available through GitHub*. © 2024 Copyright for this paper by its authors.","BioASQ; Few-Shot Learning; GPT-4; LLMs; QLoRa fine-tuning; Question Answering; RAG; Zero-Shot Learning","Algorithmic languages; Benchmarking; Natural language processing systems; Network security; Problem oriented languages; Zero-shot learning; BioASQ; Few-shot learning; Fine tuning; GPT-4; Language model; Large language model; Open-source; QLoRa fine-tuning; Question Answering; Retrieval augmented generation","Faggioli G.; Ferro N.; Galuscakova P.; de Herrera A.G.S.","CEUR-WS","English","Conference paper","Final","","Scopus","2-s2.0-85201624420"
"Dehbozorgi N.; Kunuku M.T.; Pouriyeh S.","Dehbozorgi, Nasrin (57192573637); Kunuku, Mourya Teja (58796084400); Pouriyeh, Seyedamin (57195966015)","57192573637; 58796084400; 57195966015","Personalized Pedagogy Through a LLM-Based Recommender System","2024","Communications in Computer and Information Science","2151 CCIS","","","63","70","7","0","10.1007/978-3-031-64312-5_8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199805197&doi=10.1007%2f978-3-031-64312-5_8&partnerID=40&md5=a33639e783d06fc2d56298af2ba8237a","College of Computing and Software Engineering, Kennesaw State University, Georgia, United States","Dehbozorgi N., College of Computing and Software Engineering, Kennesaw State University, Georgia, United States; Kunuku M.T., College of Computing and Software Engineering, Kennesaw State University, Georgia, United States; Pouriyeh S., College of Computing and Software Engineering, Kennesaw State University, Georgia, United States","The educational landscape is evolving with the integration of AI, large language models (LLMs), and generative AI, requiring educators to adopt state-of-the-art technologies and strategies in their pedagogical practices. Pedagogical Design Patterns (PDPs) have garnered attention for disseminating best practices and bridging the gap between research and practice. However, their widespread adoption is hindered by limited publicly available resources and fragmented publishing platforms. To address this, we propose leveraging LLMs to recommend pedagogical practices, drawing from existing PDPs. Our model utilizes a local knowledge base and the Retrieval Augmented Generation (RAG) framework to create query contexts for LLM prompts. Initial findings show promise, with an accuracy score of 0.83 and high relevance of recommendations to input queries. This study presents early results of our ongoing project, supporting further development of the model. The proposed system aims to empower novice educators by providing expert wisdom to enrich their teaching methodologies. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.","Educational Recommender System; Large Language Models; Pedagogical Design Patterns; Retrieval Augmented Generation","Computational linguistics; Knowledge based systems; Design Patterns; Educational recommende system; Language model; Large language model; Model-based OPC; Pedagogical design pattern; Pedagogical designs; Pedagogical practices; Retrieval augmented generation; State-of-the-art technology; Recommender systems","Olney A.M.; Chounta I.-A.; Liu Z.; Santos O.C.; Bittencourt I.I.","Springer Science and Business Media Deutschland GmbH","English","Conference paper","Final","","Scopus","2-s2.0-85199805197"
"Wang Y.; Li S.; Zheng Q.; Song L.; Li Z.; Chang A.; Li H.L.; Chen Y.","Wang, Yitu (57217597387); Li, Shiyu (57209603733); Zheng, Qilin (57209591223); Song, Linghao (56900307100); Li, Zongwang (57352041500); Chang, Andrew (57216648884); Li, Hai lHelenr (57201321031); Chen, Yiran (9737381600)","57217597387; 57209603733; 57209591223; 56900307100; 57352041500; 57216648884; 57201321031; 9737381600","NDSEARCH: Accelerating Graph-Traversal-Based Approximate Nearest Neighbor Search through Near Data Processing","2024","Proceedings - International Symposium on Computer Architecture","","","","368","381","13","0","10.1109/ISCA59077.2024.00035","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201143773&doi=10.1109%2fISCA59077.2024.00035&partnerID=40&md5=fb7e17459114183890b1ccd29902ce5f","Duke University, Durham, NC, United States; University of California, Los Angeles, CA, United States; Samsung Semiconductor, Inc., San Jose, CA, United States","Wang Y., Duke University, Durham, NC, United States; Li S., Duke University, Durham, NC, United States; Zheng Q., Duke University, Durham, NC, United States; Song L., University of California, Los Angeles, CA, United States; Li Z., Samsung Semiconductor, Inc., San Jose, CA, United States; Chang A., Samsung Semiconductor, Inc., San Jose, CA, United States; Li H.L., Duke University, Durham, NC, United States; Chen Y., Duke University, Durham, NC, United States","Approximate nearest neighbor search (ANNS) is a key retrieval technique for vector database and many data center applications, such as person re-identification and recommendation systems. It is also fundamental to retrieval augmented generation (RAG) for large language models (LLM) now. Among all the ANNS algorithms, graph-traversal-based ANNS achieves the highest recall rate. However, as the size of dataset increases, the graph may require hundreds of gigabytes of memory, exceeding the main memory capacity of a single workstation node. Although we can do partitioning and use solid-state drive (SSD) as the backing storage, the limited SSD I/O bandwidth severely degrades the performance of the system. To address this challenge, we present NDSEARCh, a hardware-software co-designed near-data processing (NDP) solution for ANNS processing. NDSeARCH consists of a novel in-storage computing architecture, namely, SEARSSD, that supports the ANNS kernels and leverages logic unit (LUN)-level parallelism inside the NAND flash chips. NDSEARCH also includes a processing model that is customized for NDP and cooperates with SearSSD. The processing model enables us to apply a two-level scheduling to improve the data locality and exploit the internal bandwidth in NDSearch, and a speculative searching mechanism to further accelerate the ANNS workload. Our results show that NDSEARCH improves the throughput by up to 31.7 ×, 14.6 ×, 7.4 × 2.9 × over CPU, GPU, a state-of-the-art SmartSSD-only design, and DeepStore, respectively. NDSEARCH also achieves two orders-of-magnitude higher energy efficiency than CPU and GPU. © 2024 IEEE.","Approximate Nearest Neighbor Search; Hardware/Software Co-Design; Near Data Processing","Bandwidth; Data handling; Energy efficiency; Memory architecture; Nearest neighbor search; Search engines; Approximate Nearest Neighbor Search; Datacenter; Graph traversals; Hardware/software codesign; Language model; Near data processing; Nearest-neighbour search algorithms; Person re identifications; Processing model; Retrieval techniques; Computation theory","","Institute of Electrical and Electronics Engineers Inc.","English","Conference paper","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85201143773"
"","","","2024 16th International Conference on Human System Interaction, HSI 2024","2024","International Conference on Human System Interaction, HSI","","","","","","477","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201563189&partnerID=40&md5=46321d53e3bc56f12ab4feafbc03cb56","","","The proceedings contain 79 papers. The topics discussed include: towards retrieval augmented generation over large video libraries; age and multimodal signals on smartphone devices; comparison of individualized and group-based machine learning approaches to predict rate of perceived exertion of professional football players; improving Alzheimer’s diagnosis using vision transformers and transfer learning; evaluating the efficacy of large language models in identifying phishing attempts; secure audio classification for voice assistants: a multi-party homomorphic approach; human pose estimation based biomechanical feature extraction for long jumps; a novel device and system for fall detection under the shower; and PredictStr: a balanced benchmark dataset for improve stroke prediction.","","","","IEEE Computer Society","English","Conference review","Final","","Scopus","2-s2.0-85201563189"
"Dobriy D.","Dobriy, Daniil (57740814800)","57740814800","Employing RAG to Create a Conference Knowledge Graph from Text","2024","CEUR Workshop Proceedings","3747","","","18","","","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203317673&partnerID=40&md5=16e9ffb1be06509864b372b91808c489","Vienna University of Economics and Business, Welthandelsplatz 1, Vienna, 1020, Austria","Dobriy D., Vienna University of Economics and Business, Welthandelsplatz 1, Vienna, 1020, Austria","In this paper, we present Semantic Observer, a platform that 1) defines a FAIR Conference Ontology for describing academic conferences, 2) presents an RAG architecture that constructs a Conference Knowledge Graph based on this ontology, 3) evaluates the architecture on a corpus of latest available CORE conference websites. The Conference Ontology models key entities such as conferences, workshops and challenges, organizer and programme committees, calls for papers and proposals as well as major deadlines and relevant topics. In the evaluation, we compare the performance of three leading Large Language Models: GPT-4 Turbo and Claude 3 Opus - in supporting the Knowledge Graph construction from text. The best-performing RAG architecture is then implemented in Semantic Observer and available in a SPARQL endpoint to make up-to-date conference information FAIR: findable, accessible, interoperable and reusable. © 2024 Copyright for this paper by its authors.","Knowledge Graph; Ontology Engineering; Research Ecosystem; Retrieval-Augmented Generation; Semantic Web; Web Crawling","Engineering research; Interoperability; Latent semantic analysis; Ontology; Reusability; Semantics; Web crawler; Academic conferences; Graph-based; Knowledge graphs; Ontology engineering; Ontology model; Ontology's; Research ecosystem; Retrieval-augmented generation; Semantic-Web; Web Crawling; Knowledge graph","Tiwari S.; Tiwari S.; Tiwari S.; Mihindukulasooriya N.; Mihindukulasooriya N.; Osborne F.; Osborne F.; Kontokostas D.; Kontokostas D.; D�Souza J.; Kejriwal M.; Pellegrino M.A.; Rula A.; Gayo J.E.L.; Cochez M.; Alam M.","CEUR-WS","English","Conference paper","Final","","Scopus","2-s2.0-85203317673"
"Xu S.; Chen M.; Chen S.","Xu, Sheng (58864578800); Chen, Mike (57222484048); Chen, Shuwen (56113818700)","58864578800; 57222484048; 56113818700","Enhancing Retrieval-Augmented Generation Models with Knowledge Graphs: Innovative Practices Through a Dual-Pathway Approach","2024","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","14880 LNAI","","","398","409","11","0","10.1007/978-981-97-5678-0_34","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201184058&doi=10.1007%2f978-981-97-5678-0_34&partnerID=40&md5=e67ee41eb47c1f53ceebb2f7242a8ad6","School of Computer Engineering, Jiangsu Second Normal University, Nanjing, 211200, China; Jiangsu Province Engineering Research Center of Basic Education Big Data Application, Nanjing, 211200, China","Xu S., School of Computer Engineering, Jiangsu Second Normal University, Nanjing, 211200, China; Chen M., School of Computer Engineering, Jiangsu Second Normal University, Nanjing, 211200, China, Jiangsu Province Engineering Research Center of Basic Education Big Data Application, Nanjing, 211200, China; Chen S., School of Computer Engineering, Jiangsu Second Normal University, Nanjing, 211200, China, Jiangsu Province Engineering Research Center of Basic Education Big Data Application, Nanjing, 211200, China","This manuscript delves into the augmentation of Retrieval-Augmented Generation (RAG) through Knowledge Graphs (KG), aimed at elevating the performance of Natural Language Processing (NLP) tasks. Despite the remarkable strides made by Large Language Models (LLMs) in the domain of language comprehension and generation, challenges persist in handling tasks requiring granular or specialized domain knowledge. To address this issue, researchers have proposed the RAG system, which enhances task performance and interpretability by amalgamating retrieval modules with LLMs. However, current RAG systems still face deficiencies in managing retrieval noise and hallucination issues. The article proposes a novel dual-pathway approach, integrating structured Knowledge Graph data into the retrieval module of RAG, to refine retrieval quality and yield more accurate and coherent outputs. Experimental validation demonstrates the efficacy of this approach in enhancing the accuracy and reliability of generated content, particularly in controlling hallucinations and bolstering the output's reliability when processing lengthy text inputs. Moreover, this methodology offers significant flexibility and customizability, facilitating adjustments in retrieval patterns and output formats according to the diverse requirements of different tasks, heralding widespread applicability in artificial intelligence-powered question-answering systems and text comprehension tasks. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2024.","Hallucination Problem; Knowledge Graph (KG); Retrieval-Augmented Generation (RAG)","Domain Knowledge; Information retrieval; Natural language processing systems; Generation systems; Hallucination problem; Innovative practices; Knowledge graph; Knowledge graphs; Language model; Natural languages; Pathway approach; Performance; Retrieval-augmented generation; Knowledge graph","Huang D.-S.; Si Z.; Chen W.","Springer Science and Business Media Deutschland GmbH","English","Conference paper","Final","","Scopus","2-s2.0-85201184058"
"","","","25th International Conference on Artificial Intelligence in Education, AIED 2024","2024","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","14829 LNAI","","","","","952","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200263593&partnerID=40&md5=d60491b82eb8db4f62cf0ed630f90b85","","","The proceedings contain 76 papers. The special focus in this conference is on Artificial Intelligence in Education. The topics include: PBChat: Enhance Student’s Problem Behavior Diagnosis with Large Language Model; Generating Situated Reflection Triggers About Alternative Solution Paths: A Case Study of Generative AI for Computer-Supported Collaborative Learning; Automated Assessment of Encouragement and Warmth in Classrooms Leveraging Multimodal Emotional Features and ChatGPT; ruffle &Riley: Insights from Designing and Evaluating a Large Language Model-Based Conversational Tutoring System; knowledge Tracing Unplugged: From Data Collection to Model Deployment; grading Documentation with Machine Learning; supporting Teaching-to-the-Curriculum by Linking Diagnostic Tests to Curriculum Goals: Using Textbook Content as Context for Retrieval-Augmented Generation with Large Language Models; VerAs: Verify Then Assess STEM Lab Reports; Evaluating the Effectiveness of Comparison Activities in a CTAT Tutor for Algorithmic Thinking; automated Long Answer Grading with RiceChem Dataset; knowledge Tracing as Language Processing: A Large-Scale Autoregressive Paradigm; Can GPT4 Answer Educational Tests? Empirical Analysis of Answer Quality Based on Question Complexity and Difficulty; understanding Gender Effects in Game-Based Learning: The Role of Self-Explanation; calcium Regulation Assignment: Alternative Styles in Successfully Learning About Biological Mechanisms; Who’s Helping Who? When Students Use ChatGPT to Engage in Practice Lab Sessions; Deep-IRT with a Temporal Convolutional Network for Reflecting Students’ Long-Term History of Ability Data; How to Teach Programming in the AI Era? Using LLMs as a Teachable Agent for Debugging; improving the Validity of Automatically Generated Feedback via Reinforcement Learning; automatic Detection of Narrative Rhetorical Categories and Elements on Middle School Written Essays; marking: Visual Grading with Highlighting Errors and Annotating Missing Bits; Jill Watson: A Virtual Teaching Assistant Powered by ChatGPT; evaluating the Design Features of an Intelligent Tutoring System for Advanced Mathematics Learning; anticipating Student Abandonment and Failure: Predictive Models in High School Settings.","","","Olney A.M.; Chounta I.-A.; Liu Z.; Santos O.C.; Bittencourt I.I.","Springer Science and Business Media Deutschland GmbH","English","Conference review","Final","","Scopus","2-s2.0-85200263593"
"Xu S.; Kurisummoottil Thomas C.; Hashash O.; Muralidhar N.; Saad W.; Ramakrishnan N.","Xu, Shengzhe (57207757414); Kurisummoottil Thomas, Christo (57203899160); Hashash, Omar (57226836400); Muralidhar, Nikhil (57188815395); Saad, Walid (57203259001); Ramakrishnan, Naren (35507966200)","57207757414; 57203899160; 57226836400; 57188815395; 57203259001; 35507966200","Large Multi-Modal Models (LMMs) as Universal Foundation Models for AI-Native Wireless Systems","2024","IEEE Network","38","5","","10","20","10","1","10.1109/MNET.2024.3427313","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199115312&doi=10.1109%2fMNET.2024.3427313&partnerID=40&md5=c436c47d0b1614a978735df0f03209fd","Virginia Tech, Department of Computer Science, Arlington, 22203, VA, United States; Virginia Tech, Bradley Department of Electrical and Computer Engineering, Arlington, 22203, VA, United States; Stevens Institute of Technology, Department of Computer Science, Hoboken, 07030, NJ, United States","Xu S., Virginia Tech, Department of Computer Science, Arlington, 22203, VA, United States; Kurisummoottil Thomas C., Virginia Tech, Bradley Department of Electrical and Computer Engineering, Arlington, 22203, VA, United States; Hashash O., Virginia Tech, Bradley Department of Electrical and Computer Engineering, Arlington, 22203, VA, United States; Muralidhar N., Stevens Institute of Technology, Department of Computer Science, Hoboken, 07030, NJ, United States; Saad W., Virginia Tech, Bradley Department of Electrical and Computer Engineering, Arlington, 22203, VA, United States; Ramakrishnan N., Virginia Tech, Department of Computer Science, Arlington, 22203, VA, United States","Large language models (LLMs) and foundation models have been recently touted as a game-changer for 6 G systems. However, recent efforts on LLMs for wireless networks are limited to a direct application of existing language models that were designed for natural language processing (NLP) applications. To address this challenge and create wireless-centric foundation models, this paper presents a comprehensive vision on how to design universal foundation models that are tailored towards the unique needs of next-generation wireless systems, thereby paving the way towards the deployment of artificial intelligence (AI)-native networks. Diverging from NLP-based foundation models, the proposed framework promotes the design of large multi-modal models (LMMs) fostered by three key capabilities: 1) processing of multi-modal sensing data, 2) grounding of physical symbol representations in real-world wireless systems using causal reasoning and retrieval-augmented generation (RAG), and 3) enabling instructibility from the wireless environment feedback to facilitate dynamic network adaptation thanks to logical and mathematical reasoning facilitated by neuro-symbolic AI. In essence, these properties enable the proposed LMM framework to build universal capabilities that cater to various cross-layer networking tasks and alignment of intents across different domains. Preliminary results from experimental evaluation demonstrate the efficacy of grounding using RAG in LMMs, and showcase the alignment of LMMs with wireless system designs. Furthermore, the enhanced rationale exhibited in the responses to mathematical questions by LMMs, compared to vanilla LLMs, demonstrates the logical and mathematical reasoning capabilities inherent in LMMs. Building on those results, we present a sequel of open questions and challenges for LMMs. We then conclude with a set of recommendations that ignite the path towards LMM-empowered AI-native systems.  © 1986-2012 IEEE.","AI-native; Alignment; Grounding; Instructibility; Large multi-modal models; Universal foundation model","Alignment; Artificial intelligence; Computational linguistics; Natural language processing systems; Network layers; Search engines; Artificial intelligence-native; Cognition; Foundation models; Instructibility; Large multi-modal model; Modal models; Multi-modal; Symbol; Universal foundation model; Wireless communications; Wireless sensor networks","","Institute of Electrical and Electronics Engineers Inc.","English","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85199115312"
"Arora C.; Grundy J.; Puli L.; Layton N.","Arora, Chetan (55848706400); Grundy, John (7102156137); Puli, Louise (57224370191); Layton, Natasha (24402578200)","55848706400; 7102156137; 57224370191; 24402578200","Towards Standards-Compliant Assistive Technology Product Specifications via LLMs","2024","Proceedings - 32nd IEEE International Requirements Engineering Conference Workshops, REW 2024","","","","385","389","4","0","10.1109/REW61692.2024.00060","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203105153&doi=10.1109%2fREW61692.2024.00060&partnerID=40&md5=cc36becb262d313e84ee228f2520549e","Monash University, Faculty of It, Melbourne, Australia; Rehabilitation, Ageing and Independent Living Research Centre (RAIL), Monash University, Melbourne, Australia","Arora C., Monash University, Faculty of It, Melbourne, Australia; Grundy J., Monash University, Faculty of It, Melbourne, Australia; Puli L., Rehabilitation, Ageing and Independent Living Research Centre (RAIL), Monash University, Melbourne, Australia; Layton N., Rehabilitation, Ageing and Independent Living Research Centre (RAIL), Monash University, Melbourne, Australia","In the rapidly evolving field of assistive technology (AT), ensuring that products meet national and international standards is essential for user safety, efficacy, and accessibility. In this vision paper, we introduce CompliAT, a pioneering framework designed to streamline the compliance process of AT product specifications with these standards through the innovative use of Large Language Models (LLMs). CompliAT ad-dresses three critical tasks: checking terminology consistency, classifying products according to standards, and tracing key product specifications to standard requirements. We tackle the challenge of terminology consistency to ensure that the language used in product specifications aligns with relevant standards, reducing misunderstandings and non-compliance risks. We propose a novel approach for product classification, leveraging a retrieval-augmented generation model to accurately categorize AT products aligning to international standards, despite the sparse availability of training data. Finally, CompliAT implements a traceability and compliance mechanism from key product specifications to standard requirements, ensuring all aspects of an AT product are thoroughly vetted against the standards. By semi-automating these processes, CompliAT aims to significantly reduce the time and effort required for AT product standards compliance and uphold quality and safety standards. We outline our planned implementation and evaluation for CompliAT.  © 2024 IEEE.","Assistive Technology; Large Language Models (LLMs); Product Specifications; Regulatory Compliance; Retrieval Augmented Generation (RAG)","Regulatory compliance; Specifications; Terminology; Assistive technology; Critical tasks; International standards; Language model; Large language model; National standard; Product specifications; Retrieval augmented generation; Standard requirements; Technology products; Assistive technology","Liebel G.; Hadar I.; Spoletini P.","Institute of Electrical and Electronics Engineers Inc.","English","Conference paper","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85203105153"
"Hennekeuser D.; Vaziri D.D.; Golchinfar D.; Schreiber D.; Stevens G.","Hennekeuser, Darius (58924626600); Vaziri, Daryoush Daniel (56017513000); Golchinfar, David (57211144596); Schreiber, Dirk (56016769800); Stevens, Gunnar (8908623500)","58924626600; 56017513000; 57211144596; 56016769800; 8908623500","Enlarged Education – Exploring the Use of Generative AI to Support Lecturing in Higher Education","2024","International Journal of Artificial Intelligence in Education","","","","","","","0","10.1007/s40593-024-00424-y","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200659514&doi=10.1007%2fs40593-024-00424-y&partnerID=40&md5=daf7c56d8e4d8a44e5695c41fbf56d3d","University of Applied Sciences Bonn-Rhein-Sieg, Sankt Augustin, Germany; University of Siegen, Siegen, Germany","Hennekeuser D., University of Applied Sciences Bonn-Rhein-Sieg, Sankt Augustin, Germany; Vaziri D.D., University of Applied Sciences Bonn-Rhein-Sieg, Sankt Augustin, Germany; Golchinfar D., University of Applied Sciences Bonn-Rhein-Sieg, Sankt Augustin, Germany; Schreiber D., University of Applied Sciences Bonn-Rhein-Sieg, Sankt Augustin, Germany; Stevens G., University of Siegen, Siegen, Germany","Large Language Models (LLMs) are rapidly gaining attention across the open-source and commercial fields, bolstered by their constantly growing capabilities. While such models have a vast array of applications, their integration into higher education—as supportive tools for lecturers—has been largely unexplored. Exploring this area entails understanding the specific requirements and viewpoints of higher education lecturers. We developed an LLM-based assistant with retrieval augmented generation (RAG) capabilities and lecturing materials as its data foundation. For the design of the system, we followed a user-centered design approach. Subsequently, we conducted user studies and qualitative interviews with university lecturers. Our findings suggest that lecturers are ready to use LLMs with RAG in higher education under the condition that such systems are reliable, explainable, controllable, and trustworthy. We discuss design implications that designers of LLM-based systems should consider when developing such tools for higher education. This paper adds to the scarce existing studies on the usage of LLMs in educational contexts. © International Artificial Intelligence in Education Society 2024.","AI; Education; Human-centered Design; Large Language Models; Natural Language Processing; Semantic Search","Artificial intelligence; Computational linguistics; Natural language processing systems; Semantic Web; User centered design; High educations; Human-centred designs; Language model; Language processing; Large language model; Natural language processing; Natural languages; Open-source; Semantic search; Supportive tools; Semantics","","Springer","English","Article","Article in press","","Scopus","2-s2.0-85200659514"
"Šarčević A.; Tomičić I.; Merlin A.; Horvat M.","Šarčević, Antonia (59214268100); Tomičić, Ivan (59214297800); Merlin, Andrija (59214268200); Horvat, Marko (26660715200)","59214268100; 59214297800; 59214268200; 26660715200","Enhancing Programming Education with Open-Source Generative AI Chatbots","2024","2024 47th ICT and Electronics Convention, MIPRO 2024 - Proceedings","","","","2051","2056","5","0","10.1109/MIPRO60963.2024.10569736","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198220739&doi=10.1109%2fMIPRO60963.2024.10569736&partnerID=40&md5=a03740e974d3a484cd4eaa2b1a8e60d6","University Of Zagreb, Faculty Of Electrical Engineering And Computing, Department Of Applied Computing, Zagreb, Croatia","Šarčević A., University Of Zagreb, Faculty Of Electrical Engineering And Computing, Department Of Applied Computing, Zagreb, Croatia; Tomičić I., University Of Zagreb, Faculty Of Electrical Engineering And Computing, Department Of Applied Computing, Zagreb, Croatia; Merlin A., University Of Zagreb, Faculty Of Electrical Engineering And Computing, Department Of Applied Computing, Zagreb, Croatia; Horvat M., University Of Zagreb, Faculty Of Electrical Engineering And Computing, Department Of Applied Computing, Zagreb, Croatia","This paper describes the development of an Open-Source Generative AI Chatbot, utilizing free Large Language Models (LLM) to enrich the student learning experience for a university course in 'Introduction to Programming'. The article aims to provide a step-by-step guide for selecting, fine-tuning, and evaluating available models. As a first step in choosing the appropriate LLM, which provides the most accurate responses while not requiring excessive computing power, the article will cover a discussion of the advantages and disadvantages of local vs. cloud-available models. After selecting a few promising models, the next stage includes fine-tuning LLMs to answer domain-specific questions using a dataset containing essential rules, guidelines, and explanatory content regarding the subject. The crucial aspect of selecting a model was evaluating answers, and in this context, both human and automatic evaluation techniques will be presented. Finally, it is possible to enhance the model performance and accuracy by incorporating Retrieval-Augmented Generation (RAG) techniques and exploring the influence of various factors, such as different vector databases, model temperatures, maximum token lengths, prompt templates, embeddings, repetition penalties, and chunking sizes. Our results show that chatbots have significant potential to improve academic support and learning efficiency, as well as personalized education in general.  © 2024 IEEE.","chatbots; digital learning; education; generative models; large language models; natural language processing","Computational linguistics; Computing power; E-learning; Education computing; Learning systems; Open source software; Chatbots; Digital-learning; Fine tuning; Generative model; Language model; Language processing; Large language model; Natural language processing; Natural languages; Open-source; Natural language processing systems","Babic S.; Car Z.; Cicin-Sain M.; Cisic D.; Ergovic P.; Grbac T.G.; Gradisnik V.; Gros S.; Jokic A.; Jovic A.; Jurekovic D.; Katulic T.; Koricic M.; Mornar V.; Petrovic J.; Skala K.; Skvorc D.; Sruk V.; Svaco M.; Tijan E.; Vrcek N.; Vrdoljak B.","Institute of Electrical and Electronics Engineers Inc.","English","Conference paper","Final","","Scopus","2-s2.0-85198220739"
"Řehulka E.; Šuppa M.","Řehulka, Erik (58682918700); Šuppa, Marek (57220026093)","58682918700; 57220026093","RAG Meets Detox: Enhancing Text Detoxification Using Open Large Language Models with Retrieval Augmented Generation","2024","CEUR Workshop Proceedings","3740","","","3021","3031","10","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201614999&partnerID=40&md5=832380a21dc27483fce0ccfb200ec746","Comenius University, Bratislava, Slovakia; Cisco Systems, United States","Řehulka E., Comenius University, Bratislava, Slovakia; Šuppa M., Comenius University, Bratislava, Slovakia, Cisco Systems, United States","In this work we present our solution at the Multilingual Text Detoxification 2024 task, whose objective is to take toxic text and convert into one that conveys the same meaning without containing any toxicity. Our approach utilizes open Large Language Models extended with dynamic prompt creation combined with Retrieval Augmented Generation. The evaluation results show that despite its simplicity, our method has the potential to provide competitive results, as evidenced by both the automatic and manual evaluation executed by the task organizers. Overall, our approach ranked 5th in the manual evaluation, with our best-performing language, German, even surpassing the human reference. © 2024 Copyright for this paper by its authors.","Llama3; LLM; PAN 2024; Retrieval Augmented Generation; text detoxification; toxic text","Evaluation results; Language model; Llama3; LLM; Multilingual texts; PAN 2024; Retrieval augmented generation; Text detoxification; Toxic text; Detoxification","Faggioli G.; Ferro N.; Galuscakova P.; de Herrera A.G.S.","CEUR-WS","English","Conference paper","Final","","Scopus","2-s2.0-85201614999"
"Yan L.; Zhao L.; Echeverria V.; Jin Y.; Alfredo R.; Li X.; Gaševi’c D.; Martinez-Maldonado R.","Yan, Lixiang (57222734702); Zhao, Linxuan (57485829100); Echeverria, Vanessa (56016639400); Jin, Yueqiao (58165770400); Alfredo, Riordan (57485285700); Li, Xinyu (57219407940); Gaševi’c, Dragan (8549413500); Martinez-Maldonado, Roberto (55255183300)","57222734702; 57485829100; 56016639400; 58165770400; 57485285700; 57219407940; 8549413500; 55255183300","VizChat: Enhancing Learning Analytics Dashboards with Contextualised Explanations Using Multimodal Generative AI Chatbots","2024","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","14830 LNAI","","","180","193","13","0","10.1007/978-3-031-64299-9_13","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200213627&doi=10.1007%2f978-3-031-64299-9_13&partnerID=40&md5=6683146504130e2c6091bdb9badc406a","Monash University, Clayton, 3108, VIC, Australia","Yan L., Monash University, Clayton, 3108, VIC, Australia; Zhao L., Monash University, Clayton, 3108, VIC, Australia; Echeverria V., Monash University, Clayton, 3108, VIC, Australia; Jin Y., Monash University, Clayton, 3108, VIC, Australia; Alfredo R., Monash University, Clayton, 3108, VIC, Australia; Li X., Monash University, Clayton, 3108, VIC, Australia; Gaševi’c D., Monash University, Clayton, 3108, VIC, Australia; Martinez-Maldonado R., Monash University, Clayton, 3108, VIC, Australia","Learning analytics dashboards (LADs) serve as pivotal tools in transforming complex learner data into actionable insights for educational stakeholders. Despite their potential, the effectiveness of LADs, particularly the visualisations they utilise, has been under scrutiny. Concerns have been raised about their potential to cause cognitive overload, especially for users with limited data visualisation literacy, thus questioning their practical utility in supporting decision-making and reflective practices. This tool paper tackles these concerns by introducing VizChat, an open-sourced, prototype chatbot designed to augment LADs by providing contextualised, AI-generated explanations for visualisations. Developed on multimodal generative AI (GPT-4V) and retrieval-augmented generation (Langchain), VizChat offers on-demand, contextually relevant explanations that aim to improve user comprehension without overwhelming them with excessive information. Through a case study, we demonstrated VizChat’s diverse capabilities, including actively seeking clarifications on ambiguous queries, personalising responses based on previous user interactions, providing contextually relevant explanations of specific visualisations, integrating information from multiple visualisations for a comprehensive response, and offering detailed insights into the data collection and analysis processes behind each visualisation. Such efforts support the paradigm shift from exploratory to explanatory approaches in LADs, highlighting the potential of integrating generative AI and chatbots to enhance the educational value of learning analytics. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.","Chatbots; Generative Artificial Intelligence; GPT; Learning Analytics; LLM; Multimodal; Visualisation","Data visualization; Decision making; Metadata; Chatbots; Cognitive overload; Decision-making practices; Generative artificial intelligence; GPT; Learning analytic; Limited data; LLM; Multi-modal; Reflective practise; Visualization","Olney A.M.; Chounta I.-A.; Liu Z.; Santos O.C.; Bittencourt I.I.","Springer Science and Business Media Deutschland GmbH","English","Conference paper","Final","","Scopus","2-s2.0-85200213627"
"Patil P.; Mathews J.; James J.; Patil A.; Rukhande S.","Patil, Pranav (59324148700); Mathews, Justin (59323514100); James, Joel (59323830100); Patil, Aditya (59323674200); Rukhande, Smita (57218211229)","59324148700; 59323514100; 59323830100; 59323674200; 57218211229","From Data to Dialogue: Building a Domain-Agnostic Conversational Question Answering System","2024","2024 IEEE International Conference on Information Technology, Electronics and Intelligent Communication Systems, ICITEICS 2024","","","","","","","0","10.1109/ICITEICS61368.2024.10625247","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203705681&doi=10.1109%2fICITEICS61368.2024.10625247&partnerID=40&md5=5211f6559517db2030ad42da37619731","Fr. C. Rodrigues Institute of Technology, Department of Computer Engineering, Navi Mumbai, India","Patil P., Fr. C. Rodrigues Institute of Technology, Department of Computer Engineering, Navi Mumbai, India; Mathews J., Fr. C. Rodrigues Institute of Technology, Department of Computer Engineering, Navi Mumbai, India; James J., Fr. C. Rodrigues Institute of Technology, Department of Computer Engineering, Navi Mumbai, India; Patil A., Fr. C. Rodrigues Institute of Technology, Department of Computer Engineering, Navi Mumbai, India; Rukhande S., Fr. C. Rodrigues Institute of Technology, Department of Computer Engineering, Navi Mumbai, India","In the realm of natural language processing (NLP), the quest for domain-specific question answering has been a focal point, emphasizing the precise extraction of factual information from designated knowledge sources in response to targeted inquiries. This project introduces a versatile, adaptable open-domain question answering system primed for seamless integration across diverse sectors, including educational institutions, e-commerce platforms, and healthcare portals. Leveraging the prowess of BERT and TAPAS, augmented with RAG (Retrieval-Augmented Generation), our system offers a holistic solution catering to varied information retrieval needs. Through fine-tuning on domain-specific datasets, both BERT and TAPAS capitalize on their respective strengths: BERT's contextual understanding and TAPAS's structured reasoning capabilities. The ensemble model dynamically selects the most suitable approach for each query, ensuring flexibility in handling diverse linguistic nuances and query types. Moreover, the system integrates language translation and voice output features to further enhance its adaptability. Evaluation on benchmark datasets reaffirms the system's efficacy in delivering precise and coherent responses, underscoring its potential as a multifaceted tool for enhancing user interaction and information retrieval across educational, ecommerce, healthcare, and other domains.  © 2024 IEEE.","BERT; Googletrans; LangChain; Large Language Model; TAPAS","Linguistics; Natural language processing systems; Query languages; Structured Query Language; Translation (languages); BERT; Domain agnostics; Domain specific; Googletrans; Langchain; Language model; Large language model; Natural languages; Question answering systems; TAPAS; Question answering","","Institute of Electrical and Electronics Engineers Inc.","English","Conference paper","Final","","Scopus","2-s2.0-85203705681"
"Xiong H.; Bian J.; Li Y.; Li X.; Du M.; Wang S.; Yin D.; Helal S.","Xiong, Haoyi (55362625600); Bian, Jiang (57206770577); Li, Yuchen (57916817100); Li, Xuhong (57204712975); Du, Mengnan (57203397578); Wang, Shuaiqiang (22636318500); Yin, Dawei (35759826200); Helal, Sumi (6602561979)","55362625600; 57206770577; 57916817100; 57204712975; 57203397578; 22636318500; 35759826200; 6602561979","When Search Engine Services meet Large Language Models: Visions and Challenges","2024","IEEE Transactions on Services Computing","","","","1","23","22","1","10.1109/TSC.2024.3451185","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202743813&doi=10.1109%2fTSC.2024.3451185&partnerID=40&md5=6f1778bcede54869113073fdd9dcc7d0","Baidu, Inc., Beijing, China; New Jersey Institute of Technology, Newark, NJ; University of Bologna, Italy","Xiong H., Baidu, Inc., Beijing, China; Bian J., Baidu, Inc., Beijing, China; Li Y., Baidu, Inc., Beijing, China; Li X., Baidu, Inc., Beijing, China; Du M., New Jersey Institute of Technology, Newark, NJ; Wang S., Baidu, Inc., Beijing, China; Yin D., Baidu, Inc., Beijing, China; Helal S., University of Bologna, Italy","Combining Large Language Models (LLMs) with search engine services marks a significant shift in the field of services computing, opening up new possibilities to enhance how we search for and retrieve information, understand content, and interact with internet services. This paper conducts an in-depth examination of how integrating LLMs with search engines can mutually benefit both technologies. We focus on two main areas: using search engines to improve LLMs (Search4LLM) and enhancing search engine functions using LLMs (LLM4Search). For Search4LLM, we investigate how search engines can provide diverse high-quality datasets for pre-training of LLMs, how they can use the most relevant documents to help LLMs learn to answer queries more accurately, how training LLMs with Learning-To-Rank (LTR) tasks can enhance their ability to respond with greater precision, and how incorporating recent search results can make LLM-generated content more accurate and current. In terms of LLM4Search, we examine how LLMs can be used to summarize content for better indexing by search engines, improve query outcomes through optimization, enhance the ranking of search results by analyzing document relevance, and help in annotating data for learning-to-rank tasks in various learning contexts. However, this promising integration comes with its challenges, which include addressing potential biases and ethical issues in training models, managing the computational and other costs of incorporating LLMs into search services, and continuously updating LLM training with the ever-changing web content. We discuss these challenges and chart out required research directions to address them. We also discuss broader implications for service computing, such as scalability, privacy concerns, and the need to adapt search engine architectures for these advanced models. IEEE","Accuracy; and Retrieve-Augmented Generation (RAG); Chatbots; Indexing; Large Language Models (LLMs); Learning-to-Rank (LTR); Search Engines; Search engines; Service computing; Training; Transformers","Indexing (materials working); Indexing (of information); Learning to rank; Metadata; Modeling languages; Online searching; Query languages; Query processing; Accuracy; And retrieve-augmented generation; Chatbots; Indexing; Internet-services; Language model; Large language model; Learning-to-rank; Service computing; Transformer; Search engines","","Institute of Electrical and Electronics Engineers Inc.","English","Article","Article in press","All Open Access; Green Open Access","Scopus","2-s2.0-85202743813"
"Mamalis M.E.; Kalampokis E.; Fitsilis F.; Theodorakopoulos G.; Tarabanis K.","Mamalis, Marios Evangelos (58510212300); Kalampokis, Evangelos (24766142200); Fitsilis, Fotios (57195073116); Theodorakopoulos, Georgios (58831467300); Tarabanis, Konstantinos (6603842415)","58510212300; 24766142200; 57195073116; 58831467300; 6603842415","A Large Language Model Agent Based Legal Assistant for Governance Applications","2024","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","14841 LNCS","","","286","301","15","0","10.1007/978-3-031-70274-7_18","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202607024&doi=10.1007%2f978-3-031-70274-7_18&partnerID=40&md5=3f7afbb49068ef42d2bf229112cd6964","Information Systems Laboratory, University of Macedonia, Thessaloniki, 54636, Greece; Department for Scientific Documentation and Supervision, Hellenic Parliament, Athens, Greece; Hellenic State Legal Council, Athens, Greece","Mamalis M.E., Information Systems Laboratory, University of Macedonia, Thessaloniki, 54636, Greece; Kalampokis E., Information Systems Laboratory, University of Macedonia, Thessaloniki, 54636, Greece; Fitsilis F., Department for Scientific Documentation and Supervision, Hellenic Parliament, Athens, Greece; Theodorakopoulos G., Hellenic State Legal Council, Athens, Greece; Tarabanis K., Information Systems Laboratory, University of Macedonia, Thessaloniki, 54636, Greece","Large Language Models (LLMs) have gained significant traction, primarily due to their potential disruptive influence across industries reliant on natural language processing . Governance stands out as one such sector. Notably, there has been a surge in research activity surrounding the implications of LLMs in deciphering complex legal corpora. This research offers substantial assistance to various stakeholders, including decision-makers, administrators, and citizens. This article focuses on the design and implementation of an LLM-based legal assistant tailored for interacting with legal resources. To achieve this, a real-world scenario has been chosen, incorporating models GPT3.5 and GPT4 as the LLMs, a well-defined legal corpus comprising European Union (EU) legislation and case law concerning the General Data Protection Regulation (GDPR), alongside a series of reference legal queries of varying complexity. Retrieval Augmented Generation (RAG) as well as agent methodologies are employed to seamlessly integrate the LLMs’ functionalities with the customized dataset. The results appear to be promising, as the system managed to correctly address the majority of the legal queries, though with variable precision. Expectantly, the complexity of the queries severely impacted the quality of the outcome. © IFIP International Federation for Information Processing 2024.","Artificial intelligence; GDPR; Large language model; Law making; Legal assistant; Policy making; Public administration","Decision making; Natural language processing systems; Query languages; Agent based; General data protection regulations; Language model; Large language model; Law making; Legal assistant; Legal corpus; Legal queries; Model agents; Policy making; Public administration","Janssen M.; Crompvoets J.; Gil-Garcia J.R.; Lee H.; Lindgren I.; Nikiforova A.; Viale Pereira G.","Springer Science and Business Media Deutschland GmbH","English","Conference paper","Final","","Scopus","2-s2.0-85202607024"
"Murthy K.V.S.S.; Rajanikanth J.; Shiva Shankar R.; Ravi Swaroop C.H.; Ravibabu D.","Murthy, K.V.S.S. (58810333100); Rajanikanth, J. (55604779200); Shiva Shankar, R. (55372511900); Ravi Swaroop, C.H. (57203923024); Ravibabu, D. (9736208900)","58810333100; 55604779200; 55372511900; 57203923024; 9736208900","GenerativeAI in Personal Dairy Information Retrieval for Criminal Investigation","2024","Algorithms in Advanced Artificial Intelligence","","","","507","513","6","0","10.1201/9781003529231-76","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199828047&doi=10.1201%2f9781003529231-76&partnerID=40&md5=2dbbba07af42c7d762bfcaf61a44636e","Dept of Computer Science and Engineering, Sagi Ramakrishnam Raju Engineering College, Andhra Pradesh, Bhimavaram, India","Murthy K.V.S.S., Dept of Computer Science and Engineering, Sagi Ramakrishnam Raju Engineering College, Andhra Pradesh, Bhimavaram, India; Rajanikanth J., Dept of Computer Science and Engineering, Sagi Ramakrishnam Raju Engineering College, Andhra Pradesh, Bhimavaram, India; Shiva Shankar R., Dept of Computer Science and Engineering, Sagi Ramakrishnam Raju Engineering College, Andhra Pradesh, Bhimavaram, India; Ravi Swaroop C.H., Dept of Computer Science and Engineering, Sagi Ramakrishnam Raju Engineering College, Andhra Pradesh, Bhimavaram, India; Ravibabu D., Dept of Computer Science and Engineering, Sagi Ramakrishnam Raju Engineering College, Andhra Pradesh, Bhimavaram, India","Criminal investigation involves studying facts for trials, using forensic science techniques. A wide-ranging criminal investigation involves various methods such as searching, interviews, interrogations, evidence collection, and preservation. During the investigation of specific crimes, recent demographic changes have been observed, indicating a higher priority for their investigation. This paper explores a crime investigation using Generative AI and Information Retrieval, focusing on Personal Dairy and its impact on crime involvement probability Using Bayes Belief Network Classification. Retriever Augmented Generation (RAG) is an AI framework that utilizes external knowledge to provide accurate and current crime information for large language models (LLMs) and offer users insights into their generative process. © 2024 Taylor & Francis Group, London.","Artificial Intelligence; Bayes Belief Network; Crime Investigation; LLM; Retriever Augmented Generation etc","","","CRC Press","English","Book chapter","Final","","Scopus","2-s2.0-85199828047"
"Liao R.; Jia X.; Li Y.; Ma Y.; Tresp V.","Liao, Ruotong (57566178900); Jia, Xu (58664390500); Li, Yangzhe (58885785200); Ma, Yunpu (57194413081); Tresp, Volker (6603805670)","57566178900; 58664390500; 58885785200; 57194413081; 6603805670","GenTKG: Generative Forecasting on Temporal Knowledge Graph with Large Language Models","2024","Findings of the Association for Computational Linguistics: NAACL 2024 - Findings","","","","4303","4317","14","1","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197880327&partnerID=40&md5=52a37ef070b0c5dc4e1de6a823271050","LMU Munich, Germany; Munich Center for Machine Learning (MCML), Germany; Technical University of Munich, Germany; Siemens AG, Germany","Liao R., LMU Munich, Germany, Munich Center for Machine Learning (MCML), Germany; Jia X., Technical University of Munich, Germany; Li Y., Technical University of Munich, Germany; Ma Y., LMU Munich, Germany, Munich Center for Machine Learning (MCML), Germany, Siemens AG, Germany; Tresp V., LMU Munich, Germany, Munich Center for Machine Learning (MCML), Germany","The rapid advancements in large language models (LLMs) have ignited interest in the temporal knowledge graph (tKG) domain, where conventional embedding-based and rule-based methods dominate. The question remains open of whether pre-trained LLMs can understand structured temporal relational data and replace them as the foundation model for temporal relational forecasting. Therefore, we bring temporal knowledge forecasting into the generative setting. However, challenges occur in the huge chasms between complex temporal graph data structure and sequential natural expressions LLMs can handle, and between the enormous data sizes of tKGs and heavy computation costs of finetuning LLMs. To address these challenges, we propose a novel retrieval-augmented generation framework named GenTKG combining a temporal logical rule-based retrieval strategy and few-shot parameter-efficient instruction tuning to solve the above challenges, respectively. Extensive experiments have shown that GenTKG outperforms conventional methods of temporal relational forecasting with low computation resources using extremely limited training data as few as 16 samples. GenTKG also highlights remarkable cross-domain generalizability with outperforming performance on unseen datasets without re-training, and in-domain generalizability regardless of time split in the same dataset. Our work reveals the huge potential of LLMs in the tKG domain and opens a new frontier for generative forecasting on tKGs. The code and data are released here: https://github.com/mayhugotong/GenTKG. © 2024 Association for Computational Linguistics.","","Computational linguistics; Forecasting; Computation costs; Data size; Embeddings; Foundation models; Knowledge graphs; Language model; Relational data; Rule-based method; Temporal graphs; Temporal knowledge; Knowledge graph","Duh K.; Gomez H.; Bethard S.","Association for Computational Linguistics (ACL)","English","Conference paper","Final","","Scopus","2-s2.0-85197880327"
"Leng Z.-J.; Li B.-T.; Zheng C.-G.","Leng, Zhi-Jie (8390488300); Li, Bao-Tai (59234017400); Zheng, Cheng-Gong (59145689700)","8390488300; 59234017400; 59145689700","Evaluation and Path of High-quality Development of New Agricultural Business and Service Entities in the Raw Grain Industry Chain; [原粮产业链中新型农业经营服务主体高质量发展评价及路径]","2024","Science and Technology of Cereals, Oils and Foods","32","4","","218","226","8","0","10.16210/j.cnki.1007-7561.2024.04.027","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199491739&doi=10.16210%2fj.cnki.1007-7561.2024.04.027&partnerID=40&md5=57a2e27d1f58e0a3b719e8a3db9b8db4","College of Economics and Management, Heilongjiang Bayi Agricultural University, Heilongjiang, Daqing, 163319, China","Leng Z.-J., College of Economics and Management, Heilongjiang Bayi Agricultural University, Heilongjiang, Daqing, 163319, China; Li B.-T., College of Economics and Management, Heilongjiang Bayi Agricultural University, Heilongjiang, Daqing, 163319, China; Zheng C.-G., College of Economics and Management, Heilongjiang Bayi Agricultural University, Heilongjiang, Daqing, 163319, China","The important path for the high-quality development of the raw grain industry chain in the three provinces of Northeast China is for the new agricultural business entities introduce modern production factors into grain farmers through socialized services. Therefore, it is urgent to evaluate whether there are demonstration entities with high-quality development among these new agricultural business and service entities, and to make clear their high-quality development path to lead other new agricultural management and service entities in serving small grain farmers through socialized services. In this regard, an evaluation model of high-quality development of agricultural business and service entities was constructed, and was characterized by considering the introduction of socialized services of modern production factors, setting the target values of all indicators to fully realize high-quality development based on policy objectives, and counting them into weights. The evaluation results showed that socialized service companies in the basic and full-scale realization stages of high-quality development can be used as demonstration entities of high-quality development. They had the ability to lead other new agricultural business and service entities to apply modern production factors, and provide full-process services and digitally empower service contents. It is concluded that the key path for the above-mentioned demonstration socialized service companies, which could lead other new agricultural business and service entities and serve small grain farmers, is to establish a socialized service platform. This platform can introduce large language model and retrieval-augmented generation technology to intelligently generate socialized service schemes. © 2024 Science and Technology of Cereals,Oils and Foods Magazine Agency. All rights reserved.","entropy weight method; grain farmers; high-quality development; new agricultural business and service entities; the raw grain industry chain","","","Science and Technology of Cereals,Oils and Foods Magazine Agency","Chinese","Article","Final","","Scopus","2-s2.0-85199491739"
"Miladi F.; Psyché V.; Lemire D.","Miladi, Fatma (57198347276); Psyché, Valéry (22433359100); Lemire, Daniel (10238969400)","57198347276; 22433359100; 10238969400","Leveraging GPT-4 for Accuracy in Education: A Comparative Study on Retrieval-Augmented Generation in MOOCs","2024","Communications in Computer and Information Science","2150 CCIS","","","427","434","7","0","10.1007/978-3-031-64315-6_40","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200245298&doi=10.1007%2f978-3-031-64315-6_40&partnerID=40&md5=8c20520fcfab761e4d53a2a1ef790039","TELUQ University, 5800 rue Saint-Denis, Montreal, H2S 3L5, QC, Canada","Miladi F., TELUQ University, 5800 rue Saint-Denis, Montreal, H2S 3L5, QC, Canada; Psyché V., TELUQ University, 5800 rue Saint-Denis, Montreal, H2S 3L5, QC, Canada; Lemire D., TELUQ University, 5800 rue Saint-Denis, Montreal, H2S 3L5, QC, Canada","Large Language Models (LLMs), such as Generative Pretrained Transformers (GPTs), have demonstrated remarkable capabilities in natural language processing (NLP). However, these models often encounter challenges such as inaccuracies and hallucinations, which can undermine their utility. Retrieval-Augmented Generation (RAG) has emerged as a promising approach to enhance model accuracy and reliability by integrating external databases. This study investigates the use of RAG to improve the accuracy of GPT models in educational settings, particularly within the realm of Massive Open Online Courses (MOOCs). Through a comparative analysis of various GPT model iterations, we observed a significant improvement in accuracy, increasing from 60% with GPT-3.5 to 80% using the RAG-augmented GPT-4. This enhancement highlights the considerable potential of RAG-augmented GPT models in improving the accuracy of content generation. Such enhanced accuracy suggests revolutionizing assessment methodologies and learning experiences, fostering an educational environment that is more interactive and tailored to individual needs. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.","Evaluation; Exercises assessments; Generative pre-trained transformers; GPT; MOOC; Online learning; Retrieval augmented generation","E-learning; Learning algorithms; Learning systems; Comparatives studies; Evaluation; Exercise assessment; Generative pre-trained transformer; Generative pretrained transformer; Language model; Massive open online course; Online learning; Retrieval augmented generation; Transformer modeling; Natural language processing systems","Olney A.M.; Chounta I.-A.; Liu Z.; Santos O.C.; Bittencourt I.I.","Springer Science and Business Media Deutschland GmbH","English","Conference paper","Final","","Scopus","2-s2.0-85200245298"
"Abane A.; Battou A.; Merzouki M.","Abane, Amar (57196412292); Battou, Abdella (6603417705); Merzouki, Mheni (57197848699)","57196412292; 6603417705; 57197848699","An Adaptable AI Assistant for Network Management","2024","Proceedings of IEEE/IFIP Network Operations and Management Symposium 2024, NOMS 2024","","","","","","","0","10.1109/NOMS59830.2024.10574957","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198367006&doi=10.1109%2fNOMS59830.2024.10574957&partnerID=40&md5=45777b7aecc8cdfb942c1460e4f9ce71","NIST, MD, United States","Abane A., NIST, MD, United States; Battou A., NIST, MD, United States; Merzouki M., NIST, MD, United States","This paper presents a network management AI assistant built with Large Language Models. It adapts at runtime to the network state and specific platform, leveraging techniques like prompt engineering, document retrieval, and Knowledge Graph integration. The AI assistant aims to simplify management tasks and is easily reproducible with available source code. © 2024 IEEE.","graph database; knowledge graph; LLMs; Neo4j; network management; RAG; text embeddings","Graph Databases; Information retrieval; Knowledge management; Network management; Embeddings; Graph database; Knowledge graphs; Language model; LLM; Neo4j; Networks management; RAG; Runtimes; Text embedding; Knowledge graph","Hong J.W.-K.; Seok S.-J.; Nomura Y.; Wang Y.-C.; Choi B.-Y.; Kim M.-S.; Riggio R.; Tsai M.-H.; dos Santos C.R.P.","Institute of Electrical and Electronics Engineers Inc.","English","Conference paper","Final","","Scopus","2-s2.0-85198367006"
"Kawashima S.; Shiramatsu S.; Mizumoto T.","Kawashima, Soki (59257774400); Shiramatsu, Shun (24605680200); Mizumoto, Takeshi (59173493200)","59257774400; 24605680200; 59173493200","Development of RAG System for Digital Transformation of Local Government and Considering Optimal Document-Segmentation Methods","2024","Lecture Notes in Networks and Systems","1004 LNNS","","","603","617","14","0","10.1007/978-981-97-3305-7_48","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201095193&doi=10.1007%2f978-981-97-3305-7_48&partnerID=40&md5=19c06196cab091d6b8d2483141c5a56f","Nagoya Institute of Technology, Gokiso-cho, Showa-ku, Aichi, Nagoya, 466-8555, Japan; Hylable Inc, 2-203, Suzuoto Bldg., 2-26-12, Minami Otsuka, Tokyo, Toshima-City, 170-0005, Japan","Kawashima S., Nagoya Institute of Technology, Gokiso-cho, Showa-ku, Aichi, Nagoya, 466-8555, Japan; Shiramatsu S., Nagoya Institute of Technology, Gokiso-cho, Showa-ku, Aichi, Nagoya, 466-8555, Japan; Mizumoto T., Hylable Inc, 2-203, Suzuoto Bldg., 2-26-12, Minami Otsuka, Tokyo, Toshima-City, 170-0005, Japan","Administrative documents are accumulating yearly, increasing the burden of document retrieval in administrative work. We developed a retrieval augmented generation (RAG) system for administrative digital transformation and tested its effectiveness. We presented participants with tasks related to administrative issues and compared the accuracy and time taken to respond using the RAG system with those using traditional manual systems. We also set up groups with varying levels of experience and knowledge, i.e., administrative officers in charge, officers from other departments, and students, to analyze the effectiveness of the RAG system in each group. For short-answer questions, the administrative officers in charge achieved a 93.3% correct-answer rate, comparable to manual work, while reducing working time by 23.6%. Students improved their correct-answer rate by 40.0% and reduced working time by 79.8% through the RAG system use. For descriptive questions, however, the system use led to lower evaluations. The evaluation for descriptive questions was based on accuracy of the response, completeness of the response, accuracy of the background, context, and reasons, and completeness of the background, context, and reasons. Retrieval accuracy increased with longer segments, with longer segments yielding higher correct-answer rate in short-answer questions and shorter segments resulted in higher evaluations for descriptive questions. We also explored the optimal document-segmentation character count for the RAG system in administration tasks. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2024.","Document segmentation; Explainable artificial intelligence; GovTech; Large language model; Retrieval augmented generation","Information retrieval; Digital transformation; Document segmentation; Explainable artificial intelligence; Generation systems; Govtech; Language model; Large language model; Retrieval augmented generation; System use; Working time; Students","Yang X.-S.; Sherratt S.; Dey N.; Joshi A.","Springer Science and Business Media Deutschland GmbH","English","Conference paper","Final","","Scopus","2-s2.0-85201095193"
"Caffagni D.; Cocchi F.; Moratelli N.; Sarto S.; Cornia M.; Baraldi L.; Cucchiara R.","Caffagni, Davide (58616589800); Cocchi, Federico (58636703500); Moratelli, Nicholas (58100211000); Sarto, Sara (57831658000); Cornia, Marcella (57192079235); Baraldi, Lorenzo (55919206200); Cucchiara, Rita (7006870483)","58616589800; 58636703500; 58100211000; 57831658000; 57192079235; 55919206200; 7006870483","Wiki-LLaVA: Hierarchical Retrieval-Augmented Generation for Multimodal LLMs","2024","IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops","","","","1818","1826","8","2","10.1109/CVPRW63382.2024.00188","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198977492&doi=10.1109%2fCVPRW63382.2024.00188&partnerID=40&md5=0915c6f3fa258c84440a4a032db37946","University of Modena and Reggio Emilia, Italy; University of Pisa, Italy; IIT-CNR, Italy","Caffagni D., University of Modena and Reggio Emilia, Italy; Cocchi F., University of Modena and Reggio Emilia, Italy, University of Pisa, Italy; Moratelli N., University of Modena and Reggio Emilia, Italy; Sarto S., University of Modena and Reggio Emilia, Italy; Cornia M., University of Modena and Reggio Emilia, Italy; Baraldi L., University of Modena and Reggio Emilia, Italy; Cucchiara R., University of Modena and Reggio Emilia, Italy, IIT-CNR, Italy","Multimodal LLMs are the natural evolution of LLMs, and enlarge their capabilities so as to work beyond the pure textual modality. As research is being carried out to design novel architectures and vision-and-language adapters, in this paper we concentrate on endowing such models with the capability of answering questions that require external knowledge. Our approach, termed Wiki-LLaVA, aims at integrating an external knowledge source of multimodal documents, which is accessed through a hierarchical retrieval pipeline. Relevant passages, using this approach, are retrieved from the external knowledge source and employed as additional context for the LLM, augmenting the effectiveness and precision of generated dialogues. We conduct extensive experiments on datasets tailored for visual question answering with external data and demonstrate the appropriateness of our approach.  © 2024 IEEE.","","Modeling languages; Visual languages; External knowledge; Hierarchical retrieval; Knowledge sources; Multi-modal; Natural evolution; Novel architecture; Question Answering; Question answering","","IEEE Computer Society","English","Conference paper","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85198977492"
"Kefalas D.; Christakis S.; Fdida S.; Makris N.; Syrigos I.; Passas V.; Korakis T.","Kefalas, Dimitris (58121508100); Christakis, Sokratis (59238005900); Fdida, Serge (6701658861); Makris, Nikos (55401220200); Syrigos, Ilias (55587899600); Passas, Virgilios (55588380500); Korakis, Thanasis (16030975700)","58121508100; 59238005900; 6701658861; 55401220200; 55587899600; 55588380500; 16030975700","slAIces: an LLM Chatbot for Simplifying Experiments with the SLICES-RI","2024","2024 IFIP Networking Conference, IFIP Networking 2024","","","","660","665","5","0","10.23919/IFIPNetworking62109.2024.10619821","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202430672&doi=10.23919%2fIFIPNetworking62109.2024.10619821&partnerID=40&md5=ea27cd39c10e50c10ebb555b866da7f6","Laboratoire LiP6/CNRS, Sorbonne University, Paris, France; University of Thessaly, Dept. of Electrical and Computer Engineering, Greece; Centre for Research and Technology Hellas, CERTH, Greece","Kefalas D., Laboratoire LiP6/CNRS, Sorbonne University, Paris, France, University of Thessaly, Dept. of Electrical and Computer Engineering, Greece; Christakis S., Laboratoire LiP6/CNRS, Sorbonne University, Paris, France, University of Thessaly, Dept. of Electrical and Computer Engineering, Greece; Fdida S., Laboratoire LiP6/CNRS, Sorbonne University, Paris, France; Makris N., University of Thessaly, Dept. of Electrical and Computer Engineering, Greece, Centre for Research and Technology Hellas, CERTH, Greece; Syrigos I., University of Thessaly, Dept. of Electrical and Computer Engineering, Greece, Centre for Research and Technology Hellas, CERTH, Greece; Passas V., University of Thessaly, Dept. of Electrical and Computer Engineering, Greece, Centre for Research and Technology Hellas, CERTH, Greece; Korakis T., University of Thessaly, Dept. of Electrical and Computer Engineering, Greece, Centre for Research and Technology Hellas, CERTH, Greece","SLICES-RI is the outcome of several years of evolution of the concept of a networking test platform, that has recently transformed into a scientific instrument for the assessment of new research challenges in the Digital Infrastructures domain. Making large-scale scientific instruments easily accessible has always been challenging, often hindered by the complexity of the underlying platforms, the size and diversity of resources and the low-level settings that experimenters need to configure. Emerging technologies such as artificial intelligence(AI) have ignited a wave of innovation, inspiring companies, professionals, and researchers to incorporate chatbot assistants into their projects. These assistants revolutionize user experience by simplifying access to information and resources, significantly increasing productivity and presenting a familiar interface. In this work, we introduce slAIces, an LLM-based chatbot specifically designed to ease access to the SLICES-RI. slAIces utilizes the Generative Pre-trained Transformer(GPT) GPT-4 model to create a sophisticated Retrieval Augmented Generation(RAG) system. This system provides external knowledge by leveraging a properly preprocessed dataset, which includes documentation from SLICES-RI and all integrated testbeds. The contribution of this study lies in its methodology and recommendations for enriching the information on the test platform to enhance the quality of the service provided. We demonstrate that this chatbot significantly reduces the learning curve for new experimenters to become acquainted with the infrastructure. It exposes the appropriate level of abstraction, enabling experimenters to conduct complex experiments mobilizing the extensive and diverse resources available within a large-scale infrastructure like SLICES-RI.  © 2024 IFIP.","chatbot; GPT; LLM; RAG; Research Infrastructure; SLICES","Abstracting; Instrument scales; Instrument testing; Chatbots; Digital infrastructures; Generative pre-trained transformer; LLM; Research challenges; Research infrastructure; Retrieval augmented generation; Scientific instrument; SLICES; Test platforms","","Institute of Electrical and Electronics Engineers Inc.","English","Conference paper","Final","","Scopus","2-s2.0-85202430672"
"Singla A.D.; Tripathi S.; Victoria A.H.","Singla, Arjun Dev (59288194900); Tripathi, Shashank (59286666200); Victoria, A. Helen (58121257400)","59288194900; 59286666200; 58121257400","HICON AI: Higher Education Counseling Bot","2024","Proceedings - 2024 4th International Conference on Pervasive Computing and Social Networking, ICPCSN 2024","","","","779","784","5","0","10.1109/ICPCSN62568.2024.00131","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201672156&doi=10.1109%2fICPCSN62568.2024.00131&partnerID=40&md5=12268fd9382ed7808c97a0eb67b25042","Department of Networking and Communications, SRM Institute of Science and Technology, Kattankulatur, India","Singla A.D., Department of Networking and Communications, SRM Institute of Science and Technology, Kattankulatur, India; Tripathi S., Department of Networking and Communications, SRM Institute of Science and Technology, Kattankulatur, India; Victoria A.H., Department of Networking and Communications, SRM Institute of Science and Technology, Kattankulatur, India","As more and more students are seeking counseling services to help them pursue higher education opportunities abroad, it has become apparent that there is a lack of automation and a monopolization of counseling agencies, which presents a challenge for these students. To address this issue, this study has developed HICON AI: Higher Education Counselor. HI-CON made from Higher - Counseling is an innovative application that offers personalized college selection and preparation recommendations to students. By asking a set of defined questions, the bot gets to know the user and provides tailored guidance based on the information provided, utilizing refined Machine Learning modelsand Retrieval Augmented Generation. This study has specifically used Llama 2, LLM by meta for the considered use case, because of its high performance and financial viability. The developednew product ensures the highest level of accuracy and reliability. © 2024 IEEE.","Categorizer; HICON AI; LLMs; Machine Learning; Natural Language Processing; Resume Screener; Retrieval Augmented Generation; text to Speech","Adversarial machine learning; Bot (Internet); Botnet; Contrastive Learning; Machine learning; Natural language processing systems; Categorizer; HICON AI; Language processing; LLM; Machine-learning; Natural language processing; Natural languages; Resume screener; Retrieval augmented generation; Text to speech; Students","","Institute of Electrical and Electronics Engineers Inc.","English","Conference paper","Final","","Scopus","2-s2.0-85201672156"
"Kang C.; Novak D.; Urbanova K.; Cheng Y.; Hu Y.","Kang, Cheng (57191376989); Novak, Daniel (7103230238); Urbanova, Katerina (57226803696); Cheng, Yuqing (58703712700); Hu, Yong (59051094200)","57191376989; 7103230238; 57226803696; 58703712700; 59051094200","Domain-Specific Improvement on Psychotherapy Chatbot Using Assistant","2024","2024 IEEE International Conference on Acoustics, Speech, and Signal Processing Workshops, ICASSPW 2024 - Proceedings","","","","351","355","4","0","10.1109/ICASSPW62465.2024.10626529","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202434078&doi=10.1109%2fICASSPW62465.2024.10626529&partnerID=40&md5=08d9668bfc71d61ece7f0fa698311333","Czech Technical University in Prague, Prague, Czech Republic; The University of Hong Kong, Hong Kong; National Institute of Mental Health, Prague, Czech Republic; The Shenzhen Mental Health Centre, China","Kang C., Czech Technical University in Prague, Prague, Czech Republic; Novak D., Czech Technical University in Prague, Prague, Czech Republic; Urbanova K., Czech Technical University in Prague, Prague, Czech Republic, National Institute of Mental Health, Prague, Czech Republic; Cheng Y., The University of Hong Kong, Hong Kong, The Shenzhen Mental Health Centre, China; Hu Y., The University of Hong Kong, Hong Kong","Large language models (LLMs) have demonstrated impressive generalization capabilities on specific tasks with human-written instruction data. However, the limited quantity, diversity, and professional expertise of such instruction data raise concerns about the performance of LLMs in psychotherapy tasks when provided with domain-specific instructions. To address this, we firstly propose Domain-Specific Assistant Instructions based on AlexanderStreet therapy, and secondly we use an adaption fine-tuning method and retrieval augmented generation method to improve pre-trained LLMs. Through quantitative evaluation of linguistic quality using automatic and human evaluation, we observe that pre-trained LLMs on Psychotherapy Assistant Instructions outperform state-of-the-art LLMs response baselines. Our Assistant-Instruction approach offers a half-annotation method to align pre-trained LLMs with instructions, and provide pre-trained LLMs more psychotherapy knowledge.  © 2024 IEEE.","Adaption Fine-tuning; Assistant-Instruction; Knowledge Retrieval; Large Language Model; Parameter Efficient Fine-Tuning; Psychotherapy Chatbot","Adaption fine-tuning; Assistant-instruction; Chatbots; Fine tuning; Knowledge retrieval; Language model; Large language model; Parameter efficient fine-tuning; Psychotherapy chatbot; Linguistics","","Institute of Electrical and Electronics Engineers Inc.","English","Conference paper","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85202434078"
"","","","25th International Conference on Artificial Intelligence in Education, AIED 2024","2024","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","14830 LNAI","","","","","952","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200220675&partnerID=40&md5=30906c928758c55efad0706360f4dfc0","","","The proceedings contain 76 papers. The special focus in this conference is on Artificial Intelligence in Education. The topics include: PBChat: Enhance Student’s Problem Behavior Diagnosis with Large Language Model; Generating Situated Reflection Triggers About Alternative Solution Paths: A Case Study of Generative AI for Computer-Supported Collaborative Learning; Automated Assessment of Encouragement and Warmth in Classrooms Leveraging Multimodal Emotional Features and ChatGPT; ruffle &Riley: Insights from Designing and Evaluating a Large Language Model-Based Conversational Tutoring System; knowledge Tracing Unplugged: From Data Collection to Model Deployment; grading Documentation with Machine Learning; supporting Teaching-to-the-Curriculum by Linking Diagnostic Tests to Curriculum Goals: Using Textbook Content as Context for Retrieval-Augmented Generation with Large Language Models; VerAs: Verify Then Assess STEM Lab Reports; Evaluating the Effectiveness of Comparison Activities in a CTAT Tutor for Algorithmic Thinking; automated Long Answer Grading with RiceChem Dataset; knowledge Tracing as Language Processing: A Large-Scale Autoregressive Paradigm; Can GPT4 Answer Educational Tests? Empirical Analysis of Answer Quality Based on Question Complexity and Difficulty; understanding Gender Effects in Game-Based Learning: The Role of Self-Explanation; calcium Regulation Assignment: Alternative Styles in Successfully Learning About Biological Mechanisms; Who’s Helping Who? When Students Use ChatGPT to Engage in Practice Lab Sessions; Deep-IRT with a Temporal Convolutional Network for Reflecting Students’ Long-Term History of Ability Data; How to Teach Programming in the AI Era? Using LLMs as a Teachable Agent for Debugging; improving the Validity of Automatically Generated Feedback via Reinforcement Learning; automatic Detection of Narrative Rhetorical Categories and Elements on Middle School Written Essays; marking: Visual Grading with Highlighting Errors and Annotating Missing Bits; Jill Watson: A Virtual Teaching Assistant Powered by ChatGPT; evaluating the Design Features of an Intelligent Tutoring System for Advanced Mathematics Learning; anticipating Student Abandonment and Failure: Predictive Models in High School Settings.","","","Olney A.M.; Chounta I.-A.; Liu Z.; Santos O.C.; Bittencourt I.I.","Springer Science and Business Media Deutschland GmbH","English","Conference review","Final","","Scopus","2-s2.0-85200220675"
"Wiratunga N.; Abeyratne R.; Jayawardena L.; Martin K.; Massie S.; Nkisi-Orji I.; Weerasinghe R.; Liret A.; Fleisch B.","Wiratunga, Nirmalie (13405064600); Abeyratne, Ramitha (57206897541); Jayawardena, Lasal (58983537000); Martin, Kyle (57200230178); Massie, Stewart (10242574900); Nkisi-Orji, Ikechukwu (57195720655); Weerasinghe, Ruvan (13005100600); Liret, Anne (6506503357); Fleisch, Bruno (58265850800)","13405064600; 57206897541; 58983537000; 57200230178; 10242574900; 57195720655; 13005100600; 6506503357; 58265850800","CBR-RAG: Case-Based Reasoning for Retrieval Augmented Generation in LLMs for Legal Question Answering","2024","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","14775 LNAI","","","445","460","15","1","10.1007/978-3-031-63646-2_29","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198479753&doi=10.1007%2f978-3-031-63646-2_29&partnerID=40&md5=610cf4d4735b6fe4db74ab37c897d871","Robert Gordon University, Aberdeen, United Kingdom; Informatics Institute of Technology, Colombo, Sri Lanka; BT France, Puteaux, France","Wiratunga N., Robert Gordon University, Aberdeen, United Kingdom; Abeyratne R., Robert Gordon University, Aberdeen, United Kingdom; Jayawardena L., Robert Gordon University, Aberdeen, United Kingdom, Informatics Institute of Technology, Colombo, Sri Lanka; Martin K., Robert Gordon University, Aberdeen, United Kingdom; Massie S., Robert Gordon University, Aberdeen, United Kingdom; Nkisi-Orji I., Robert Gordon University, Aberdeen, United Kingdom; Weerasinghe R., Informatics Institute of Technology, Colombo, Sri Lanka; Liret A., BT France, Puteaux, France; Fleisch B., BT France, Puteaux, France","Retrieval-Augmented Generation (RAG) enhances Large Language Model (LLM) output by providing prior knowledge as context to input. This is beneficial for knowledge-intensive and expert reliant tasks, including legal question-answering, which require evidence to validate generated text outputs. We highlight that Case-Based Reasoning (CBR) presents key opportunities to structure retrieval as part of the RAG process in an LLM. We introduce CBR-RAG, where CBR cycle’s initial retrieval stage, its indexing vocabulary, and similarity knowledge containers are used to enhance LLM queries with contextually relevant cases. This integration augments the original LLM query, providing a richer prompt. We present an evaluation of CBR-RAG, and examine different representations (i.e. general and domain-specific embeddings) and methods of comparison (i.e. inter, intra and hybrid similarity) on the task of legal question-answering. Our results indicate that the context provided by CBR’s case reuse enforces similarity between relevant components of the questions and the evidence base leading to significant improvements in the quality of generated answers. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.","CBR; Indexing; LLMs; RAG; Retrieval; Text Embedding","Computational linguistics; Embeddings; Indexing (of information); Information retrieval; Natural language processing systems; Casebased reasonings (CBR); Embeddings; Indexing; Language model; Legal questions; LLM; Question Answering; Retrieval; Retrieval-augmented generation; Text embedding; Case based reasoning","Recio-Garcia J.A.; Orozco-del-Castillo M.G.; Bridge D.","Springer Science and Business Media Deutschland GmbH","English","Conference paper","Final","","Scopus","2-s2.0-85198479753"
"Kato M.; Koshino M.; Ogoshi S.; Ogoshi Y.","Kato, Masaki (59240470400); Koshino, Makoto (14625272800); Ogoshi, Sakiko (55904233800); Ogoshi, Yasuhiro (6507103122)","59240470400; 14625272800; 55904233800; 6507103122","Educational Support System for Children with Developmental Disabilities through Offline Large Language Models and Retrieval-Augmented Generation","2024","International Journal of Information and Education Technology","14","7","","955","960","5","0","10.18178/ijiet.2024.14.7.2122","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200048547&doi=10.18178%2fijiet.2024.14.7.2122&partnerID=40&md5=0907b68f6e3935bf04e775651d176e1e","Department of Electronics and Information Engineering, National Institute of Technology Ishikawa College, Ishikawa, Tsubata, Japan; Department of Electronics and Information Engineering, National Institute of Technology Fukui College, Fukui, Japan; Department of Human and Artificial Intelligent Systems Graduate School of Engineering, University of Fukui, Fukui, Japan","Kato M., Department of Electronics and Information Engineering, National Institute of Technology Ishikawa College, Ishikawa, Tsubata, Japan; Koshino M., Department of Electronics and Information Engineering, National Institute of Technology Ishikawa College, Ishikawa, Tsubata, Japan; Ogoshi S., Department of Electronics and Information Engineering, National Institute of Technology Fukui College, Fukui, Japan; Ogoshi Y., Department of Human and Artificial Intelligent Systems Graduate School of Engineering, University of Fukui, Fukui, Japan","In recent years, there has been a growing need for tailored educational and support measures for children with developmental disorders in Japan. Approximately 8.8% of students in regular classes require special support, necessitating close collaboration and information sharing among schools, families, and welfare facilities. However, teachers and supporters face challenges such as instructional skills, workload, and parent interactions, which cannot be resolved simply by increasing years of experience. Collaboration with external specialized institutions is an effective measure, but few schools engage in regular information sharing. This study proposes the use of Large Language Models (LLMs) and Retrieval-Augmented Generation (RAG) based on the support information and behavioral history of students accumulated in the Individualized Educational Support System. The proposed approach offers practical solutions to the lack of experience in special education, insufficient collaboration, and workload issues. Experiments with a question-answering system using multiple models confirmed the possibility of providing answers based on content specific to each child. The effectiveness of a summary system in providing individualized support was confirmed through evaluations by actual supporters. The proposed approach demonstrates the potential for addressing the challenges faced in supporting children with developmental disorders in Japan. © 2024 by the authors.","collaborative support; developmental disabilities; individualized educational support; Large Language Models (LLMs); Retrieval-Augmented Generation (RAG)","","","International Journal of Information and Education Technology","English","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85200048547"
"Lee M.; An S.; Kim M.-S.","Lee, Myeonghwa (57226515161); An, Seonho (59207090800); Kim, Min-Soo (58619495800)","57226515161; 59207090800; 58619495800","PlanRAG: A Plan-then-Retrieval Augmented Generation for Generative Large Language Models as Decision Makers","2024","Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL 2024","1","","","6537","6555","18","1","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199505798&partnerID=40&md5=a11952224fe29f5722ea5d463e399521","School of Computing, KAIST, South Korea","Lee M., School of Computing, KAIST, South Korea; An S., School of Computing, KAIST, South Korea; Kim M.-S., School of Computing, KAIST, South Korea","In this paper, we conduct a study to utilize LLMs as a solution for decision making that requires complex data analysis. We define Decision QA as the task of answering the best decision, dbest, for a decision-making question Q, business rules R and a database D. Since there is no benchmark that can examine Decision QA, we propose Decision QA benchmark, DQA. It has two scenarios, Locating and Building, constructed from two video games (Europa Universalis IV and Victoria 3) that have almost the same goal as Decision QA. To address Decision QA effectively, we also propose a new RAG technique called the iterative plan-then-retrieval augmented generation (PlanRAG). Our PlanRAG-based LM generates the plan for decision making as the first step, and the retriever generates the queries for data analysis as the second step. The proposed method outperforms the state-of-the-art iterative RAG method by 15.8% in the Locating scenario and by 7.4% in the Building scenario, respectively. We release our code and benchmark at https://github.com/myeon9h/PlanRAG. © 2024 Association for Computational Linguistics.","","Computational linguistics; Data handling; Information analysis; Iterative methods; Best decision; Business rules; Complex data; Decision makers; Decisions makings; Language model; State of the art; Video-games; Decision making","Duh K.; Gomez H.; Bethard S.","Association for Computational Linguistics (ACL)","English","Conference paper","Final","","Scopus","2-s2.0-85199505798"
"Coelho G.M.C.; Nascimento E.R.S.; Izquierdo Y.T.; García G.M.; Feijó L.; Lemos M.; Garcia R.L.S.; de Oliveira A.R.; Pinheiro J.P.; Casanova M.A.","Coelho, Gustavo M. C. (57947670500); Nascimento, Eduardo R. S. (58370544200); Izquierdo, Yenier T. (57197823435); García, Grettel M. (57193669391); Feijó, Lucas (59138620900); Lemos, Melissa (22334047700); Garcia, Robinson L. S. (58221187600); de Oliveira, Aiko R. (59139726300); Pinheiro, João P. (58296557900); Casanova, Marco A. (7102125708)","57947670500; 58370544200; 57197823435; 57193669391; 59138620900; 22334047700; 58221187600; 59139726300; 58296557900; 7102125708","Improving the Accuracy of Text-to-SQL Tools Based on Large Language Models for Real-World Relational Databases","2024","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","14910 LNCS","","","93","107","14","0","10.1007/978-3-031-68309-1_8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202148175&doi=10.1007%2f978-3-031-68309-1_8&partnerID=40&md5=0e6301e0c25f098a8bf0b8cd29c66622","Instituto Tecgraf, PUC-Rio, RJ, Rio de Janeiro, 22451-900, Brazil; Petrobras, RJ, Rio de Janeiro, 20031-912, Brazil; Departamento de Informática, PUC-Rio, RJ, Rio de Janeiro, 22451-900, Brazil","Coelho G.M.C., Instituto Tecgraf, PUC-Rio, RJ, Rio de Janeiro, 22451-900, Brazil; Nascimento E.R.S., Instituto Tecgraf, PUC-Rio, RJ, Rio de Janeiro, 22451-900, Brazil; Izquierdo Y.T., Instituto Tecgraf, PUC-Rio, RJ, Rio de Janeiro, 22451-900, Brazil; García G.M., Instituto Tecgraf, PUC-Rio, RJ, Rio de Janeiro, 22451-900, Brazil; Feijó L., Instituto Tecgraf, PUC-Rio, RJ, Rio de Janeiro, 22451-900, Brazil; Lemos M., Instituto Tecgraf, PUC-Rio, RJ, Rio de Janeiro, 22451-900, Brazil; Garcia R.L.S., Petrobras, RJ, Rio de Janeiro, 20031-912, Brazil; de Oliveira A.R., Instituto Tecgraf, PUC-Rio, RJ, Rio de Janeiro, 22451-900, Brazil, Departamento de Informática, PUC-Rio, RJ, Rio de Janeiro, 22451-900, Brazil; Pinheiro J.P., Departamento de Informática, PUC-Rio, RJ, Rio de Janeiro, 22451-900, Brazil; Casanova M.A., Instituto Tecgraf, PUC-Rio, RJ, Rio de Janeiro, 22451-900, Brazil, Departamento de Informática, PUC-Rio, RJ, Rio de Janeiro, 22451-900, Brazil","Real-world relational databases (RW-RDB) have large, complex schemas often expressed in terms alien to end-users. This scenario is challenging to LLM-based text-to-SQL tools, that is, tools that translate Natural Language (NL) sentences into SQL queries using a Large Language Model (LLM). Indeed, their accuracy on RW-RDBs is considerably less than that reported for well-known synthetic benchmarks. This paper then introduces a technique to improve the accuracy of LLM-based text-to-SQL tools on RW-RDBs using Retrieval-Augmented Generation. The technique consists of two steps. Using the RW-RDB schema, the first step generates a synthetic dataset E of pairs (QN,QS), where QN is an NL sentence and QS is the corresponding SQL translation. The core contribution of the paper is an algorithm that implements this first step. Given an input NL sentence QI, the second step retrieves pairs (QN,QS) from E based on the similarity of QI and QN, and prompts such pairs to the LLM to improve accuracy. To argue in favor of the proposed technique, the paper includes experiments with an RW-RDB, which is in production at an Energy company, and a well-known text-to-SQL prompt strategy. It repeats the experiments with Mondial, an openly available database with a large schema. These experiments constitute a second contribution of the paper. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.","GPT; Large Language Models; RAG; Relational Databases; Retrieval-Augmented Generation; Text-to-SQL","Benchmarking; Modeling languages; Query languages; Search engines; Structured Query Language; Translation (languages); GPT; Language model; Large language model; Model-based OPC; Natural languages; RAG; Real-world; Relational Database; Retrieval-augmented generation; Text-to-SQL; Relational database systems","Strauss C.; Amagasa T.; Manco G.; Kotsis G.; Khalil I.; Tjoa A.M.","Springer Science and Business Media Deutschland GmbH","English","Conference paper","Final","","Scopus","2-s2.0-85202148175"
"Pan J.; Liang W.S.; Yidi Y.","Pan, Jonathan (55579064200); Liang, Wong Swee (36106599200); Yidi, Yuan (59259262200)","55579064200; 36106599200; 59259262200","RAGLog: Log Anomaly Detection using Retrieval Augmented Generation","2024","Proceedings - 2024 IEEE World Forum on Public Safety Technology, WFPST 2024","","","","169","174","5","0","10.1109/WFPST58552.2024.00034","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201179281&doi=10.1109%2fWFPST58552.2024.00034&partnerID=40&md5=77770875b0eb1d5b7b818cba501305f3","Home Team Science and Technology Agency, Singapore","Pan J., Home Team Science and Technology Agency, Singapore; Liang W.S., Home Team Science and Technology Agency, Singapore; Yidi Y., Home Team Science and Technology Agency, Singapore","The ability to detect log anomalies from system logs is a vital activity needed to ensure cyber resiliency of systems. It is applied for fault identification or facilitate cyber investigation and digital forensics. However, as logs belonging to different systems and components differ significantly, the challenge to perform such analysis is humanly challenging from the volume, variety and velocity of logs. This is further complicated by the lack or unavailability of anomalous log entries to develop trained machine learning or artificial intelligence models for such purposes. In this research work, we explore the use of a Retrieval Augmented Large Language Model that leverages a vector database to detect anomalies from logs. We used a Question and Answer configuration pipeline. To the best of our knowledge, our experiment which we called RAGLog is a novel one and the experimental results show much promise. © 2024 IEEE.","Large Language Model; Log analysis; Retrieval Augmented Generation","Artificial intelligence; Computational linguistics; Digital forensics; Well logging; Anomaly detection; Fault identifications; Intelligence models; Language model; Large language model; Log analysis; Machine-learning; Retrieval augmented generation; Anomaly detection","","Institute of Electrical and Electronics Engineers Inc.","English","Conference paper","Final","","Scopus","2-s2.0-85201179281"
"Tahir A.; Cheng L.; Liu H.","Tahir, Anique (57209498098); Cheng, Lu (57206471993); Liu, Huan (7409751811)","57209498098; 57206471993; 7409751811","JORA: JAX Tensor-Parallel LoRA Library for Retrieval Augmented Fine-Tuning","2024","Proceedings of the Annual Meeting of the Association for Computational Linguistics","3","","","152","159","7","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203786620&partnerID=40&md5=5858c4402c8d4ba0b867bf589bae2c76","Arizona State University, 699 S. Mill Avenue, Tempe, AZ, United States; University of Illinois Chicago, 851 S. Morgan St., Chicago, IL, United States","Tahir A., Arizona State University, 699 S. Mill Avenue, Tempe, AZ, United States; Cheng L., University of Illinois Chicago, 851 S. Morgan St., Chicago, IL, United States; Liu H., Arizona State University, 699 S. Mill Avenue, Tempe, AZ, United States","The scaling of Large Language Models (LLMs) for retrieval-based tasks, particularly in Retrieval Augmented Generation (RAG), faces significant memory constraints, especially when fine-tuning extensive prompt sequences. Current open-source libraries support full-model inference and fine-tuning across multiple GPUs but fall short of accommodating the efficient parameter distribution required for retrieved context. Addressing this gap, we introduce a novel framework for PEFT-compatible fine-tuning of GPT models, leveraging distributed training. Our framework uniquely utilizes JAX’s just-in-time (JIT) compilation and tensor-sharding for efficient resource management, thereby enabling accelerated fine-tuning with reduced memory requirements. This advancement significantly improves the scalability and feasibility of fine-tuning LLMs for complex RAG applications, even on systems with limited GPU resources. Our experiments show more than 12x improvement in runtime compared to Hugging Face/DeepSpeed implementation with four GPUs while consuming less than half the VRAM per GPU. © 2024 Association for Computational Linguistics.","","Memory management; Problem oriented languages; Resource allocation; 'current; Fine tuning; Full model; Language model; Library support; Memory constraints; Model inference; Multiple GPUs; Open-source libraries; Scalings; Tensors","Cao Y.; Feng Y.; Xiong D.","Association for Computational Linguistics (ACL)","English","Conference paper","Final","","Scopus","2-s2.0-85203786620"
"Zheng Y.; Li X.; Huang Y.; Liang Q.; Guo T.; Hou M.; Gao B.; Tian M.; Liu Z.; Luo W.","Zheng, Ying (59243990600); Li, Xueyi (59293042000); Huang, Yaying (58289976900); Liang, Qianru (57223328059); Guo, Teng (57198501181); Hou, Mingliang (59243170700); Gao, Boyu (57054714700); Tian, Mi (58490205200); Liu, Zitao (56101750800); Luo, Weiqi (57194349411)","59243990600; 59293042000; 58289976900; 57223328059; 57198501181; 59243170700; 57054714700; 58490205200; 56101750800; 57194349411","Automatic Lesson Plan Generation via Large Language Models with Self-critique Prompting","2024","Communications in Computer and Information Science","2150 CCIS","","","163","178","15","0","10.1007/978-3-031-64315-6_13","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200270422&doi=10.1007%2f978-3-031-64315-6_13&partnerID=40&md5=73530d1d83fdfba289588ce331f91a5f","Guangdong Institute of Smart Education, Jinan University, Guangzhou, China; TAL Education Group, Beijing, China","Zheng Y., Guangdong Institute of Smart Education, Jinan University, Guangzhou, China; Li X., Guangdong Institute of Smart Education, Jinan University, Guangzhou, China; Huang Y., Guangdong Institute of Smart Education, Jinan University, Guangzhou, China; Liang Q., Guangdong Institute of Smart Education, Jinan University, Guangzhou, China; Guo T., Guangdong Institute of Smart Education, Jinan University, Guangzhou, China; Hou M., TAL Education Group, Beijing, China; Gao B., Guangdong Institute of Smart Education, Jinan University, Guangzhou, China; Tian M., TAL Education Group, Beijing, China; Liu Z., Guangdong Institute of Smart Education, Jinan University, Guangzhou, China; Luo W., Guangdong Institute of Smart Education, Jinan University, Guangzhou, China","In this paper, we utilize the understanding and generative abilities of large language models (LLMs) to automatically produce customized lesson plans. This addresses the common challenge where conventional plans may not sufficiently meet the distinct requirements of various teaching contexts and student populations. We propose a novel three-stage process, that encompasses the gradual generation of each key component of the lesson plan using Retrieval-Augmented Generation (RAG), self-critique by the LLMs, and subsequent refinement. We generate math lesson plans for grades 2 to 5 at the elementary school levels, covering over 80 topics using this method. Three experienced educators were invited to develop comprehensive lesson plan evaluation criteria, which are then used to benchmark our LLM-generated lesson plans against actual lesson plans on the same topics. Three evaluators assess the quality, relevance, and applicability of the plans. The results of the evaluation indicate that our approach can generate high-quality lesson plans. This innovative approach can significantly streamline the process of lesson planning and reduce the burden on educators.  © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.","","Computational linguistics; Quality control; Elementary schools; Evaluation criteria; High quality; Innovative approaches; Language model; Lesson plans; Plan evaluation; Plan generation; Student populations; Three-stage process; Teaching","Olney A.M.; Chounta I.-A.; Liu Z.; Santos O.C.; Bittencourt I.I.","Springer Science and Business Media Deutschland GmbH","English","Conference paper","Final","","Scopus","2-s2.0-85200270422"
"Lan Q.; Kaul A.; Das Pattanaik N.K.; Pattanayak P.; Pandurangan V.","Lan, Qianlong (59261788200); Kaul, Anuj (57201031905); Das Pattanaik, Nishant Kumar (59260880600); Pattanayak, Piyush (59261979400); Pandurangan, Vinothini (59260880700)","59261788200; 57201031905; 59260880600; 59261979400; 59260880700","Securing Applications of Large Language Models: A Shift-Left Approach","2024","IEEE International Conference on Electro Information Technology","","","","378","379","1","0","10.1109/eIT60633.2024.10609922","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201311949&doi=10.1109%2feIT60633.2024.10609922&partnerID=40&md5=7ac85d6840709fa9f1a6f43f720a1c94","Global Information Security at EBay","Lan Q., Global Information Security at EBay; Kaul A., Global Information Security at EBay; Das Pattanaik N.K., Global Information Security at EBay; Pattanayak P., Global Information Security at EBay; Pandurangan V., Global Information Security at EBay","The emergence of large language models (LLMs) has brought forth remarkable capabilities in various domains, yet it also poses inherent risks to trustfulness, encompassing concerns such as toxicity, stereotype bias, adversarial robustness, ethics, privacy, and fairness. Particularly in sensitive applications like customer support chatbots, AI assistants, and digital information automation, which handle privacy-sensitive data, the adoption of generative pre-trained transformer (GPT) models is pervasive. However, ensuring robust security measures to mitigate potential security vulnerabilities is imperative. This paper advocates for a proactive approach termed ""security shift-left,""which emphasizes integrating security measures early in the development lifecycle to bolster the security posture of LLM-based applications. Our proposed method leverages basic machine learning (ML) techniques and retrieval-augmented generation (RAG) to effectively address security concerns. We present empirical evidence validating the efficacy of our approach with one LLM-based security application designed for the detection of malicious intent, utilizing both open-source datasets and synthesized datasets. By adopting this security shift-left methodology, developers can confidently develop LLM-based applications with robust security protection, safeguarding against potential threats and vulnerabilities. © 2024 IEEE.","LLMs; Security Integration; Security Shift-Left","Adversarial machine learning; Data privacy; FORTH (programming language); Generative adversarial networks; Customer support; Inherent risk; Language model; Large language model; Model-based OPC; Robust security; Security integration; Security measure; Security shift-leave; Sensitive application; Differential privacy","","IEEE Computer Society","English","Conference paper","Final","","Scopus","2-s2.0-85201311949"
"Di Marcantonio G.","Di Marcantonio, Giorgia (57200315411)","57200315411","Artificial Intelligence, Large Language Models (LLMs), and Retrieval-Augmented Generation (RAG). New tools for accessing archival and bibliographic resources; [Intelligenza artificiale, Large Language Models (LLMs) e Retrieval-Augmented Generation (RAG). Nuovi strumenti per l’accesso alle risorse archivistiche e bibliografiche]","2024","Bibliothecae.it","13","1","","146","173","27","0","10.6092/issn.2283-9364/19982","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200805627&doi=10.6092%2fissn.2283-9364%2f19982&partnerID=40&md5=35269583b3f80e9a338aad9eafd14993","","","Large Language Models (LLMs) and Retrieval-Augmented Generation (RAG) systems offer a new paradigm for querying and retrieving information, making the resource recovery processes more efficient and accurate due to their ability to learn and generate responses based on vast knowledge databases. This paper aims to demonstrate these systems in a simplified form to initiate a scientific discussion on the possibility of integrating these technologies into archival and bibliographic resource retrieval systems, and more broadly, into cultural heritage management. © The Author(s) 2024.","Archives; Artificial Intelligence (AI); Large Language Models (LLMs); Libraries; Retrieval Knowledge; Retrieval-Augmented Generation (RAG)","","","Universita di Bologna, Dipartimento di Beni Culturali, Alma Mater Studiorum","Italian","Article","Final","","Scopus","2-s2.0-85200805627"
"Li X.; Henriksson A.; Duneld M.; Nouri J.; Wu Y.","Li, Xiu (57258078100); Henriksson, Aron (52463615100); Duneld, Martin (56176877300); Nouri, Jalal (36608737900); Wu, Yongchao (57257970000)","57258078100; 52463615100; 56176877300; 36608737900; 57257970000","Supporting Teaching-to-the-Curriculum by Linking Diagnostic Tests to Curriculum Goals: Using Textbook Content as Context for Retrieval-Augmented Generation with Large Language Models","2024","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","14829 LNAI","","","118","132","14","0","10.1007/978-3-031-64302-6_9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200234051&doi=10.1007%2f978-3-031-64302-6_9&partnerID=40&md5=c3c36a89c61b3558d4ae56f3f1e5a06c","Stockholm University, NOD-huset, Borgarfjordsgatan 12, Stockholm, 16455, Sweden","Li X., Stockholm University, NOD-huset, Borgarfjordsgatan 12, Stockholm, 16455, Sweden; Henriksson A., Stockholm University, NOD-huset, Borgarfjordsgatan 12, Stockholm, 16455, Sweden; Duneld M., Stockholm University, NOD-huset, Borgarfjordsgatan 12, Stockholm, 16455, Sweden; Nouri J., Stockholm University, NOD-huset, Borgarfjordsgatan 12, Stockholm, 16455, Sweden; Wu Y., Stockholm University, NOD-huset, Borgarfjordsgatan 12, Stockholm, 16455, Sweden","Using AI for automatically linking exercises to curriculum goals can support many educational use cases and facilitate teaching-to-the-curriculum by ensuring that exercises adequately reflect and encompass the curriculum goals, ultimately enabling curriculum-based assessment. Here, we introduce this novel task and create a manually labeled dataset where two types of diagnostic tests are linked to curriculum goals for Biology G7-9 in Sweden. We cast the problem both as an information retrieval task and a multi-class text classification task and explore unsupervised approaches to both, as labeled data for such tasks is typically scarce. For the information retrieval task, we employ state-of-the-art embedding model ADA-002 for semantic textual similarity (STS), while we prompt a large language model in the form of ChatGPT to classify diagnostic tests into curriculum goals. For both task formulations, we investigate different ways of using textbook content as a pivot to provide additional context for linking diagnostic questions to curriculum goals. We show that a combination of the two approaches in a retrieval-augmented generation model, whereby STS is used for retrieving textbook content as context to ChatGPT that then performs zero-shot classification, leads to the best classification accuracy (73.5%), outperforming both STS-based classification (67.5%) and LLM-based classification without context (71.5%). Finally, we showcase how the proposed method could be used in pedagogical practices. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.","ChatGPT; Large Language Models; Retrieval-Augmented Generation; Semantic Textual Similarity; Teaching-to-the-Curriculum","Classification (of information); Computational linguistics; Curricula; Information retrieval; Statistical tests; Teaching; Text processing; Zero-shot learning; ChatGPT; Diagnostic tests; Educational use; Language model; Large language model; Novel task; Retrieval-augmented generation; Semantic textual similarity; Teaching-to-the-curriculum; Textual similarities; Semantics","Olney A.M.; Chounta I.-A.; Liu Z.; Santos O.C.; Bittencourt I.I.","Springer Science and Business Media Deutschland GmbH","English","Conference paper","Final","","Scopus","2-s2.0-85200234051"
"Prapty R.T.; Kundu A.; Iyengar A.","Prapty, Renascence Tarafder (57219435615); Kundu, Ashish (23482383700); Iyengar, Arun (7005401000)","57219435615; 23482383700; 7005401000","Poster: CrystalBall - Attack Graphs Using Large Language Models and RAGs","2024","Proceedings - International Conference on Distributed Computing Systems","","","","1450","1451","1","0","10.1109/ICDCS60910.2024.00146","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203164625&doi=10.1109%2fICDCS60910.2024.00146&partnerID=40&md5=ae9155d2a0da19dc215e8f16d8ff9e95","University of California Irvine, United States; Cisco Research","Prapty R.T., University of California Irvine, United States; Kundu A., Cisco Research; Iyengar A., Cisco Research","Attack graphs provide a way to model multiple attack vectors and multi-step attacks in a holistic manner that a malicious actor could use to compromise a system. Traditional methods of generating attack graphs involve expert knowledge, manual curation, and computational algorithms that might not cover the entire threat landscape due to the ever-evolving nature of vulnerabilities and exploits. This paper explores the approach of leveraging large language models (LLMs), such as GPT4, to automate the generation of attack graphs by intelligently chaining CVEs based on their preconditions and effects. It also shows how to utilize LLMs to create attack graphs from threat reports.  © 2024 IEEE.","Attack Graph; CVE; Large Language Model; Threat Report","Attack graph; Attack vector; Curation; CVE; Expert knowledge; Holistic manner; Language model; Large language model; Multi-step attacks; Threat report; Knowledge graph","","Institute of Electrical and Electronics Engineers Inc.","English","Conference paper","Final","","Scopus","2-s2.0-85203164625"
"Glukhikh I.N.; Chernysheva T.Y.; Shentsov Y.A.","Glukhikh, Igor N. (14622542900); Chernysheva, Tatiana Y. (24443742100); Shentsov, Yaroslav A. (58928488700)","14622542900; 24443742100; 58928488700","Decision support in a smart greenhouse using large language model with retrieval augmented generation","2024","Proceedings of SPIE - The International Society for Optical Engineering","13217","","132170S","","","","0","10.1117/12.3035606","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200748633&doi=10.1117%2f12.3035606&partnerID=40&md5=756af7361a08aeb524bcaf002c4fd98b","University of Tyumen, 6, Volodarskogo street, Tyumen, 625003, Russian Federation","Glukhikh I.N., University of Tyumen, 6, Volodarskogo street, Tyumen, 625003, Russian Federation; Chernysheva T.Y., University of Tyumen, 6, Volodarskogo street, Tyumen, 625003, Russian Federation; Shentsov Y.A., University of Tyumen, 6, Volodarskogo street, Tyumen, 625003, Russian Federation","The paper discusses the application of large language models for the development of decision support systems, particularly in the agro-industry. The thesis that decision support is necessary in the sphere of agriculture is confirmed. In order to optimize the activity of smart greenhouses it is reasonable to implement information systems and technologies using large language models. The architecture of decision support system with Retrieval Augmented Generation technology for controlling disease incidence of plants cultivated is proposed. Experiments with the implemented decision support system have been carried out. It is concluded that the application of large language models in the operation of smart greenhouses is promising for use in agriculture in general. © 2024 SPIE.","decision support system; Large Language Model; Retrieval Augmented Generation; smart greenhouse; system architecture","Agriculture; Artificial intelligence; Computational linguistics; Computer architecture; Greenhouses; Information use; Network architecture; Agroindustries; Decision supports; Disease incidence; Generation technologies; Information systems and technologies; Language model; Large language model; Retrieval augmented generation; Smart greenhouse; Systems architecture; Decision support systems","Eshankulov K.; Gibadullin A.","SPIE","English","Conference paper","Final","","Scopus","2-s2.0-85200748633"
"Asai A.; Wu Z.; Wang Y.; Sil A.; Hajishirzi H.","Asai, Akari (57205407908); Wu, Zeqiu (57219735284); Wang, Yizhong (57200286333); Sil, Avirup (42662281900); Hajishirzi, Hannaneh (23008126600)","57205407908; 57219735284; 57200286333; 42662281900; 23008126600","SELF-RAG: LEARNING TO RETRIEVE, GENERATE, AND CRITIQUE THROUGH SELF-REFLECTION","2024","12th International Conference on Learning Representations, ICLR 2024","","","","","","","15","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200583576&partnerID=40&md5=11f85d13cc96fb96d39fbb16ba5f717d","University of Washington, United States; Allen Institute for AI, United States; IBM Research AI, United States","Asai A., University of Washington, United States; Wu Z., University of Washington, United States; Wang Y., University of Washington, United States, Allen Institute for AI, United States; Sil A., IBM Research AI, United States; Hajishirzi H., University of Washington, United States, Allen Institute for AI, United States","Despite their remarkable capabilities, large language models (LLMs) often produce responses containing factual inaccuracies due to their sole reliance on the parametric knowledge they encapsulate. Retrieval-Augmented Generation (RAG), an ad hoc approach that augments LMs with retrieval of relevant knowledge, decreases such issues. However, indiscriminately retrieving and incorporating a fixed number of retrieved passages, regardless of whether retrieval is necessary, or passages are relevant, diminishes LM versatility or can lead to unhelpful response generation. We introduce a new framework called Self-Reflective Retrieval-Augmented Generation (SELF-RAG) that enhances an LM's quality and factuality through retrieval and self-reflection. Our framework trains a single arbitrary LM that adaptively retrieves passages on-demand, and generates and reflects on retrieved passages and its own generations using special tokens, called reflection tokens. Generating reflection tokens makes the LM controllable during the inference phase, enabling it to tailor its behavior to diverse task requirements. Experiments show that SELF-RAG (7B and 13B parameters) significantly outperforms state-of-the-art LLMs and retrieval-augmented models on a diverse set of tasks. Specifically, SELF-RAG outperforms ChatGPT and retrieval-augmented Llama2-chat on Open-domain QA, reasoning and fact verification tasks, and it shows significant gains in improving factuality and citation accuracy for long-form generations relative to these models. © 2024 12th International Conference on Learning Representations, ICLR 2024. All rights reserved.","","Ad hoc approach; Fixed numbers; Language model; On demands; Response generation; Self reflection; State of the art; Verification task","","International Conference on Learning Representations, ICLR","English","Conference paper","Final","","Scopus","2-s2.0-85200583576"
"Xiao W.; Song C.; Chen S.; Chen W.","Xiao, Wenke (58386797400); Song, Chi (36780183600); Chen, Shilin (35483515200); Chen, Wei (57087431600)","58386797400; 36780183600; 35483515200; 57087431600","Key technologies and construction strategies of large language models for traditional Chinese medicine; [中医药大语言模型的关键技术与构建策略]","2024","Chinese Traditional and Herbal Drugs","55","17","","5747","5756","9","0","10.7501/j.issn.0253-2670.2024.17.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203156325&doi=10.7501%2fj.issn.0253-2670.2024.17.001&partnerID=40&md5=ed93bfd416b0b840069936e2f88ffa50","Innovative Institute of Chinese Medicine and Pharmacy, Academy for Interdiscipline, Chengdu University of Traditional Chinese Medicine, Chengdu, 611137, China; Institute of Herbgenomics, Chengdu University of Traditional Chinese Medicine, Chengdu, 611137, China","Xiao W., Innovative Institute of Chinese Medicine and Pharmacy, Academy for Interdiscipline, Chengdu University of Traditional Chinese Medicine, Chengdu, 611137, China; Song C., Innovative Institute of Chinese Medicine and Pharmacy, Academy for Interdiscipline, Chengdu University of Traditional Chinese Medicine, Chengdu, 611137, China, Institute of Herbgenomics, Chengdu University of Traditional Chinese Medicine, Chengdu, 611137, China; Chen S., Innovative Institute of Chinese Medicine and Pharmacy, Academy for Interdiscipline, Chengdu University of Traditional Chinese Medicine, Chengdu, 611137, China, Institute of Herbgenomics, Chengdu University of Traditional Chinese Medicine, Chengdu, 611137, China; Chen W., Innovative Institute of Chinese Medicine and Pharmacy, Academy for Interdiscipline, Chengdu University of Traditional Chinese Medicine, Chengdu, 611137, China, Institute of Herbgenomics, Chengdu University of Traditional Chinese Medicine, Chengdu, 611137, China","By processing and understanding natural language data, large language models (LLM) enable the high-quality information retrieval, knowledge extraction, etc., and provide new opportunities for traditional Chinese medicine (TCM) research. Based on recent developments of LLM in TCM, the present work summarizes the data storage and processing algorithms, as well as artificial intelligence methods, such as retrieval-augmented generation, mixture of experts, reinforcement learning from human feedback, and knowledge distillation for developing LLM. It also summarizes methods for training fine-tuning and performance evaluation of LLM. In response to the characteristics of TCM data, strategies for developing LLM for TCM are proposed, which focuses on developing high-quality datasets, integrating mixture of experts, rapid information extraction, and model training and optimization. Additionally, it outlines specific application scenarios of LLM in TCM. The aim of this work is to provide insights for the development and application of LLM in TCM, promoting the modernization and intelligent development of TCM. © 2024 Editorial Office of Chinese Traditional and Herbal Drugs. All rights reserved.","knowledge distillation; large language models; mixture of experts; reinforcement learning from human feedback; retrieval-augmented generation; traditional Chinese medicine","algorithm; Article; artificial intelligence; Chinese medicine; feedback system; human; information retrieval; information storage; large language model","","Editorial Office of Chinese Traditional and Herbal Drugs","Chinese","Article","Final","","Scopus","2-s2.0-85203156325"
"Arslan M.; Cruz C.","Arslan, Muhammad (55807840100); Cruz, Christophe (7202701902)","55807840100; 7202701902","Business-RAG: Information Extraction for Business Insights","2024","ICSBT International Conference on Smart Business Technologies","","","","88","94","6","1","10.5220/0012812800003764","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202339768&doi=10.5220%2f0012812800003764&partnerID=40&md5=1c7cb2b0f5068aae54ca41eff2eeb7db","Laboratoire Interdisciplinaire Carnot de Bourgogne (ICB), Université de Bourgogne, Dijon, France","Arslan M., Laboratoire Interdisciplinaire Carnot de Bourgogne (ICB), Université de Bourgogne, Dijon, France; Cruz C., Laboratoire Interdisciplinaire Carnot de Bourgogne (ICB), Université de Bourgogne, Dijon, France","Enterprises depend on diverse data like invoices, news articles, legal documents, and financial records to operate. Efficient Information Extraction (IE) is essential for extracting valuable insights from this data for decision-making. Natural Language Processing (NLP) has transformed IE, enabling rapid and accurate analysis of vast datasets. Tasks such as Named Entity Recognition (NER), Relation Extraction (RE), Event Extraction (EE), Term Extraction (TE), and Topic Modeling (TM) are vital across sectors. Yet, implementing these methods individually can be resource-intensive, especially for smaller organizations lacking in Research and Development (R&D) capabilities. Large Language Models (LLMs), powered by Generative Artificial Intelligence (GenAI), offer a cost-effective solution, seamlessly handling multiple IE tasks. Despite their capabilities, LLMs may struggle with domain-specific queries, leading to inaccuracies. To overcome this challenge, Retrieval-Augmented Generation (RAG) complements LLMs by enhancing IE with external data retrieval, ensuring accuracy and relevance. While the adoption of RAG with LLMs is increasing, comprehensive business applications utilizing this integration remain limited. This paper addresses this gap by introducing a novel application named Business-RAG, showcasing its potential and encouraging further research in this domain. Copyright © 2024 by SCITEPRESS - Science and Technology Publications, Lda.","Business Intelligence (BI); Decision-Making; Information Extraction (IE); Large Language Models (LLMs); Natural Language Processing (NLP); Retrieval-Augmented Generation (RAG)","Data accuracy; Financial data processing; Large datasets; Metadata; Modeling languages; Natural language processing systems; Network security; Online searching; Business intelligence; Business-intelligence; Decisions makings; Information extraction; Language model; Language processing; Large language model; Natural language processing; Natural languages; Retrieval-augmented generation; Cost effectiveness","Hammoudi S.; Wijnhoven F.; Emrouznejad A.","Science and Technology Publications, Lda","English","Conference paper","Final","","Scopus","2-s2.0-85202339768"
"Yazaki M.; Maki S.; Furuya T.; Inoue K.; Nagai K.; Nagashima Y.; Maruyama J.; Toki Y.; Kitagawa K.; Iwata S.; Kitamura T.; Gushiken S.; Noguchi Y.; Inoue M.; Shiga Y.; Inage K.; Orita S.; Nakada T.; Ohtori S.","Yazaki, Megumi (57189255203); Maki, Satoshi (55929920500); Furuya, Takeo (26967671500); Inoue, Ken (59212889200); Nagai, Ko (57271689400); Nagashima, Yuki (57913169900); Maruyama, Juntaro (57215721532); Toki, Yasunori (59212078300); Kitagawa, Kyota (57992924500); Iwata, Shuhei (57434936500); Kitamura, Takaki (58314626500); Gushiken, Sho (59213082700); Noguchi, Yuji (57226857287); Inoue, Masahiro (37044482700); Shiga, Yasuhiro (56585560100); Inage, Kazuhide (48661146200); Orita, Sumihisa (57211777006); Nakada, Takaaki (35584094500); Ohtori, Seiji (57211788745)","57189255203; 55929920500; 26967671500; 59212889200; 57271689400; 57913169900; 57215721532; 59212078300; 57992924500; 57434936500; 58314626500; 59213082700; 57226857287; 37044482700; 56585560100; 48661146200; 57211777006; 35584094500; 57211788745","Emergency Patient Triage Improvement through a Retrieval-Augmented Generation Enhanced Large-Scale Language Model","2024","Prehospital Emergency Care","","","","","","","0","10.1080/10903127.2024.2374400","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198110065&doi=10.1080%2f10903127.2024.2374400&partnerID=40&md5=bfdd24005f1aed13b25b67ba46e4e720","Department of Orthopaedic Surgery, Graduate School of Medicine, Chiba University, Chiba, Japan; Tertiary Emergency Medical Center, Tokyo Metropolitan Bokutoh Hospital, Tokyo, Japan; Department of Emergency and Critical Care Medicine, Chiba University, Chiba, Japan; Center for Frontier Medical Engineering, Chiba University, Chiba, Japan","Yazaki M., Department of Orthopaedic Surgery, Graduate School of Medicine, Chiba University, Chiba, Japan, Tertiary Emergency Medical Center, Tokyo Metropolitan Bokutoh Hospital, Tokyo, Japan, Department of Emergency and Critical Care Medicine, Chiba University, Chiba, Japan; Maki S., Department of Orthopaedic Surgery, Graduate School of Medicine, Chiba University, Chiba, Japan, Center for Frontier Medical Engineering, Chiba University, Chiba, Japan; Furuya T., Department of Orthopaedic Surgery, Graduate School of Medicine, Chiba University, Chiba, Japan; Inoue K., Tertiary Emergency Medical Center, Tokyo Metropolitan Bokutoh Hospital, Tokyo, Japan; Nagai K., Tertiary Emergency Medical Center, Tokyo Metropolitan Bokutoh Hospital, Tokyo, Japan; Nagashima Y., Department of Orthopaedic Surgery, Graduate School of Medicine, Chiba University, Chiba, Japan; Maruyama J., Department of Orthopaedic Surgery, Graduate School of Medicine, Chiba University, Chiba, Japan; Toki Y., Department of Orthopaedic Surgery, Graduate School of Medicine, Chiba University, Chiba, Japan; Kitagawa K., Department of Orthopaedic Surgery, Graduate School of Medicine, Chiba University, Chiba, Japan; Iwata S., Department of Orthopaedic Surgery, Graduate School of Medicine, Chiba University, Chiba, Japan; Kitamura T., Department of Orthopaedic Surgery, Graduate School of Medicine, Chiba University, Chiba, Japan; Gushiken S., Department of Orthopaedic Surgery, Graduate School of Medicine, Chiba University, Chiba, Japan; Noguchi Y., Department of Orthopaedic Surgery, Graduate School of Medicine, Chiba University, Chiba, Japan; Inoue M., Department of Orthopaedic Surgery, Graduate School of Medicine, Chiba University, Chiba, Japan; Shiga Y., Department of Orthopaedic Surgery, Graduate School of Medicine, Chiba University, Chiba, Japan; Inage K., Department of Orthopaedic Surgery, Graduate School of Medicine, Chiba University, Chiba, Japan; Orita S., Department of Orthopaedic Surgery, Graduate School of Medicine, Chiba University, Chiba, Japan, Center for Frontier Medical Engineering, Chiba University, Chiba, Japan; Nakada T., Department of Emergency and Critical Care Medicine, Chiba University, Chiba, Japan; Ohtori S., Department of Orthopaedic Surgery, Graduate School of Medicine, Chiba University, Chiba, Japan","Objectives: Emergency medical triage is crucial for prioritizing patient care in emergency situations, yet its effectiveness can vary significantly based on the experience and training of the personnel involved. This study aims to evaluate the efficacy of integrating Retrieval Augmented Generation (RAG) with Large Language Models (LLMs), specifically OpenAI's GPT models, to standardize triage procedures and reduce variability in emergency care. Methods: We created 100 simulated triage scenarios based on modified cases from the Japanese National Examination for Emergency Medical Technicians. These scenarios were processed by the RAG-enhanced LLMs, and the models were given patient vital signs, symptoms, and observations from emergency medical services (EMS) teams as inputs. The primary outcome was the accuracy of triage classifications, which was used to compare the performance of the RAG-enhanced LLMs with that of emergency medical technicians and emergency physicians. Secondary outcomes included the rates of under-triage and over-triage. Results: The Generative Pre-trained Transformer 3.5 (GPT-3.5) with RAG model achieved a correct triage rate of 70%, significantly outperforming Emergency Medical Technicians (EMTs) with 35% and 38% correct rates, and emergency physicians with 50% and 47% correct rates (p < 0.05). Additionally, this model demonstrated a substantial reduction in under-triage rates to 8%, compared with 33% for GPT-3.5 without RAG, and 39% for GPT-4 without RAG. Conclusions: The integration of RAG with LLMs shows promise in improving the accuracy and consistency of medical assessments in emergency settings. Further validation in diverse medical settings with broader datasets is necessary to confirm the effectiveness and adaptability of these technologies in live environments. © 2024 National Association of EMS Physicians.","","","","Taylor and Francis Ltd.","English","Article","Article in press","","Scopus","2-s2.0-85198110065"
"Jeong S.; Baek J.; Cho S.; Hwang S.J.; Park J.C.","Jeong, Soyeong (56562251600); Baek, Jinheon (57219628188); Cho, Sukmin (57552840900); Hwang, Sung Ju (57687927300); Park, Jong C. (58618718900)","56562251600; 57219628188; 57552840900; 57687927300; 58618718900","Adaptive-RAG: Learning to Adapt Retrieval-Augmented Large Language Models through Question Complexity","2024","Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL 2024","1","","","7029","7043","14","1","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198827309&partnerID=40&md5=4ea15475bab138fd59db22a42cb6b1e0","School of Computing, Korea Advanced Institute of Science and Technology, South Korea; Graduate School of AI, Korea Advanced Institute of Science and Technology, South Korea","Jeong S., School of Computing, Korea Advanced Institute of Science and Technology, South Korea; Baek J., Graduate School of AI, Korea Advanced Institute of Science and Technology, South Korea; Cho S., School of Computing, Korea Advanced Institute of Science and Technology, South Korea; Hwang S.J., School of Computing, Korea Advanced Institute of Science and Technology, South Korea, Graduate School of AI, Korea Advanced Institute of Science and Technology, South Korea; Park J.C., School of Computing, Korea Advanced Institute of Science and Technology, South Korea","Retrieval-Augmented Large Language Models (LLMs), which incorporate the non-parametric knowledge from external knowledge bases into LLMs, have emerged as a promising approach to enhancing response accuracy in several tasks, such as Question-Answering (QA). However, even though there are various approaches dealing with queries of different complexities, they either handle simple queries with unnecessary computational overhead or fail to adequately address complex multi-step queries; yet, not all user requests fall into only one of the simple or complex categories. In this work, we propose a novel adaptive QA framework that can dynamically select the most suitable strategy for (retrieval-augmented) LLMs from the simplest to the most sophisticated ones based on the query complexity. Also, this selection process is operationalized with a classifier, which is a smaller LM trained to predict the complexity level of incoming queries with automatically collected labels, obtained from actual predicted outcomes of models and inherent inductive biases in datasets. This approach offers a balanced strategy, seamlessly adapting between the iterative and single-step retrieval-augmented LLMs, as well as the no-retrieval methods, in response to a range of query complexities. We validate our model on a set of open-domain QA datasets, covering multiple query complexities, and show that ours enhances the overall efficiency and accuracy of QA systems, compared to relevant baselines including the adaptive retrieval approaches. © 2024 Association for Computational Linguistics.","","Classification (of information); Computational linguistics; Information retrieval; Natural language processing systems; Complexity levels; Computational overheads; External knowledge; Inductive bias; Language model; Multisteps; Nonparametrics; Query complexity; Question Answering; Simple++; Iterative methods","Duh K.; Gomez H.; Bethard S.","Association for Computational Linguistics (ACL)","English","Conference paper","Final","","Scopus","2-s2.0-85198827309"
"Chia H.; Oliveira A.I.; Azevedo P.","Chia, Henrique (59301700800); Oliveira, Ana Ines (59301872200); Azevedo, Pedro (59301917400)","59301700800; 59301872200; 59301917400","Implementation of an intelligent virtual assistant based on LLM models for irrigation optimization","2024","Proceedings - 8th International Young Engineers Forum on Electrical and Computer Engineering, YEF-ECE 2024","","","","94","100","6","0","10.1109/YEF-ECE62614.2024.10624819","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202350423&doi=10.1109%2fYEF-ECE62614.2024.10624819&partnerID=40&md5=22d9b30756c8958d683d7d1764069931","NOVA School of Science and Technology (NOVA FCT), Caparica, Portugal; Center of Technology and Systems (UNINOVA-CTS) and Associated Lab of Intelligent Systems (LASI), NOVA School of Science and Technology (NOVA FCT), Caparica, Portugal; Hidrosoph, Lda, Oeiras, Portugal","Chia H., NOVA School of Science and Technology (NOVA FCT), Caparica, Portugal; Oliveira A.I., Center of Technology and Systems (UNINOVA-CTS) and Associated Lab of Intelligent Systems (LASI), NOVA School of Science and Technology (NOVA FCT), Caparica, Portugal; Azevedo P., Hidrosoph, Lda, Oeiras, Portugal","This paper explores the application of new AI capabilities and Large Languages Models (LLMs) in agriculture by developing an intelligent virtual assistant. The assistant aims to provide essential information on crops, vulnerabilities, and optimization strategies. The study focuses on implementing a robust pipeline architecture that trains LLMs for practical scenarios. This architecture ensures data and demonstrates substantial domain knowledge. Central to this approach is the Retrieval-Augmented Generation (RAG) technology, which organizes information into a streamlined format for efficient retrieval. Unlike fine-Tuning methods, RAG separates base knowledge from the model, enabling a faster and more adapted pipeline. This proposal transforms retrieved information into an accessible format, facilitating rapid access to comprehensive agricultural expertise. © 2024 IEEE.","Agriculture; Fine-Tuning; Intelligent Virtual Assistant; Irrigation Practices; knowledge; LLM; Retrieval Augmented Generation","Fine tuning; Intelligent virtual assistant; Irrigation optimization; Irrigation practices; Knowledge; Language model; Large language model; Optimization strategy; Retrieval augmented generation; Virtual assistants; Irrigation","","Institute of Electrical and Electronics Engineers Inc.","English","Conference paper","Final","","Scopus","2-s2.0-85202350423"
"Minor M.; Kaucher E.","Minor, Mirjam (55584612800); Kaucher, Eduard (59217774500)","55584612800; 59217774500","Retrieval Augmented Generation with LLMs for Explaining Business Process Models","2024","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","14775 LNAI","","","175","190","15","0","10.1007/978-3-031-63646-2_12","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198413770&doi=10.1007%2f978-3-031-63646-2_12&partnerID=40&md5=91c991ae40a4badab308cf8cbfa06275","Department of Business Informatics, Goethe University Frankfurt, Frankfurt, Germany","Minor M., Department of Business Informatics, Goethe University Frankfurt, Frankfurt, Germany; Kaucher E., Department of Business Informatics, Goethe University Frankfurt, Frankfurt, Germany","Large language models (LLMs) and retrieval augmented generation (RAG) are undergoing rapid development. Considering a case base as a memory in a RAG system provides novel opportunities for text generation. In this paper, we investigate the role Case-Based Reasoning (CBR) could play for supporting RAG systems in generating accessible explanations of business process models. We experiment with two different case bases in a RAG system. Case base a) is dedicated to support prompt chaining by reusing index knowledge on the cases with the aim to deal with large process models that do not fit into the context window size of a recent LLM. Second, case base b) contains model-text pairs to serve as in-context examples to enhance prompt templates. Approach b) aims to improve the quality of generated text explanations for process models of normal size. Our contribution opens a novel application area for process-oriented CBR. Further, our case-based RAG system provides a contemporary alternative to traditional Natural Language Processing pipelines. The experimental results contribute to gain some insights on an inherent capability threshold of GPT-4 at which the performance decreases much earlier than having reached the given context window size, on the number of retrieved cases a recent RAG system should use as in-context examples, and on suitable prompt templates. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.","Large Language models; Process-oriented CBR; Retrieval-Augmented Generation","Computational linguistics; Natural language processing systems; Pipeline processing systems; Business process modeling; Case base; Casebased reasonings (CBR); Generation systems; Language model; Large language model; Process-models; Process-oriented; Process-oriented case-based reasoning; Retrieval-augmented generation; Case based reasoning","Recio-Garcia J.A.; Orozco-del-Castillo M.G.; Bridge D.","Springer Science and Business Media Deutschland GmbH","English","Conference paper","Final","","Scopus","2-s2.0-85198413770"
"Vakayil S.; Sujitha Juliet D.; Anitha J.; Vakayil S.","Vakayil, Sonia (59210220800); Sujitha Juliet, D. (59210752100); Anitha, J. (35099994900); Vakayil, Sunil (57215816481)","59210220800; 59210752100; 35099994900; 57215816481","RAG-Based LLM Chatbot Using Llama-2","2024","ICDCS 2024 - 2024 7th International Conference on Devices, Circuits and Systems","","","","195","199","4","0","10.1109/ICDCS59278.2024.10561020","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197908123&doi=10.1109%2fICDCS59278.2024.10561020&partnerID=40&md5=214f97dd44549af8e97e69cabcfc8ba8","School of Computer Science and Technology, Karunya Institute of Technology and Sciences, Coimbatore, India; Management Development Centre, Loyola Institute of Business Adminstation, Chennai, India","Vakayil S., School of Computer Science and Technology, Karunya Institute of Technology and Sciences, Coimbatore, India; Sujitha Juliet D., School of Computer Science and Technology, Karunya Institute of Technology and Sciences, Coimbatore, India; Anitha J., School of Computer Science and Technology, Karunya Institute of Technology and Sciences, Coimbatore, India; Vakayil S., Management Development Centre, Loyola Institute of Business Adminstation, Chennai, India","Chatbots, otherwise known as autonomous conversational agents, are a rising utilitarian application of Natural Language Processing. They enable the streamlining of information searches and improve user productivity and experience. This study focuses on building a chatbot that is aimed at assisting victims of sexual harassment, using a Large Language Model (LLM). While ML-based chatbots are a notable prospect, LLM-powered chatbots offer more human-like conversations and can surpass humans in empathy. This project evaluated the performance of the LLM Llama-2 model in generating accurate and empathetic answers to create a supportive, sensitive, and informative chatbot for the victims of sexual harassment. The model leverages Retrieval Augmented generation to achieve a commendable accuracy of above 95%, providing information in an understanding and helpful tone. The model is also capable of providing helpful advice without judgement or preconceived notions about the victim, one of the reasons victims do not report their harassers. © 2024 IEEE.","chatbot; empathy; harassment; Llama-2; LLM","Natural language processing systems; Chatbots; Conversational agents; Empathy; Harassment; Language model; Language processing; Large language model; Llama-2; Natural languages; Sexual harassment; Autonomous agents","","Institute of Electrical and Electronics Engineers Inc.","English","Conference paper","Final","","Scopus","2-s2.0-85197908123"
"McAvinue S.; Dev K.","McAvinue, Sarah (59313209800); Dev, Kapal (57190336390)","59313209800; 57190336390","Comparative evaluation of Large Language Models using key metrics and emerging tools","2024","Expert Systems","","","","","","","0","10.1111/exsy.13719","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203066672&doi=10.1111%2fexsy.13719&partnerID=40&md5=31d9a42926818640d3ea3b96babd1661","Health Service Executive (HSE), Dublin, Ireland; Department of Computer Science and ADAPT Centre, Munster Technological University, Cork, Bishopstown, Ireland; Department of Electrical and Computer Engineering, Lebanese American University, Byblos, Lebanon; Centre for Research Impact & Outcome, Chitkara University Institute of Engineering and Technology, Chitkara University, Punjab, Rajpura, India","McAvinue S., Health Service Executive (HSE), Dublin, Ireland, Department of Computer Science and ADAPT Centre, Munster Technological University, Cork, Bishopstown, Ireland; Dev K., Department of Computer Science and ADAPT Centre, Munster Technological University, Cork, Bishopstown, Ireland, Department of Electrical and Computer Engineering, Lebanese American University, Byblos, Lebanon, Centre for Research Impact & Outcome, Chitkara University Institute of Engineering and Technology, Chitkara University, Punjab, Rajpura, India","This research involved designing and building an interactive generative AI application to conduct a comparative analysis of two advanced Large Language Models (LLMs), GPT-4, and Claude 2, using Langsmith evaluation tools. The project was developed to explore the potential of LLMs in facilitating postgraduate course recommendations within a simulated environment at Munster Technological University (MTU). Designed for comparative analysis, the application enables testing of GPT-4 and Claude 2 and can be hosted flexibly on either Amazon Web Services (AWS) or Azure. It utilizes advanced natural language processing and retrieval-augmented generation (RAG) techniques to process proprietary data tailored to postgraduate needs. A key component of this research was the rigorous assessment of the LLMs using the Langsmith evaluation tool against both customized and standard benchmarks. The evaluation focused on metrics such as bias, safety, accuracy, cost, robustness, and latency. Additionally, adaptability covering critical features like language translation and internet access, was independently researched since the Langsmith tool does not evaluate this metric. This ensures a holistic assessment of the LLM's capabilities. © 2024 John Wiley & Sons Ltd.","Claude 2; generative AI; GPT-4; Langsmith; Large Language Models (LLMs); LLM evaluation","Benchmarking; Metadata; Modeling languages; Translation (languages); Claude 2; Comparative analyzes; Generative AI; GPT-4; Langsmith; Language model; Large language model; Large language model evaluation; Model evaluation; Natural language processing systems","","John Wiley and Sons Inc","English","Article","Article in press","All Open Access; Green Open Access","Scopus","2-s2.0-85203066672"
"Abraham S.; Ewards V.; Terence S.","Abraham, Shawn (59221555800); Ewards, Vinodh (59221693400); Terence, Sebastian (58642379000)","59221555800; 59221693400; 58642379000","Interactive Video Virtual Assistant Framework with Retrieval Augmented Generation for E-Learning","2024","Proceedings of the 3rd International Conference on Applied Artificial Intelligence and Computing, ICAAIC 2024","","","","1192","1199","7","0","10.1109/ICAAIC60222.2024.10575255","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198722106&doi=10.1109%2fICAAIC60222.2024.10575255&partnerID=40&md5=4166fd32daa6960531da8be505b9437d","Karunya Institute of Technology and Sciences, Department of Computer Science and Engineering, Coimbatore, India","Abraham S., Karunya Institute of Technology and Sciences, Department of Computer Science and Engineering, Coimbatore, India; Ewards V., Karunya Institute of Technology and Sciences, Department of Computer Science and Engineering, Coimbatore, India; Terence S., Karunya Institute of Technology and Sciences, Department of Computer Science and Engineering, Coimbatore, India","In the era of a new digital world, there has been a decline in social interactions among humans in a physical setting. These concerns have made educational institutions focus on holistic development, which is recognized to be crucial for the overall growth and performance of a student. Nevertheless, concerns like inadequate student teacher and peer interactions, in an online setting can have adverse effects in the long run. This paper presents an analysis and the benefits of utilizing an interactive virtual assistant framework as a means to abridge the growing disconnect of modern technologies from the traditional classroom setting, closing in on the gap brought about by virtual learning medium. This research study examines the online and hybrid learning approach, highlighting its drawbacks in comparison to conventional teaching methodologies while trying to improve the current situation. The virtual assistant framework presented in this study makes use of cutting-edge technologies in the field of NLP dialogue systems and video generation using Wav2Lip, (a lip-sync model) and GFPGAN model for face-specific enhancement. The Virtual assistant is developed and demonstrated as a learning aid in both hybrid and physical classrooms. Further applications and performance improvements of the framework are discussed. © 2024 IEEE.","Generative Adversarial Network (GAN); interactive learning; Interactive Virtual Assistant (IVA); Large Language Model (LLM); Lip-sync; Retrieval Augmented Generation (RAG); Vector store; Video Chatbot","Generative adversarial networks; Learning systems; Speech processing; Students; Chatbots; Generative adversarial network; Interactive learning; Interactive virtual assistant; Language model; Large language model; Lip sync; Retrieval augmented generation; Vector store; Video chatbot; Virtual assistants; E-learning","","Institute of Electrical and Electronics Engineers Inc.","English","Conference paper","Final","","Scopus","2-s2.0-85198722106"
"Petrović N.; Suljović S.; Dordević S.; Vujović V.; Stokić I.","Petrović, Nenad (57206900973); Suljović, Suad (54403894300); Dordević, Srdan (58761126000); Vujović, Vuk (57191580496); Stokić, Ivana (59323976800)","57206900973; 54403894300; 58761126000; 57191580496; 59323976800","RAG-Enriched Approach to Network Standardization: MGF Based Calculation of Average Bit Error Probability in Nakagami-m Fading Environment with Selection Diversity Receiver Case Study","2024","2024 59th International Scientific Conference on Information, Communication and Energy Systems and Technologies, ICEST 2024 - Proceedings","","","","","","","0","10.1109/ICEST62335.2024.10639812","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203719494&doi=10.1109%2fICEST62335.2024.10639812&partnerID=40&md5=b4768aff4835fcfa629c7969262a266b","University of Niš, Faculty of Electronic Engineering, Niš, Serbia; Academy of Applied Technical Studies Belgrade, Belgrade, Serbia; Information Technology MB University, Belgrade, Serbia","Petrović N., University of Niš, Faculty of Electronic Engineering, Niš, Serbia; Suljović S., Academy of Applied Technical Studies Belgrade, Belgrade, Serbia; Dordević S., Academy of Applied Technical Studies Belgrade, Belgrade, Serbia; Vujović V., Information Technology MB University, Belgrade, Serbia; Stokić I., Academy of Applied Technical Studies Belgrade, Belgrade, Serbia","This paper analyzes a wireless system subject to Nakagami-m fading and Nakagami-m co-channel interference (CCI). To counteract these adverse effects at the receiver, an L-branch SC receiver is employed. The study calculates the average bit error probability (ABEP) using the moment generating function (MGF) for a wireless system with SC combining. Analytical results for CCI will be derived in closed form and presented graphically. Additionally, we introduce LLM-based approach leveraging RAG in order to reduce effort needed for standardisation compliance in network experiments.  © 2024 IEEE.","Average Bit Error Probability (ABEP); Co-Channel Interference (CCI); Moment Generating Function (MGF); Nakagami-m; Retrieval Augmented Generation (RAG); Selection Combining (SC)","Communication channels (information theory); Error statistics; Fading channels; Radiation hardening; Average bit error probability; Co-channel interference; Co-channel interferences; Generating functions; Moment generating function; Nakagami-m; Retrieval augmented generation; Selection combining; Cochannel interference","Dimitrov K.L.; Doncov N.S.; Kostov M.","Institute of Electrical and Electronics Engineers Inc.","English","Conference paper","Final","","Scopus","2-s2.0-85203719494"
"Vidivelli S.; Ramachandran M.; Dharunbalaji A.","Vidivelli, S. (49362389100); Ramachandran, Manikandan (37061393600); Dharunbalaji, A. (58220533000)","49362389100; 37061393600; 58220533000","Efficiency-Driven Custom Chatbot Development: Unleashing LangChain, RAG, and Performance-Optimized LLM Fusion","2024","Computers, Materials and Continua","80","2","","2423","2442","19","0","10.32604/cmc.2024.054360","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201286479&doi=10.32604%2fcmc.2024.054360&partnerID=40&md5=6bd5fb1835bace53ee4d3a498b2e4e9a","School of Computing, SASTRA Deemed University, Tamilnadu, Thanjavur, 613401, India","Vidivelli S., School of Computing, SASTRA Deemed University, Tamilnadu, Thanjavur, 613401, India; Ramachandran M., School of Computing, SASTRA Deemed University, Tamilnadu, Thanjavur, 613401, India; Dharunbalaji A., School of Computing, SASTRA Deemed University, Tamilnadu, Thanjavur, 613401, India","This exploration acquaints a momentous methodology with custom chatbot improvement that focuses on proficiency close by viability. We accomplish this by joining three key innovations: LangChain, Retrieval Augmented Generation (RAG), and enormous language models (LLMs) tweaked with execution proficient strategies like LoRA and QLoRA. LangChain takes into consideration fastidious fitting of chatbots to explicit purposes, guaranteeing engaged and important collaborations with clients. RAG’s web scratching capacities engage these chatbots to get to a tremendous store of data, empowering them to give exhaustive and enlightening reactions to requests. This recovered data is then decisively woven into reaction age utilizing LLMs that have been calibrated with an emphasis on execution productivity. This combination approach offers a triple advantage: further developed viability, upgraded client experience, and extended admittance to data. Chatbots become proficient at taking care of client questions precisely and productively, while instructive and logically pertinent reactions make a more regular and drawing in cooperation for clients. At last, web scratching enables chatbots to address a more extensive assortment of requests by conceding them admittance to a more extensive information base. By digging into the complexities of execution proficient LLM calibrating and underlining the basic job of web-scratched information, this examination offers a critical commitment to propelling custom chatbot plan and execution. The subsequent chatbots feature the monstrous capability of these advancements in making enlightening, easy to understand, and effective conversational specialists, eventually changing the manner in which clients cooperate with chatbots. © 2024 Tech Science Press. All rights reserved.","fine tuning; LangChain; retrieval augumental generation (RAG)","Chatbots; Combination approaches; Fine tuning; Information basis; Langchain; Language model; Performance; Retrieval augumental generation; Information use","","Tech Science Press","English","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85201286479"
"Batista V.A.; Gomes D.S.M.; Evsukoff A.","Batista, Vitor A. (58195039500); Gomes, Diogo S. M. (57220037802); Evsukoff, Alexandre (6603431535)","58195039500; 57220037802; 6603431535","SESAME - self-supervised framework for extractive question answering over document collections","2024","Journal of Intelligent Information Systems","","","","","","","0","10.1007/s10844-024-00869-6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200053286&doi=10.1007%2fs10844-024-00869-6&partnerID=40&md5=28be74cc3a95ab80f91eab6489242768","PEC/Coppe, Federal University of Rio de Janeiro, POBox 68506, RJ, Rio de Janeiro, 21941-972, Brazil; PETROBRAS S.A., Rua General Canabarro, 500, RJ, Rio de Janeiro, Brazil","Batista V.A., PEC/Coppe, Federal University of Rio de Janeiro, POBox 68506, RJ, Rio de Janeiro, 21941-972, Brazil, PETROBRAS S.A., Rua General Canabarro, 500, RJ, Rio de Janeiro, Brazil; Gomes D.S.M., PETROBRAS S.A., Rua General Canabarro, 500, RJ, Rio de Janeiro, Brazil; Evsukoff A., PEC/Coppe, Federal University of Rio de Janeiro, POBox 68506, RJ, Rio de Janeiro, 21941-972, Brazil","Question Answering is one of the most relevant areas in the field of Natural Language Processing, rapidly evolving with promising results due to the increasing availability of suitable datasets and the advent of new technologies, such as Generative Models. This article introduces SESAME, a Self-supervised framework for Extractive queStion Answering over docuMent collEctions. SESAME aims to enhance open-domain question answering systems (ODQA) by leveraging domain adaptation with synthetic datasets, enabling efficient question answering over private document collections with low resource usage. The framework incorporates recent advances with large language models, and an efficient hybrid method for context retrieval. We conducted several sets of experiments with the Machine Reading for Question Answering (MRQA) 2019 Shared Task datasets, FAQuAD - a Brazilian Portuguese reading comprehension dataset, Wikipedia, and Retrieval-Augmented Generation Benchmark, to demonstrate SESAME’s effectiveness. The results indicate that SESAME’s domain adaptation using synthetic data significantly improves QA performance, generalizes across different domains and languages, and competes with or surpasses state-of-the-art systems in ODQA. Finally, SESAME is an open-source tool, and all code, datasets and experimental data are available for public use in our repository. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2024.","LLM; Neural networks; NLP; Question answering; Transformers","Open systems; Document collection; Domain adaptation; Language processing; LLM; Natural languages; Neural-networks; Open domain question answering; Question Answering; Question answering systems; Transformer; Natural language processing systems","","Springer","English","Article","Article in press","","Scopus","2-s2.0-85200053286"
"Sokolov A.P.; Zamelin P.; Kamelina Y.; Plastova P.","Sokolov, Andrey P. (59180520600); Zamelin, Pavel (59234587300); Kamelina, Yulia (59234587400); Plastova, Polina (59234214800)","59180520600; 59234587300; 59234587400; 59234214800","Generative Reader Optimization in the RAG-System","2024","Proceedings of 2024 5th International Conference on Neural Networks and Neurotechnologies, NeuroNT 2024","","","","135","138","3","0","10.1109/NeuroNT62606.2024.10585446","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199670868&doi=10.1109%2fNeuroNT62606.2024.10585446&partnerID=40&md5=c3c325a774deacd9937ddabed27e2f69","Moscow State University, Moscow, Russian Federation; National Research Universit, Higher School of Economics Nizhniy, Novgorog, Russian Federation; National Research Lobachevsky, State University of Nizhny Novgorod, Nizhny Novgorod, Russian Federation","Sokolov A.P., Moscow State University, Moscow, Russian Federation; Zamelin P., National Research Universit, Higher School of Economics Nizhniy, Novgorog, Russian Federation; Kamelina Y., National Research Lobachevsky, State University of Nizhny Novgorod, Nizhny Novgorod, Russian Federation; Plastova P., National Research Lobachevsky, State University of Nizhny Novgorod, Nizhny Novgorod, Russian Federation","This paper proposes the simple methodology for optimizing a generative reader subsystem as part of a RAG QA-system. Described methodology can be used as a preliminary optimization that could help building the question-answering system of the reasonable quality in a short time period. The main principle of this methodology is the usage of the OpenAI 's GPT-4 generative model as a gold reference generative reader. Our methodology describes the procedure for generation of the synthetic dataset and defines main optimization metrics. Usage of synthetic datasets makes it possible to accurately control that all changes in the QA-system make its answers closer in average to the gold reference reader. Based on the developed methodology we performed the set of basic optimization experiments to quickly find the better configuration of the reader subsystem. These experiments made it possible to significantly improve the quality of the answers of the reader subsystem. As a result, we achieved relative improvement of the semantic similarity between the answers of our reader and the reference one based on GPT-4 for almost 50% by BLEURT scale and 26% by the SAS scale. Our methodology was verified on the QA-dataset in Russian language but it's also applicable to any other language without significant modifications.  © 2024 IEEE.","LLM; QA-systems; RAG; retriever augmented generation; semantic similarity","Gold; LLM; Optimisations; QA system; Question answering systems; RAG; Retriever augmented generation; Semantic similarity; Simple++; Synthetic datasets; Time-periods; Semantics","Shaposhnikov S.; Saint Petersburg Electrotechnical University �LETI�, Prof. Popov Str. 5, Saint Petersburg","Institute of Electrical and Electronics Engineers Inc.","English","Conference paper","Final","","Scopus","2-s2.0-85199670868"
"Kováčiková J.V.; Šuppa M.","Kováčiková, Jana Viktória (59278311100); Šuppa, Marek (57220026093)","59278311100; 57220026093","Thinking, Fast and Slow: From the Speed of FastText to the Depth of Retrieval Augmented Large Language Models For Humour Classification","2024","CEUR Workshop Proceedings","3740","","","1862","1867","5","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201632876&partnerID=40&md5=efc0b924345107af0f264372f10137c7","Comenius University, Bratislava, Slovakia; Cisco Systems, United States","Kováčiková J.V., Comenius University, Bratislava, Slovakia; Šuppa M., Comenius University, Bratislava, Slovakia, Cisco Systems, United States","In this paper, we present the submission of our team NaiveNeuron to the JOKER 2024 task competition on Automatic Humour Analysis. Our first approach involves utilizing a fastText classifier for Task 2. Our subsequent approaches then incorporate Retrieval-Augmented Generation (RAG) with Large Language Models (LLMs) and adapt it for Humour Classification. By utilizing fastText, known for its efficiency, along with the depth and contextual understanding provided by RAG-enhanced LLMs, we demonstrate significant potential for improvements in humour detection accuracy. Although such systems may not be able to obtain the best possible accuracy as of yet, due to their simplicity we view them as highly potent baselines and believe they may be a very solid starting point for future research in this area. © 2024 Copyright for this paper by its authors.","fastText; Humour classification; Large Language Model; Retrieval Agumented Generation","Contextual understanding; Detection accuracy; Fasttext; Humor classification; Its efficiencies; Language model; Large language model; Retrieval agumented generation; Classification (of information)","Faggioli G.; Ferro N.; Galuscakova P.; de Herrera A.G.S.","CEUR-WS","English","Conference paper","Final","","Scopus","2-s2.0-85201632876"
"Zeng S.; Zhang J.; He P.; Xing Y.; Liu Y.; Xu H.; Ren J.; Wang S.; Yin D.; Chang Y.; Tang J.","Zeng, Shenglai (58825289600); Zhang, Jiankun (58899565800); He, Pengfei (57226608397); Xing, Yue (57218201336); Liu, Yiding (57194505428); Xu, Han (57218087947); Ren, Jie (57211311893); Wang, Shuaiqiang (22636318500); Yin, Dawei (35759826200); Chang, Yi (25824668400); Tang, Jiliang (56245477300)","58825289600; 58899565800; 57226608397; 57218201336; 57194505428; 57218087947; 57211311893; 22636318500; 35759826200; 25824668400; 56245477300","The Good and The Bad: Exploring Privacy Issues in Retrieval-Augmented Generation (RAG)","2024","Proceedings of the Annual Meeting of the Association for Computational Linguistics","","","","4505","4524","19","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198150173&partnerID=40&md5=d1d3b59494a4403339fac21f1960bd3f","Michigan State University, United States; Baidu, Inc.; School of Artificial Intelligence, Jilin University, China; International Center of Future Science, Jilin University, China; Engineering Research Center of Knowledge-Driven Human-Machine Intelligence, MOE, China","Zeng S., Michigan State University, United States; Zhang J., School of Artificial Intelligence, Jilin University, China, International Center of Future Science, Jilin University, China, Engineering Research Center of Knowledge-Driven Human-Machine Intelligence, MOE, China; He P., Michigan State University, United States; Xing Y., Michigan State University, United States; Liu Y., Baidu, Inc.; Xu H., Michigan State University, United States; Ren J., Michigan State University, United States; Wang S., Baidu, Inc.; Yin D., Baidu, Inc.; Chang Y., School of Artificial Intelligence, Jilin University, China, International Center of Future Science, Jilin University, China, Engineering Research Center of Knowledge-Driven Human-Machine Intelligence, MOE, China; Tang J., Michigan State University, United States","Retrieval-augmented generation (RAG) is a powerful technique to facilitate language model with proprietary and private data, where data privacy is a pivotal concern. Whereas extensive research has demonstrated the privacy risks of large language models (LLMs), the RAG technique could potentially reshape the inherent behaviors of LLM generation, posing new privacy issues that are currently under-explored. In this work, we conduct extensive empirical studies with novel attack methods, which demonstrate the vulnerability of RAG systems on leaking the private retrieval database. Despite the new risk brought by RAG on the retrieval data, we further reveal that RAG can mitigate the leakage of the LLMs' training data. Overall, we provide new insights in this paper for privacy protection of retrieval-augmented LLMs, which benefit both LLMs and RAG systems builders. Our code is available at https://github.com/phycholosogy/RAG-privacy. © 2024 Association for Computational Linguistics.","","Anonymity; Computational linguistics; Data privacy; Information leakage; Attack methods; Empirical studies; Generation systems; Generation techniques; Language model; Model generation; Model training; Privacy issue; Privacy risks; Private data; Differential privacy","Ku L.-W.; Martins A.; Srikumar V.","Association for Computational Linguistics (ACL)","English","Conference paper","Final","","Scopus","2-s2.0-85198150173"
"Miladi F.; Psyché V.; Lemire D.","Miladi, Fatma (57198347276); Psyché, Valéry (22433359100); Lemire, Daniel (10238969400)","57198347276; 22433359100; 10238969400","Comparative Performance of GPT-4, RAG-Augmented GPT-4, and Students in MOOCs","2024","Communications in Computer and Information Science","2162 CCIS","","","81","92","11","0","10.1007/978-3-031-65996-6_7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200739796&doi=10.1007%2f978-3-031-65996-6_7&partnerID=40&md5=b70c533d14dde233565a0b7d3e59686b","TELUQ University, 5800 rue Saint-Denis, Montreal, H2S 3L5, QC, Canada","Miladi F., TELUQ University, 5800 rue Saint-Denis, Montreal, H2S 3L5, QC, Canada; Psyché V., TELUQ University, 5800 rue Saint-Denis, Montreal, H2S 3L5, QC, Canada; Lemire D., TELUQ University, 5800 rue Saint-Denis, Montreal, H2S 3L5, QC, Canada","Generative Pretrained Transformers (GPT) have significantly improved natural language processing, showcasing enormous versatility across diverse applications. Although GPT models have enormous potential, they frequently encounter issues such as mistakes and hallucinations, which may limit their practical use. Addressing these shortcomings, Retrieval-Augmented Generation (RAG) represents an innovative approach that potentially enhances the accuracy and reliability of these models by leveraging external databases to correct and enrich their outputs. In our study, a RAG-augmented GPT-4 model was tested within an AI-focused Massive Open Online Course (MOOC) and outperformed a standard GPT-4 model, achieving an 85% success rate compared to 81%. Notably, it also surpassed the average student performance, underscoring its ability to deliver precise and contextually relevant responses. These findings suggest the potential of RAG in enhancing AI models for educational use and indicate that instructors can leverage this technology to refine assessment methods and that students can achieve more personalized and engaging learning experiences. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.","Evaluation; GPT; Large Language Models; MOOC; Online Education; Retrieval-Augmented Generation; Text Embeddings","E-learning; Education computing; Embeddings; Natural language processing systems; Comparative performance; Embeddings; Evaluation; Generative pretrained transformer; Language model; Large language model; Massive open online course; On-line education; Retrieval-augmented generation; Text embedding; Students","Basiouni A.; Frasson C.","Springer Science and Business Media Deutschland GmbH","English","Conference paper","Final","","Scopus","2-s2.0-85200739796"
"Kamel Boulos M.N.; Dellavalle R.","Kamel Boulos, Maged N. (35268147800); Dellavalle, Robert (7003806771)","35268147800; 7003806771","NVIDIA’s “Chat with RTX” Custom Large Language Model and Personalized AI Chatbot Augments the Value of Electronic Dermatology Reference Material","2024","JMIR Dermatology","7","","e58396","","","","0","10.2196/58396","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200647996&doi=10.2196%2f58396&partnerID=40&md5=8b42887ef414bd4664dba18ea42f8bcc","School of Medicine, University of Lisbon, Lisbon, Portugal; Department of Dermatology, University of Minnesota Medical School, Minneapolis, MN, United States","Kamel Boulos M.N., School of Medicine, University of Lisbon, Lisbon, Portugal; Dellavalle R., Department of Dermatology, University of Minnesota Medical School, Minneapolis, MN, United States","This paper demonstrates a new, promising method using generative artificial intelligence (AI) to augment the educational value of electronic textbooks and research papers (locally stored on user’s machine) and maximize their potential for self-study, in a way that goes beyond the standard electronic search and indexing that is already available in all of these textbooks and files. The presented method runs fully locally on the user’s machine, is generally affordable, and does not require high technical expertise to set up and customize with the user’s own content. © Maged N Kamel Boulos, Robert Dellavalle.","AI; AI chatbots; artificial intelligence; dermatology; education; generative AI; large language models; NVIDIA RTX; RAG; retrieval-augmented generation; self-study","","","JMIR Publications Inc.","English","Review","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85200647996"
"Samarajeewa C.; De Silva D.; Osipov E.; Alahakoon D.; Manic M.","Samarajeewa, Chamod (57206898891); De Silva, Daswin (55242193900); Osipov, Evgeny (14042402300); Alahakoon, Damminda (6602546111); Manic, Milos (6603474732)","57206898891; 55242193900; 14042402300; 6602546111; 6603474732","Causal Reasoning in Large Language Models using Causal Graph Retrieval Augmented Generation","2024","International Conference on Human System Interaction, HSI","","","","","","","0","10.1109/HSI61632.2024.10613566","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201523447&doi=10.1109%2fHSI61632.2024.10613566&partnerID=40&md5=dceeddff54c1a4c2b0a7b43b9980a227","La Trobe University, Centre for Data Analytics and Cognition, Australia; Luleå University of Technology, Department of Computer Science, Electrical and Space Engineering, Sweden; Virginia Commonwealth University, Department of Computer Science, Richmond, United States","Samarajeewa C., La Trobe University, Centre for Data Analytics and Cognition, Australia; De Silva D., La Trobe University, Centre for Data Analytics and Cognition, Australia; Osipov E., Luleå University of Technology, Department of Computer Science, Electrical and Space Engineering, Sweden; Alahakoon D., La Trobe University, Centre for Data Analytics and Cognition, Australia; Manic M., Virginia Commonwealth University, Department of Computer Science, Richmond, United States","Large Language Models (LLMs) are leading the Generative Artificial Intelligence transformation in natural language understanding. Beyond language understanding, LLMs have demonstrated capabilities in reasoning tasks, including commonsense, logical, and mathematical reasoning. However, their proficiency in causal understanding has been limited due to the complex nature of causal reasoning. Several recent studies have discussed the role of external causal models for improved causal understanding. Building on the success of Retrieval-Augmented Generation (RAG) for factual reasoning in LLMs, this paper introduces a novel approach that utilizes Causal Graphs as external sources for establishing causal relationships between complex vectors. This method is empirically evaluated using two benchmark datasets across the metrics of Context Relevance, Answer Relevance, and Grounding, in its ability to retrieve relevant context with causal alignment. The retrieval effectiveness is further compared with traditional RAG methods that are based on semantic proximity.  © 2024 IEEE.","","Generative adversarial networks; Causal graph; Causal reasoning; Commonsense reasoning; Complex nature; Language model; Language understanding; Logical reasoning; Mathematical reasoning; Natural language understanding; Reasoning tasks; Semantics","","IEEE Computer Society","English","Conference paper","Final","","Scopus","2-s2.0-85201523447"
"Kuppa A.; Nicholls J.; Le-Khac N.-A.","Kuppa, Aditya (57210862271); Nicholls, Jack (57221812852); Le-Khac, Nhien-An (16175564100)","57210862271; 57221812852; 16175564100","Manipulating Prompts and Retrieval-Augmented Generation for LLM Service Providers","2024","Proceedings of the International Conference on Security and Cryptography","","","","777","785","8","0","10.5220/0012803100003767","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202904232&doi=10.5220%2f0012803100003767&partnerID=40&md5=176054f4b48a45799c94278edfd9012b","Mirror Security, Dublin, Ireland; School of Computer Science, Univeristy College Dublin, Dublin, Ireland","Kuppa A., Mirror Security, Dublin, Ireland; Nicholls J., Mirror Security, Dublin, Ireland; Le-Khac N.-A., School of Computer Science, Univeristy College Dublin, Dublin, Ireland","The emergence of large language models (LLMs) has revolutionized the field of AI, introducing a new era of generative models applied across diverse use cases. Within this evolving AI application ecosystem, numerous stakeholders, including LLM and AI application service providers, use these models to cater to user needs. A significant challenge arises due to the need for more visibility and understanding of the inner workings of these models to end-users. This lack of transparency can lead to concerns about how the models are being used, how outputs are generated, the nature of the data they are trained on, and the potential biases they may harbor. The user trust becomes a critical aspect of deploying and managing these advanced AI applications. This paper highlights the safety and integrity issues associated with service providers who may introduce covert, unsafe policies into their systems. Our study focuses on two attacks: the injection of biased content in generative AI search services, and the manipulation of LLM outputs during inference by altering attention heads. Through empirical experiments, we show that malicious service providers can covertly inject malicious content into the outputs generated by LLMs without the awareness of the end-user. This study reveals the subtle yet significant ways LLM outputs can be compromised, highlighting the importance of vigilance and advanced security measures in AI-driven applications. We demonstrate empirically that is it possible to increase the citation score of LLM output to include erroneous or unnecessary sources of information to redirect a reader to a desired source of information. © 2024 by SCITEPRESS – Science and Technology Publications, Lda.","Adversarial; Generative AI; LLM; Security; Service Providers","","Di Vimercati S.De.C.; Samarati P.","Science and Technology Publications, Lda","English","Conference paper","Final","","Scopus","2-s2.0-85202904232"
"Taylor A.; Magwira M.; Chamangwana C.; Chapuma E.; Liwewe T.; Kankhwali C.","Taylor, Amelia (57218954988); Magwira, Macphail (59323922800); Chamangwana, Chimwemwe (59323764500); Chapuma, Evelyn (59323764600); Liwewe, Thokozani (59253177100); Kankhwali, Chisomo (59253088600)","57218954988; 59323922800; 59323764500; 59323764600; 59253177100; 59253088600","Self-Directed Learning for Community Health Workers in Malawi Through Generative AI","2024","Proceedings - 2024 IEEE 12th International Conference on Healthcare Informatics, ICHI 2024","","","","574","579","5","0","10.1109/ICHI61247.2024.00092","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203710302&doi=10.1109%2fICHI61247.2024.00092&partnerID=40&md5=86666d832e0b55df60a74e65f5804528","Malawi University of Business and Applied Sciences, Blantyre, Malawi; Kuyesera AI Lab., Blantyre, Malawi; Lilongwe District Health Office, Malawi","Taylor A., Malawi University of Business and Applied Sciences, Blantyre, Malawi, Kuyesera AI Lab., Blantyre, Malawi; Magwira M., Kuyesera AI Lab., Blantyre, Malawi; Chamangwana C., Kuyesera AI Lab., Blantyre, Malawi; Chapuma E., Kuyesera AI Lab., Blantyre, Malawi; Liwewe T., Kuyesera AI Lab., Blantyre, Malawi, Lilongwe District Health Office, Malawi; Kankhwali C., Kuyesera AI Lab., Blantyre, Malawi, Lilongwe District Health Office, Malawi","In many lower and middle-income countries, a lack of resources affects the availability and quality of education and training. In the healthcare domain, access to knowledge can make the difference between life and death. Timely access to technical and clinical guidelines to support decisions is crucial. Healthcare workers need access to up-to-date guidelines on case definitions for surveillance, treatment protocols, and relevant clinical and medical knowledge. However, guidelines documents tend to be bulky and complex and may change over time in response to health priorities, research, or public health emergencies. Generative AI has proven to be a disruptive technology in health care, but its limitations and applicability are subject to experimentation. We present evidence that Large Language Models (LLMs) can be leveraged to facilitate needs-driven and self-directed learning regarding guidelines for healthcare professionals in Malawi. We developed an application called IntelSurv that uses GPT -4 to achieve a 'chat' -like functionality where users ask questions about priority diseases, seek clarification on the use of case identification forms, and have access to technical guidelines published by the Ministry of Health. IntelSurv is both a web app and a mobile app and can run either online or offline. Healthcare professionals engaged in disease surveillance and community health in two major cities in Malawi tested the tool and gave positive feedback on its impact. We report on the development of the tool, and its use of GPT -4. We discuss choices of features and functionalities in response to testing and feedback from users. © 2024 IEEE.","answers dataset; community health workers; feedback loop; GPT-4; LLMs; prompting; questions; RAG; self-directed learning","Diseases; Personnel training; Answer dataset; Community Health Workers; Feedback loops; GPT-4; Language model; Large language model; Prompting; Question; RAG; Self-directed learning; Electronic health record","","Institute of Electrical and Electronics Engineers Inc.","English","Conference paper","Final","","Scopus","2-s2.0-85203710302"
"Bakharia A.; Abdi S.","Bakharia, Aneesha (35483119700); Abdi, Solmaz (57215930238)","35483119700; 57215930238","Shaping Programming and Data Science Education: Insights from GenAI Technical Book Trends","2024","Proceedings - 2024 IEEE International Conference on Advanced Learning Technologies, ICALT 2024","","","","116","120","4","0","10.1109/ICALT61570.2024.00040","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203800202&doi=10.1109%2fICALT61570.2024.00040&partnerID=40&md5=fd0d54872787fcfbec2c1fcd467c70cf","School of Electrical Engineering and Computer Science, The University of Queensland, Brisbane, Australia; Australian Energy Market Operator, Brisbane, Australia","Bakharia A., School of Electrical Engineering and Computer Science, The University of Queensland, Brisbane, Australia; Abdi S., Australian Energy Market Operator, Brisbane, Australia","As GenAI technologies, particularly Large Language Models (LLMs), continue to revolutionize programming and data science, it is increasingly vital for educators to adapt computer science curricula. This paper presents a review of recent technical books on AI-Assisted programming and utilizes the findings to guide curriculum changes in higher education. Our analysis underscores the necessity for novel teaching strategies, emphasizing skills like problem decomposition, top-down design, and advanced debugging. Furthermore, it emphasizes the crucial expansion of curricula to encompass courses on developing applications based on LLMs, utilizing libraries such as LangChain and incorporating Retrieval Augmented Generation functionality. Our analysis reveals a significant gap in technical literature regarding the ethical and societal impacts of GenAI, highlighting the urgent need for programming curricula to evolve and equip students with the skills required to ethically develop AI-enhanced software products. This paper advocates for curriculum development that not only aligns with the latest industry trends but also contributes to research on AI-assisted coding and its future impact. © 2024 IEEE.","AI-assisted programming; Data science education; Programming curriculum development; Programming education","Artificial intelligence; AI-assisted programming; Computer science curricula; Curriculum changes; Curriculum development; Data science education; High educations; Language model; Programming curriculum development; Programming education; Science education; Data Science","Altinay Z.; Chang M.; Kuo R.; Tlili A.","Institute of Electrical and Electronics Engineers Inc.","English","Conference paper","Final","","Scopus","2-s2.0-85203800202"
"","","","CLEF 2024 - Working Notes of the Conference and Labs of the Evaluation Forum","2024","CEUR Workshop Proceedings","3740","","","","","3529","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201594389&partnerID=40&md5=9a90cca38596b7391cd3bbcd62ef658e","","","The proceedings contain 339 papers. The topics discussed include: overview of MultiCardioNER task at BioASQ 2024 on medical specialty and language adaptation of clinical NER systems for Spanish, English and Italian; transformer-based disease and drug named entity recognition in multilingual clinical texts: MultiCardioNER challenge; LLM fine-tuning with biomedical open-source data; can open-source LLMs compete with commercial models? exploring the few-shot performance of current GPT models in biomedical tasks; multilingual clinical NER for diseases and medications recognition in cardiology texts using BERT embeddings; enhancing biomedical question answering with parameter-efficient fine-tuning and hierarchical retrieval augmented generation; generative large language models augmented hybrid retrieval system for biomedical question answering; comparative analyses of multilingual drug entity recognition systems for clinical case reports in cardiology; and enhancing biomedical document ranking with domain knowledge incorporation in a multi-stage retrieval approach.","","","Faggioli G.; Ferro N.; Galuscakova P.; de Herrera A.G.S.","CEUR-WS","English","Conference review","Final","","Scopus","2-s2.0-85201594389"
"","","","32nd International Conference on Case-Based Reasoning, ICCBR 2024","2024","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","14775 LNAI","","","","","460","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198482399&partnerID=40&md5=909e46f468f0730419b64b5c01b1f99e","","","The proceedings contain 29 papers. The special focus in this conference is on Case-Based Reasoning. The topics include: CBRkit: An Intuitive Case-Based Reasoning Toolkit for Python; towards a Case-Based Support for Responding Emergency Calls; Examining the Potential of Sequence Patterns from EEG Data as Alternative Case Representation for Seizure Detection; identifying Missing Sensor Values in IoT Time Series Data: A Weight-Based Extension of Similarity Measures for Smart Manufacturing; Explaining Multiple Instances Counterfactually:User Tests of Group-Counterfactuals for XAI; The Intelligent Tutoring System AI-VT with Case-Based Reasoning and Real Time Recommender Models; ensemble Stacking Case-Based Reasoning for Regression; Extracting Indexing Features for CBR from Deep Neural Networks: A Transfer Learning Approach; An Empirical Analysis of User Preferences Regarding XAI Metrics; Use Case-Specific Reuse of XAI Strategies: Design and Analysis Through an Evaluation Metrics Library; Visualization of Similarity Models for CBR Comprehension and Maintenance; improving Complex Adaptations in Process-Oriented Case-Based Reasoning by Applying Rule-Based Adaptation; even-Ifs from If-Onlys: Are the Best Semi-factual Explanations Found Using Counterfactuals as Guides?; preface; using Case-Based Causal Reasoning to Provide Explainable Counterfactual Diagnosis in Personalized Sprint Training; Retrieval Augmented Generation with LLMs for Explaining Business Process Models; Integrating kNN Retrieval with Inference on Graphical Models in Case-Based Reasoning; counterfactual-Based Synthetic Case Generation; Automatic Adjusting Global Similarity Measures in Learning CBR Systems; a Case-Based Reasoning and Explaining Model for Temporal Point Process; item-Specific Similarity Assessments for Explainable Depression Screening; autocompletion of Architectural Spatial Configurations Using Case-Based Reasoning, Graph Clustering, and Deep Learning; olaaaf: A General Adaptation Prototype; CBR-Ren: A Case-Based Reasoning Driven Retriever-Generator Model for Hybrid Long-Form Numerical Reasoning; CBR-RAG: Case-Based Reasoning for Retrieval Augmented Generation in LLMs for Legal Question Answering; on Implementing Case-Based Reasoning with Large Language Models; aligning to Human Decision-Makers in Military Medical Triage.","","","Recio-Garcia J.A.; Orozco-del-Castillo M.G.; Bridge D.","Springer Science and Business Media Deutschland GmbH","English","Conference review","Final","","Scopus","2-s2.0-85198482399"
"Ghanbari Haez S.; Segala M.; Bellan P.; Magnolini S.; Sanna L.; Consolandi M.; Dragoni M.","Ghanbari Haez, Saba (57865001400); Segala, Marina (59156410800); Bellan, Patrizio (57204825247); Magnolini, Simone (56530696900); Sanna, Leonardo (59265215200); Consolandi, Monica (57216831165); Dragoni, Mauro (19638448200)","57865001400; 59156410800; 57204825247; 56530696900; 59265215200; 57216831165; 19638448200","A Retrieval-Augmented Generation Strategy to Enhance Medical Chatbot Reliability","2024","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","14844 LNAI","","","213","223","10","0","10.1007/978-3-031-66538-7_22","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200788990&doi=10.1007%2f978-3-031-66538-7_22&partnerID=40&md5=7876303e36127a3ff1264c4c07365321","Fondazione Bruno Kessler, Trento, Italy; Free University of Bozen, Bolzano, Italy","Ghanbari Haez S., Fondazione Bruno Kessler, Trento, Italy, Free University of Bozen, Bolzano, Italy; Segala M., Fondazione Bruno Kessler, Trento, Italy; Bellan P., Fondazione Bruno Kessler, Trento, Italy; Magnolini S., Fondazione Bruno Kessler, Trento, Italy; Sanna L., Fondazione Bruno Kessler, Trento, Italy; Consolandi M., Fondazione Bruno Kessler, Trento, Italy; Dragoni M., Fondazione Bruno Kessler, Trento, Italy","The advent of Large Language Models opened new perspectives concerning their usage within the digital health domain. However, their intrinsic probabilistic and unpredictable behavior needs the design of trustworthy strategies aiming to avoid the creation of hallucinations that, especially within the digital health domain, may lead to severe harm. Such an issue has been addressed with the adoption of Retrieval-Augmented Generation solutions, where the text generation task is supported by controlled knowledge injected into the prompts. Even if the hallucination issue is mitigated, the generation of certified information (such as trustworthy content granted by the system’s owner) requires more sophisticated strategies. In this work, we propose an approach where the classic Retrieval-Augmented Generation pipeline is enhanced with a further initial step where the Large Language Model is asked to generate a preliminary text used to query the repository of certified information for presenting the appropriate content to the final user. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.","","Information retrieval; Chatbots; Language model; Probabilistics; Text generations; Computational linguistics","Finkelstein J.; Moskovitch R.; Parimbelli E.","Springer Science and Business Media Deutschland GmbH","English","Conference paper","Final","","Scopus","2-s2.0-85200788990"
"Hammane Z.; Ben-Bouazza F.-E.; Fennan A.","Hammane, Zakaria (59301856300); Ben-Bouazza, Fatima-Ezzahraa (57219598648); Fennan, Abdelhadi (55935734000)","59301856300; 57219598648; 55935734000","SelfRewardRAG: Enhancing Medical Reasoning with Retrieval-Augmented Generation and Self-Evaluation in Large Language Models","2024","2024 International Conference on Intelligent Systems and Computer Vision, ISCV 2024","","","","","","","0","10.1109/ISCV60512.2024.10620139","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202354128&doi=10.1109%2fISCV60512.2024.10620139&partnerID=40&md5=03c24aad430e0e0298687748f2e4bf0e","Abdelmalek Essaadi University, Faculty of Sciences Tetouan, Département Informatique, Data and Intelligent Systems (DIS) Team, Tetouan, Morocco; Hassan 1st University, Faculty of Sciences and Technology, Settat LaMSN-la Maison des Sciences, Morocco; Abdelmalek Essaadi University, Faculty of Sciences and Techniques, Department of Computer Sciences, Data and Intelligent Systems (DIS) Team, Tangier, Morocco","Hammane Z., Abdelmalek Essaadi University, Faculty of Sciences Tetouan, Département Informatique, Data and Intelligent Systems (DIS) Team, Tetouan, Morocco; Ben-Bouazza F.-E., Hassan 1st University, Faculty of Sciences and Technology, Settat LaMSN-la Maison des Sciences, Morocco; Fennan A., Abdelmalek Essaadi University, Faculty of Sciences and Techniques, Department of Computer Sciences, Data and Intelligent Systems (DIS) Team, Tangier, Morocco","In this study, we present a pioneering approach known as Retrieval Augmented Generation (RAG), which integrates Large Language Models (LLMs) with dynamic data retrieval to surmount the challenge of knowledge obsolescence, a matter of particular significance in the healthcare domain. This innovative system leverages real-time access to up-to-date clinical records, thereby enabling the generation of precise and informed responses, a notable leap over the conventional limitations faced by LLMs due to their reliance on static datasets. Our methodology embodies the seamless integration of RAG with LLMs to adeptly retrieve pertinent medical information from continuously updated repositories, such as PubMed, and to synthesize this information into accurate responses for medical queries. This advancement marks a considerable enhancement in the application of AI within medical decision-making processes, ensuring that the information provided remains both current and relevant. The effectiveness of our approach is validated through a series of experiments, which demonstrate a significant improvement in the accuracy and timeliness of the AI-generated responses, thereby underscoring its transformative potential for medical AI applications. Furthermore, the foundational principles underlying our system indicate its broader applicability in various other fields confronted with the challenges of rapidly changing knowledge bases. Through this work, we not only address the critical need for real-time information integration in healthcare AI but also establish a paradigm for future AI systems, promoting the incorporation of continuous learning and updating mechanisms to enhance their efficacy and relevance. © 2024 IEEE.","Healthcare; Incorporation; Large Language Models; Retrieval Augmented Generation","Continuous time systems; Data retrieval; Dynamic data; Healthcare; Healthcare domains; Incorporation; Language model; Large language model; Medical reasonings; Retrieval augmented generation; Self evaluation; Obsolescence","Sabri M.A.; Yahyaouy A.; el Fazazy K.; Riffi J.; Mahraz M.A.","Institute of Electrical and Electronics Engineers Inc.","English","Conference paper","Final","","Scopus","2-s2.0-85202354128"
"Wilkerson K.; Leake D.","Wilkerson, Kaitlynne (58618228400); Leake, David (7007094004)","58618228400; 7007094004","On Implementing Case-Based Reasoning with Large Language Models","2024","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","14775 LNAI","","","404","417","13","0","10.1007/978-3-031-63646-2_26","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198431602&doi=10.1007%2f978-3-031-63646-2_26&partnerID=40&md5=7e9bd1a72f7c33703b86d02c415245dc","Luddy School, Indiana University, Bloomington, 47408, IN, United States","Wilkerson K., Luddy School, Indiana University, Bloomington, 47408, IN, United States; Leake D., Luddy School, Indiana University, Bloomington, 47408, IN, United States","Systems based on Large Language Models (LLMs), such as ChatGPT, have impressive performance but also well-known issues with erroneous output. Retrieval Augmented Generation (RAG), which typically presents the LLM with text snippets of additional knowledge retrieved from an external knowledge base, is a popular method for increasing LLM accuracy. This paper presents initial studies exploring augmenting LLMs with cases rather than snippets and prompting LLMs towards performing case-based reasoning. The studies consider four possible scenarios, exploring the potential benefit of LLMs performing different subparts of the CBR process: (1) a scenario in which the LLM is prompted to adapt a presented case, (2) a scenario in which the LLM is first prompted to perform similarity assessment to select a case from a set of candidates, and then to adapt the selected case, (3) a scenario in which the LLM is prompted to select the two most similar cases to a problem and generate an adapted/combined solution in light of both, and (4) a scenario in which the LLM selects the nearest neighbor and nearest unlike neighbor and generates an adapted/combined solution based on both. Results of tests using Llama and ChatGPT are encouraging for the accuracy benefits of providing LLMs with cases and raise questions for future study. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.","Case-Based Reasoning; ChatGPT; Large Language Models; Llama; Retrieval Augmented Generation","Computational linguistics; Knowledge based systems; Additional knowledge; Casebased reasonings (CBR); ChatGPT; Combined solution; Language model; Large language model; Llama; Performance; Retrieval augmented generation; Text snippets; Case based reasoning","Recio-Garcia J.A.; Orozco-del-Castillo M.G.; Bridge D.","Springer Science and Business Media Deutschland GmbH","English","Conference paper","Final","","Scopus","2-s2.0-85198431602"
"O'Leary D.E.","O'Leary, Daniel E. (58406823900)","58406823900","The Rise and Design of Enterprise Large Language Models","2024","IEEE Intelligent Systems","39","1","","60","63","3","2","10.1109/MIS.2023.3345591","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187176216&doi=10.1109%2fMIS.2023.3345591&partnerID=40&md5=a00bc2d954a5827e61f287d75130c3db","University of Southern California, Los Angeles, 90089, CA, United States","O'Leary D.E., University of Southern California, Los Angeles, 90089, CA, United States","This article investigates a new phenomenon of enterprise large language models (ELLMs) focusing on what they are, why they are being developed, and what are some key capabilities. In addition, the article drills down on issues associated with integrating retrieval augmented generation approaches into ELLMs, including emerging research issues.  © 2001-2011 IEEE.","","Drill-down; Language model; Research issues; Computational linguistics","","Institute of Electrical and Electronics Engineers Inc.","English","Article","Final","","Scopus","2-s2.0-85187176216"
"Li J.; Liu Y.; Fan W.; Wei X.-Y.; Liu H.; Tang J.; Li Q.","Li, Jiatong (58109041600); Liu, Yunqing (58109805200); Fan, Wenqi (57188735401); Wei, Xiao-Yong (8880187800); Liu, Hui (57218493066); Tang, Jiliang (56245477300); Li, Qing (57199178903)","58109041600; 58109805200; 57188735401; 8880187800; 57218493066; 56245477300; 57199178903","Empowering Molecule Discovery for Molecule-Caption Translation With Large Language Models: A ChatGPT Perspective","2024","IEEE Transactions on Knowledge and Data Engineering","36","11","","6071","6083","12","3","10.1109/TKDE.2024.3393356","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192189078&doi=10.1109%2fTKDE.2024.3393356&partnerID=40&md5=2ff67f7c267f625ea852d45daece7dfe","The Hong Kong Polytechnic University, Department of Computing, Hung Hom, Hong Kong; Michigan State University, East Lansing, 48824-2604, MI, United States","Li J., The Hong Kong Polytechnic University, Department of Computing, Hung Hom, Hong Kong; Liu Y., The Hong Kong Polytechnic University, Department of Computing, Hung Hom, Hong Kong; Fan W., The Hong Kong Polytechnic University, Department of Computing, Hung Hom, Hong Kong; Wei X.-Y., The Hong Kong Polytechnic University, Department of Computing, Hung Hom, Hong Kong; Liu H., Michigan State University, East Lansing, 48824-2604, MI, United States; Tang J., Michigan State University, East Lansing, 48824-2604, MI, United States; Li Q., The Hong Kong Polytechnic University, Department of Computing, Hung Hom, Hong Kong","Molecule discovery plays a crucial role in various scientific fields, advancing the design of tailored materials and drugs, which contributes to the development of society and human well-being. Specifically, molecule-caption translation is an important task for molecule discovery, aligning human understanding with molecular space. However, most of the existing methods heavily rely on domain experts, require excessive computational cost, or suffer from sub-optimal performance. On the other hand, Large Language Models (LLMs), like ChatGPT, have shown remarkable performance in various cross-modal tasks due to their powerful capabilities in natural language understanding, generalization, and in-context learning (ICL), which provides unprecedented opportunities to advance molecule discovery. Despite several previous works trying to apply LLMs in this task, the lack of domain-specific corpus and difficulties in training specialized LLMs still remain challenges. In this work, we propose a novel LLM-based framework (MolReGPT) for molecule-caption translation, where an In-Context Few-Shot Molecule Learning paradigm is introduced to empower molecule discovery with LLMs like ChatGPT to perform their in-context learning capability without domain-specific pre-training and fine-tuning. MolReGPT leverages the principle of molecular similarity to retrieve similar molecules and their text descriptions from a local database to enable LLMs to learn the task knowledge from context examples. We evaluate the effectiveness of MolReGPT on molecule-caption translation, including molecule understanding and text-based molecule generation. Experimental results show that compared to fine-tuned models, MolReGPT outperforms MolT5-base and is comparable to MolT5-large without additional training. To the best of our knowledge, MolReGPT is the first work to leverage LLMs via in-context learning in molecule-caption translation for advancing molecule discovery. Our work expands the scope of LLM applications, as well as providing a new paradigm for molecule discovery and design.  © 2024 IEEE.","Drug discovery; in-context learning; large language models (LLMs); retrieval augmented generation","Computational linguistics; Computer architecture; Job analysis; Knowledge management; Learning systems; Recurrent neural networks; Chatbots; Context learning; Domain specific; Drug discovery; In contexts; In-context learning; Language model; Large language model; Retrieval augmented generation; Task analysis; Molecules","","IEEE Computer Society","English","Article","Final","","Scopus","2-s2.0-85192189078"
"Meem J.A.; Rashid M.S.; Dong Y.; Hristidis V.","Meem, Jannat Ara (57221604235); Rashid, Muhammad Shihab (57340118000); Dong, Yue (57189375935); Hristidis, Vagelis (6507537461)","57221604235; 57340118000; 57189375935; 6507537461","PAT-Questions: A Self-Updating Benchmark for Present-Anchored Temporal Question-Answering","2024","Proceedings of the Annual Meeting of the Association for Computational Linguistics","","","","13129","13148","19","1","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196959448&partnerID=40&md5=6d56b08e5ab6a2717f95944799055323","University of California, Riverside, United States","Meem J.A., University of California, Riverside, United States; Rashid M.S., University of California, Riverside, United States; Dong Y., University of California, Riverside, United States; Hristidis V., University of California, Riverside, United States","Existing work on Temporal Question Answering (TQA) has predominantly focused on questions anchored to specific timestamps or events (e.g. 'Who was the US president in 1970?'). Little work has studied questions whose temporal context is relative to the present time (e.g. 'Who was the previous US president?'). We refer to this problem as Present-Anchored Temporal QA (PATQA). PATQA poses unique challenges: (1) large language models (LLMs) may have outdated knowledge, (2) complex temporal relationships (e.g. 'before', 'previous') are hard to reason, (3) multi-hop reasoning may be required, and (4) the gold answers of benchmarks must be continuously updated. To address these challenges, we introduce the PAT-Questions benchmark, which includes single and multi-hop temporal questions. The answers in PAT-Questions can be automatically refreshed by re-running SPARQL queries on a knowledge graph, if available. We evaluate several state-of-the-art LLMs and a SOTA temporal reasoning model (TEMPREASON-T5) on PAT-Questions through direct prompting and retrieval-augmented generation (RAG). The results highlight the limitations of existing solutions in PATQA and motivate the need for new methods to improve PATQA reasoning capabilities. © 2024 Association for Computational Linguistics.","","Benchmarking; Computational linguistics; Problem oriented languages; Spatio-temporal data; Complex temporal relationships; Knowledge graphs; Language model; Multi-hops; Question Answering; Self-updating; Single hop; State of the art; Temporal questions; Time-stamp; Question answering","Ku L.-W.; Martins A.; Srikumar V.","Association for Computational Linguistics (ACL)","English","Conference paper","Final","","Scopus","2-s2.0-85196959448"
"Höhn S.","Höhn, Sviatlana (57201976852)","57201976852","Non-Referential Functions of Language in Social Agents: The Case of Social Proximity","2024","TEICAI 2024 - 1st Workshop Towards Ethical and Inclusive Conversational AI: Language Attitudes, Linguistic Diversity, and Language Rights, Proceedings of the Workshop","","","","36","41","5","1","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188742738&partnerID=40&md5=1de69951a3fdada7f4f8be964acdc11c","LuxAI S. A., Luxembourg, Luxembourg","Höhn S., LuxAI S. A., Luxembourg, Luxembourg","Non-referential functions of language such as setting group boundaries, identity construction and regulation of social proximity have rarely found place in the language technology creation process. Nevertheless, their importance has been postulated in literature. While multiple methods to include social information in large language models (LLM) cover group properties (gender, age, geographic relations, professional characteristics), a combination of group social characteristics and individual features of an agent (natural or artificial) play a role in social interaction but have not been studied in generated language. This article explores the orchestration of prompt engineering and retrieval-augmented generation techniques to linguistic features of social proximity and distance in language generated by an LLM. The study uses the immediacy/distance model from literature to analyse language generated by an LLM for different recipients. This research reveals that kinship terms are almost the only way of displaying immediacy in LLM-made conversations. © 2024 Association for Computational Linguistics.","","Creation process; Geographics; Group boundary; Group properties; Language model; Language technology; Multiple methods; Social agents; Social information; Social proximity; Economic and social effects","Hosseini-Kivanani N.; Hohn S.; Anastasiou D.; Migge B.; Soltan A.; Dippold D.; Kamlovskaya E.; Philippy F.","Association for Computational Linguistics (ACL)","English","Conference paper","Final","","Scopus","2-s2.0-85188742738"
"Anantha R.; Bethi T.; Vodianik D.; Chappidi S.","Anantha, Raviteja (57219738967); Bethi, Tharun (58775353400); Vodianik, Danil (58775517800); Chappidi, Srinivas (58509886700)","57219738967; 58775353400; 58775517800; 58509886700","Context Tuning for Retrieval Augmented Generation","2024","UncertaiNLP 2024 - Workshop on Uncertainty-Aware NLP, Proceedings of the Workshop","","","","15","22","7","1","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188662450&partnerID=40&md5=3f5361f13607a04776ebc34f7519e6b1","Apple","Anantha R., Apple; Bethi T., Apple; Vodianik D., Apple; Chappidi S., Apple","Large language models (LLMs) have the remarkable ability to solve new tasks with just a few examples, but they need access to the right tools. Retrieval Augmented Generation (RAG) addresses this problem by retrieving a list of relevant tools for a given task. However, RAG’s tool retrieval step requires all the required information to be explicitly present in the query. This is a limitation, as semantic search, the widely adopted tool retrieval method, can fail when the query is incomplete or lacks context. To address this limitation, we propose Context Tuning for RAG, which employs a smart context retrieval system to fetch relevant information that improves both tool retrieval and plan generation. Our lightweight context retrieval model uses numerical, categorical, and habitual usage signals to retrieve and rank context items. Our empirical results demonstrate that context tuning significantly enhances semantic search, achieving a 3.5-fold and 1.5-fold improvement in Recall@K for context retrieval and tool retrieval tasks respectively, and resulting in an 11.6% increase in LLM-based planner accuracy. Additionally, we show that our proposed lightweight model using Reciprocal Rank Fusion (RRF) with LambdaMART outperforms GPT-4 based retrieval. Moreover, we observe context augmentation at plan generation, even after tool retrieval, reduces hallucination. © 2024 Association for Computational Linguistics.","","Computational linguistics; Information retrieval; Semantic Web; Semantics; Tuning; Context retrieval; Language model; Model use; Model-based OPC; Plan generation; Retrieval methods; Retrieval models; Retrieval systems; S-tools; Semantic search; Search engines","Vazquez R.; Celikkanat H.; Ulmer D.; Tiedemann J.; Swayamdipta S.; Aziz W.; Plank B.; Plank B.; Baan J.; de Marneffe M.-C.","Association for Computational Linguistics (ACL)","English","Conference paper","Final","","Scopus","2-s2.0-85188662450"
"González Torres J.J.; Bîndilă M.-B.; Hofstee S.; Szondy D.; Nguyen Q.-H.; Wang S.; Englebienne G.","González Torres, Juan José (59156383800); Bîndilă, Mihai-Bogdan (59157048800); Hofstee, Sebastiaan (57982609100); Szondy, Daniel (59156257400); Nguyen, Quang-Hung (59156785200); Wang, Shenghui (57191711697); Englebienne, Gwenn (25824791100)","59156383800; 59157048800; 57982609100; 59156257400; 59156785200; 57191711697; 25824791100","Automated Question-Answer Generation for Evaluating RAG-based Chatbots","2024","1st Workshop on Patient-Oriented Language Processing, CL4Health 2024 at LREC-COLING 2024 - Workshop Proceedings","","","","204","214","10","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195187720&partnerID=40&md5=a0f86b391fb3d4f8998babf57c56d152","University of Twente, Drienerlolaan 5, Enschede, 7522 NB, Netherlands","González Torres J.J., University of Twente, Drienerlolaan 5, Enschede, 7522 NB, Netherlands; Bîndilă M.-B., University of Twente, Drienerlolaan 5, Enschede, 7522 NB, Netherlands; Hofstee S., University of Twente, Drienerlolaan 5, Enschede, 7522 NB, Netherlands; Szondy D., University of Twente, Drienerlolaan 5, Enschede, 7522 NB, Netherlands; Nguyen Q.-H., University of Twente, Drienerlolaan 5, Enschede, 7522 NB, Netherlands; Wang S., University of Twente, Drienerlolaan 5, Enschede, 7522 NB, Netherlands; Englebienne G., University of Twente, Drienerlolaan 5, Enschede, 7522 NB, Netherlands","In this research, we propose a framework to generate human-like question-answer pairs with long or factoid answers automatically and, based on them, automatically evaluate the quality of Retrieval-Augmented Generation (RAG). Our framework can also create datasets that assess hallucination levels of Large Language Models (LLMs) by simulating unanswerable questions. We then apply the framework to create a dataset of question-answer (QA) pairs based on more than 1,000 leaflets about the medical and administrative procedures of a hospital. The dataset was evaluated by hospital specialists, who confirmed that more than 50% of the QA pairs are applicable. Finally, we show that our framework can be used to evaluate LLM performance by using Llama-2-13B fine-tuned in Dutch (Vanroy, 2023) with the generated dataset, and show the method’s use in testing models with regard to answering unanswerable and factoid questions appears promising. © 2024 ELRA Language Resource Association: CC BY-NC 4.0.","Chatbot Evaluation; Hallucination Detection; LLMs; Retrieval Augmented Generation","Large datasets; Quality control; Statistical tests; Administrative procedures; Chatbot evaluation; Chatbots; Hallucination detection; Human like; Language model; Large language model; Medical procedures; Question-answer pairs; Retrieval augmented generation; Hospitals","Demner-Fushman D.; Ananiadou S.; Thompson P.; Ondov B.","European Language Resources Association (ELRA)","English","Conference paper","Final","","Scopus","2-s2.0-85195187720"
"Fan R.-Z.; Fan Y.; Chen J.; Guo J.; Zhang R.; Cheng X.","Fan, Run-Ze (58601696900); Fan, Yixing (57192068697); Chen, Jiangui (57222524111); Guo, Jiafeng (24174196100); Zhang, Ruqing (57201357082); Cheng, Xueqi (55855927900)","58601696900; 57192068697; 57222524111; 24174196100; 57201357082; 55855927900","RIGHT: Retrieval-Augmented Generation for Mainstream Hashtag Recommendation","2024","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","14608 LNCS","","","39","55","16","3","10.1007/978-3-031-56027-9_3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189761228&doi=10.1007%2f978-3-031-56027-9_3&partnerID=40&md5=24166a56e29cc9925524f268700de152","ICT, CAS, CAS Key Lab of Network Data Science and Technology, Beijing, China; University of Chinese Academy of Sciences, Beijing, China","Fan R.-Z., ICT, CAS, CAS Key Lab of Network Data Science and Technology, Beijing, China, University of Chinese Academy of Sciences, Beijing, China; Fan Y., ICT, CAS, CAS Key Lab of Network Data Science and Technology, Beijing, China, University of Chinese Academy of Sciences, Beijing, China; Chen J., ICT, CAS, CAS Key Lab of Network Data Science and Technology, Beijing, China, University of Chinese Academy of Sciences, Beijing, China; Guo J., ICT, CAS, CAS Key Lab of Network Data Science and Technology, Beijing, China, University of Chinese Academy of Sciences, Beijing, China; Zhang R., ICT, CAS, CAS Key Lab of Network Data Science and Technology, Beijing, China, University of Chinese Academy of Sciences, Beijing, China; Cheng X., ICT, CAS, CAS Key Lab of Network Data Science and Technology, Beijing, China, University of Chinese Academy of Sciences, Beijing, China","Automatic mainstream hashtag recommendation aims to accurately provide users with concise and popular topical hashtags before publication. Generally, mainstream hashtag recommendation faces challenges in the comprehensive difficulty of newly posted tweets in response to new topics, and the accurate identification of mainstream hashtags beyond semantic correctness. However, previous retrieval-based methods based on a fixed predefined mainstream hashtag list excel in producing mainstream hashtags, but fail to understand the constant flow of up-to-date information. Conversely, generation-based methods demonstrate a superior ability to comprehend newly posted tweets, but their capacity is constrained to identifying mainstream hashtags without additional features. Inspired by the recent success of the retrieval-augmented technique, in this work, we attempt to adopt this framework to combine the advantages of both approaches. Meantime, with the help of the generator component, we could rethink how to further improve the quality of the retriever component at a low cost. Therefore, we propose RetrIeval-augmentedGenerative MainstreamHashTag Recommender (RIGHT), which consists of three components: (i) a retriever seeks relevant hashtags from the entire tweet-hashtags set; (ii) a selector enhances mainstream identification by introducing global signals; and (iii) a generator incorporates input tweets and selected hashtags to directly generate the desired hashtags. The experimental results show that our method achieves significant improvements over state-of-the-art baselines. Moreover, RIGHT can be easily integrated into large language models, improving the performance of ChatGPT by more than 10%. Code will be released at: https://github.com/ict-bigdatalab/RIGHT. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.","Hashtag recommendation; Retrieval-augmented generation; Social media","Information retrieval; Social networking (online); Augmented technique; Constant flow; Excel; Hashtag recommendation; Hashtags; Low-costs; Retrieval-augmented generation; Social media; State of the art; Three-component; Semantics","Goharian N.; Tonellotto N.; He Y.; Lipani A.; McDonald G.; Macdonald C.; Ounis I.","Springer Science and Business Media Deutschland GmbH","English","Conference paper","Final","","Scopus","2-s2.0-85189761228"
"Wölfel M.; Shirzad M.B.; Reich A.; Anderer K.","Wölfel, Matthias (8870295600); Shirzad, Mehrnoush Barani (57170244800); Reich, Andreas (57893774800); Anderer, Katharina (58848799400)","8870295600; 57170244800; 57893774800; 58848799400","Knowledge-Based and Generative-AI-Driven Pedagogical Conversational Agents: A Comparative Study of Grice’s Cooperative Principles and Trust","2024","Big Data and Cognitive Computing","8","1","2","","","","4","10.3390/bdcc8010002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183340198&doi=10.3390%2fbdcc8010002&partnerID=40&md5=53e0d8356dddd4d3c434c109504e3bb8","Faculty of Computer Science and Business Information Systems, Karlsruhe University of Applied Sciences, Moltkestr. 30, Karlsruhe, 76131, Germany; Faculty of Business, Economics and Social Sciences, University of Hohenheim, Schloss Hohenheim 1, Stuttgart, 70599, Germany; Faculty of Computer Science, Institut for Anthropomatics and Robotics (IAR), Karlsruher Institut for Technology (KIT), Kaiserstr. 12, Karlsruhe, 76131, Germany","Wölfel M., Faculty of Computer Science and Business Information Systems, Karlsruhe University of Applied Sciences, Moltkestr. 30, Karlsruhe, 76131, Germany, Faculty of Business, Economics and Social Sciences, University of Hohenheim, Schloss Hohenheim 1, Stuttgart, 70599, Germany; Shirzad M.B., Faculty of Business, Economics and Social Sciences, University of Hohenheim, Schloss Hohenheim 1, Stuttgart, 70599, Germany; Reich A., Faculty of Business, Economics and Social Sciences, University of Hohenheim, Schloss Hohenheim 1, Stuttgart, 70599, Germany; Anderer K., Faculty of Computer Science and Business Information Systems, Karlsruhe University of Applied Sciences, Moltkestr. 30, Karlsruhe, 76131, Germany, Faculty of Computer Science, Institut for Anthropomatics and Robotics (IAR), Karlsruher Institut for Technology (KIT), Kaiserstr. 12, Karlsruhe, 76131, Germany","The emergence of generative language models (GLMs), such as OpenAI’s ChatGPT, is changing the way we communicate with computers and has a major impact on the educational landscape. While GLMs have great potential to support education, their use is not unproblematic, as they suffer from hallucinations and misinformation. In this paper, we investigate how a very limited amount of domain-specific data, from lecture slides and transcripts, can be used to build knowledge-based and generative educational chatbots. We found that knowledge-based chatbots allow full control over the system’s response but lack the verbosity and flexibility of GLMs. The answers provided by GLMs are more trustworthy and offer greater flexibility, but their correctness cannot be guaranteed. Adapting GLMs to domain-specific data trades flexibility for correctness. © 2023 by the authors.","chatbot; conversational agent; digital assistant; digital tutor; education; generative AI; generative language model; large language model; retrieval augmented generation","Computational linguistics; E-learning; Chatbots; Conversational agents; Digital assistants; Digital tutor; Generative AI; Generative language model; Language model; Large language model; Retrieval augmented generation; Knowledge based systems","","Multidisciplinary Digital Publishing Institute (MDPI)","English","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85183340198"
"Dean M.; Bond R.R.; McTear M.F.; Mulvenna M.D.","Dean, Max (58979039300); Bond, Raymond R. (36019802200); McTear, Michael F. (6603439632); Mulvenna, Maurice D. (6507434648)","58979039300; 36019802200; 6603439632; 6507434648","ChatPapers: An AI Chatbot for Interacting with Academic Research","2023","2023 31st Irish Conference on Artificial Intelligence and Cognitive Science, AICS 2023","","","","","","","0","10.1109/AICS60730.2023.10470521","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189941104&doi=10.1109%2fAICS60730.2023.10470521&partnerID=40&md5=9e1b49d8ea19f894d29096943fbf1046","School of Computing, Ulster University, Belfast, United Kingdom","Dean M., School of Computing, Ulster University, Belfast, United Kingdom; Bond R.R., School of Computing, Ulster University, Belfast, United Kingdom; McTear M.F., School of Computing, Ulster University, Belfast, United Kingdom; Mulvenna M.D., School of Computing, Ulster University, Belfast, United Kingdom","A growing and significant number of computer science related papers are being published; hence it is challenging to keep up with the latest research. This paper describes the development of a large language model (LLM) augmentation chatbot and user interface that provides responses to research queries in the domain of computer science. Around 200,000 computer science research papers from arXiv were embedded, resulting in 11 million vectors (based on 'chunks' from the papers). Each vector is comprised of 384 numbers/dimensions. Technologies used include Langchain, a Vector Database, and Semantic Searching with document / query embeddings. The chatbot was tested using 30 sample questions that could be asked by computer science students across several topics and from different education levels (i.e., BSc, MSc and PhD level). The responses from this chatbot were compared with those from GPT-4. The responses with and without prompting were also compared. Readability metrics (Flesch-Kincaid and Coleman-Liau) were used to compare the responses from this LLM with GPT-4. Retrieval Augmented Generation Assessment (RAGAS), a novel LLM self-evaluation method was used to evaluate the system. We observed that the developed system provides more suitable responses to the user based on the readability level at which the questions were asked.  © 2023 IEEE.","chatbot; Coleman-Liau; Flesch-Kincaid; GPT-4; Langchain; large language model; Readability metrics; retrieval augmented generation; Retrieval Augmented Generation Assessment; semantic search; vector database","Computational linguistics; Education computing; Semantic Web; Semantics; User interfaces; Chatbots; Coleman; Coleman-liau; Flesch-kincaid; GPT-4; Langchain; Language model; Large language model; Readability metric; Retrieval augmented generation; Retrieval augmented generation assessment; Semantic search; Vector database; Vectors","","Institute of Electrical and Electronics Engineers Inc.","English","Conference paper","Final","","Scopus","2-s2.0-85189941104"
"Yang H.; Zhang M.; Wei D.; Guo J.","Yang, Hao (57208745952); Zhang, Min (57282022500); Wei, Daimeng (57219324919); Guo, Jiaxin (57232978300)","57208745952; 57282022500; 57219324919; 57232978300","SRAG: Speech Retrieval Augmented Generation for Spoken Language Understanding","2024","2024 IEEE 2nd International Conference on Control, Electronics and Computer Technology, ICCECT 2024","","","","370","374","4","0","10.1109/ICCECT60629.2024.10546001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195954068&doi=10.1109%2fICCECT60629.2024.10546001&partnerID=40&md5=b9d8be919dc667f6dc57b5ebed0686ea","Huawei CO., Ltd, 2012 Labs, Beijing, China","Yang H., Huawei CO., Ltd, 2012 Labs, Beijing, China; Zhang M., Huawei CO., Ltd, 2012 Labs, Beijing, China; Wei D., Huawei CO., Ltd, 2012 Labs, Beijing, China; Guo J., Huawei CO., Ltd, 2012 Labs, Beijing, China","Retrieval augmented generation (RAG) has shown promise for enhancing natural language understanding (NLU) capabilities of large language models (LLMs) by retrieving relevant knowledge as prompts. Extending RAG to spoken language understanding (SLU) represents an important research direction. This paper proposes a RAG approach for improving SLU. First, the encoder of a pretrained automatic speech recognition model is utilized for speech retrieval over the training set. The corresponding texts and intent labels are then formulated as prompts to guide the SLU decoder. Furthermore, a prompt attention mechanism is introduced to strengthen the attention between generation and prompts. Experiments demonstrate that the proposed speech RAG approach substantially outperforms conventional end-to-end and cascaded SLU models in intent prediction from speech. This highlights the efficacy of leveraging retrieval-based prompting to incorporate external knowledge for advancing SLU. © 2024 IEEE.","Large Language Models; Retrieval Augmented Generation; Spoken Language Understanding","Computational linguistics; Knowledge management; Speech communication; Attention mechanisms; Automatic speech recognition; Language model; Large language model; Natural language understanding; Recognition models; Retrieval augmented generation; Speech retrieval; Spoken language understanding; Training sets; Speech recognition","","Institute of Electrical and Electronics Engineers Inc.","English","Conference paper","Final","","Scopus","2-s2.0-85195954068"
"Ampazis N.","Ampazis, Nicholas (56159384700)","56159384700","Improving RAG Quality for Large Language Models with Topic-Enhanced Reranking","2024","IFIP Advances in Information and Communication Technology","712","","","74","87","13","0","10.1007/978-3-031-63215-0_6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197347075&doi=10.1007%2f978-3-031-63215-0_6&partnerID=40&md5=ac7bee78e10dbb3841dbb41a01a2be30","Department of Financial and Management Engineering, School of Engineering, University of the Aegean, Chios, Greece","Ampazis N., Department of Financial and Management Engineering, School of Engineering, University of the Aegean, Chios, Greece","The rapid growth of Large Language Models (LLMs) has increased the demand for effective retrieval mechanisms in Retrieval Augmented Generation (RAG). Current RAG models primarily rely on vector similarity matching, which limits their ability to uncover latent semantic relationships between queries and documents. To enhance the retrieval phase of RAG, we propose a framework that incorporates topic modeling in the RAG pipeline for semantically reranking the retrieved results. This approach, which we refer to as Topic Enhanced Reranking (TER), enables the retrieval system to utilize latent topics within queries and documents, thereby improving the overall precision and semantic relevance of the RAG results. We present a detailed overview of the proposed method, followed by its experimental evaluation on both the retrieval stage and the end-to-end performance of the RAG pipeline. We compare our results against baseline RAG and a state of the art reranker in order to demonstrate the effectiveness of TER in improving both the retrieval performance and the quality of text produced by the LLM. © IFIP International Federation for Information Processing 2024.","Large Language Models; Retrieval Augmented Generation; Topic Modeling","Computational linguistics; Information retrieval; Modeling languages; Semantics; 'current; Language model; Large language model; Rapid growth; Re-ranking; Retrieval augmented generation; Retrieval mechanisms; Similarity-matching; Topic Modeling; Vector similarity; Pipelines","Maglogiannis I.; Iliadis L.; Papaleonidas A.; Macintyre J.; Avlonitis M.","Springer Science and Business Media Deutschland GmbH","English","Conference paper","Final","","Scopus","2-s2.0-85197347075"
"Zografos G.; Kefalidis V.; Moussiades L.","Zografos, George (58399150300); Kefalidis, Vasileios (59170295800); Moussiades, Lefteris (15727965400)","58399150300; 59170295800; 15727965400","LLM-Based Course Comprehension Evaluator","2024","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","14798 LNCS","","","405","414","9","0","10.1007/978-3-031-63028-6_35","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195871625&doi=10.1007%2f978-3-031-63028-6_35&partnerID=40&md5=2661a5d84fd358603c422abb7dd863ab","Democritus University of Thrace, Kavala, 65404, Greece","Zografos G., Democritus University of Thrace, Kavala, 65404, Greece; Kefalidis V., Democritus University of Thrace, Kavala, 65404, Greece; Moussiades L., Democritus University of Thrace, Kavala, 65404, Greece","Large language models (LLMs) like GPT-4 reshape intelligent tutoring systems by enabling nuanced natural language interactions. Leveraging LLMs’ capabilities, this study introduces an innovative Lesson Comprehension Evaluator, utilizing advanced Natural Language Processing (NLP) methods and Augmented Retrieval Generation (RAG) to assess course material comprehension. Through a web interface, students engage with tailored questions and receive feedback, fostering immersive learning experiences. Each response undergoes rigorous evaluation against a ground truth LLM-generated knowledge base, encompassing semantic comprehension, specificity, and correctness metrics. These evaluations provide insights into students’ course understanding, informing future pedagogical strategies. By incorporating auditory options for accessibility and gamification elements for enhanced engagement, this approach facilitates self-paced, deeper learning, fostering dynamic and enriching learning environments. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.","GPT-4; Intelligent Tutoring Systems; Retrieval Augmented Generation (RAG)","Education computing; Knowledge based systems; Natural language processing systems; Semantics; Students; GPT-4; Intelligent tutoring; Intelligent tutoring system; Language model; Language processing; Model-based OPC; Natural language interaction; Natural languages; Retrieval augmented generation; Tutoring system; Computer aided instruction","Sifaleras A.; Lin F.","Springer Science and Business Media Deutschland GmbH","English","Conference paper","Final","","Scopus","2-s2.0-85195871625"
"Yang S.; Zhu J.; Wang J.; Xu X.; Shao Z.; Yao L.; Zheng B.; Huang H.","Yang, Shanglin (59123005200); Zhu, Jialin (59123005300); Wang, Jialin (57203720639); Xu, Xiaohan (58069670800); Shao, Zihang (59122152200); Yao, Liwei (59123430000); Zheng, Benchang (57211678777); Huang, Hu (57203038042)","59123005200; 59123005300; 57203720639; 58069670800; 59122152200; 59123430000; 57211678777; 57203038042","Retrieval-Augmented Generation with Quantized Large Language Models: A Comparative Analysis","2023","ACM International Conference Proceeding Series","","","","120","124","4","0","10.1145/3653081.3653102","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192813473&doi=10.1145%2f3653081.3653102&partnerID=40&md5=a276fea953ad514ab1b330f2af12e602","China Academy of Launch Vehicle Technology, Intelligent Game and Decision Laboratory, Beijing, 100076, China","Yang S., China Academy of Launch Vehicle Technology, Intelligent Game and Decision Laboratory, Beijing, 100076, China; Zhu J., China Academy of Launch Vehicle Technology, Intelligent Game and Decision Laboratory, Beijing, 100076, China; Wang J., China Academy of Launch Vehicle Technology, Intelligent Game and Decision Laboratory, Beijing, 100076, China; Xu X., China Academy of Launch Vehicle Technology, Intelligent Game and Decision Laboratory, Beijing, 100076, China; Shao Z., China Academy of Launch Vehicle Technology, Intelligent Game and Decision Laboratory, Beijing, 100076, China; Yao L., China Academy of Launch Vehicle Technology, Intelligent Game and Decision Laboratory, Beijing, 100076, China; Zheng B., China Academy of Launch Vehicle Technology, Intelligent Game and Decision Laboratory, Beijing, 100076, China; Huang H., China Academy of Launch Vehicle Technology, Intelligent Game and Decision Laboratory, Beijing, 100076, China","Large language models have demonstrated emergent intelligence and ability to handle a wide array of tasks. However, the reliability of these models in terms of factual accuracy and timely knowledge acquisition remains a challenge. Researchers explore the implementation of retrieval-augmented generation methods, aiming to enhance the authenticity and specificity in knowledge-intensive tasks. This paper discusses the practical application in industrial settings, particularly in assisting design personnel with navigating complex standards and quality manuals. Utilizing an open-source model with 6 billion parameters, the study employs quantization technology for local deployment, addressing computational challenges. The retrieval-augmented generation framework is analyzed, emphasizing the integration of document parsing, vector databases, and text embedding models. Experimental results compare models at different quantization levels, revealing trade-offs between response time, model size, and performance metrics. The findings suggest that 4-bit integer quantization is optimal for standard document retrieval and question-answering tasks, highlighting practical considerations for CPU inference. The paper concludes with insights into hyper-parameter tuning, model comparisons, and future optimizations for enhanced performance in edge device deployments of large language models.  © 2023 ACM.","Large language models; Quantization; Retrieval-augmented generation","Computational linguistics; Information retrieval; Comparative analyzes; Generation method; Industrial settings; Knowledge intensive tasks; Language model; Large language model; Open-source model; Quality manual; Quantisation; Retrieval-augmented generation; Economic and social effects","","Association for Computing Machinery","English","Conference paper","Final","","Scopus","2-s2.0-85192813473"
"Maryamah M.; Irfani M.M.; Tri Raharjo E.B.; Rahmi N.A.; Ghani M.; Raharjana I.K.","Maryamah, Maryamah (59007149600); Irfani, Muhammad Maula (59007054800); Tri Raharjo, Edric Boby (59007219600); Rahmi, Netri Alia (59007149700); Ghani, Mohammad (57204973352); Raharjana, Indra Kharisma (57202163318)","59007149600; 59007054800; 59007219600; 59007149700; 57204973352; 57202163318","Chatbots in Academia: A Retrieval-Augmented Generation Approach for Improved Efficient Information Access","2024","KST 2024 - 16th International Conference on Knowledge and Smart Technology","","","","259","264","5","0","10.1109/KST61284.2024.10499652","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191662023&doi=10.1109%2fKST61284.2024.10499652&partnerID=40&md5=8343cbe6477c200e247a4af30fd1bef3","Universitas Airlangga, Data Science Technology, Faculty of Advanced Technology and Multidiscipline, Surabaya, Indonesia; Universitas Airlangga, Informations Systems, Faculty of Science and Technology, Surabaya, Indonesia","Maryamah M., Universitas Airlangga, Data Science Technology, Faculty of Advanced Technology and Multidiscipline, Surabaya, Indonesia; Irfani M.M., Universitas Airlangga, Data Science Technology, Faculty of Advanced Technology and Multidiscipline, Surabaya, Indonesia; Tri Raharjo E.B., Universitas Airlangga, Data Science Technology, Faculty of Advanced Technology and Multidiscipline, Surabaya, Indonesia; Rahmi N.A., Universitas Airlangga, Data Science Technology, Faculty of Advanced Technology and Multidiscipline, Surabaya, Indonesia; Ghani M., Universitas Airlangga, Data Science Technology, Faculty of Advanced Technology and Multidiscipline, Surabaya, Indonesia; Raharjana I.K., Universitas Airlangga, Informations Systems, Faculty of Science and Technology, Surabaya, Indonesia","In today's digital age, higher education utilizes chatbots as virtual assistants to assist users, especially prospective students to access information easily. A chatbot is an application in natural language conversations to simulate intelligent interactions. Intelligent chatbots are needed to understand user needs and answer questions relevantly. We propose a chatbot with Retrieval Augmented Generation approach involving a retriever with cosine similarity search using OpenAI Ada embeddings to obtain relevant documents. The LLM OpenAI GPT-3.5- Turbo then generates the final answer. The chatbot mechanism begins with the retrieval module systematically identifying documents stored in the vector database that contain relevant information related to the user's query. The selected documents and query are provided to the LLM as part of the prompt to generate responses based on the knowledge provided in the relevant documents. The retrieval method is evaluated based on two criteria: the search method and the embedding model. The comparison method uses similarity search with Maximum Marginal Relevance (MMR) Search and the proposed embedding method against other models such as Google Embedding-001 and MPNet-Multilingual. The retrieval process is assessed using an evaluation dataset that incorporates Recall and Precision metrics, while answer generation is measured with BLEU and ROUGE Score. The observed disparity result between similarity search and MMR is not notably significant. Nonetheless, our chatbot holds an advantage in referencing past conversations due to its ability to store conversation history. Furthermore, potential enhancements are identified by augmenting the knowledge provided to the LLM in forthcoming iterations.  © 2024 IEEE.","Academic Chatbots; Large Language Models; Retrieval-Augmented Generation; Technology","Education computing; Information retrieval; Query processing; Academic chatbot; Chatbots; Embeddings; Information access; Language model; Large language model; Relevant documents; Retrieval-augmented generation; Similarity search; Technology; Embeddings","","Institute of Electrical and Electronics Engineers Inc.","English","Conference paper","Final","","Scopus","2-s2.0-85191662023"
"Zhang B.; Yang H.; Zhou T.; Ali Babar M.; Liu X.-Y.","Zhang, Boyu (58480793600); Yang, Hongyang (57204013580); Zhou, Tianyu (58664515200); Ali Babar, Muhammad (6602842620); Liu, Xiao-Yang (44361326100)","58480793600; 57204013580; 58664515200; 6602842620; 44361326100","Enhancing Financial Sentiment Analysis via Retrieval Augmented Large Language Models","2023","ICAIF 2023 -  4th ACM International Conference on AI in Finance","","","","349","356","7","22","10.1145/3604237.3626866","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179046770&doi=10.1145%2f3604237.3626866&partnerID=40&md5=96b329903cb5a91366a6251c0ace939b","The University of Adelaide, Australia; Columbia University, United States; Brown University, United States; Rensselaer Polytechnic Institut, United States","Zhang B., The University of Adelaide, Australia; Yang H., Columbia University, United States; Zhou T., Brown University, United States; Ali Babar M., The University of Adelaide, Australia; Liu X.-Y., Columbia University, United States, Rensselaer Polytechnic Institut, United States","Financial sentiment analysis is critical for valuation and investment decision-making. Traditional NLP models, however, are limited by their parameter size and the scope of their training datasets, which hampers their generalization capabilities and effectiveness in this field. Recently, Large Language Models (LLMs) pre-trained on extensive corpora have demonstrated superior performance across various NLP tasks due to their commendable zero-shot abilities. Yet, directly applying LLMs to financial sentiment analysis presents challenges: The discrepancy between the pre-training objective of LLMs and predicting the sentiment label can compromise their predictive performance. Furthermore, the succinct nature of financial news, often devoid of sufficient context, can significantly diminish the reliability of LLMs' sentiment analysis. To address these challenges, we introduce a retrieval-augmented LLMs framework for financial sentiment analysis. This framework includes an instruction-tuned LLMs module, which ensures LLMs behave as predictors of sentiment labels, and a retrieval-augmentation module which retrieves additional context from reliable external sources. Benchmarked against traditional models and LLMs like ChatGPT and LLaMA, our approach achieves 15% to 48% performance gain in accuracy and F1 score. © 2023 ACM.","Instruction Tuning; Large Language Models; Retrieval Augmented Generation; Sentiment Analysis","Computational linguistics; Decision making; Investments; Reliability analysis; Generalization capability; Instruction tuning; Investment decision making; Language model; Large language model; Performance; Pre-training; Retrieval augmented generation; Sentiment analysis; Training dataset; Sentiment analysis","","Association for Computing Machinery, Inc","English","Conference paper","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85179046770"
"Li X.; Li Z.; Shi C.; Xu Y.; Du Q.; Tan M.; Huang J.","Li, Xiang (58959399700); Li, Zhenyu (58959287300); Shi, Chen (57224924189); Xu, Yong (58959355900); Du, Qing (36664475600); Tan, Mingkui (22837202600); Huang, Jun (57199287007)","58959399700; 58959287300; 57224924189; 58959355900; 36664475600; 22837202600; 57199287007","AlphaFin: Benchmarking Financial Analysis with Retrieval-Augmented Stock-Chain Framework","2024","2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation, LREC-COLING 2024 - Main Conference Proceedings","","","","773","783","10","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195934691&partnerID=40&md5=d7f5acab0a70f5aff9a75286b4203402","South China University of Technology, China; Alibaba Group, China","Li X., South China University of Technology, China; Li Z., South China University of Technology, China; Shi C., Alibaba Group, China; Xu Y., South China University of Technology, China; Du Q., South China University of Technology, China; Tan M., South China University of Technology, China; Huang J., Alibaba Group, China","The task of financial analysis primarily encompasses two key areas: stock trend prediction and the corresponding financial question answering. Currently, machine learning and deep learning algorithms (ML&DL) have been widely applied for stock trend predictions, leading to significant progress. However, these methods fail to provide reasons for predictions, lacking interpretability and reasoning processes. Also, they can not integrate textual information such as financial news or reports. Meanwhile, large language models (LLMs) have remarkable textual understanding and generation ability. But due to the scarcity of financial training datasets and limited integration with real-time knowledge, LLMs still suffer from hallucinations and are unable to keep up with the latest information. To tackle these challenges, we first release AlphaFin datasets, combining traditional research datasets, real-time financial data, and handwritten chain-of-thought (CoT) data. It has a positive impact on training LLMs for completing financial analysis. We then use AlphaFin datasets to benchmark a state-of-the-art method, called Stock-Chain, for effectively tackling the financial analysis task, which integrates retrieval-augmented generation (RAG) techniques. Extensive experiments are conducted to demonstrate the effectiveness of our framework on financial analysis. © 2024 ELRA Language Resource Association: CC BY-NC 4.0.","Chain-of-Thoughts; Finance; Financial Question Answering; Large Language Models; Retrieval-Augmented Generation; Stock Trend Prediction","Computational linguistics; Deep learning; Forecasting; Learning algorithms; Chain-of-thought; Financial analysis; Financial question answering; Language model; Large language model; Machine-learning; Question Answering; Real- time; Retrieval-augmented generation; Stock trend prediction; Finance","Calzolari N.; Kan M.-Y.; Hoste V.; Lenci A.; Sakti S.; Xue N.","European Language Resources Association (ELRA)","English","Conference paper","Final","","Scopus","2-s2.0-85195934691"
"Loukas L.; Stogiannidis I.; Diamantopoulos O.; Malakasiotis P.; Vassos S.","Loukas, Lefteris (57290783500); Stogiannidis, Ilias (58588938600); Diamantopoulos, Odysseas (58719550700); Malakasiotis, Prodromos (14832921300); Vassos, Stavros (25927703400)","57290783500; 58588938600; 58719550700; 14832921300; 25927703400","Making LLMs Worth Every Penny: Resource-Limited Text Classification in Banking","2023","ICAIF 2023 -  4th ACM International Conference on AI in Finance","","","","392","400","8","7","10.1145/3604237.3626891","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179841074&doi=10.1145%2f3604237.3626891&partnerID=40&md5=8881fd8469aaf5d0294092c0b1aa7f7b","Helvia.ai, Dept. of Informatics, Athens Univ. of Economics and Business, Greece; Dept. of Informatics, Athens Univ. of Economics and Business, Greece","Loukas L., Helvia.ai, Dept. of Informatics, Athens Univ. of Economics and Business, Greece; Stogiannidis I., Helvia.ai, Dept. of Informatics, Athens Univ. of Economics and Business, Greece; Diamantopoulos O., Helvia.ai, Dept. of Informatics, Athens Univ. of Economics and Business, Greece; Malakasiotis P., Dept. of Informatics, Athens Univ. of Economics and Business, Greece; Vassos S., Helvia.ai, Dept. of Informatics, Athens Univ. of Economics and Business, Greece","Standard Full-Data classifiers in NLP demand thousands of labeled examples, which is impractical in data-limited domains. Few-shot methods offer an alternative, utilizing contrastive learning techniques that can be effective with as little as 20 examples per class. Similarly, Large Language Models (LLMs) like GPT-4 can perform effectively with just 1-5 examples per class. However, the performance-cost trade-offs of these methods remain underexplored, a critical concern for budget-limited organizations. Our work addresses this gap by studying the aforementioned approaches over the Banking77 financial intent detection dataset, including the evaluation of cutting-edge LLMs by OpenAI, Cohere, and Anthropic in a comprehensive set of few-shot scenarios. We complete the picture with two additional methods: first, a cost-effective querying method for LLMs based on retrieval-augmented generation (RAG), able to reduce operational costs multiple times compared to classic few-shot approaches, and second, a data augmentation method using GPT-4, able to improve performance in data-limited scenarios. Finally, to inspire future research, we provide a human expert's curated subset of Banking77, along with extensive error analysis. © 2023 ACM.","Anthropic; Claude; Cohere; Few-shot; GPT; LLMs; NLP; OpenAI","Budget control; Classification (of information); Economic and social effects; Learning systems; Natural language processing systems; Text processing; Anthropic; Claude; Cohere; Few-shot; GPT; Language model; Large language model; Limited domains; Openai; Text classification; Cost effectiveness","","Association for Computing Machinery, Inc","English","Conference paper","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85179841074"
"Al Hasan Rony M.R.; Süß C.; Bhat S.R.; Sudhi V.; Schneider J.; Vogel M.; Teucher R.; Friedl K.E.; Sahoo S.","Al Hasan Rony, Md Rashad (57203302415); Süß, Christian (58669036900); Bhat, Sinchana Ramakanth (58668982200); Sudhi, Viju (57226695685); Schneider, Julia (58669008400); Vogel, Maximilian (58668883100); Teucher, Roman (57803401500); Friedl, Ken E. (58668908600); Sahoo, Soumya (58668908700)","57203302415; 58669036900; 58668982200; 57226695685; 58669008400; 58668883100; 57803401500; 58668908600; 58668908700","CarExpert: Leveraging Large Language Models for In-Car Conversational Question Answering","2023","EMNLP 2023 - 2023 Conference on Empirical Methods in Natural Language Processing, Proceedings of the Industry Track","","","","586","604","18","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184655308&partnerID=40&md5=14a37efd9fb632ee8f1ceaac2e7f8c61","BMW Group; Fraunhofer IAIS; BIG PICTURE GmbH, Germany; ONSEI GmbH, Germany","Al Hasan Rony M.R., BMW Group; Süß C., BMW Group; Bhat S.R., Fraunhofer IAIS; Sudhi V., Fraunhofer IAIS; Schneider J., ONSEI GmbH, Germany; Vogel M., BIG PICTURE GmbH, Germany; Teucher R., Fraunhofer IAIS; Friedl K.E., BMW Group; Sahoo S., Fraunhofer IAIS","Large language models (LLMs) have demonstrated remarkable performance by following natural language instructions without fine-tuning them on domain-specific tasks and data. However, leveraging LLMs for domain-specific question answering suffers from severe limitations. The generated answer tends to hallucinate due to the training data collection time (when using off-the-shelf), complex user utterance and wrong retrieval (in retrieval-augmented generation). Furthermore, due to the lack of awareness about the domain and expected output, such LLMs may generate unexpected and unsafe answers that are not tailored to the target domain. In this paper, we propose CarExpert, an in-car retrieval-augmented conversational question-answering system leveraging LLMs for different tasks. Specifically, CarExpert employs LLMs to control the input, provide domain-specific documents to the extractive and generative answering components, and controls the output to ensure safe and domain-specific answers. A comprehensive empirical evaluation exhibits that CarExpert outperforms state-of-the-art LLMs in generating natural, safe and car-specific answers. © 2023 Association for Computational Linguistics.","","Natural language processing systems; Collection time; Data collection; Domain specific; Language model; Natural languages; Performance; Question Answering; Specific tasks; Training data; Without fine-tuning; Computational linguistics","Wang M.; Zitouni I.","Association for Computational Linguistics (ACL)","English","Conference paper","Final","","Scopus","2-s2.0-85184655308"
"Chauhan P.; Sahani R.K.; Datta S.; Qadir A.; Raj M.; Ali M.M.","Chauhan, Pratyush (58998964600); Sahani, Rahul Kumar (58836115400); Datta, Soham (59284513200); Qadir, Ali (58999115200); Raj, Manish (57208865576); Ali, Mohd Mohsin (57890872800)","58998964600; 58836115400; 59284513200; 58999115200; 57208865576; 57890872800","Evaluating Top-k RAG-based approach for Game Review Generation","2024","Proceedings - International Conference on Computing, Power, and Communication Technologies, IC2PCT 2024","","","","258","263","5","0","10.1109/IC2PCT60090.2024.10486273","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191169668&doi=10.1109%2fIC2PCT60090.2024.10486273&partnerID=40&md5=ca501a4ce5bcd5b118297d150766a94b","Bennett University, Dept of Computer Science, Greater Noida, India","Chauhan P., Bennett University, Dept of Computer Science, Greater Noida, India; Sahani R.K., Bennett University, Dept of Computer Science, Greater Noida, India; Datta S., Bennett University, Dept of Computer Science, Greater Noida, India; Qadir A., Bennett University, Dept of Computer Science, Greater Noida, India; Raj M., Bennett University, Dept of Computer Science, Greater Noida, India; Ali M.M., Bennett University, Dept of Computer Science, Greater Noida, India","Having access to public opinion for a particular product can be a cumbersome task. There are multiple reviews for the same product. Some may be good or bad depending on the bias of the reviewer. Using LLMs for the interpretation of this data would make it easier to understand the overall perception of a product. This is a study regarding how well RAG+LLMs can be used as Game Review Generators, built using state-of-the-art open source LLM LLaMA 2 13b and the Retrieval Augmented Generation framework llamaindex. The goal here is to generate and evaluate game reviews that take elements from a set of game reviews regarding a particular game without using any form of fine-tuning. This is achieved by using a rudimentary 'query engine' over a subset of publicly available game reviews. Game reviews are converted to vector stores which allow us to use top-k semantic retrieval for inference. This technique of providing data to an LLM from a document is called Retrieval Augmented Generation or RAG. Upon experimenting, game-specific reviews were generated (without using any form of fine-tuning) with the help of RAG combined with a top-k semantic retrieval ranking system. The application of this technique goes beyond simple game review generation, it can be used to generate and query context-specific information on any product given enough base information.  © 2024 IEEE.","large language models (LLM); LLAMaindex; naïve retrieval augmented generation (RAG); top-k semantic retrieval; video game review generation","Human computer interaction; Information retrieval; Social aspects; Fine tuning; Game reviews; Language model; Large language model; Llamaindex; Naive retrieval augmented generation; Semantic retrieval; Top-k semantic retrieval; Video game review generation; Video-games; Semantics","","Institute of Electrical and Electronics Engineers Inc.","English","Conference paper","Final","","Scopus","2-s2.0-85191169668"
"Hang C.N.; Wei Tan C.; Yu P.-D.","Hang, Ching Nam (57205457095); Wei Tan, Chee (59244715400); Yu, Pei-Duo (56470129600)","57205457095; 59244715400; 56470129600","MCQGen: A Large Language Model-Driven MCQ Generator for Personalized Learning","2024","IEEE Access","12","","","102261","102273","12","0","10.1109/ACCESS.2024.3420709","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197026241&doi=10.1109%2fACCESS.2024.3420709&partnerID=40&md5=cabb0b76d15d7c3f8a653e7727f8a250","Saint Francis University, Yam Pak Charitable Foundation School of Computing and Information Sciences, Hong Kong, Hong Kong; Nanyang Technological University, College of Computing and Data Science, Jurong West, 639798, Singapore; Chung Yuan Christian University, Department of Applied Mathematics, Taoyuan, 320314, Taiwan","Hang C.N., Saint Francis University, Yam Pak Charitable Foundation School of Computing and Information Sciences, Hong Kong, Hong Kong; Wei Tan C., Nanyang Technological University, College of Computing and Data Science, Jurong West, 639798, Singapore; Yu P.-D., Chung Yuan Christian University, Department of Applied Mathematics, Taoyuan, 320314, Taiwan","In the dynamic landscape of contemporary education, the evolution of teaching strategies such as blended learning and flipped classrooms has highlighted the need for efficient and effective generation of multiple-choice questions (MCQs). To address this, we introduce MCQGen, a novel generative artificial intelligence framework designed for the automated creation of MCQs. MCQGen uniquely integrates a large language model (LLM) with retrieval-augmented generation and advanced prompt engineering techniques, drawing from an extensive external knowledge base. This integration significantly enhances the ability of the LLM to produce educationally relevant questions that align with both the goals of educators and the diverse learning needs of students. The framework employs innovative prompt engineering, combining chain-of-thought and self-refine prompting techniques, to enhance the performance of the LLM. This process leads to the generation of questions that are not only contextually relevant and challenging but also reflective of common student misconceptions, contributing effectively to personalized learning experiences and enhancing student engagement and understanding. Our extensive evaluations showcase the effectiveness of MCQGen in producing high-quality MCQs for various educational needs and learning styles. The framework demonstrates its potential to significantly reduce the time and expertise required for MCQ creation, marking its practical utility in modern education. In essence, MCQGen offers an innovative and robust solution for the automated generation of MCQs, enhancing personalized learning in the digital era.  © 2013 IEEE.","Large language models; multiple-choice questions; personalized learning; prompt engineering; retrieval-augmented generation","Computational linguistics; Education computing; Knowledge based systems; Teaching; Blended learning; Engineering techniques; Language model; Large language model; Model-driven; Multiple-choice questions; Personalized learning; Prompt engineering; Retrieval-augmented generation; Teaching strategy; Students","","Institute of Electrical and Electronics Engineers Inc.","English","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85197026241"
"Ryu C.; Lee S.; Pang S.; Choi C.; Choi H.; Min M.; Sohn J.-Y.","Ryu, Cheol (58886886400); Lee, Seolhwa (58886949700); Pang, Subeen (58886627500); Choi, Chanyeol (58886949800); Choi, Hojun (58886559600); Min, Myeonggee (58886754600); Sohn, Jy-Yong (57195476528)","58886886400; 58886949700; 58886627500; 58886949800; 58886559600; 58886754600; 57195476528","Retrieval-based Evaluation for LLMs: A Case Study in Korean Legal QA","2023","NLLP 2023 - Natural Legal Language Processing Workshop 2023, Proceedings of the Workshop","","","","132","137","5","4","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185008870&partnerID=40&md5=52e1578316e95acc68d79fcdfb27f825","Linq Labs; Law&Good; Yonsei University, South Korea","Ryu C., Linq Labs; Lee S., Linq Labs; Pang S., Linq Labs; Choi C., Linq Labs; Choi H., Law&Good; Min M., Law&Good; Sohn J.-Y., Yonsei University, South Korea","While large language models (LLMs) have demonstrated significant capabilities in text generation, their utilization in areas requiring domain-specific expertise, such as law, must be approached cautiously. This caution is warranted due to the inherent challenges associated with LLM-generated texts, including the potential presence of factual errors. Motivated by this issue, we propose Eval-RAG, a new evaluation method for LLM-generated texts. Unlike existing methods, Eval-RAG evaluates the validity of generated texts based on the related document that are collected by the retriever. In other words, Eval-RAG adopts the idea of retrieval augmented generation (RAG) for the purpose of evaluation. Our experimental results on Korean Legal Question-Answering (QA) tasks show that conventional LLM-based evaluation methods can be better aligned with Lawyers' evaluations, by combining with Eval-RAG. In addition, our qualitative analysis show that Eval-RAG successfully finds the factual errors in LLM-generated texts, while existing evaluation methods cannot. © 2023 Association for Computational Linguistics.","","Case-studies; Domain specific; Evaluation methods; Language model; Legal questions; Model-based evaluation; New evaluation methods; Question Answering; Question Answering Task; Text generations; Computational linguistics","Preotiuc-Pietro D.; Goanta C.; Chalkidis I.; Barrett L.; Spanakis G.; Aletras N.","Association for Computational Linguistics (ACL)","English","Conference paper","Final","","Scopus","2-s2.0-85185008870"
"Piro L.; Bianchi T.; Alessandrelli L.; Chizzola A.; Casiraghi D.; Sancassani S.; Gatti N.","Piro, Ludovica (57226114854); Bianchi, Tommaso (57218717934); Alessandrelli, Luca (59208984400); Chizzola, Andrea (59209327500); Casiraghi, Daniela (57218220234); Sancassani, Susanna (6507746479); Gatti, Nicola (6602167825)","57226114854; 57218717934; 59208984400; 59209327500; 57218220234; 6507746479; 6602167825","MyLearningTalk: An LLM-Based Intelligent Tutoring System","2024","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","14629 LNCS","","","428","431","3","0","10.1007/978-3-031-62362-2_39","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197820207&doi=10.1007%2f978-3-031-62362-2_39&partnerID=40&md5=a791c4990d64d0b66232c0c571b3c88e","Dipartimento di Elettronica Informazione e Bioingegneria, Politecnico di Milano, Milan, 20133, Italy","Piro L., Dipartimento di Elettronica Informazione e Bioingegneria, Politecnico di Milano, Milan, 20133, Italy; Bianchi T., Dipartimento di Elettronica Informazione e Bioingegneria, Politecnico di Milano, Milan, 20133, Italy; Alessandrelli L., Dipartimento di Elettronica Informazione e Bioingegneria, Politecnico di Milano, Milan, 20133, Italy; Chizzola A., Dipartimento di Elettronica Informazione e Bioingegneria, Politecnico di Milano, Milan, 20133, Italy; Casiraghi D., Dipartimento di Elettronica Informazione e Bioingegneria, Politecnico di Milano, Milan, 20133, Italy; Sancassani S., Dipartimento di Elettronica Informazione e Bioingegneria, Politecnico di Milano, Milan, 20133, Italy; Gatti N., Dipartimento di Elettronica Informazione e Bioingegneria, Politecnico di Milano, Milan, 20133, Italy","Thanks to recent advancements in natural language interaction, dialogue-based online Intelligent Tutoring Systems (ITS) employing Large Language Models (LLMs) have begun to emerge. However, the effective design of LLM-based ITS interfaces to support learning still requires attention. In this demo, we present the initial implementation of MyLearningTalk (MLT), a web-based ITS powered by LLMs. MLT exploits state-of-the-art techniques such as retrieval augmented generation to offer interactive features to provide users with grounded answers and a tailored experience to enhance and facilitate the learning process. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.","Intelligent Tutoring Systems; LLMs; Web User Interfaces","E-learning; Intelligent vehicle highway systems; Learning systems; Online systems; User interfaces; Websites; Intelligent tutoring; Intelligent tutoring system; Language model; Large language model; Model-based OPC; Natural language interaction; Support learning; Systems interfaces; Tutoring system; Web user interface; Computer aided instruction","Stefanidis K.; Systä K.; Matera M.; Heil S.; Kondylakis H.; Quintarelli E.","Springer Science and Business Media Deutschland GmbH","English","Conference paper","Final","","Scopus","2-s2.0-85197820207"
"Shao Z.; Gong Y.; Shen Y.; Huang M.; Duan N.; Chen W.","Shao, Zhihong (57216690477); Gong, Yeyun (55953770000); Shen, Yelong (56729408300); Huang, Minlie (7404260571); Duan, Nan (52163366000); Chen, Weizhu (23007589000)","57216690477; 55953770000; 56729408300; 7404260571; 52163366000; 23007589000","Enhancing Retrieval-Augmented Large Language Models with Iterative Retrieval-Generation Synergy","2023","Findings of the Association for Computational Linguistics: EMNLP 2023","","","","9248","9274","26","9","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182857221&partnerID=40&md5=d4dd45932eae90be4156e6880b7ede27","The CoAI Group, DCST, Institute for Artificial Intelligence, Tsinghua University, Beijing, 100084, China; State Key Lab of Intelligent Technology and Systems, Tsinghua University, Beijing, 100084, China; Beijing National Research Center for Information Science and Technology, Tsinghua University, Beijing, 100084, China; Microsoft Research Asia, China; Microsoft Azure AI","Shao Z., The CoAI Group, DCST, Institute for Artificial Intelligence, Tsinghua University, Beijing, 100084, China, State Key Lab of Intelligent Technology and Systems, Tsinghua University, Beijing, 100084, China, Beijing National Research Center for Information Science and Technology, Tsinghua University, Beijing, 100084, China; Gong Y., Microsoft Research Asia, China; Shen Y., Microsoft Azure AI; Huang M., The CoAI Group, DCST, Institute for Artificial Intelligence, Tsinghua University, Beijing, 100084, China; Duan N., Microsoft Research Asia, China; Chen W., Microsoft Azure AI","Retrieval-augmented generation has raise extensive attention as it is promising to address the limitations of large language models including outdated knowledge and hallucinations. However, retrievers struggle to capture relevance, especially for queries with complex information needs. Recent work has proposed to improve relevance modeling by having large language models actively involved in retrieval, i.e., to guide retrieval with generation. In this paper, we show that strong performance can be achieved by a method we call ITER-RETGEN, which synergizes retrieval and generation in an iterative manner: a model's response to a task input shows what might be needed to finish the task, and thus can serve as an informative context for retrieving more relevant knowledge which in turn helps generate a better response in another iteration. Compared with recent work which interleaves retrieval with generation when completing a single output, ITER-RETGEN processes all retrieved knowledge as a whole and largely preserves the flexibility in generation without structural constraints. We evaluate ITER-RETGEN on multi-hop question answering, fact verification, and commonsense reasoning, and show that it can flexibly leverage parametric knowledge and non-parametric knowledge, and is superior to or competitive with state-of-the-art retrieval-augmented baselines while causing fewer overheads of retrieval and generation. We can further improve performance via generation-augmented retrieval adaptation. © 2023 Association for Computational Linguistics.","","Computational linguistics; Knowledge management; Modeling languages; Natural language processing systems; Commonsense reasoning; Complex information; Language model; Model response; Multi-hops; Nonparametrics; Performance; Question Answering; Relevance models; Structural constraints; Iterative methods","","Association for Computational Linguistics (ACL)","English","Conference paper","Final","","Scopus","2-s2.0-85182857221"
"Roychowdhury S.; Jain N.; Soman S.","Roychowdhury, Sujoy (58919830500); Jain, Nishkarsh (58919168100); Soman, Sumit (55613386300)","58919830500; 58919168100; 55613386300","Unlocking Telecom Domain Knowledge Using LLMs","2024","2024 16th International Conference on COMmunication Systems and NETworkS, COMSNETS 2024","","","","267","269","2","2","10.1109/COMSNETS59351.2024.10427044","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186661201&doi=10.1109%2fCOMSNETS59351.2024.10427044&partnerID=40&md5=a709d007b82f164a46deeb85715b7605","Ericsson R&d, Bangalore, India","Roychowdhury S., Ericsson R&d, Bangalore, India; Jain N., Ericsson R&d, Bangalore, India; Soman S., Ericsson R&d, Bangalore, India","Conversational assistants have become increasingly popular as they use Large Language Models (LLMs) and Retrieval Augmented Generation (RAG) for domain context. In this work, we present an end-to-end solution that leverages RAG for telecom domain Question Answering (QA) on standards documents. We highlight that retrieval quality is important, along with an efficient indexing mechanism for the document embeddings. We also index images and tables for QA on standards documents. Our Telecom Knowledge Assistant is useful for handling specific queries from telecom domain experts, as well as for novice learners. The developed approach and solution are amenable to adapt for other domains as well.  © 2024 IEEE.","","Information retrieval; Natural language processing systems; Domain knowledge; Embeddings; End-to-end solutions; Index table; Indexing mechanisms; Language model; Question Answering; Retrieval quality; Standard documents; Telecom; Domain Knowledge","","Institute of Electrical and Electronics Engineers Inc.","English","Conference paper","Final","","Scopus","2-s2.0-85186661201"
"Stewart Kirubakaran S.; Jasper Wilsie Kathrine G.; Grace Mary Kanaga E.; Mahimai Raja J.; Ruban Gino Singh A.; Yuvaraajan E.","Stewart Kirubakaran, S. (58573991400); Jasper Wilsie Kathrine, G. (57130545500); Grace Mary Kanaga, E. (57218189213); Mahimai Raja, J. (59173494200); Ruban Gino Singh, A. (59173936300); Yuvaraajan, E. (59173494300)","58573991400; 57130545500; 57218189213; 59173494200; 59173936300; 59173494300","A RAG-based Medical Assistant Especially for Infectious Diseases","2024","7th International Conference on Inventive Computation Technologies, ICICT 2024","","","","1128","1133","5","0","10.1109/ICICT60155.2024.10544639","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196085291&doi=10.1109%2fICICT60155.2024.10544639&partnerID=40&md5=bb3a836c6ff60ba0657bb461751d08dd","Karunya Institute of Technology And Sciences, Division of Cse, Tamil Nadu, Coimbatore, India; Karunya Institute of Technology And Sciences, Division of Dscs, Tamil Nadu, Coimbatore, India","Stewart Kirubakaran S., Karunya Institute of Technology And Sciences, Division of Cse, Tamil Nadu, Coimbatore, India; Jasper Wilsie Kathrine G., Karunya Institute of Technology And Sciences, Division of Cse, Tamil Nadu, Coimbatore, India; Grace Mary Kanaga E., Karunya Institute of Technology And Sciences, Division of Dscs, Tamil Nadu, Coimbatore, India; Mahimai Raja J., Karunya Institute of Technology And Sciences, Division of Cse, Tamil Nadu, Coimbatore, India; Ruban Gino Singh A., Karunya Institute of Technology And Sciences, Division of Cse, Tamil Nadu, Coimbatore, India; Yuvaraajan E., Karunya Institute of Technology And Sciences, Division of Cse, Tamil Nadu, Coimbatore, India","Infectious diseases like COVID-19 have gained international attention recently. Furthermore, there are significantly fewer doctors per capita in densely populated nations like India, which hurts those in need. Under such circumstances, natural language processing techniques might make it feasible to create an intelligent and engaging chatbot system. The primary objective of the effort is to develop an interactive solution that is entirely open source and can be easily installed on a local computer using the most recent data. Even though there are numerous chatbots on the market, proposed solutions highlight the need to provide individualized and sympathetic responses. Getting Back While the data is stored in the graph database as nodes and relationships, and the knowledge graph is constructed on top of it, augmented generation is utilized to extract the pertinent content from the data. To improve the generator's context, pertinent sections are collected during the question-answering process. This reduces hallucinations and increases the correctness of abstractions by providing external knowledge streams. Furthermore, the research study employs a text-to-speech model that was replicated from a physician's voice recording to narrate the produced responses, thereby augmenting user confidence and interaction. Academic institutions and healthcare organizations can benefit from this work by better understanding the value and effectiveness of applying NLP techniques to infectious disease research.  © 2024 IEEE.","chatbot; COVID-19; knowledge graph; large language model; natural language processing; retrieval augmented generation","Graph Databases; Knowledge graph; Natural language processing systems; Open systems; Chatbots; Infectious disease; Knowledge graphs; Language model; Language processing; Large language model; Natural language processing; Natural languages; Per capita; Retrieval augmented generation; COVID-19","","Institute of Electrical and Electronics Engineers Inc.","English","Conference paper","Final","","Scopus","2-s2.0-85196085291"
"Welz L.; Lanquillon C.","Welz, Laslo (57925845000); Lanquillon, Carsten (24178557600)","57925845000; 24178557600","Enhancing Large Language Models Through External Domain Knowledge","2024","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","14736 LNAI","","","135","146","11","0","10.1007/978-3-031-60615-1_9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195445690&doi=10.1007%2f978-3-031-60615-1_9&partnerID=40&md5=d87fa0b5e07f30a80369e62b69271ab0","Heilbronn University of Applied Sciences, Max-Planck-Str. 39, Heilbronn, 74081, Germany","Welz L., Heilbronn University of Applied Sciences, Max-Planck-Str. 39, Heilbronn, 74081, Germany; Lanquillon C., Heilbronn University of Applied Sciences, Max-Planck-Str. 39, Heilbronn, 74081, Germany","Large Language Models (LLM) demonstrate promising results in generating content with current fine-tuning and prompting methods. Yet, they have limited application in industrial knowledge management or specific expert domains, due to weak factuality and safety-critical hallucination. Therefore, it is necessary to enhance the language model with external knowledge. The provision and representation of the external knowledge holds several challenges and problems. This paper proposes a human-centred LLM-based system architecture designed as a modular extension, which improves the overall factuality of the generated output. Following a design science research approach, first the problems and objectives of the research are identified. In the next step the artifact is developed based on requirements deducted from literature. Eventually, the functionality of the artifact is demonstrated as a proof-of-concept in a case study. The research contributes an initial approach for effective and grounded knowledge transfer, which minimizes the risk of hallucination from LLM-generated content.   © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.","Expert Knowledge; Information Retrieval; Large Language Models; Retrieval Augmented Generation","Accident prevention; Computational linguistics; Domain Knowledge; Information retrieval; 'current; Domain knowledge; Expert knowledge; External knowledge; Fine tuning; Language model; Large language model; Model-based systems; Retrieval augmented generation; Systems architecture; Knowledge management","Degen H.; Ntoa S.","Springer Science and Business Media Deutschland GmbH","English","Conference paper","Final","","Scopus","2-s2.0-85195445690"
"","","","20th IFIP WG 12.5 International Conference on Artificial Intelligence Applications and Innovations, AIAI 2024","2024","IFIP Advances in Information and Communication Technology","714","","","","","1497","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197628796&partnerID=40&md5=7388e4a5c47005f33743dc0d4fa9fbac","","","The proceedings contain 108 papers. The special focus in this conference is on Artificial Intelligence Applications and Innovations. The topics include: Strategizing the Shallows: Leveraging Multi-Agent Reinforcement Learning for Enhanced Tactical Decision-Making in Littoral Naval Warfare; multi-dimensional Classification on Social Media Data for Detailed Reporting with Large Language Models; LLM Prompting Versus Fine-Tuning PLMs: A Comparative Study on Keyword Generation from Customer Feedback; greekT5: Sequence-to-Sequence Models for Greek News Summarization; generating Profiles of News Commentators with Language Models; enhancing Financial Market Prediction with Reinforcement Learning and Ensemble Learning; AI-Driven Sentiment Trend Analysis: Enhancing Topic Modeling Interpretation with ChatGPT; preface; detecting Illicit Data Leaks on Android Smartphones Using an Artificial Intelligence Models; an Algorithmic Data Pipeline Architecture for the Production of Personalized Telecom Product Offers; improving Agricultural Image Classification by Mining Images; enhancing Predictive Process Monitoring with Conformal Prediction; online Reinforcement Learning for Designing Automotive Hybrid Assembly Sequence: A Task Clustering-Guided Approach; SMT: Self-supervised Approach for Multiple Animal Detection and Tracking; Improved NO2 Prediction Using Machine Learning Algorithms; benign Paroxysmal Positional Vertigo Disorders Classification Using Eye Tracking Data; Improving RAG Quality for Large Language Models with Topic-Enhanced Reranking; the Impact of Augmentation Techniques on Icon Detection Using Machine Learning Techniques; unlocking User Privacy: A Systematic Survey of Factors and Methods in Predicting App Permission Decisions; toward Unsupervised Energy Consumption Anomaly Detection; simulation Study for Evaluating Efficiency of McPhail Traps in Olive Groves; predictive Maintenance Under Absence of Sensor Data; pollutant Concentration Prediction by Random Forest to Estimate a Contaminant Source Position; Machine Learning Models for Electricity Generation Forecasting from a PV Farm.","","","Maglogiannis I.; Iliadis L.; Papaleonidas A.; Macintyre J.; Avlonitis M.","Springer Science and Business Media Deutschland GmbH","English","Conference review","Final","","Scopus","2-s2.0-85197628796"
"Muludi K.; Fitria K.M.; Triloka J.; Sutedi","Muludi, Kurnia (53264415400); Fitria, Kaira Milani (58979156100); Triloka, Joko (56401829500); Sutedi (57195267636)","53264415400; 58979156100; 56401829500; 57195267636","Retrieval-Augmented Generation Approach: Document Question Answering using Large Language Model","2024","International Journal of Advanced Computer Science and Applications","15","3","","776","785","9","0","10.14569/IJACSA.2024.0150379","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189943350&doi=10.14569%2fIJACSA.2024.0150379&partnerID=40&md5=b3c38533a1a335a606e07d42a7489644","Informatics Engineering Graduate Program, Darmajaya Informatics and Business Institute, Bandar Lampung, Indonesia","Muludi K., Informatics Engineering Graduate Program, Darmajaya Informatics and Business Institute, Bandar Lampung, Indonesia; Fitria K.M., Informatics Engineering Graduate Program, Darmajaya Informatics and Business Institute, Bandar Lampung, Indonesia; Triloka J., Informatics Engineering Graduate Program, Darmajaya Informatics and Business Institute, Bandar Lampung, Indonesia; Sutedi, Informatics Engineering Graduate Program, Darmajaya Informatics and Business Institute, Bandar Lampung, Indonesia","This study introduces the Retrieval Augmented Generation (RAG) method to improve Question-Answering (QA) systems by addressing document processing in Natural Language Processing problems. It represents the latest breakthrough in applying RAG to document question and answer applications, overcoming previous QA system obstacles. RAG combines search techniques in vector store and text generation mechanism developed by Large Language Models, offering a time-efficient alternative to manual reading limitations. The research evaluates RAG's that use Generative Pre-trained Transformer 3.5 or GPT-3.5-turbo from the ChatGPT model and its impact on document data processing, comparing it with other applications. This research also provides datasets to test the capabilities of the QA document system. The proposed dataset and Stanford Question Answering Dataset (SQuAD) are used for performance testing. The study contributes theoretically by advancing methodologies and knowledge representation, supporting benchmarking in research communities. Results highlight RAG's superiority: achieving a precision of 0.74 in Recall-Oriented Understudy for Gisting Evaluation (ROUGE) testing, outperforming others at 0.5; obtaining an F1 score of 0.88 in BERTScore, surpassing other QA apps at 0.81; attaining a precision of 0.28 in Bilingual Evaluation Understudy (BLEU) testing, surpassing others with a precision of 0.09; and scoring 0.33 in Jaccard Similarity, outshining others at 0.04. These findings underscore RAG's efficiency and competitiveness, promising a positive impact on various industrial sectors through advanced Artificial Intelligence (AI) technology. © (2024), (Science and Information Organization). All Rights Reserved.","GPT; Large Language Model; Natural Language Processing; Question Answering; Retrieval Augmented Generation","Competition; Computational linguistics; Data handling; Knowledge representation; Search engines; Statistical tests; Generation method; GPT; Language model; Language processing; Large language model; Natural language processing; Natural languages; Question Answering; Question answering systems; Retrieval augmented generation; Natural language processing systems","","Science and Information Organization","English","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85189943350"
"Keleş O.; Bayraklı Ö.T.","Keleş, Onur (59156802200); Bayraklı, Ömer Turan (59156802300)","59156802200; 59156802300","LLaMA-2-Econ: Enhancing Title Generation, Abstract Classification, and Academic Q&A in Economic Research","2024","Joint Workshop of the 7th Financial Technology and Natural Language Processing, the 5th Knowledge Discovery from Unstructured Data in Financial Services and the 4th Economics and Natural Language Processing, FinNLP-KDF-ECONLP 2024 at LREC-COLING 2024 - Workshop Proceedings","","","","212","218","6","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195190955&partnerID=40&md5=41305d3d4cd0b944705cc8d3c4d68496","Boğaziçi University, Istanbul University Department of Linguistics, Department of Econometrics, Turkey","Keleş O., Boğaziçi University, Istanbul University Department of Linguistics, Department of Econometrics, Turkey; Bayraklı Ö.T., Boğaziçi University, Istanbul University Department of Linguistics, Department of Econometrics, Turkey","Using Quantized Low Rank Adaptation and Parameter Efficient Fine Tuning, we fine-tuned Meta AI’s LLaMA-2-7B large language model as a research assistant in the field of economics for three different types of tasks: title generation, abstract classification, and question and answer. The model was fine-tuned on economics paper abstracts and syntheticically created question-answer dialogues based on the abstracts. For the title generation, the results of the experiment demonstrated that LLaMA-2-Econ (the fine-tuned model) surpassed the base model (7B and 13B) with few shot learning, and comparable models of similar size like Mistral-7B and Bloom-7B in the BLEU and ROUGE metrics. For abstract categorization, LLaMA-2-Econ outperformed different machine and deep learning algorithms in addition to state-of-the-art models like GPT 3.5 and GPT 4 with both single and representative few shot learning. We tested the fine-tuned Q&A model by comparing its output with the base LLaMA-2-7B-chat with a Retrieval Augmented Generation (RAG) pipeline with semantic search and dense vector indexing, and found that LLaMA-2 performed on a par with the base model with RAG. © 2024 ELRA Language Resource Association.","economics; LLaMA-2; PEFT; QLoRA; SFT","Abstracting; Deep learning; Economics; Learning systems; Semantics; Base models; Economic research; Fine tuning; Language model; LLaMA-2; PEFT; QLoRA; SFT; State of the art; Title generation; Learning algorithms","Chen C.-C.; Ma Z.; Hahn U.","European Language Resources Association (ELRA)","English","Conference paper","Final","","Scopus","2-s2.0-85195190955"
"","","","3rd Ukrainian Natural Language Processing Workshop, UNLP 2024 at LREC-COLING 2024 - Workshop Proceedings","2024","3rd Ukrainian Natural Language Processing Workshop, UNLP 2024 at LREC-COLING 2024 - Workshop Proceedings","","","","","","146","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195184674&partnerID=40&md5=038f63e82fa6e6593e5f845b895b3c6a","","","The proceedings contain 16 papers. The topics discussed include: a contemporary news corpus of Ukrainian (CNC-UA): compilation, annotation, publication; introducing the djinni recruitment dataset: a corpus of anonymized CVs and job postings; instant messaging platforms news multi-task classification for stance, sentiment, and discrimination detection; setting up the data printer with improved English to Ukrainian machine translation; automated extraction of hypo-hypernym relations for the Ukrainian WordNet; Ukrainian visual word sense disambiguation benchmark; fine-tuning and retrieval augmented generation for question answering using affordable large language models; from bytes to borsch: fine-tuning gemma and mistral for the Ukrainian language representation; and entity embellishment mitigation in LLMs output with noisy synthetic dataset for alignment.","","","Romanyshyn M.","European Language Resources Association (ELRA)","English","Conference review","Final","","Scopus","2-s2.0-85195184674"
"Zhang R.; Du H.; Liu Y.; Niyato D.; Kang J.; Sun S.; Shen X.; Poor H.V.","Zhang, Ruichen (57221800822); Du, Hongyang (57211884589); Liu, Yinqiu (57209318696); Niyato, Dusit (8919714700); Kang, Jiawen (55960988400); Sun, Sumei (7404509781); Shen, Xuemin (58094942200); Poor, H. Vincent (55665272100)","57221800822; 57211884589; 57209318696; 8919714700; 55960988400; 7404509781; 58094942200; 55665272100","Interactive AI with Retrieval-Augmented Generation for Next Generation Networking","2024","IEEE Network","","","","1","1","0","2","10.1109/MNET.2024.3401159","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193268130&doi=10.1109%2fMNET.2024.3401159&partnerID=40&md5=2f1d8b816105ce721a4d187c77e1cab9","School of Computer Science and Engineering, Nanyang Technological University, Singapore; School of Automation, Guangdong University of Technology, China; Institute for Infocomm Research, Agency for Science, Technology and Research, Singapore; Department of Electrical and Computer Engineering, University of Waterloo, Canada; Department of Electrical and Computer Engineering, Princeton University, Princeton, NJ, USA","Zhang R., School of Computer Science and Engineering, Nanyang Technological University, Singapore; Du H., School of Computer Science and Engineering, Nanyang Technological University, Singapore; Liu Y., School of Computer Science and Engineering, Nanyang Technological University, Singapore; Niyato D., School of Computer Science and Engineering, Nanyang Technological University, Singapore; Kang J., School of Automation, Guangdong University of Technology, China; Sun S., Institute for Infocomm Research, Agency for Science, Technology and Research, Singapore; Shen X., Department of Electrical and Computer Engineering, University of Waterloo, Canada; Poor H.V., Department of Electrical and Computer Engineering, Princeton University, Princeton, NJ, USA","With the advance of artificial intelligence (AI), the concept of interactive AI (IAI) has been introduced, which can interactively understand and respond not only to human user input but also to dynamic system and network conditions. In this article, we explore an integration and enhancement of IAI in networking.We first comprehensively review recent developments and future perspectives of AI and then introduce the technology and components of IAI. We then explore the integration of IAI into next-generation networks, focusing on how implicit and explicit interactions can enhance network functionality, improve user experience, and promote efficient network management. Subsequently, we propose an IAI-enabled network management and optimization framework, which consists of environment, perception, action, and brain units. We also design a pluggable large language model (LLM) module and retrieval augmented generation (RAG) module to build the knowledge base and contextual memory for decision-making in the brain unit. We demonstrate through case studies that our IAI framework can effectively perform optimization problem design. Finally, we discuss potential research directions for IAI-based networks. IEEE","AGI; Artificial intelligence; Data models; Heuristic algorithms; IAI; networking; Optimization; pluggable LLM module; Prediction algorithms; Predictive models; problem formulation; RAG; Task analysis","Decision making; Heuristic algorithms; Job analysis; Knowledge based systems; Network management; Next generation networks; AGI; Heuristics algorithm; Interactive AI; Language-modeling module; Networking; Optimisations; Pluggable large language model module; Prediction algorithms; Predictive models; Problem formulation; Retrieval augmented generation; Task analysis; Optimization","","Institute of Electrical and Electronics Engineers Inc.","English","Article","Article in press","All Open Access; Green Open Access","Scopus","2-s2.0-85193268130"
"Omeed H.K.; Alani A.O.; Rasul I.H.; Ashir A.M.; Mohammed S.A.","Omeed, Holan K. (59185266600); Alani, Ahmed O. (59185266700); Rasul, Ibrahim H. (59184508700); Ashir, Abubakar M. (56296716000); Mohammed, Sava Ahmed (59184659600)","59185266600; 59185266700; 59184508700; 56296716000; 59184659600","Integrating Computer Vision and language model for interactive AI - Robot","2024","2024 21st International Multi-Conference on Systems, Signals and Devices, SSD 2024","","","","124","131","7","0","10.1109/SSD61670.2024.10548649","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196710982&doi=10.1109%2fSSD61670.2024.10548649&partnerID=40&md5=ff6c610ac61ed81eb3104590d41a24ac","Tishk International University, Dept. of Information Technology, Arbil, Iraq","Omeed H.K., Tishk International University, Dept. of Information Technology, Arbil, Iraq; Alani A.O., Tishk International University, Dept. of Information Technology, Arbil, Iraq; Rasul I.H., Tishk International University, Dept. of Information Technology, Arbil, Iraq; Ashir A.M., Tishk International University, Dept. of Information Technology, Arbil, Iraq; Mohammed S.A., Tishk International University, Dept. of Information Technology, Arbil, Iraq","This research presents an innovative approach to integrating robotic systems with artificial intelligence, addressing long-standing challenges in their functionality. Utilizing YOLOv9 object detection model, Large Language Model LLM, Retrieval Augmented Generation RAG, alongside a 6 degree of freedom robotic arm 6DOF, the design achieves seamless interaction and multifaceted functionality. Key design choices, including hardware selection (Raspberry Pi 58GB) and utilization of various techniques, optimize performance. Experimental results demonstrate a confidence level of 1.0 at a confidence threshold of 0.970 for all classes combined. In the F1-Confidence curve, the all-classes curve achieves an F1 score of 0.84 at a confidence threshold of 0.524, showcasing overall strong performance and a balanced trade-off between precision and recall. The synthesis of diverse methodological approaches underscores the developmental trajectory of this sophisticated robotic assistant, showcasing its transformative potential in promoting effective operations beyond conventional paradigms. © 2024 IEEE.","AI-Enhanced Robotics; Artificial Intelligence; Large Language Model Applications; Robotic Personal Assistant; Robotics","Computational linguistics; Computer vision; Degrees of freedom (mechanics); Intelligent robots; Object detection; AI-enhanced robotic; Confidence threshold; Innovative approaches; Language model; Large language model application; Model application; Performance; Personal assistants; Robotic personal assistant; Vision model; Economic and social effects","","Institute of Electrical and Electronics Engineers Inc.","English","Conference paper","Final","","Scopus","2-s2.0-85196710982"
"Abdelazim H.; Tharwat M.; Mohamed A.","Abdelazim, Hazem (58754585800); Tharwat, Mohamed (58754648500); Mohamed, Ammar (25929443300)","58754585800; 58754648500; 25929443300","Semantic Embeddings for Arabic Retrieval Augmented Generation (ARAG)","2023","International Journal of Advanced Computer Science and Applications","14","11","","1328","1334","6","0","10.14569/IJACSA.2023.01411135","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179181459&doi=10.14569%2fIJACSA.2023.01411135&partnerID=40&md5=9da1aa519f39c737a9116bde497ef66c","School of Computing and Digital Technology, ESLSCA University, Cairo, Egypt","Abdelazim H., School of Computing and Digital Technology, ESLSCA University, Cairo, Egypt; Tharwat M., School of Computing and Digital Technology, ESLSCA University, Cairo, Egypt; Mohamed A., School of Computing and Digital Technology, ESLSCA University, Cairo, Egypt","In recent times, Retrieval Augmented Generation (RAG) models have garnered considerable attention, primarily due to the impressive capabilities exhibited by Large Language Models (LLMs). Nevertheless, the Arabic language, despite its significance and widespread use, has received relatively less research emphasis in this field. A critical element within RAG systems is the Information Retrieval component, and at its core lies the vector embedding process commonly referred to as “semantic embedding”. This study encompasses an array of multilingual semantic embedding models, intending to enhance the model’s ability to comprehend and generate Arabic text effectively. We conducted an extensive evaluation of the performance of ten cutting-edge Multilingual Semantic embedding models, employing a publicly available ARCD dataset as a benchmark and assessing their performance using the average Recall@k metric. The results showed that the Microsoft E5 sentence embedding model outperformed all other models on the ARCD dataset, with Recall@10 exceeding 90% © (2023), (Science and Information Organization). All Rights Reserved.","Arabic NLP; large language models; retrieval augmented generation; semantic embedding","Computational linguistics; Embeddings; Natural language processing systems; Search engines; Semantics; Arabic languages; Arabic NLP; Critical elements; Embedding process; Generation systems; Language model; Large language model; Performance; Retrieval augmented generation; Semantic embedding; Benchmarking","","Science and Information Organization","English","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85179181459"
"Datta V.D.; Ganesh S.; Haas R.E.; Talukder A.K.","Datta, V Dinesh (58777893300); Ganesh, Sakthi (57205200975); Haas, Roland E. (57196720657); Talukder, Asoke K. (9734726700)","58777893300; 57205200975; 57196720657; 9734726700","GREAT AI in Medical Appropriateness and Value-Based-Care","2023","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","14418 LNCS","","","16","33","17","0","10.1007/978-3-031-49601-1_2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180527813&doi=10.1007%2f978-3-031-49601-1_2&partnerID=40&md5=4c27a648eb683a24f14789f02fc3ae5b","Kakatiya Medical College, Nizampura, Rangampet Street, Telangana, Warangal, 506007, India; XAITeck GmbH, Heinrich-Otto-Straße 71, Wendlingen, 73240, Germany; International Institute of Information Technology, 26/C, Electronics City, Hosur Road, Bengaluru, 560100, India; BlueRose Technologies, 1-1, Langford Road, Shanti Nagar, Bengaluru, 560027, India; Computer Science & Engineering, National Institute of Technology, Surathkal, India; SRIT, 113/1B ITPL Road, Brookfield, Bengaluru, 560037, India","Datta V.D., Kakatiya Medical College, Nizampura, Rangampet Street, Telangana, Warangal, 506007, India; Ganesh S., XAITeck GmbH, Heinrich-Otto-Straße 71, Wendlingen, 73240, Germany; Haas R.E., XAITeck GmbH, Heinrich-Otto-Straße 71, Wendlingen, 73240, Germany, International Institute of Information Technology, 26/C, Electronics City, Hosur Road, Bengaluru, 560100, India; Talukder A.K., XAITeck GmbH, Heinrich-Otto-Straße 71, Wendlingen, 73240, Germany, BlueRose Technologies, 1-1, Langford Road, Shanti Nagar, Bengaluru, 560027, India, Computer Science & Engineering, National Institute of Technology, Surathkal, India, SRIT, 113/1B ITPL Road, Brookfield, Bengaluru, 560037, India","Fee For Service, also known as Volume Based Care (VBC) model of healthcare encourages service volume – more service more reward. This model of care results in unnecessary, inappropriate, and wasted medical services. In the US, Fraud, Waste, and Abuse (FWA) ranges between $760 billion to $935 billion, accounting for approximately 25% of total healthcare spending. In India, the waste caused by FWA is estimated to be as high as 35%. This is due to a lack of smart digital health, absence of AI models, and lack of preventive vigilance against inappropriate medical interventions. Inappropriate medical intervention costs valuable resources and causes patient harm. This paper proposes GREAT AI (Generative, Responsible, Explainable, Adaptive, and Trustworthy Artificial Intelligence) in Medical Appropriateness. We show how GREAT AI is used to offer appropriate medical services. Moreover, we show how GREAT AI can function in vigilance role to curb FWA. We present two GREAT AI models namely MAKG (Medical Appropriateness Knowledge Graph) and RAG-GPT (Retrieval Augmented Generation – Generative Pretrained Transformer). MAKG is used as an autonomous coarse-grained medical-inappropriateness vigilance model for payers and regulators. Whereas RAG-GPT is used as a fine-grained LLM, with human-in-the-loop for medical appropriateness and medical inappropriateness model where the actor human-in-the loop can be anybody like providers, patients, payers, regulators, funders, or researchers. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.","Adaptive AI; Explainable AI; Generative AI; GREAT AI; MAKG; Medical Appropriateness; RAG-GPT; Responsible AI; Trustworthy AI","Patient treatment; Adaptive AI; Explainable AI; Generative AI; GREAT AI; Knowledge graphs; Medical appropriateness; Medical appropriateness knowledge graph; Responsible AI; Retrieval augmented generation – generative pretrained transformer; Trustworthy AI; Knowledge graph","Goyal V.; Kumar D.; Kumar N.; Bhowmick S.S.; Goyal P.; Goyal N.","Springer Science and Business Media Deutschland GmbH","English","Conference paper","Final","","Scopus","2-s2.0-85180527813"
"Ghodratnama S.; Zakershahrak M.","Ghodratnama, Samira (57203909285); Zakershahrak, Mehrdad (57211415197)","57203909285; 57211415197","Adapting LLMs for Efficient, Personalized Information Retrieval: Methods and Implications","2024","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","14518 LNCS","","","17","26","9","0","10.1007/978-981-97-0989-2_2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189749520&doi=10.1007%2f978-981-97-0989-2_2&partnerID=40&md5=9b756047f094d12d1808c9d656585173","Macquaire University, Sydney, Australia","Ghodratnama S., Macquaire University, Sydney, Australia; Zakershahrak M., Macquaire University, Sydney, Australia","The advent of Large Language Models (LLMs) heralds a pivotal shift in online user interactions with information. Traditional Information Retrieval (IR) systems primarily relied on query-document matching, whereas LLMs excel in comprehending and generating human-like text, thereby enriching the IR experience significantly. While LLMs are often associated with chatbot functionalities, this paper extends the discussion to their explicit application in information retrieval. We explore methodologies to optimize the retrieval process, select optimal models, and effectively scale and orchestrate LLMs, aiming for cost-efficiency and enhanced result accuracy. A notable challenge, model hallucination-where the model yields inaccurate or misinterpreted data-is addressed alongside other model-specific hurdles. Our discourse extends to crucial considerations including user privacy, data optimization, and the necessity for system clarity and interpretability. Through a comprehensive examination, we unveil not only innovative strategies for integrating Language Models (LLMs) with Information Retrieval (IR) systems, but also the consequential considerations that underline the need for a balanced approach aligned with user-centric principles. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2024.","Examining Language Learning Model-Integrated Applications; Retrieval-Augmented Generation (RAG); Scaling and Orchestrating LLM-based Applications","Computational linguistics; Search engines; Examining language learning model-integrated application; Information-retrieval systems; Integrated applications; Language learning models; Language model; Model-based OPC; Personalized information retrieval; Retrieval-augmented generation; Scaling and orchestrating large language model-based application; Scalings; Information retrieval","Monti F.; Plebani P.; Moha N.; Paik H.; Barzen J.; Ramachandran G.; Bianchini D.; Tamburri D.A.; Mecella M.","Springer Science and Business Media Deutschland GmbH","English","Conference paper","Final","","Scopus","2-s2.0-85189749520"
"Kharitonova K.; Pérez-Fernández D.; Gutiérrez-Hernando J.; Gutiérrez-Fandiño A.; Callejas Z.; Griol D.","Kharitonova, Ksenia (57221904366); Pérez-Fernández, David (57224983441); Gutiérrez-Hernando, Javier (58922489200); Gutiérrez-Fandiño, Asier (57221713729); Callejas, Zoraida (55991672400); Griol, David (15765332600)","57221904366; 57224983441; 58922489200; 57221713729; 55991672400; 15765332600","Incorporating evidence into mental health Q&A: a novel method to use generative language models for validated clinical content extraction","2024","Behaviour and Information Technology","","","","","","","0","10.1080/0144929X.2024.2321959","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186908711&doi=10.1080%2f0144929X.2024.2321959&partnerID=40&md5=32dda5bf25f72c4e907bde37dbf3a270","Department Software Engineering, University of Granada, Granada, Spain; Department of Mathematics, Universidad Autónoma de Madrid, Ciudad Universitaria de Cantoblanco, Madrid, Spain; LHF Labs, Bizkaia, Bilbao, Spain; Research Centre for Information and Communication Technologies (CITIC-UGR), University of Granada, Granada, Spain","Kharitonova K., Department Software Engineering, University of Granada, Granada, Spain; Pérez-Fernández D., Department of Mathematics, Universidad Autónoma de Madrid, Ciudad Universitaria de Cantoblanco, Madrid, Spain; Gutiérrez-Hernando J., Department Software Engineering, University of Granada, Granada, Spain; Gutiérrez-Fandiño A., LHF Labs, Bizkaia, Bilbao, Spain; Callejas Z., Department Software Engineering, University of Granada, Granada, Spain, Research Centre for Information and Communication Technologies (CITIC-UGR), University of Granada, Granada, Spain; Griol D., Department Software Engineering, University of Granada, Granada, Spain","Generative language models have changed the way we interact with computers using natural language. With the release of increasingly advanced GPT models, systems are able to correctly respond to questions in various domains. However, they still have important limitations, such as hallucinations, lack of substance in answers, inability to justify responses, or showing high confidence with fabricated content. In digital mental health, every decision must be traceable and based on scientific evidence and these shortcomings are hindering the integration of LLMs into clinical practice. In this paper, we provide a novel automated method to develop evidence-based question answering systems. Powerful state-of-the-art generalist language models are used and forced to employ only contents in validated clinical guidelines, tracking the source of the evidence for each generated response. This way, the system is able to protect users from hallucinatory responses. As a proof of concept, we present the results obtained building question-answering systems circumscribed to the clinical practice guidelines of the Spanish National Health System about the management of depression and attention deficit hyperactivity disorder. The coherence, veracity, and evidence supporting the responses have been evaluated by human experts obtaining high reliability, clarity, completeness, and traceability of evidence results. © 2024 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group.","clinical practice guide; generative language model; large language model; mental health; Question-answering; retrieval-augmented generation","Artificial intelligence; Natural language processing systems; Clinical practice guide; Clinical practices; Generative language model; Language model; Large language model; Mental health; Question Answering; Question answering systems; Retrieval-augmented generation; Computational linguistics","","Taylor and Francis Ltd.","English","Article","Article in press","All Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85186908711"
"Boskovic I.; Tabas V.","Boskovic, Ivan (58986404700); Tabas, Vladan (58986582300)","58986404700; 58986582300","Proposal for Enhancing Legal Advisory Services in the Montenegrin Banking Sector with Artificial Intelligence","2024","2024 28th International Conference on Information Technology, IT 2024","","","","","","","0","10.1109/IT61232.2024.10475735","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190449104&doi=10.1109%2fIT61232.2024.10475735&partnerID=40&md5=578e26d7f60d9334a51ba8b06a23117d","It Advanced Services, Podgorica, Montenegro; Čikom, Podgorica, Montenegro","Boskovic I., It Advanced Services, Podgorica, Montenegro; Tabas V., Čikom, Podgorica, Montenegro","This paper examines the integration of Large Language Models (LLMs) and Retrieval-Augmented Generation (RAG) in improving legal advisory services within the Montenegrin banking industry. It explores the vectorization of regulatory documents using ADA-2 embedding model, the storage and management of these vectorized forms in Chroma DB, and the utilization of GPT-4 for processing relevant documents to generate user responses, providing insights into the use of artificial intelligence (AI) for legal advisement and financial education.  © 2024 IEEE.","","Advisory services; Banking industry; Banking sectors; Embeddings; Financial education; Language model; Regulatory documents; Relevant documents; Vectorization; Artificial intelligence","","Institute of Electrical and Electronics Engineers Inc.","English","Conference paper","Final","","Scopus","2-s2.0-85190449104"
"Haugsbaken H.; Hagelia M.","Haugsbaken, Halvdan (59163690000); Hagelia, Marianne (58536506700)","59163690000; 58536506700","A New AI Literacy For The Algorithmic Age: Prompt Engineering Or Eductional Promptization?","2024","2024 4th International Conference on Applied Artificial Intelligence, ICAPAI 2024","","","","","","","0","10.1109/ICAPAI61893.2024.10541229","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195360294&doi=10.1109%2fICAPAI61893.2024.10541229&partnerID=40&md5=efc73e60a6dd9226b1e5eef5d80a4333","Ostfold University College, Dept. of Education, Ict and Learning, Halden, Norway","Haugsbaken H., Ostfold University College, Dept. of Education, Ict and Learning, Halden, Norway; Hagelia M., Ostfold University College, Dept. of Education, Ict and Learning, Halden, Norway","The introduction and rapid adoption of particular Artificial Intelligence (AI) technologies such as Large Language Models, where among other, Chat Generative Pre-trained Transformer (ChatGPT) is a prominent one, have caused a significant increase in research interest for prompt engineering. Prompt engineering can be loosely described as a new emerging field where one attempts to develop particular methods, strategies, and frameworks with the main aim of organizing and structuring inputs in such a way that sophisticated AI systems can perform different tasks. These methods, techniques, and frameworks can be concepts like in-context learning, Chain-of-Thought (CoT), Retrieval Augmented Generation, ReAct prompting, and Directional Stimulus Prompting. These approaches are mainly developed so users can communicate more effectively and accurately with AI language models and enable obtaining better outputs or responses tailored to queries or goals they set. As an extension and new contribution to the mentioned research field, this conceptual paper aims to introduce, propose, and theorize the notion of 'educational promptization'. This will be done by connecting prompting to a particular social scientific practice perspective, sociomateriality. The rationale for arguing, however, is related to a need to develop an alternative research perspective to those that already dominate the mentioned research field, a research stream this conceptual paper also aims to engage with. Educational promptization is suggested as there is a demand to develop a more student-centric media literacy, especially as students and teachers engage with AI language interpreters on a daily basis. This means that the proposed educational promptization can arguably be considered to be part of a future AI literacy. An essential component of it is that one has to encompass the relational and symmetrical engagement with AI models. This is perhaps required because students will most likely be challenged to master the knowledge and skills in designing prompts, while simultaneously being capable of critically and meaningfully assessing the output of the prompts they created. In other words, mastering the complex input-and-output engagements with an AI system will be essential in students' future learning processes.  © 2024 IEEE.","digital competence; education; prompt; prompt engineering; sociomateriality; student","Computational linguistics; E-learning; Education computing; Engineering education; Learning systems; Algorithmics; Artificial intelligence systems; Artificial intelligence technologies; Digital competence; Language model; Prompt; Prompt engineering; Research fields; Research interests; Socio materialities; Students","","Institute of Electrical and Electronics Engineers Inc.","English","Conference paper","Final","","Scopus","2-s2.0-85195360294"
"","","","UncertaiNLP 2024 - Workshop on Uncertainty-Aware NLP, Proceedings of the Workshop","2024","UncertaiNLP 2024 - Workshop on Uncertainty-Aware NLP, Proceedings of the Workshop","","","","","","135","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188661032&partnerID=40&md5=9d3acf2024519c49a637c850efa75aaa","","","The proceedings contain 13 papers. The topics discussed include: calibration-tuning: teaching large language models to know what they don’t know; context tuning for retrieval augmented generation; optimizing relation extraction in medical texts through active learning: a comparative analysis of trade-offs; linguistic obfuscation attacks and large language model uncertainty; aligning uncertainty: leveraging LLMS to analyze uncertainty transfer in text summarization; how does beam search improve span-level confidence estimation in generative sequence labeling?; efficiently acquiring human feedback with Bayesian deep learning; order effects in annotation tasks: further evidence of annotation sensitivity; the effect of generalization on the inadequacy of the mode; don’t blame the data, blame the model: understanding noise and bias when learning from subjective annotations; and combining confidence elicitation and sample-based methods for uncertainty quantification in misinformation mitigation.","","","Vazquez R.; Celikkanat H.; Ulmer D.; Tiedemann J.; Swayamdipta S.; Aziz W.; Plank B.; Plank B.; Baan J.; de Marneffe M.-C.","Association for Computational Linguistics (ACL)","English","Conference review","Final","","Scopus","2-s2.0-85188661032"
"Duca A.L.","Duca, Angelica Lo (58994022700)","58994022700","Using Retrieval Augmented Generation to Build the Context for Data-Driven Stories","2024","Proceedings of the International Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications","1","","","690","696","6","0","10.5220/0012419700003660","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190882072&doi=10.5220%2f0012419700003660&partnerID=40&md5=c53f7305e80cfafc4b59343b1894f3eb","Institute of Informatics and Telematics, National Research Council, via G. Moruzzi 1, Pisa, 56124, Italy","Duca A.L., Institute of Informatics and Telematics, National Research Council, via G. Moruzzi 1, Pisa, 56124, Italy","Data Storytelling (DS) is building data-driven stories to communicate the result of a data analysis process effectively. However, it may happen that data storytellers lack the competences to build compelling texts to include in the data-driven stories. In this paper, we propose a novel strategy to enhance DS by automatically generating context for data-driven stories, leveraging the capabilities of Generative AI (GenAI). This contextual information provides the background knowledge necessary for the audience to understand the story's message fully. Our approach uses Retrieval Augmented Generation (RAG), which adapts large language models (LLMs), the core concept behind GenAI, to the specific domain required by a data-driven story. We demonstrate the effectiveness of our method through a practical case study on salmon aquaculture, showcasing the ability of GenAI to enrich DS with relevant context. We also describe some possible strategies to evaluate the generated context and ethical issues may raise when using GenAI in DS. © 2024 by SCITEPRESS – Science and Technology Publications, Lda.","Data Storytelling; Data Visualization; Generative AI; Retrieval Augmented Generation","","Radeva P.; Furnari A.; Bouatouch K.; Sousa A.A.","Science and Technology Publications, Lda","English","Conference paper","Final","All Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85190882072"
"Wijesinghe A.; Rajapakse C.; Asanka D.","Wijesinghe, Abhiru (59030880900); Rajapakse, Chathura (57211268610); Asanka, Dinesh (57194777710)","59030880900; 57211268610; 57194777710","Artificial Intelligence Model to Suggest Sewing Operations Through Sketch Analysis","2024","ICARC 2024 - 4th International Conference on Advanced Research in Computing: Smart and Innovative Trends in Next Generation Computing Technologies","","","","97","102","5","0","10.1109/ICARC61713.2024.10499761","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192135442&doi=10.1109%2fICARC61713.2024.10499761&partnerID=40&md5=fbda06a8eb96be240517e3bbd839b1b2","University of Kelaniya, Department of Industrial Management, Kelaniya, Sri Lanka","Wijesinghe A., University of Kelaniya, Department of Industrial Management, Kelaniya, Sri Lanka; Rajapakse C., University of Kelaniya, Department of Industrial Management, Kelaniya, Sri Lanka; Asanka D., University of Kelaniya, Department of Industrial Management, Kelaniya, Sri Lanka","With experienced apparel technicians migrating abroad, inexperienced newcomers struggle analyzing sketches to determine optimal construction methods. Manual interpretation takes extensive time and multiplies sampling expenses from missteps. This research demonstrates large language models (LLMs) like GPT-4 can accurately suggest sewing sequences from drawings to slash costs. We developed an AI ensemble leveraging computer vision and LLMs to annotate sketches with likely production directives at over 70% precision. Compared to novice technicians' 60% accuracy, this automates breakdown drafting for rapid iterations. By training on past image-operation pairings, the model reliably recommends stitch types, tools and steps for new sketches. Confidence metrics identify when human oversight is beneficial. This intelligence augmentation assists upskilling novices while increasing development efficiency. The methodology decreased sampling costs by 30% and duration by 25% over manual approaches in trials. By expediting iterations with automated validations, it enables agile adjustments closer to market needs. The system can expand across garment categories given sufficient data. This pioneering research tackles industry migration effects through AI, breaking dependence on disappearing expertise. With proven cost and time reductions, adoption can accelerate sector-wide production efficiency.  © 2024 IEEE.","Apparel Industry; Large Language Models; Multi-modality; Retrieval Augmented Generation; Sewing Operation","Computational linguistics; Apparel industry; Construction method; Human oversight; Intelligence models; Language model; Large language model; Multi-modality; Optimal construction; Retrieval augmented generation; Sewing operation; Production efficiency","","Institute of Electrical and Electronics Engineers Inc.","English","Conference paper","Final","","Scopus","2-s2.0-85192135442"
"Xia Y.; Xiao Z.; Jazdi N.; Weyrich M.","Xia, Yuchen (57956208500); Xiao, Zhewen (58970363900); Jazdi, Nasser (24491873600); Weyrich, Michael (6507626557)","57956208500; 58970363900; 24491873600; 6507626557","Generation of Asset Administration Shell With Large Language Model Agents: Toward Semantic Interoperability in Digital Twins in the Context of Industry 4.0","2024","IEEE Access","12","","","84863","84877","14","0","10.1109/ACCESS.2024.3415470","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196507322&doi=10.1109%2fACCESS.2024.3415470&partnerID=40&md5=d3b6a24589fff2448a8b54c51af9cdd8","Institute of Industrial Automation and Software Engineering, University of Stuttgart, Stuttgart, 70550, Germany","Xia Y., Institute of Industrial Automation and Software Engineering, University of Stuttgart, Stuttgart, 70550, Germany; Xiao Z., Institute of Industrial Automation and Software Engineering, University of Stuttgart, Stuttgart, 70550, Germany; Jazdi N., Institute of Industrial Automation and Software Engineering, University of Stuttgart, Stuttgart, 70550, Germany; Weyrich M., Institute of Industrial Automation and Software Engineering, University of Stuttgart, Stuttgart, 70550, Germany","This research introduces a novel approach for achieving semantic interoperability in digital twins and assisting the creation of Asset Administration Shell (AAS) as digital twin model within the context of Industry 4.0. The foundational idea of our research is that the communication based on semantics and the generation of meaningful textual data are directly linked, and we posit that these processes are equivalent if the exchanged information can be serialized in text form. Based on this, we construct a 'semantic node' data structure in our research to capture the semantic essence of textual data. Then, a system powered by large language models is designed and implemented to process the 'semantic node' and generate standardized digital twin models (AAS instance models in the context of Industry 4.0) from raw textual data collected from datasheets describing technical assets. Our evaluation demonstrates an effective generation rate of 62-79%, indicating a substantial proportion of the information from the source text can be translated error-free to the target digital twin instance model with the generative capability of large language models. This result has a direct application in the context of Industry 4.0, and the designed system is implemented as a data model generation tool for reducing the manual effort in creating AAS model by automatically translating unstructured textual data into a standardized AAS model. The generated AAS model can be integrated into AAS-compliant digital twin software for seamless information exchange and communication. In our evaluation, a comparative analysis of different LLMs and an in-depth ablation study of Retrieval-Augmented Generation (RAG) mechanisms provide insights into the effectiveness of LLM systems for interpreting technical concepts and translating data. Our findings emphasize LLMs' capability to automate AAS instance creation and contribute to the broader field of semantic interoperability for digital twins in industrial applications. The prototype implementation and evaluation results are presented on our GitHub Repository: https://github.com/YuchenXia/AASbyLLM. © 2013 IEEE.","Asset administration shell; digital twin; generative AI; industry 4.0; large language model; retrieval-augmented generation; semantic interoperability","Computational linguistics; Industry 4.0; Interoperability; Search engines; Translation (languages); Unified Modeling Language; Asset administration shell; Context models; Fourth industrial revolution; Generative AI; Industrial revolutions; Language model; Large language model; Retrieval-augmented generation; Semantic interoperability; Textual data; Semantics","","Institute of Electrical and Electronics Engineers Inc.","English","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85196507322"
"Hang C.N.; Yu P.-D.; Tan C.W.","Hang, Ching Nam (57205457095); Yu, Pei-Duo (56470129600); Tan, Chee Wei (58856511000)","57205457095; 56470129600; 58856511000","TrumorGPT: Query Optimization and Semantic Reasoning over Networks for Automated Fact-Checking","2024","2024 58th Annual Conference on Information Sciences and Systems, CISS 2024","","","","","","","0","10.1109/CISS59072.2024.10480162","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190626782&doi=10.1109%2fCISS59072.2024.10480162&partnerID=40&md5=419e520545338afb41d0df18278d0f15","City University of Hong Kong, Department of Computer Science, Hong Kong, Hong Kong; Saint Francis University, School of Computing and Information Sciences, Hong Kong; Chung Yuan Christian University, Department of Applied Mathematics, Taiwan; Nanyang Technological University, School of Computer Science and Engineering, Singapore","Hang C.N., City University of Hong Kong, Department of Computer Science, Hong Kong, Hong Kong, Saint Francis University, School of Computing and Information Sciences, Hong Kong; Yu P.-D., Chung Yuan Christian University, Department of Applied Mathematics, Taiwan; Tan C.W., Nanyang Technological University, School of Computer Science and Engineering, Singapore","In the age of social media, the rapid spread of misinformation and rumors has led to the emergence of infodemics, where false information poses a significant threat to society. To combat this issue, we introduce TrumorGPT, a novel generative artificial intelligence solution designed for automated fact-checking. TrumorGPT aims to distinguish ""trumors"", which are rumors that turn out to be true, providing a crucial tool in differentiating between mere speculation and verified facts. This framework merges machine learning with natural language processing techniques, leveraging a large language model (LLM) with few-shot learning for knowledge graph construction and semantic reasoning. TrumorGPT addresses the ""hallucination""issue common in LLMs and the limitations of static training data by incorporating retrieval-augmented generation. This approach involves accessing and utilizing information from regularly updated knowledge graphs that consist of the latest news and information, ensuring that fact-checking of TrumorGPT is based on the most recent data. Accessing updated knowledge graphs greatly enhances the proficiency of TrumorGPT in delivering accurate and reliable information promptly. Evaluating with extensive datasets, TrumorGPT demonstrates superior performance in automated fact-checking. Its ability to effectively conduct automated fact-checking across various platforms marks a critical step forward in the fight against misinformation, enhancing trust and accuracy in the digital information age. © 2024 IEEE.","Fact-checking; knowledge graph; large language models; retrieval-augmented generation; semantic reasoning","Automation; Computational linguistics; Knowledge management; Learning systems; Natural language processing systems; Semantics; Fact-checking; Knowledge graphs; Language model; Large language model; Machine-learning; Queries optimization; Query semantics; Retrieval-augmented generation; Semantic reasoning; Social media; Knowledge graph","","Institute of Electrical and Electronics Engineers Inc.","English","Conference paper","Final","","Scopus","2-s2.0-85190626782"
"Fasha M.; Rub F.A.; Matar N.; Sowan B.; Al Khaldy M.; Barham H.","Fasha, Mohammad (57219010614); Rub, Faisal Abul (59155639500); Matar, Nasim (49964100900); Sowan, Bilal (36242284200); Al Khaldy, Mohammad (57207795824); Barham, Hussam (59155736400)","57219010614; 59155639500; 49964100900; 36242284200; 57207795824; 59155736400","Mitigating the OWASP Top 10 For Large Language Models Applications using Intelligent Agents","2024","2nd International Conference on Cyber Resilience, ICCR 2024","","","","","","","0","10.1109/ICCR61006.2024.10532874","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195129802&doi=10.1109%2fICCR61006.2024.10532874&partnerID=40&md5=df06e4d1ed0e6398620ce4dc61a84c9d","University Of Petra, Business Intelligence And Data Analytics Department, Amman, Jordan; University Of Petra, EBusiness And Commerce Department, Amman, Jordan","Fasha M., University Of Petra, Business Intelligence And Data Analytics Department, Amman, Jordan; Rub F.A., University Of Petra, Business Intelligence And Data Analytics Department, Amman, Jordan; Matar N., University Of Petra, Business Intelligence And Data Analytics Department, Amman, Jordan; Sowan B., University Of Petra, Business Intelligence And Data Analytics Department, Amman, Jordan; Al Khaldy M., University Of Petra, Business Intelligence And Data Analytics Department, Amman, Jordan; Barham H., University Of Petra, EBusiness And Commerce Department, Amman, Jordan","Large Language Models (LLMs) have emerged as a transformative and disruptive technology, enabling a wide range of applications in natural language processing, machine translation, and beyond. However, this widespread integration of LLMs also raised several security concerns highlighted by the Open Web Application Security Project (OWASP), which has identified the top 10 security vulnerabilities inherent in LLM applications. Addressing these vulnerabilities is crucial, given the increasing reliance on LLMs and the potential threats to data integrity, confidentiality, and service availability. This paper presents a framework designed to mitigate the security risks outlined in the OWASP Top 10. Our proposed model leverages LLM-enabled intelligent agents, offering a new approach to proactively identify, assess, and counteract security threats in real-time. The proposed framework serves as an initial blueprint for future research and development, aiming to enhance the security measures of LLMs and protect against emerging threats in this rapidly evolving landscape.  © 2024 IEEE.","AutoGen; Large Language Model (LLM); OWASP Top 10; Retrieval Augmented Generation (RAG)","Blueprints; Computational linguistics; Natural language processing systems; Autogen; Disruptive technology; Language model; Language processing; Large language model; Model application; Natural languages; Open web application security project top 10; Open web application security projects; Retrieval augmented generation; Intelligent agents","","Institute of Electrical and Electronics Engineers Inc.","English","Conference paper","Final","","Scopus","2-s2.0-85195129802"
"Jiang Z.; Xu F.F.; Gao L.; Sun Z.; Liu Q.; Dwivedi-Yu J.; Yang Y.; Callan J.; Neubig G.","Jiang, Zhengbao (57216621895); Xu, Frank F. (57192255529); Gao, Luyu (57219488985); Sun, Zhiqing (57210638438); Liu, Qian (59283137800); Dwivedi-Yu, Jane (57793213900); Yang, Yiming (35231480000); Callan, Jamie (35588436200); Neubig, Graham (36141167700)","57216621895; 57192255529; 57219488985; 57210638438; 59283137800; 57793213900; 35231480000; 35588436200; 36141167700","Active Retrieval Augmented Generation","2023","EMNLP 2023 - 2023 Conference on Empirical Methods in Natural Language Processing, Proceedings","","","","7969","7992","23","33","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178918038&partnerID=40&md5=b9faab01416542cb36d3a9da551c10ad","Language Technologies Institute, Carnegie Mellon University, United States; Sea AI Lab; FAIR, Meta, United States","Jiang Z., Language Technologies Institute, Carnegie Mellon University, United States; Xu F.F., Language Technologies Institute, Carnegie Mellon University, United States; Gao L., Language Technologies Institute, Carnegie Mellon University, United States; Sun Z., Language Technologies Institute, Carnegie Mellon University, United States; Liu Q., Sea AI Lab; Dwivedi-Yu J., FAIR, Meta, United States; Yang Y., Language Technologies Institute, Carnegie Mellon University, United States; Callan J., Language Technologies Institute, Carnegie Mellon University, United States; Neubig G., Language Technologies Institute, Carnegie Mellon University, United States","Despite the remarkable ability of large language models (LMs) to comprehend and generate language, they have a tendency to hallucinate and create factually inaccurate output. Augmenting LMs by retrieving information from external knowledge resources is one promising solution. Most existing retrieval augmented LMs employ a retrieve-and-generate setup that only retrieves information once based on the input. This is limiting, however, in more general scenarios involving generation of long texts, where continually gathering information throughout generation is essential. In this work, we provide a generalized view of active retrieval augmented generation, methods that actively decide when and what to retrieve across the course of the generation. We propose Forward-Looking Active REtrieval augmented generation (FLARE), a generic method which iteratively uses a prediction of the upcoming sentence to anticipate future content, which is then utilized as a query to retrieve relevant documents to regenerate the sentence if it contains low-confidence tokens. We test FLARE along with baselines comprehensively over 4 long-form knowledge-intensive generation tasks/datasets. FLARE achieves superior or competitive performance on all tasks, demonstrating the effectiveness of our method. © 2023 Association for Computational Linguistics.","","Computational linguistics; Competitive performance; External knowledge; Forward looking; Generation method; Generic method; Knowledge resource; Language model; Relevant documents; Iterative methods","Bouamor H.; Pino J.; Bali K.","Association for Computational Linguistics (ACL)","English","Conference paper","Final","","Scopus","2-s2.0-85178918038"
"Anand A.; Goel A.; Hira M.; Buldeo S.; Kumar J.; Verma A.; Gupta R.; Shah R.R.","Anand, Avinash (58508044100); Goel, Arnav (58507822300); Hira, Medha (58508044000); Buldeo, Snehal (58778217200); Kumar, Jatin (58279528200); Verma, Astha (57661763200); Gupta, Rushali (58146794600); Shah, Rajiv Ratn (56121902800)","58508044100; 58507822300; 58508044000; 58778217200; 58279528200; 57661763200; 58146794600; 56121902800","SciPhyRAG - Retrieval Augmentation to Improve LLMs on Physics Q &A","2023","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","14418 LNCS","","","50","63","13","1","10.1007/978-3-031-49601-1_4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180529387&doi=10.1007%2f978-3-031-49601-1_4&partnerID=40&md5=9be687203d3310d1bd921b4869b096a3","Indraprastha Institute of Information Technology, Delhi, India","Anand A., Indraprastha Institute of Information Technology, Delhi, India; Goel A., Indraprastha Institute of Information Technology, Delhi, India; Hira M., Indraprastha Institute of Information Technology, Delhi, India; Buldeo S., Indraprastha Institute of Information Technology, Delhi, India; Kumar J., Indraprastha Institute of Information Technology, Delhi, India; Verma A., Indraprastha Institute of Information Technology, Delhi, India; Gupta R., Indraprastha Institute of Information Technology, Delhi, India; Shah R.R., Indraprastha Institute of Information Technology, Delhi, India","Large Language Models (LLMs) have showcased their value across diverse domains, yet their efficacy in computationally intensive tasks remains limited in accuracy. This paper introduces a comprehensive methodology to construct a resilient dataset focused on High School Physics, leveraging retrieval augmentation. Subsequent finetuning of a Large Language Model through instructional calibration is proposed to elevate outcome precision and depth. The central aspiration is reinforcing LLM efficiency in educational contexts, facilitating more precise, well-contextualized, and informative results. By bridging the gap between LLM capabilities and the demands of complex educational tasks, this approach seeks to empower educators and students alike, offering enhanced support and enriched learning experiences. Compared to Vicuna-7b, the finetuned retrieval augmented model SciPhy-RAG exhibits a 16.67% increase in BERTScore and 35.2% increase on ROUGE-2 scores. This approach has the potential to be used to reshape Physics Q &A by LLMs and has a lasting impact on their use for Physics education. Furthermore, the data sets released can be a reference point for future research and educational domain tasks such as Automatic Evaluation and Question Generation. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.","Document Retrieval; Large Language Models; Natural Language Processing; Neural Text Generation; Question-Answering","Computational linguistics; Education computing; Information retrieval; Diverse domains; Document Retrieval; Language model; Language processing; Large language model; Natural language processing; Natural languages; Neural text generation; Question Answering; Text generations; Natural language processing systems","Goyal V.; Kumar D.; Kumar N.; Bhowmick S.S.; Goyal P.; Goyal N.","Springer Science and Business Media Deutschland GmbH","English","Conference paper","Final","","Scopus","2-s2.0-85180529387"
"Yu H.; Guo P.; Sano A.","Yu, Han (57211212815); Guo, Peikun (58637996200); Sano, Akane (54788353200)","57211212815; 58637996200; 54788353200","Zero-Shot ECG Diagnosis with Large Language Models and Retrieval-Augmented Generation","2023","Proceedings of Machine Learning Research","225","","","650","663","13","3","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184351776&partnerID=40&md5=23d02797897faa386760824f59295d05","Department of Electrical and Computer Engineering, Rice University, United States; Department of Computer Science, Rice University, United States","Yu H., Department of Electrical and Computer Engineering, Rice University, United States; Guo P., Department of Computer Science, Rice University, United States; Sano A., Department of Electrical and Computer Engineering, Rice University, United States","Recently, Large Language Models (LLMs) have become essential players in the deep learning domain. While their capabilities are evident across various textual tasks, this study aims to bridge the gap and explore the potential of leveraging LLMs in diagnosing cardiac diseases and sleep apnea from Electrocardiography (ECG). Earlier work touched on converting ECG signals into text for LLMs, but a comprehensive LLM-based approach for dealing with more complicated symptoms remains relatively unexplored. To investigate the ECG diagnosis with an LLM-based approach, our research introduces a zero-shot retrieval-augmented diagnosis technique. We have built databases filled with specific domain knowledge for cardiac symptom and sleep apnea diagnosis, which encourages the LLMs from merely relying on the inherent LLM knowledge to a more holistic pipeline from carefully crafting prompts and infusing expert knowledge to guide LLMs. We evaluate the proposed approach on two datasets for diagnosing arrhythmia and sleep apnea, respectively. The evaluation results indicate that our zero-shot approach not only surpasses previous few-shot LLM-based methods but is also competitive with supervised learning techniques fully trained on extensive datasets. © 2023 H. Yu, P. Guo & A. Sano.","Apnea; Arrhythmia; Electrocardiogram (ECG); Large Language Model (LLM); Retrieval-Augmented Generation (RAG); Zero-Shot Learning","Computational linguistics; Deep learning; Diseases; Domain Knowledge; Learning systems; Sleep research; Supervised learning; Apnea; Arrhythmia; Cardiac disease; Electrocardiogram; Electrocardiogram signal; Language model; Large language model; Model based approach; Retrieval-augmented generation; Sleep apnea; Electrocardiograms","Hegselmann S.; Parziale A.; Shanmugam D.; Tang S.; Asiedu M.N.; Chang S.; Hartvigsen T.; Singh H.","ML Research Press","English","Conference paper","Final","","Scopus","2-s2.0-85184351776"
"","","","20th IFIP WG 12.5 International Conference on Artificial Intelligence Applications and Innovations, AIAI 2024","2024","IFIP Advances in Information and Communication Technology","711","","","","","1497","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197574382&partnerID=40&md5=450ba0dc769714c82670e07dbdafb6b4","","","The proceedings contain 108 papers. The special focus in this conference is on Artificial Intelligence Applications and Innovations. The topics include: Strategizing the Shallows: Leveraging Multi-Agent Reinforcement Learning for Enhanced Tactical Decision-Making in Littoral Naval Warfare; multi-dimensional Classification on Social Media Data for Detailed Reporting with Large Language Models; LLM Prompting Versus Fine-Tuning PLMs: A Comparative Study on Keyword Generation from Customer Feedback; greekT5: Sequence-to-Sequence Models for Greek News Summarization; generating Profiles of News Commentators with Language Models; enhancing Financial Market Prediction with Reinforcement Learning and Ensemble Learning; AI-Driven Sentiment Trend Analysis: Enhancing Topic Modeling Interpretation with ChatGPT; preface; detecting Illicit Data Leaks on Android Smartphones Using an Artificial Intelligence Models; an Algorithmic Data Pipeline Architecture for the Production of Personalized Telecom Product Offers; improving Agricultural Image Classification by Mining Images; enhancing Predictive Process Monitoring with Conformal Prediction; online Reinforcement Learning for Designing Automotive Hybrid Assembly Sequence: A Task Clustering-Guided Approach; SMT: Self-supervised Approach for Multiple Animal Detection and Tracking; Improved NO2 Prediction Using Machine Learning Algorithms; benign Paroxysmal Positional Vertigo Disorders Classification Using Eye Tracking Data; Improving RAG Quality for Large Language Models with Topic-Enhanced Reranking; the Impact of Augmentation Techniques on Icon Detection Using Machine Learning Techniques; unlocking User Privacy: A Systematic Survey of Factors and Methods in Predicting App Permission Decisions; toward Unsupervised Energy Consumption Anomaly Detection; simulation Study for Evaluating Efficiency of McPhail Traps in Olive Groves; predictive Maintenance Under Absence of Sensor Data; pollutant Concentration Prediction by Random Forest to Estimate a Contaminant Source Position; Machine Learning Models for Electricity Generation Forecasting from a PV Farm.","","","Maglogiannis I.; Iliadis L.; Papaleonidas A.; Macintyre J.; Avlonitis M.","Springer Science and Business Media Deutschland GmbH","English","Conference review","Final","","Scopus","2-s2.0-85197574382"
"Almeida R.; Sousa H.; Cunha L.F.; Guimarães N.; Campos R.; Jorge A.","Almeida, Rúben (58825134400); Sousa, Hugo (57225819459); Cunha, Luís F. (57534330600); Guimarães, Nuno (36780798400); Campos, Ricardo (15130810800); Jorge, Alípio (55938897400)","58825134400; 57225819459; 57534330600; 36780798400; 15130810800; 55938897400","Physio: An LLM-Based Physiotherapy Advisor","2024","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","14612 LNCS","","","189","193","4","0","10.1007/978-3-031-56069-9_16","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189349474&doi=10.1007%2f978-3-031-56069-9_16&partnerID=40&md5=6eb677366e055312b13c5e457c62f3f8","INESC TEC, Porto, Portugal; University of Porto, Porto, Portugal; University of Beira Interior, Covilhã, Portugal; Ci2 - Smart Cities Research Centre, Tomar, Portugal","Almeida R., INESC TEC, Porto, Portugal; Sousa H., INESC TEC, Porto, Portugal, University of Porto, Porto, Portugal; Cunha L.F., INESC TEC, Porto, Portugal, University of Porto, Porto, Portugal; Guimarães N., INESC TEC, Porto, Portugal, University of Porto, Porto, Portugal; Campos R., INESC TEC, Porto, Portugal, University of Beira Interior, Covilhã, Portugal, Ci2 - Smart Cities Research Centre, Tomar, Portugal; Jorge A., INESC TEC, Porto, Portugal, University of Porto, Porto, Portugal"," The capabilities of the most recent language models have increased the interest in integrating them into real-world applications. However, the fact that these models generate plausible, yet incorrect text poses a constraint when considering their use in several domains. Healthcare is a prime example of a domain where text-generative trustworthiness is a hard requirement to safeguard patient well-being. In this paper, we present Physio, a chat-based application for physical rehabilitation. Physio is capable of making an initial diagnosis while citing reliable health sources to support the information provided. Furthermore, drawing upon external knowledge databases, Physio can recommend rehabilitation exercises and over-the-counter medication for symptom relief. By combining these features, Physio can leverage the power of generative models for language processing while also conditioning its response on dependable and verifiable sources. A live demo of Physio is available at https://physio.inesctec.pt. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.","Conversational health agents; Information extraction; Retrieval-augmented generation","Conversational health agent; External knowledge; Information extraction; Knowledge database; Language model; Physical rehabilitation; Real-world; Rehabilitation exercise; Retrieval-augmented generation; Well being","Goharian N.; Tonellotto N.; He Y.; Lipani A.; McDonald G.; Macdonald C.; Ounis I.","Springer Science and Business Media Deutschland GmbH","English","Conference paper","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85189349474"
"Schulz T.; Luttermann M.; Möller R.","Schulz, Tim (59207728900); Luttermann, Malte (58096090600); Möller, Ralf (57205092803)","59207728900; 58096090600; 57205092803","AutoRAG: Grounding Text and Symbols","2024","KI - Kunstliche Intelligenz","","","","","","","2","10.1007/s13218-024-00850-z","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196429918&doi=10.1007%2fs13218-024-00850-z&partnerID=40&md5=2d722532918f73c8c81c2008fc2b2148","Institute of Information Systems, University of Lübeck, Lübeck, Germany; German Research Center for Artificial Intelligence (DFKI), Lübeck, Germany","Schulz T., Institute of Information Systems, University of Lübeck, Lübeck, Germany; Luttermann M., German Research Center for Artificial Intelligence (DFKI), Lübeck, Germany; Möller R., Institute of Information Systems, University of Lübeck, Lübeck, Germany, German Research Center for Artificial Intelligence (DFKI), Lübeck, Germany","In safety critical domains such as the healthcare domain, systems for natural language question answering demand special correctness guarantees. Modeling problem domains formally allows for automatic transparent reasoning, but handling comprehensive formal models may quickly demand expert knowledge. Ultimately, we need a system which is as easily accessible as large language models while the correctness of its output should be checkable using trusted knowledge. Since words are ambiguous in general but concepts of a formal model are not, we propose to expand the vocabulary of a language model by concepts of a knowledge base: Motivated by retrieval-augmented generation, we introduce AutoRAG, which does not retrieve data from external sources, rather it perceives parts of the knowledge base from special vocabulary, trained by auto-encoding text and concepts. Our AutoRAG implementation for a use case in the field of nosocomial pneumonia describes concepts it associates with the input and can naturally provide a graphical depiction from the expert-made knowledge bas to allow for feasible text sanity checks. © The Author(s) 2024.","","Gallium arsenide; III-V semiconductors; Knowledge based systems; Natural language processing systems; Safety engineering; Expert knowledge; External sources; Formal modeling; Healthcare domains; Language model; Model problems; Natural language questions; Problem domain; Question Answering; Safety-critical domain; Computational linguistics","","Springer Science and Business Media Deutschland GmbH","English","Article","Article in press","All Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85196429918"
"Chang T.A.; Tomanek K.; Hoffmann J.; Thain N.; van Liemt E.; Meier-Hellstern K.; Dixon L.","Chang, Tyler A. (57223724186); Tomanek, Katrin (57702885400); Hoffmann, Jessica (58115395400); Thain, Nithum (57210028654); van Liemt, Erin (58960494900); Meier-Hellstern, Kathleen (6602341233); Dixon, Lucas (57213291768)","57223724186; 57702885400; 58115395400; 57210028654; 58960494900; 6602341233; 57213291768","Detecting Hallucination and Coverage Errors in Retrieval Augmented Generation for Controversial Topics","2024","2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation, LREC-COLING 2024 - Main Conference Proceedings","","","","4729","4743","14","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195891954&partnerID=40&md5=30276a0a4db94fb1edf691f2e9e7dc8d","Google Research, United States; UC San Diego, United States","Chang T.A., Google Research, United States, UC San Diego, United States; Tomanek K., Google Research, United States; Hoffmann J., Google Research, United States; Thain N., Google Research, United States; van Liemt E., Google Research, United States; Meier-Hellstern K., Google Research, United States; Dixon L., Google Research, United States","We explore a strategy to handle controversial topics in LLM-based chatbots based on Wikipedia's Neutral Point of View (NPOV) principle: acknowledge the absence of a single true answer and surface multiple perspectives. We frame this as retrieval augmented generation, where perspectives are retrieved from a knowledge base and the LLM is tasked with generating a fluent and faithful response from the given perspectives. As a starting point, we use a deterministic retrieval system and then focus on common LLM failure modes that arise during this approach to text generation, namely hallucination and coverage errors. We propose and evaluate three methods to detect such errors based on (1) word-overlap, (2) salience, and (3) LLM-based classifiers. Our results demonstrate that LLM-based classifiers, even when trained only on synthetic errors, achieve high error detection performance, with ROC AUC scores of 95.3% for hallucination and 90.5% for coverage error detection on unambiguous error cases. We show that when no training data is available, our other methods still yield good results on hallucination (84.0%) and coverage error (85.2%) detection. © 2024 ELRA Language Resource Association: CC BY-NC 4.0.","conversational systems; evaluation methodologies; natural language generation","Information retrieval; Knowledge based systems; Natural language processing systems; Chatbots; Controversial topics; Conversational systems; Deterministics; Evaluation methodologies; Fluents; Multiple perspectives; Natural language generation; Surface multiples; Wikipedia; Error detection","Calzolari N.; Kan M.-Y.; Hoste V.; Lenci A.; Sakti S.; Xue N.","European Language Resources Association (ELRA)","English","Conference paper","Final","","Scopus","2-s2.0-85195891954"
"","","","20th IFIP WG 12.5 International Conference on Artificial Intelligence Applications and Innovations, AIAI 2024","2024","IFIP Advances in Information and Communication Technology","712","","","","","1497","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197583098&partnerID=40&md5=bfa4239e391901827692d0d81bc1b5e5","","","The proceedings contain 108 papers. The special focus in this conference is on Artificial Intelligence Applications and Innovations. The topics include: Strategizing the Shallows: Leveraging Multi-Agent Reinforcement Learning for Enhanced Tactical Decision-Making in Littoral Naval Warfare; multi-dimensional Classification on Social Media Data for Detailed Reporting with Large Language Models; LLM Prompting Versus Fine-Tuning PLMs: A Comparative Study on Keyword Generation from Customer Feedback; greekT5: Sequence-to-Sequence Models for Greek News Summarization; generating Profiles of News Commentators with Language Models; enhancing Financial Market Prediction with Reinforcement Learning and Ensemble Learning; AI-Driven Sentiment Trend Analysis: Enhancing Topic Modeling Interpretation with ChatGPT; preface; detecting Illicit Data Leaks on Android Smartphones Using an Artificial Intelligence Models; an Algorithmic Data Pipeline Architecture for the Production of Personalized Telecom Product Offers; improving Agricultural Image Classification by Mining Images; enhancing Predictive Process Monitoring with Conformal Prediction; online Reinforcement Learning for Designing Automotive Hybrid Assembly Sequence: A Task Clustering-Guided Approach; SMT: Self-supervised Approach for Multiple Animal Detection and Tracking; Improved NO2 Prediction Using Machine Learning Algorithms; benign Paroxysmal Positional Vertigo Disorders Classification Using Eye Tracking Data; Improving RAG Quality for Large Language Models with Topic-Enhanced Reranking; the Impact of Augmentation Techniques on Icon Detection Using Machine Learning Techniques; unlocking User Privacy: A Systematic Survey of Factors and Methods in Predicting App Permission Decisions; toward Unsupervised Energy Consumption Anomaly Detection; simulation Study for Evaluating Efficiency of McPhail Traps in Olive Groves; predictive Maintenance Under Absence of Sensor Data; pollutant Concentration Prediction by Random Forest to Estimate a Contaminant Source Position; Machine Learning Models for Electricity Generation Forecasting from a PV Farm.","","","Maglogiannis I.; Iliadis L.; Papaleonidas A.; Macintyre J.; Avlonitis M.","Springer Science and Business Media Deutschland GmbH","English","Conference review","Final","","Scopus","2-s2.0-85197583098"
"Boros T.; Chivereanu R.; Dumitrescu S.D.; Purcaru O.","Boros, Tiberiu (53881015100); Chivereanu, Radu (58668882200); Dumitrescu, Stefan Daniel (36343459500); Purcaru, Octavian (59156121900)","53881015100; 58668882200; 36343459500; 59156121900","Fine-Tuning and Retrieval Augmented Generation for Question Answering Using Affordable Large Language Models","2024","3rd Ukrainian Natural Language Processing Workshop, UNLP 2024 at LREC-COLING 2024 - Workshop Proceedings","","","","75","82","7","2","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195209523&partnerID=40&md5=af54629bea217cc33c0ee56477716153","Adobe Systems, Bucharest, Romania","Boros T., Adobe Systems, Bucharest, Romania; Chivereanu R., Adobe Systems, Bucharest, Romania; Dumitrescu S.D., Adobe Systems, Bucharest, Romania; Purcaru O., Adobe Systems, Bucharest, Romania","We present our proposed system named Sherlock to UNLP 2024 Shared Task on Question Answering winning first place. We employ a mix of methods, from using automatically translated datasets to perform supervised fine-tuning and direct preference optimization on instruction-tuned models, to model weight merging and retrieval augmented generation. We present and motivate our chosen sequence of steps, as well as an ablation study to understand the effect of each additional step. The resulting model and code are made publicly available (download links provided in the paper). © 2024 ELRA Language Resource Association: CC BY-NC 4.0.","direct preference optimization; finetuning; instruction tuning; large language models; LLM; model merge; multiple choice; open-ended; open-source; question answering; RAG; re-ranking; Ukrainian language","Natural language processing systems; Direct preference optimization; Finetuning; Instruction tuning; Language model; Large language model; LLM; Model merge; Multiple choice; Open-ended; Open-source; Preference optimizations; Question Answering; RAG; Re-ranking; Ukrainian language; Computational linguistics","Romanyshyn M.","European Language Resources Association (ELRA)","English","Conference paper","Final","","Scopus","2-s2.0-85195209523"
"Yang H.; Zhang M.; Wei D.","Yang, Hao (57208745952); Zhang, Min (57282022500); Wei, Daimeng (57219324919)","57208745952; 57282022500; 57219324919","IRAG: Iterative Retrieval Augmented Generation for SLU","2024","2024 20th IEEE International Colloquium on Signal Processing and Its Applications, CSPA 2024 - Conference Proceedings","","","","30","34","4","0","10.1109/CSPA60979.2024.10525270","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193914743&doi=10.1109%2fCSPA60979.2024.10525270&partnerID=40&md5=b1d20fb3be5d0ac95147ce797b40d7b0","2012 Labs, Huawei Technologies CO., Ltd, China","Yang H., 2012 Labs, Huawei Technologies CO., Ltd, China; Zhang M., 2012 Labs, Huawei Technologies CO., Ltd, China; Wei D., 2012 Labs, Huawei Technologies CO., Ltd, China","This paper proposes an iterative retrieval augmented generation (RAG) approach to improve spoken language understanding (SLU) capabilities. First, speech retrieval over the training set is performed using a pretrained automatic speech recognition encoder. The corresponding texts and intent labels are then formulated as prompts to guide the SLU decoder, with an added prompt attention mechanism to strengthen attention between generation and prompts. Iterative search and generation occurs within 3 iterations, or earlier exit if similarity scores do not improve. Experiments demonstrate the proposed RAG approach substantially outperforms conventional end-to-end and cascaded SLU models in intent prediction from speech. This highlights the efficacy of incorporating relevant external knowledge through retrieval-based prompting to enhance SLU systems. The iterative process allows progressive refinement of predictions. Overall, this work shows promise for advancing SLU via iterative RAG.  © 2024 IEEE.","Large Language Models; Retrieval Augmented Generation; Spoken Language Understanding","Computational linguistics; Iterative methods; Attention mechanisms; Automatic speech recognition; End to end; Language model; Large language model; Retrieval augmented generation; Similarity scores; Speech retrieval; Spoken language understanding; Training sets; Speech recognition","","Institute of Electrical and Electronics Engineers Inc.","English","Conference paper","Final","","Scopus","2-s2.0-85193914743"
"Es S.; James J.; Espinosa-Anke L.; Schockaert S.","Es, Shahul (58259526300); James, Jithin (58709970400); Espinosa-Anke, Luis (56242866900); Schockaert, Steven (8886625200)","58259526300; 58709970400; 56242866900; 8886625200","RAGAS: Automated Evaluation of Retrieval Augmented Generation","2024","EACL 2024 - 18th Conference of the European Chapter of the Association for Computational Linguistics, Proceedings of System Demonstrations","","","","150","158","8","12","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188691656&partnerID=40&md5=bd2bb8bc56965b890a4be58b6ae0b982","Exploding Gradients; CardiffNLP, Cardiff University, United Kingdom; AMPLYFI, United Kingdom","Es S., Exploding Gradients; James J., Exploding Gradients; Espinosa-Anke L., CardiffNLP, Cardiff University, United Kingdom, AMPLYFI, United Kingdom; Schockaert S., CardiffNLP, Cardiff University, United Kingdom","We introduce RAGAS1 (Retrieval Augmented Generation Assessment), a framework for reference-free evaluation of Retrieval Augmented Generation (RAG) pipelines. RAG systems are composed of a retrieval module and an LLM based generation module. They provide LLMs with knowledge from a reference corpus, which can help to keep LLM based systems up-to-date and can reduce the risk of hallucinations, among others. However, evaluating RAG architectures is challenging because there are several dimensions to consider: the ability of the retrieval system to identify relevant and focused context passages, the ability of the LLM to exploit such passages in a faithful way, and the quality of the generation itself. With RAGAS, we put forward a suite of metrics which can be used to evaluate these different dimensions without having to rely on ground truth human annotations. We posit that such a framework can crucially contribute to faster evaluation cycles of RAG architectures, which is especially important given the fast adoption of LLMs. © 2024 Association for Computational Linguistics.","","Automated evaluation; Generation systems; Ground truth; Human annotations; Reference-free; Retrieval systems","Aletras N.; De Clercq O.","Association for Computational Linguistics (ACL)","English","Conference paper","Final","","Scopus","2-s2.0-85188691656"
"Omrani P.; Hosseini A.; Hooshanfar K.; Ebrahimian Z.; Toosi R.; Ali Akhaee M.","Omrani, Pouria (58417124300); Hosseini, Alireza (58714317900); Hooshanfar, Kiana (58897101000); Ebrahimian, Zahra (57837329300); Toosi, Ramin (57203889919); Ali Akhaee, Mohammad (16202081400)","58417124300; 58714317900; 58897101000; 57837329300; 57203889919; 16202081400","Hybrid Retrieval-Augmented Generation Approach for LLMs Query Response Enhancement","2024","2024 10th International Conference on Web Research, ICWR 2024","","","","22","26","4","0","10.1109/ICWR61162.2024.10533345","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194829529&doi=10.1109%2fICWR61162.2024.10533345&partnerID=40&md5=79bf70b5988704251d7bd35bd18b5458","K. N. Toosi University of Technology, Faculty of Electrical Engineering, Tehran, Iran; Adak Vira Iranian Rahjoo Company, Tehran, Iran; University of Tehran, School of Electrical and Computer Engineering, College of Engineering, Tehran, Iran","Omrani P., K. N. Toosi University of Technology, Faculty of Electrical Engineering, Tehran, Iran, Adak Vira Iranian Rahjoo Company, Tehran, Iran; Hosseini A., Adak Vira Iranian Rahjoo Company, Tehran, Iran, University of Tehran, School of Electrical and Computer Engineering, College of Engineering, Tehran, Iran; Hooshanfar K., Adak Vira Iranian Rahjoo Company, Tehran, Iran, University of Tehran, School of Electrical and Computer Engineering, College of Engineering, Tehran, Iran; Ebrahimian Z., Adak Vira Iranian Rahjoo Company, Tehran, Iran, University of Tehran, School of Electrical and Computer Engineering, College of Engineering, Tehran, Iran; Toosi R., Adak Vira Iranian Rahjoo Company, Tehran, Iran, University of Tehran, School of Electrical and Computer Engineering, College of Engineering, Tehran, Iran; Ali Akhaee M., University of Tehran, School of Electrical and Computer Engineering, College of Engineering, Tehran, Iran","In the domain of Natural Language Processing (NLP), the integration of Large Language Models (LLMs) with Retrieval-Augmented Generation (RAG) represents a significant advancement towards enhancing the depth and relevance of model-generated responses. This paper introduces a novel hybrid RAG framework that synergizes the Sentence-Window and Parent-Child methodologies with an innovative re-ranking mechanism, aimed at optimizing the query response capabilities of LLMs. By leveraging external knowledge sources more effectively, the proposed method enriches LLM outputs with greater accuracy, relevance, and information fidelity. We subject our hybrid model to rigorous evaluation against benchmark datasets and metrics, demonstrating its superior performance over existing state-of-the-art RAG techniques. The results highlight our method's enhanced ability to generate responses that are not only contextually appropriate but also demonstrate a high degree of faithfulness to the source material, thereby setting a new standard for query response enhancement in LLMs. Our study underscores the potential of hybrid RAG models in refining the interaction between LLMs and external knowledge, paving the way for future research in the field of NLP.  © 2024 IEEE.","Generative AI; LLM; NLP; Retrieval Augmented Generation (RAG)","Knowledge management; Natural language processing systems; External knowledge; Generative AI; Language model; Language processing; Large language model; Natural language processing; Natural languages; Query response; Re-ranking; Retrieval augmented generation; Benchmarking","","Institute of Electrical and Electronics Engineers Inc.","English","Conference paper","Final","","Scopus","2-s2.0-85194829529"
"Thanasi-Boçe M.; Hoxha J.","Thanasi-Boçe, Marsela (57190124778); Hoxha, Julian (55876813400)","57190124778; 55876813400","From ideas to ventures: building entrepreneurship knowledge with LLM, prompt engineering, and conversational agents","2024","Education and Information Technologies","","","","","","","2","10.1007/s10639-024-12775-z","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195600225&doi=10.1007%2fs10639-024-12775-z&partnerID=40&md5=067d997ce6fb97daf73247276a77a36a","College of Business Administration, American University of the Middle East, Egaila, Kuwait; College of Engineering, American University of the Middle East, Egaila, Kuwait","Thanasi-Boçe M., College of Business Administration, American University of the Middle East, Egaila, Kuwait; Hoxha J., College of Engineering, American University of the Middle East, Egaila, Kuwait","Entrepreneurship education has evolved to meet the demands of a dynamic business environment, necessitating innovative teaching methods to prepare entrepreneurs for market uncertainties. Large Language Models (LLMs) like the Generative Pre-trained Transformer 4 (GPT-4), recognized for their exceptional performance on public datasets, are examined in this study for their potential adaptability and interactivity nature, which align well with the dynamic nature of entrepreneurship learning. The interaction with LLMs can be enhanced by using effective prompt engineering techniques (PETs) that allow for crafting precise queries to elicit accurate and relevant responses for entrepreneurial learning. Critical concerns regarding the use of GPT-4 and conversational agents in entrepreneurship courses include the reliability and accuracy of data sources, the necessity for specific, real-time data for effective decision-making, and the lack of in-depth exploration of effective prompting strategies tailored to entrepreneurship education. Addressing these issues, this study aims to identify and compare the quality output of currently available PETs, develop innovative PETs that are well-aligned with entrepreneurial learning, and provide guidelines on how to fully utilize LLMs and conversational agents with Retrieval Augmentation Generation (RAG) technology in entrepreneurship education. The combination of conversational agents and RAG technology into a hybrid innovative approach overcomes inherent limitations in each technology separately and enhances efficiency and relevancy in entrepreneurship education through exact, dynamic interactions and advanced memory capabilities. The findings of the study significantly contribute to the field of entrepreneurship by offering practical insights for students and educators on enhancing the entrepreneurship learning experience, particularly by utilizing cutting-edge technology to improve data relevance and answer accuracy in entrepreneurial queries and scenarios. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2024.","Artificial intelligence (AI); Conversational agents; Entrepreneurship education; GPT-4; Prompt Engineering Techniques (PETs); Retrieval Augmentation Generation (RAG)","","","Springer","English","Article","Article in press","","Scopus","2-s2.0-85195600225"
"Uluslu A.Y.; Clematide S.; Michail A.","Uluslu, Ahmet Yavuz (46061294800); Clematide, Simon (24766270800); Michail, Andrianos (57286423800)","46061294800; 24766270800; 57286423800","Utilizing Large Language Models to Identify Evidence of Suicidality Risk through Analysis of Emotionally Charged Posts","2024","CLPsych 2024 - 9th Workshop on Computational Linguistics and Clinical Psychology, Proceedings of the Workshop","","","","264","269","5","3","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189188311&partnerID=40&md5=62a49a578b34a98f337f7b0c889e75a3","University of Zurich, Switzerland","Uluslu A.Y., University of Zurich, Switzerland; Clematide S., University of Zurich, Switzerland; Michail A., University of Zurich, Switzerland","This paper presents our contribution to the CLPsych 2024 shared task, focusing on the use of open-source large language models (LLMs) for suicide risk assessment through the analysis of social media posts. We achieved first place (out of 15 participating teams) in the task of providing summarized evidence of a user’s suicide risk. Our approach is based on Retrieval Augmented Generation (RAG), where we retrieve the top-k (k=5) posts with the highest emotional charge and provide the level of three different negative emotions (sadness, fear, anger) for each post during the generation phase. ©2024 Association for Computational Linguistics.","","Computational linguistics; Risk analysis; Language model; Open-source; Participating teams; Risks assessments; Social media; Suicidality; Risk assessment","Yates A.; Desmet B.; Prud�hommeaux E.; Zirikly A.; Bedrick S.; MacAvaney S.; Bar K.; Ireland M.; Ophir Y.; Ophir Y.","Association for Computational Linguistics (ACL)","English","Conference paper","Final","","Scopus","2-s2.0-85189188311"
"Rony M.R.A.H.; Sahoo S.R.; Khan A.G.; Friedl K.E.; Sudhi V.; Süß C.","Rony, Md. Rashad Al Hasan (57203302415); Sahoo, Soumya Ranjan (58668908700); Khan, Abbas Goher (58722415500); Friedl, Ken E. (58668908600); Sudhi, Viju (57226695685); Süß, Christian (58669036900)","57203302415; 58668908700; 58722415500; 58668908600; 57226695685; 58669036900","Incorporating Query Recommendation for Improving In-Car Conversational Search","2024","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","14612 LNCS","","","304","312","8","0","10.1007/978-3-031-56069-9_36","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189331891&doi=10.1007%2f978-3-031-56069-9_36&partnerID=40&md5=8a0dd72494d739619b9f54f61564cf42","BMW Group, Parkring 19-23, Garching in Munich, 85748, Germany; Fraunhofer IAIS, Zwickauer Straße 46, Dresden, 01069, Germany","Rony M.R.A.H., BMW Group, Parkring 19-23, Garching in Munich, 85748, Germany; Sahoo S.R., Fraunhofer IAIS, Zwickauer Straße 46, Dresden, 01069, Germany; Khan A.G., Fraunhofer IAIS, Zwickauer Straße 46, Dresden, 01069, Germany; Friedl K.E., BMW Group, Parkring 19-23, Garching in Munich, 85748, Germany; Sudhi V., Fraunhofer IAIS, Zwickauer Straße 46, Dresden, 01069, Germany; Süß C., BMW Group, Parkring 19-23, Garching in Munich, 85748, Germany","Retrieval-augmented generation has become an effective mechanism for conversational systems in domain-specific settings. Retrieval of a wrong document due to the lack of context from the user utterance may lead to wrong answer generation. Such an issue may reduce the user engagement and thereby the system reliability. In this paper, we propose a context-guided follow-up question recommendation to internally improve the document retrieval in an iterative approach for developing an in-car conversational system. Specifically, a user utterance is first reformulated, given the context of the conversation to facilitate improved understanding to the retriever. In the cases, where the documents retrieved by the retriever are not relevant enough for answering the user utterance, we employ a large language model (LLM) to generate question recommendation which is then utilized to perform a refined retrieval. An empirical evaluation confirms the effectiveness of our proposed approaches in in-car conversations, achieving 48% and 22% improvement in the retrieval and system generated responses, respectively, against baseline approaches. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.","Query Recommendation; Retrieval-augmented Generation","Computational linguistics; Conversational systems; Document Retrieval; Domain specific; Effective mechanisms; Follow up; Query recommendations; Retrieval-augmented generation; System reliability; User engagement; Wrong answers; Information retrieval","Goharian N.; Tonellotto N.; He Y.; Lipani A.; McDonald G.; Macdonald C.; Ounis I.","Springer Science and Business Media Deutschland GmbH","English","Conference paper","Final","","Scopus","2-s2.0-85189331891"
"Honório J.J.C.M.; Brito P.C.O.; Moura J.A.B.; Andrade N.F.","Honório, Joaquim J.C.M. (57202248601); Brito, Paulo C.O. (58448397800); Moura, J. Antão B. (7102993182); Andrade, Nazareno F. (7003429497)","57202248601; 58448397800; 7102993182; 7003429497","Large Language Models in Civic Education on the Supervision and Risk Assessment of Public Works","2024","International Conference on Computer Supported Education, CSEDU - Proceedings","2","","","27","38","11","0","10.5220/0012589300003693","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193980117&doi=10.5220%2f0012589300003693&partnerID=40&md5=a384f4c4e005e31af3ecd370f6ea2f5d","Graduate Program in Computer Science, Federal University of Campina Grande (UFCG), Brazil; Systems and Computing Department, Federal University of Campina Grande (UFCG), Brazil","Honório J.J.C.M., Graduate Program in Computer Science, Federal University of Campina Grande (UFCG), Brazil; Brito P.C.O., Graduate Program in Computer Science, Federal University of Campina Grande (UFCG), Brazil; Moura J.A.B., Systems and Computing Department, Federal University of Campina Grande (UFCG), Brazil; Andrade N.F., Systems and Computing Department, Federal University of Campina Grande (UFCG), Brazil","The Public Administration spends an estimated 13 trillion USD annually worldwide, of which approximately 20% is allocated to public works. Despite strict rules, unfinished works for legal reasons, including corruption, are not atypical, negatively impacting the region’s economy, culture, and society. Civic awareness about this problem may help reduce such losses. This study investigates the use of Large Language Models (LLM) and Retrieval-Augmented Generation (RAG) to support civic education on risks in public works. While LLMs interpret and create human language, RAGs combine text production with access to other external data, allowing contextualized responses. Here, we evaluate how these technologies can facilitate the population’s understanding of technical information about public works. To this end, we initially create and evaluate 4 Machine Learning models for risk prediction of public work failure, using data from real public works. We provide a failure estimate for each contracted work based on the most efficient model. These data and others related to government development and risk processes are accessed and presented to the user through a web support system. Tests with 35 participants indicate a significant improvement in citizens ability to understand complex aspects related to risks and contracts of public works. Copyright © 2024 by SCITEPRESS – Science and Technology Publications, Lda.","Civic Education; Large Language Models; Machine Learning; Public Works","Computational linguistics; Public administration; Risk assessment; Atypicals; Civic education; Human language; Language model; Large language model; Machine learning models; Machine-learning; Risks assessments; Technical information; Unfinished work; Machine learning","Poquet O.; Ortega-Arranz A.; Viberg O.; Chounta I.-A.; McLaren B.; Jovanovic J.","Science and Technology Publications, Lda","English","Conference paper","Final","All Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85193980117"
"Shelby L.; da Silva R.V.M.A.","Shelby, Lacy (59166384500); da Silva, Renato Villela Mafra Alves (59166645100)","59166384500; 59166645100","Retrieval-augmented Generation: Empowering Landscape Architects with Data-driven Design","2024","Journal of Digital Landscape Architecture","2024","9","","267","276","9","0","10.14627/537752025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195536410&doi=10.14627%2f537752025&partnerID=40&md5=8b6795c5fc74dfc494ca3861d07260c2","The Graduate Center, The City University of New York, NY, United States","Shelby L., The Graduate Center, The City University of New York, NY, United States; da Silva R.V.M.A., The Graduate Center, The City University of New York, NY, United States","Landscape Architects and allied professions are steadily integrating artificial intelligence (AI) and machine learning (ML) in practice and deployment to enhance design processes, optimize project management, and augment analytical practices. The application of Retrieval-Augmented Generation (RAG) models in the fields of landscape architecture, planning, ecology, and architecture is still an emerging area and is not yet fully understood or widely explored. RAG models integrate a pre-trained language model with a retrieval system, effectively merging the processes of information retrieval and language generation into a cohesive framework. However, validation of information from large language models (LLMs) in Question-Answering Systems (QAS) (driven by AI/ML algorithms), such as ChatGPT and Google Gemini poses a challenge for landscape architects. The objective of this study was to assess the performance of the RAG model applied to landscape architecture literature. To address this objective, we developed a closed-domain neural network using open-source models trained on one issue of The Journal of Digital Landscape Architecture. To evaluate its performance, we queried the neural network on a series of landscape architectural tasks including design, theory, and analytical tasks. We then used quantitative measures to evaluate the performance. The results of ROUGE scores for the RAG demonstrate its effectiveness in capturing key concepts within the landscape architecture domain, particularly noting high precision values in Rouge-1 and Rouge-L metrics. While the model shows a lower performance in capturing two-word combinations as indicated by Rouge-2 scores, it successfully retrieved relevant information efficiently, as demonstrated by higher precision across other metrics. The study highlights the potential of Closed Domain Question Answering (CDQA) systems integrated with a RAG model, trained on specialized datasets, to enhance landscape architects' work-flows. It also underscores the necessity of addressing challenges such as data curation, bias, and crea-tivity limitations to maximize the utility and success of these tools in professional landscape architecture practice. © Wichmann Verlag, VDE VERLAG GMBH.","Closed-Domain Question Answering; data-driven design; landscape architecture; large language models (LLM); Retrieval-Augmented Generation","","","VDE VERLAG GMBH","English","Article","Final","","Scopus","2-s2.0-85195536410"
"Gebreab S.A.; Salah K.; Jayaraman R.; Rehman M.H.U.; Ellaham S.","Gebreab, Senay A. (58018368200); Salah, Khaled (35617663600); Jayaraman, Raja (14520494400); Rehman, Muhammad Habib Ur (58198468600); Ellaham, Samer (59141357400)","58018368200; 35617663600; 14520494400; 58198468600; 59141357400","LLM-Based Framework for Administrative Task Automation in Healthcare","2024","12th International Symposium on Digital Forensics and Security, ISDFS 2024","","","","","","","1","10.1109/ISDFS60797.2024.10527275","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194061609&doi=10.1109%2fISDFS60797.2024.10527275&partnerID=40&md5=c1ec3ed105418492b105cd5af7fb5202","Khalifa University, Dept. of Computer & Communication Engineering, Abu Dhabi, United Arab Emirates; Khalifa University, Dept. of Management Science & Engineering, Abu Dhabi, United Arab Emirates; King's College London, Dept. of Biomedical Engineering & Imaging Sciences, London, United Kingdom; Heart & Vascular Institute & Continuous, Cleveland Clinic, Improvement Dept., Abu Dhabi, United Arab Emirates","Gebreab S.A., Khalifa University, Dept. of Computer & Communication Engineering, Abu Dhabi, United Arab Emirates; Salah K., Khalifa University, Dept. of Computer & Communication Engineering, Abu Dhabi, United Arab Emirates; Jayaraman R., Khalifa University, Dept. of Management Science & Engineering, Abu Dhabi, United Arab Emirates; Rehman M.H.U., King's College London, Dept. of Biomedical Engineering & Imaging Sciences, London, United Kingdom; Ellaham S., Heart & Vascular Institute & Continuous, Cleveland Clinic, Improvement Dept., Abu Dhabi, United Arab Emirates","Artificial Intelligence (AI) has been transformative in the healthcare sector, leading to enhanced precision in medical diagnosis, more effective treatment options, and a significant improvement in patient safety. However, computer-based administrative tasks, such as retrieval of medical and health records, patient registration, medical billing, filing and documentation, and appointment scheduling, still impose a heavy burden on healthcare professionals, causing a reduced quality of care and efficiency. In light of these challenges, this paper proposes a large language model (LLM)-based multi-agent framework designed to automate some of the administrative work in clinical settings. In our proposed solution, these LLM agents coordinate to parse instructions, breakdown tasks, and execute a sequence of actions in a workflow. They are equipped to not only execute documentation process at the database level but also operate directly on web-based electronic medical record (EMR) platforms. Moreover, the framework integrates data sources through a retrieval-augmented generation (RAG) system to allow streamlined interaction with patient information and medical records, mediated through an agent interface. The framework is designed with security in mind to defend against malicious prompts. We demonstrate the practicality of our solution by testing on various complex tasks that require the use of multiple tools and an EMR website. The result show the framework's effectiveness in handling diverse healthcare administrative tasks.  © 2024 IEEE.","autonomous agents; electronic medical record; health-care; large language models; retrieval aug-mented generation; task automation","Autonomous agents; Computational linguistics; Diagnosis; Medical computing; Medical information systems; Multi agent systems; Search engines; Websites; Administrative tasks; Electronic medical record; Healthcare sectors; Language model; Large language model; Medical record; Model-based OPC; Patient safety; Retrieval aug-mented generation; Task automation; Patient treatment","Varol A.; Karabatak M.; Varol C.; Tuba E.","Institute of Electrical and Electronics Engineers Inc.","English","Conference paper","Final","","Scopus","2-s2.0-85194061609"
"Cerrato P.L.; Halamka J.D.","Cerrato, Paul L. (57204027547); Halamka, John D. (6701836991)","57204027547; 6701836991","How AI drives innovation in cardiovascular medicine","2024","Frontiers in Cardiovascular Medicine","11","","1397921","","","","0","10.3389/fcvm.2024.1397921","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192824838&doi=10.3389%2ffcvm.2024.1397921&partnerID=40&md5=512e3fabe3140b312ed7422d033be54d","Mayo Clinic Platform, Mayo Clinic, Rochester, MN, United States","Cerrato P.L., Mayo Clinic Platform, Mayo Clinic, Rochester, MN, United States; Halamka J.D., Mayo Clinic Platform, Mayo Clinic, Rochester, MN, United States","Medicine is entering a new era in which artificial intelligence (AI) and deep learning have a measurable impact on patient care. This impact is especially evident in cardiovascular medicine. While the purpose of this short opinion paper is not to provide an in-depth review of the many applications of AI in cardiovascular medicine, we summarize some of the important advances that have taken place in this domain. 2024 Cerrato and Halamka.","artificial intelligence; cardiovascular disease; ChatGPT; innovation; large language models; retrieval augmented generation","algorithm; area under the curve; Article; artificial intelligence; atrial fibrillation; cardiac imaging; cardiology; cardiovascular function; cardiovascular risk; cardiovascular system; cardiovascular system examination; ChatGPT; clinical decision making; computed tomographic angiography; computer assisted tomography; convolutional neural network; decision making; deep learning; echocardiography; electrocardiography; follow up; health care system; heart arrhythmia; heart cycle; heart ejection fraction; heart failure; heart left ventricle ejection fraction; human; large language model; machine learning; medical education; medicine; patient care; physician; positron emission tomography; publication; resuscitation; retrieval augmented generation; single photon emission computed tomography; sinus rhythm; transthoracic echocardiography","","Frontiers Media SA","English","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85192824838"
"Mashatian S.; Armstrong D.G.; Ritter A.; Robbins J.; Aziz S.; Alenabi I.; Huo M.; Anand T.; Tavakolian K.","Mashatian, Shayan (59136146800); Armstrong, David G. (7404407396); Ritter, Aaron (59136006500); Robbins, Jeffery (7403151924); Aziz, Shereen (59136425000); Alenabi, Ilia (59136286000); Huo, Michelle (59135871600); Anand, Taneeka (59136425100); Tavakolian, Kouhyar (6505837295)","59136146800; 7404407396; 59136006500; 7403151924; 59136425000; 59136286000; 59135871600; 59136425100; 6505837295","Building Trustworthy Generative Artificial Intelligence for Diabetes Care and Limb Preservation: A Medical Knowledge Extraction Case","2024","Journal of Diabetes Science and Technology","","","","","","","0","10.1177/19322968241253568","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193730369&doi=10.1177%2f19322968241253568&partnerID=40&md5=0d28771f607684ab8ae695b46cb86c57","Biomedical Engineering Program, University of North Dakota, Grand Forks, ND, United States; Silverberry Group, Inc., Grand Forks, ND, United States; Keck School of Medicine, University of Southern California, Los Angeles, CA, United States; U.S. Department of Veterans Affairs, Little Rock, AR, United States; U.S. Department of Veterans Affairs, Washington, DC, United States; Department of Life Sciences, University of California, Los Angeles, Los Angeles, CA, United States; Oxford College of Emory University, Oxford, GA, United States","Mashatian S., Biomedical Engineering Program, University of North Dakota, Grand Forks, ND, United States, Silverberry Group, Inc., Grand Forks, ND, United States; Armstrong D.G., Keck School of Medicine, University of Southern California, Los Angeles, CA, United States; Ritter A., U.S. Department of Veterans Affairs, Little Rock, AR, United States; Robbins J., U.S. Department of Veterans Affairs, Washington, DC, United States; Aziz S., Silverberry Group, Inc., Grand Forks, ND, United States; Alenabi I., Silverberry Group, Inc., Grand Forks, ND, United States; Huo M., Department of Life Sciences, University of California, Los Angeles, Los Angeles, CA, United States; Anand T., Oxford College of Emory University, Oxford, GA, United States; Tavakolian K., Biomedical Engineering Program, University of North Dakota, Grand Forks, ND, United States","Background: Large language models (LLMs) offer significant potential in medical information extraction but carry risks of generating incorrect information. This study aims to develop and validate a retriever-augmented generation (RAG) model that provides accurate medical knowledge about diabetes and diabetic foot care to laypersons with an eighth-grade literacy level. Improving health literacy through patient education is paramount to addressing the problem of limb loss in the diabetic population. In addition to affecting patient well-being through improved outcomes, improved physician well-being is an important outcome of a self-management model for patient health education. Methods: We used an RAG architecture and built a question-and-answer artificial intelligence (AI) model to extract knowledge in response to questions pertaining to diabetes and diabetic foot care. We utilized GPT-4 by OpenAI, with Pinecone as a vector database. The NIH National Standards for Diabetes Self-Management Education served as the basis for our knowledge base. The model’s outputs were validated through expert review against established guidelines and literature. Fifty-eight keywords were used to select 295 articles and the model was tested against 175 questions across topics. Results: The study demonstrated that with appropriate content volume and few-shot learning prompts, the RAG model achieved 98% accuracy, confirming its capability to offer user-friendly and comprehensible medical information. Conclusion: The RAG model represents a promising tool for delivering reliable medical knowledge to the public which can be used for self-education and self-management for diabetes, highlighting the importance of content validation and innovative prompt engineering in AI applications. © 2024 Diabetes Technology Society.","diabetes self-education; diabetic foot ulcer; few-shot learning; generative AI; knowledge extraction; layperson education; LLM; trustworthy AI","","","SAGE Publications Inc.","English","Article","Article in press","","Scopus","2-s2.0-85193730369"
"Ding Y.; Nie J.; Wu D.; Liu C.","Ding, Yilang (59008305100); Nie, Jiawei (59007700600); Wu, Di (59008916400); Liu, Chang (59007700700)","59008305100; 59007700600; 59008916400; 59007700700","A General Approach to Website Question Answering with Large Language Models","2024","Conference Proceedings - IEEE SOUTHEASTCON","","","","894","896","2","0","10.1109/SoutheastCon52093.2024.10500166","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191710994&doi=10.1109%2fSoutheastCon52093.2024.10500166&partnerID=40&md5=d2f732e4507517a77e170e44c5902553","Emory University, United States","Ding Y., Emory University, United States; Nie J., Emory University, United States; Wu D., Emory University, United States; Liu C., Emory University, United States","Language Models (LMs), in their most basic form, perform just like any other machine learning model - they produce interpolations and extrapolations based on their training distribution. Although recent models such as OpenAI's GPT-4 have demonstrated unprecedented capabilities in absorbing the copious volumes of information in their training data, their ability to consistently reproduce factual information still remains unproven. Additionally, LMs on their own lack the ability to keep up to date with real life data without frequent fine-tuning. These drawbacks effectively render base LMs unserviceable in Question Answering scenarios where they must respond to queries regarding volatile information. Retrieval Augmented Generation (RAG) and Tool Learning [1] were proposed as solutions to these problems, and with the development and usage of associated libraries, the aforementioned problems can be greatly mitigated. In this paper, we ponder a general approach to website Question Answering that integrates the zero-shot decision-making capabilities of LMs with the RAG capabilities of LangChain and is able to be kept up to date with dynamic information without the need for constant fine-tuning.  © 2024 IEEE.","","Computational linguistics; Decision making; Zero-shot learning; Base language; Decisions makings; Dynamic information; Factual information; Fine tuning; Language model; Machine learning models; Question Answering; Real life data; Training data; Websites","","Institute of Electrical and Electronics Engineers Inc.","English","Conference paper","Final","","Scopus","2-s2.0-85191710994"
"He Z.; Bhasuran B.; Jin Q.; Tian S.; Hanna K.; Shavor C.; Arguello L.G.; Murray P.; Lu Z.","He, Zhe (55320918000); Bhasuran, Balu (57191285268); Jin, Qiao (57219779717); Tian, Shubo (57226693180); Hanna, Karim (57217859271); Shavor, Cindy (57219540824); Arguello, Lisbeth Garcia (58893941200); Murray, Patrick (58893941300); Lu, Zhiyong (57323696000)","55320918000; 57191285268; 57219779717; 57226693180; 57217859271; 57219540824; 58893941200; 58893941300; 57323696000","Quality of Answers of Generative Large Language Models Versus Peer Users for Interpreting Laboratory Test Results for Lay Patients: Evaluation Study","2024","Journal of Medical Internet Research","26","1","e56655","","","","3","10.2196/56655","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190903860&doi=10.2196%2f56655&partnerID=40&md5=9c881f6e5332fef0799c9f9e46b2f9fb","School of Information, Florida State University, Tallahassee, FL, United States; National Center for Biotechnology Information, National Library of Medicine, National Institutes of Health, Bethesda, MD, United States; Morsani College of Medicine, University of South Florida, Tampa, FL, United States","He Z., School of Information, Florida State University, Tallahassee, FL, United States; Bhasuran B., School of Information, Florida State University, Tallahassee, FL, United States; Jin Q., National Center for Biotechnology Information, National Library of Medicine, National Institutes of Health, Bethesda, MD, United States; Tian S., National Center for Biotechnology Information, National Library of Medicine, National Institutes of Health, Bethesda, MD, United States; Hanna K., Morsani College of Medicine, University of South Florida, Tampa, FL, United States; Shavor C., Morsani College of Medicine, University of South Florida, Tampa, FL, United States; Arguello L.G., Morsani College of Medicine, University of South Florida, Tampa, FL, United States; Murray P., Morsani College of Medicine, University of South Florida, Tampa, FL, United States; Lu Z., National Center for Biotechnology Information, National Library of Medicine, National Institutes of Health, Bethesda, MD, United States","Background: Although patients have easy access to their electronic health records and laboratory test result data through patient portals, laboratory test results are often confusing and hard to understand. Many patients turn to web-based forums or question-and-answer (Q&A) sites to seek advice from their peers. The quality of answers from social Q&A sites on health-related questions varies significantly, and not all responses are accurate or reliable. Large language models (LLMs) such as ChatGPT have opened a promising avenue for patients to have their questions answered. Objective: We aimed to assess the feasibility of using LLMs to generate relevant, accurate, helpful, and unharmful responses to laboratory test–related questions asked by patients and identify potential issues that can be mitigated using augmentation approaches. Methods: We collected laboratory test result–related Q&A data from Yahoo! Answers and selected 53 Q&A pairs for this study. Using the LangChain framework and ChatGPT web portal, we generated responses to the 53 questions from 5 LLMs: GPT-4, GPT-3.5, LLaMA 2, MedAlpaca, and ORCA_mini. We assessed the similarity of their answers using standard Q&A similarity-based evaluation metrics, including Recall-Oriented Understudy for Gisting Evaluation, Bilingual Evaluation Understudy, Metric for Evaluation of Translation With Explicit Ordering, and Bidirectional Encoder Representations from Transformers Score. We used an LLM-based evaluator to judge whether a target model had higher quality in terms of relevance, correctness, helpfulness, and safety than the baseline model. We performed a manual evaluation with medical experts for all the responses to 7 selected questions on the same 4 aspects. Results: Regarding the similarity of the responses from 4 LLMs; the GPT-4 output was used as the reference answer, the responses from GPT-3.5 were the most similar, followed by those from LLaMA 2, ORCA_mini, and MedAlpaca. Human answers from Yahoo data were scored the lowest and, thus, as the least similar to GPT-4–generated answers. The results of the win rate and medical expert evaluation both showed that GPT-4’s responses achieved better scores than all the other LLM responses and human responses on all 4 aspects (relevance, correctness, helpfulness, and safety). LLM responses occasionally also suffered from lack of interpretation in one’s medical context, incorrect statements, and lack of references. Conclusions: By evaluating LLMs in generating responses to patients’ laboratory test result–related questions, we found that, compared to other 4 LLMs and human answers from a Q&A website, GPT-4’s responses were more accurate, helpful, relevant, and safer. There were cases in which GPT-4 responses were inaccurate and not individualized. We identified a number of ways to improve the quality of LLM responses, including prompt engineering, prompt augmentation, retrieval-augmented generation, and response evaluation. ©Zhe He, Balu Bhasuran, Qiao Jin, Shubo Tian, Karim Hanna, Cindy Shavor, Lisbeth Garcia Arguello, Patrick Murray, Zhiyong Lu.","ChatGPT; generative AI; generative artificial intelligence; laboratory test results; large language models; natural language processing; patient education","Animals; Benchmarking; Camelids, New World; Electronic Health Records; Engineering; Humans; Language; alanine aminotransferase; albumin; alkaline phosphatase; aspartate aminotransferase; bilirubin; creatinine; follitropin; gamma glutamyltransferase; glucose; hemoglobin A1c; hepatitis B surface antigen; high density lipoprotein cholesterol; iron; ketone; lipid; prostate specific antigen; triacylglycerol; vitamin D; anion gap; Article; artificial intelligence; ChatGPT; cholesterol blood level; controlled study; cooperation; correlation coefficient; erythrocyte sedimentation rate; estimated glomerular filtration rate; glucose tolerance test; health hazard; hematocrit; human; laboratory test; language; leukocyte count; lipid fingerprinting; medical expert; medical record; natural language processing; patient education; patient safety; recall; safety; urea nitrogen blood level; animal; benchmarking; electronic health record; engineering; language; New World camelid","","JMIR Publications Inc.","English","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85190903860"
"Jain S.; Kumar A.; Roy T.; Shinde K.; Vignesh G.; Tondulkar R.","Jain, Siddhant (58968451500); Kumar, Asheesh (58967784500); Roy, Trinita (58717795100); Shinde, Kartik (57388443300); Vignesh, Goutham (58967784600); Tondulkar, Rohan (56604143000)","58968451500; 58967784500; 58717795100; 57388443300; 58967784600; 56604143000","SciSpace Literature Review: Harnessing AI for Effortless Scientific Discovery","2024","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","14612 LNCS","","","256","260","4","1","10.1007/978-3-031-56069-9_28","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189352937&doi=10.1007%2f978-3-031-56069-9_28&partnerID=40&md5=00fb0e4de6fcd240d0406162d7ea79a3","SciSpace, Bengaluru, India","Jain S., SciSpace, Bengaluru, India; Kumar A., SciSpace, Bengaluru, India; Roy T., SciSpace, Bengaluru, India; Shinde K., SciSpace, Bengaluru, India; Vignesh G., SciSpace, Bengaluru, India; Tondulkar R., SciSpace, Bengaluru, India","In the rapidly evolving landscape of academia, the scientific research community barely copes with the challenges posed by a surging volume of scientific literature. Nevertheless, discovering research remains an important step in the research workflow which is also proven to be a challenging one to automate. We present Scispace Literature Review, a sophisticated, multi-faceted tool that serves as a comprehensive solution to streamline the literature review process. By leveraging the state-of-the-art methods in vector-based search, reranking, and large language models, the tool delivers features like customizable search results, data exintegration with an AI assistant, multi-language support, top papers insights, and customizable results columns to cater a researcher’s requirements, and accelerate literature exploration. Resources for simplified sharing and documentation further enhance the scope and depth and breadth of research. We demonstrate the extensive use and popularity of the tool among researchers with various metrics, highlighting its value as a resource to elevate scientific literature review. This tool can be tried using this link: https://typeset.io/search. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.","Information Retrieval; Retrieval Augmented Generation; Vector Search","Customizable; Literature reviews; Research communities; Retrieval augmented generation; Review process; Scientific discovery; Scientific literature; Scientific researches; Vector search; Work-flows; Information retrieval","Goharian N.; Tonellotto N.; He Y.; Lipani A.; McDonald G.; Macdonald C.; Ounis I.","Springer Science and Business Media Deutschland GmbH","English","Conference paper","Final","","Scopus","2-s2.0-85189352937"
"Huan X.; Zhou H.","Huan, Xiaoli (57193355400); Zhou, Hong (59202556700)","57193355400; 59202556700","Integrating Advanced Language Models and Vector Database for Enhanced AI Query Retrieval in Web Development","2024","International Journal of Advanced Computer Science and Applications","15","6","","1","6","5","0","10.14569/IJACSA.2024.0150601","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197395079&doi=10.14569%2fIJACSA.2024.0150601&partnerID=40&md5=9bec10023516949f509a7590875f5a3f","Department of Computer Science, Troy University, Troy, AL, United States; Department of Mathematics and Computer Science, University of Saint Joseph, West Hartford, CT, United States","Huan X., Department of Computer Science, Troy University, Troy, AL, United States; Zhou H., Department of Mathematics and Computer Science, University of Saint Joseph, West Hartford, CT, United States","In the dynamic field of web development, the integration of sophisticated AI technologies for query processing has become increasingly crucial. This paper presents a framework that significantly improves the relevance of web query responses by leveraging cutting-edge technologies like Hugging Face, FAISS, Google PaLM, Gemini, and LangChain. We explore and compare the performance of both PaLM and Gemini, two powerful LLMs, to identify strengths and weaknesses in the context of web development query retrieval. Our approach capitalizes on the synergistic combination of these freely accessible tools, ultimately leading to a more efficient and user-friendly query processing system. © (2024), (Science and Information Organization). All Rights Reserved.","LLM (Large Language Model); retrieval-augmented generation; vector databases","Computational linguistics; Cutting tools; AI Technologies; Cutting edge technology; Dynamic fields; Language model; Large language model; Query response; Query retrieval; Retrieval-augmented generation; Vector database; Web development; Query processing","","Science and Information Organization","English","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85197395079"
"Sarmah B.; Mehta D.; Pasquali S.; Zhu T.","Sarmah, Bhaskarjit (57195935445); Mehta, Dhagash (36993203400); Pasquali, Stefano (57815282900); Zhu, Tianjie (58697317100)","57195935445; 36993203400; 57815282900; 58697317100","Towards reducing hallucination in extracting information from financial reports using Large Language Models","2023","ACM International Conference Proceeding Series","","","39","","","","0","10.1145/3639856.3639895","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194848398&doi=10.1145%2f3639856.3639895&partnerID=40&md5=b835165cc431883f0b1debba2a20e669","BlackRock, Inc., Gurgaon, India; BlackRock, Inc., Wilmington, DE, United States; BlackRock, Inc., New York, NY, United States","Sarmah B., BlackRock, Inc., Gurgaon, India; Mehta D., BlackRock, Inc., Wilmington, DE, United States; Pasquali S., BlackRock, Inc., New York, NY, United States; Zhu T., BlackRock, Inc., New York, NY, United States","For a financial analyst, the question and answer (Q&A) segment of the company financial report is a crucial piece of information for various analysis and investment decisions. However, extracting valuable insights from the Q&A section has posed considerable challenges as the conventional methods such as detailed reading and note-taking lack scalability and are susceptible to human errors, and Optical Character Recognition (OCR) and similar techniques encounter difficulties in accurately processing unstructured transcript text, often missing subtle linguistic nuances that drive investor decisions. Here, we demonstrate the utilization of Large Language Models (LLMs) to efficiently and rapidly extract information from earnings report transcripts while ensuring high accuracy - transforming the extraction process as well as reducing hallucination by combining retrieval-augmented generation technique as well as metadata. We evaluate the outcomes of various LLMs with and without using our proposed approach based on various objective metrics for evaluating Q&A systems, and empirically demonstrate superiority of our method.  © 2023 ACM.","Earning Call Transcripts; Financial Markets; Large Language Models; Natural Language Processing","Computational linguistics; Financial markets; Information retrieval; Natural language processing systems; Optical character recognition; Earning call transcript; Extracting information; Financial analysts; Financial reports; Investment decisions; Language model; Language processing; Large language model; Natural language processing; Natural languages; Investments","","Association for Computing Machinery","English","Conference paper","Final","","Scopus","2-s2.0-85194848398"
"Siragusa I.; Pirrone R.","Siragusa, Irene (58636100700); Pirrone, Roberto (6603614874)","58636100700; 6603614874","Conditioning Chat-GPT for Information Retrieval: The Unipa-GPT Case Study","2023","CEUR Workshop Proceedings","3551","","","","","","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178352259&partnerID=40&md5=1d1354231fe569785be2e7e9a9a6203a","Dipartimento di Ingegneria, Università Degli Studi di Palermo, Viale delle Scienze, Edificio 6, Palermo, 90128, Italy","Siragusa I., Dipartimento di Ingegneria, Università Degli Studi di Palermo, Viale delle Scienze, Edificio 6, Palermo, 90128, Italy; Pirrone R., Dipartimento di Ingegneria, Università Degli Studi di Palermo, Viale delle Scienze, Edificio 6, Palermo, 90128, Italy","This paper illustrates the architecture and training of Unipa-GPT, a Large Language Model based chatbot developed for assisting students in choosing a bachelor/master degree course at the University of Palermo. Unipa-GPT relies on gpt-3.5-turbo, it was presented in the context of the European Researchers' Night SHARPER event. In our experiments we adopted both the Retrieval Augmented Generation (RAG) approach and fine-tuning to develop the system. The whole architecture of Unipa-GPT is presented, both the RAG and the fine-tuned systems are compared, and a brief discussion on their performance is reported.  © 2023 Copyright for this paper by its authors.","ChatGPT; Fine-tuning; Large Language Model; RAG","Case-studies; Chatbots; ChatGPT; Fine tuning; Language model; Large language model; Master degree; Model-based OPC; Retrieval augmented generation; University of Palermo; Computational linguistics","Bassignana E.; Brunato D.; Polignano M.; Ramponi A.","CEUR-WS","English","Conference paper","Final","","Scopus","2-s2.0-85178352259"
"Neelakanteswara A.; Chaudhari S.; Zamani H.","Neelakanteswara, Abhiman (58073957100); Chaudhari, Shreyas (58713559700); Zamani, Hamed (56342230300)","58073957100; 58713559700; 56342230300","RAGs to Style: Personalizing LLMs with Style Embeddings","2024","PERSONALIZE 2024 - 1st Workshop on Personalization of Generative AI Systems, Proceedings of the Workshop","","","","119","123","4","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188882447&partnerID=40&md5=099dc8e1fd5874742a2a75a8e471ac09","University of Massachusetts Amherst, United States","Neelakanteswara A., University of Massachusetts Amherst, United States; Chaudhari S., University of Massachusetts Amherst, United States; Zamani H., University of Massachusetts Amherst, United States","This paper studies the use of style embeddings to enhance author profiling for the goal of personalization of Large Language Models (LLMs). Using a style-based RetrievalAugmented Generation (RAG) approach, we meticulously study the efficacy of style embeddings in capturing distinctive authorial nuances. The proposed method leverages this acquired knowledge to enhance the personalization capabilities of LLMs. In the assessment of this approach, we have employed the LaMP benchmark, specifically tailored for evaluating language models across diverse dimensions of personalization. The empirical observations from our investigation reveal that, in comparison to term matching or context matching, style proves to be marginally superior in the development of personalized LLMs. ©2024 Association for Computational Linguistics.","","Computational linguistics; Context matching; Embeddings; Language model; Matchings; Personalizations; Embeddings","Deshpande A.; Hwang E.; Murahari V.; Park J.S.; Yang D.; Sabharwal A.; Narasimhan K.; Kalyan A.","Association for Computational Linguistics (ACL)","English","Conference paper","Final","","Scopus","2-s2.0-85188882447"
"Izquierdo-Domenech J.; Linares-Pellicer J.; Ferri-Molla I.","Izquierdo-Domenech, Juan (57204239555); Linares-Pellicer, Jordi (13006508800); Ferri-Molla, Isabel (58679845800)","57204239555; 13006508800; 58679845800","Virtual Reality and Language Models, a New Frontier in Learning","2024","International Journal of Interactive Multimedia and Artificial Intelligence","8","5","","46","54","8","1","10.9781/ijimai.2024.02.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186906440&doi=10.9781%2fijimai.2024.02.007&partnerID=40&md5=338e80de2837a9d173f432f1467b2dc9","Valencian Research Institute for Artificial Intelligence (VRAIN), Universitat Politècnica de València (UPV), València, Spain","Izquierdo-Domenech J., Valencian Research Institute for Artificial Intelligence (VRAIN), Universitat Politècnica de València (UPV), València, Spain; Linares-Pellicer J., Valencian Research Institute for Artificial Intelligence (VRAIN), Universitat Politècnica de València (UPV), València, Spain; Ferri-Molla I., Valencian Research Institute for Artificial Intelligence (VRAIN), Universitat Politècnica de València (UPV), València, Spain","The proposed research introduces an innovative Virtual Reality (VR) and Large Language Model (LLM) architecture to enhance the learning process across diverse educational contexts, ranging from school to industrial settings. Leveraging the capabilities of LLMs and Retrieval-Augmented Generation (RAG), the architecture centers around an immersive VR application. This application empowers students of all backgrounds to interactively engage with their environment by posing questions and receiving informative responses in text format and with visual hints in VR, thereby fostering a dynamic learning experience. LLMs with RAG act as the backbones of this architecture, facilitating the integration of private or domain-specific data into the learning process. By seamlessly connecting various data sources through data connectors, RAG overcomes the challenge of disparate and siloed information repositories, including APIs, PDFs, SQL databases, and more. The data indexes provided by RAG solutions further streamline this process by structuring the ingested data into formats optimized for consumption by LLMs. An empirical study was conducted to evaluate the effectiveness of this VR and LLM architecture. Twenty participants, divided into Experimental and Control groups, were selected to assess the impact on their learning process. The Experimental group utilized the immersive VR application, which allowed interactive engagement with the educational environment, while the Control group followed traditional learning methods. The study revealed significant improvements in learning outcomes for the Experimental group, demonstrating the potential of integrating VR and LLMs in enhancing comprehension and engagement in learning contexts. This study presents an innovative approach that capitalizes on the synergy between LLMs and immersive VR technology, opening avenues for a transformative learning experience that transcends traditional boundaries and empowers learners across a spectrum of educational landscapes. © 2024, Universidad Internacional de la Rioja. All rights reserved.","Large Language Models; RetrievalAugmented Generation; Virtual Reality","","","Universidad Internacional de la Rioja","English","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85186906440"
"Chouhan A.; Gertz M.","Chouhan, Ashish (57211662283); Gertz, Michael (57203048165)","57211662283; 57203048165","LexDrafter: Terminology Drafting for Legislative Documents using Retrieval Augmented Generation","2024","2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation, LREC-COLING 2024 - Main Conference Proceedings","","","","10448","10458","10","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195920928&partnerID=40&md5=974d43126b8b42a5c10f2b981f68531e","Institute of Computer Science, Heidelberg University, Im Neuenheimer Feld 205, Heidelberg, Germany","Chouhan A., Institute of Computer Science, Heidelberg University, Im Neuenheimer Feld 205, Heidelberg, Germany; Gertz M., Institute of Computer Science, Heidelberg University, Im Neuenheimer Feld 205, Heidelberg, Germany","With the increase in legislative documents at the EU, the number of new terms and their definitions is increasing as well. As per the Joint Practical Guide of the European Parliament, the Council and the Commission, terms used in legal documents shall be consistent, and identical concepts shall be expressed without departing from their meaning in ordinary, legal, or technical language. Thus, while drafting a new legislative document, having a framework that provides insights about existing definitions and helps define new terms based on a document's context will support such harmonized legal definitions across different regulations and thus avoid ambiguities. In this paper, we present LexDrafter, a framework that assists in drafting Definitions articles for legislative documents using retrieval augmented generation (RAG) and existing term definitions present in different legislative documents. For this, definition elements are built by extracting definitions from existing documents. Using definition elements and RAG, a Definitions article can be suggested on demand for a legislative document that is being drafted. We demonstrate and evaluate the functionality of LexDrafter using a collection of EU documents from the energy domain. The code for LexDrafter framework is available at https://github.com/achouhan93/LexDrafter. © 2024 ELRA Language Resource Association: CC BY-NC 4.0.","EU legislative documents; EUR-Lex; large language models (LLMs); legal; retrieval-augmented generation (RAG); text generation","Information retrieval; EU legislative document; EUR-lex; European Parliament; Language model; Large language model; Legal; New terms; Practical guide; Retrieval-augmented generation; Text generations; Laws and legislation","Calzolari N.; Kan M.-Y.; Hoste V.; Lenci A.; Sakti S.; Xue N.","European Language Resources Association (ELRA)","English","Conference paper","Final","","Scopus","2-s2.0-85195920928"
"Chen B.; Bertozzi A.L.","Chen, Bohan (57223199551); Bertozzi, Andrea L. (17134312900)","57223199551; 17134312900","AutoKG: Efficient Automated Knowledge Graph Generation for Language Models","2023","Proceedings - 2023 IEEE International Conference on Big Data, BigData 2023","","","","3117","3126","9","0","10.1109/BigData59044.2023.10386454","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184978959&doi=10.1109%2fBigData59044.2023.10386454&partnerID=40&md5=b4862ec952ca7004cca003557ab4a3d9","University of California, Los Angeles, Department of Mathematics, 520 Portola Plaza, Los Angeles, 90095, CA, United States","Chen B., University of California, Los Angeles, Department of Mathematics, 520 Portola Plaza, Los Angeles, 90095, CA, United States; Bertozzi A.L., University of California, Los Angeles, Department of Mathematics, 520 Portola Plaza, Los Angeles, 90095, CA, United States","Traditional methods of linking large language models (LLMs) to knowledge bases via the semantic similarity search often fall short of capturing complex relational dynamics. To address these limitations, we introduce AutoKG, a lightweight and efficient approach for automated knowledge graph (KG) construction. For a given knowledge base consisting of text blocks, AutoKG first extracts keywords using a LLM and then evaluates the relationship weight between each pair of keywords using graph Laplace learning. We employ a hybrid search scheme combining vector similarity and graph-based associations to enrich LLM responses. Preliminary experiments demonstrate that AutoKG offers a more comprehensive and interconnected knowledge retrieval mechanism compared to the semantic similarity search, thereby enhancing the capabilities of LLMs in generating more insightful and relevant outputs.  © 2023 IEEE.","Graph Learning; Knowledge Graph; Language model; Retrieval-augmented Generation","Computational linguistics; Graphic methods; Semantic Web; Semantics; Graph construction; Graph generation; Graph learning; Hybrid search; Knowledge graphs; Language model; Retrieval-augmented generation; Search scheme; Semantic similarity; Similarity search; Knowledge graph","He J.; Palpanas T.; Hu X.; Cuzzocrea A.; Dou D.; Slezak D.; Wang W.; Gruca A.; Lin J.C.-W.; Agrawal R.","Institute of Electrical and Electronics Engineers Inc.","English","Conference paper","Final","","Scopus","2-s2.0-85184978959"
"Jeong C.","Jeong, Cheonsu (58632067500)","58632067500","A Study on the Implementation of Generative AI Services Using an Enterprise Data-Based LLM Application Architecture","2023","Advances in Artificial Intelligence and Machine Learning","3","4","","1588","1618","30","2","10.54364/aaiml.2023.1191","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177608340&doi=10.54364%2faaiml.2023.1191&partnerID=40&md5=a90fc3e725b8e095fef8840005a0417d","Department of AI Automation Team, SAMSUNG SDS, Olympic-ro 125, Songpa-gu, Seoul, South Korea","Jeong C., Department of AI Automation Team, SAMSUNG SDS, Olympic-ro 125, Songpa-gu, Seoul, South Korea","This study presents a method for implementing generative AI services by utilizing the Large Language Models (LLM) application architecture. With recent advancements in generative AI technology, LLMs have gained prominence across various domains. In this context, the research addresses the challenge of information scarcity and proposes specific remedies by harnessing LLM capabilities. The investigation delves into strategies for mitigating the issue of inadequate data, offering tailored solutions. The study delves into the efficacy of employing fine-tuning techniques and direct document integration to alleviate data insuffi-ciency. A significant contribution of this work is the development of a Retrieval-Augmented Generation (RAG) model, which tackles the aforementioned challenges. The RAG model is carefully designed to enhance information storage and retrieval processes, ensuring improved content generation. The research elucidates the key phases of the information storage and retrieval methodology underpinned by the RAG model. A comprehensive analysis of these steps is undertaken, emphasizing their significance in addressing the scarcity of data. The study highlights the efficacy of the proposed method, showcasing its applicability through illustrative instances. By implementing the RAG model for information storage and retrieval, the research not only contributes to a deeper comprehension of generative AI technology but also facilitates its practical usability within enterprises utilizing LLMs. This work holds substantial value in advancing the field of generative AI, offering insights into enhancing data-driven content generation and fostering active utilization of LLM-based services within corporate settings. © 2023 Cheonsu Jeong.","Embedding; Generative AI; LLM framework; RAG; Vector store","","","Shimur Publications","English","Article","Final","All Open Access; Bronze Open Access","Scopus","2-s2.0-85177608340"
"Selva Kumar S.; Khan A.K.M.A.; Banday I.A.; Gada M.; Shanbhag V.V.","Selva Kumar, S. (57194090806); Khan, Afifah Khan Mohammed Ajmal (58752795500); Banday, Imadh Ajaz (58751858600); Gada, Manikantha (59154339600); Shanbhag, Vibha Venkatesh (59155004500)","57194090806; 58752795500; 58751858600; 59154339600; 59155004500","Overcoming LLM Challenges using RAG-Driven Precision in Coffee Leaf Disease Remediation","2024","International Conference on Emerging Technologies in Computer Science for Interdisciplinary Applications, ICETCS 2024","","","","","","","1","10.1109/ICETCS61022.2024.10543859","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196065003&doi=10.1109%2fICETCS61022.2024.10543859&partnerID=40&md5=c531e86e88d56ade5e12114455db8fbc","B. M. S. College of Engineering, Department of Computer Science and Engineering, Bangalore, India","Selva Kumar S., B. M. S. College of Engineering, Department of Computer Science and Engineering, Bangalore, India; Khan A.K.M.A., B. M. S. College of Engineering, Department of Computer Science and Engineering, Bangalore, India; Banday I.A., B. M. S. College of Engineering, Department of Computer Science and Engineering, Bangalore, India; Gada M., B. M. S. College of Engineering, Department of Computer Science and Engineering, Bangalore, India; Shanbhag V.V., B. M. S. College of Engineering, Department of Computer Science and Engineering, Bangalore, India","This research introduces an innovative AI-driven precision agriculture system, leveraging YOLOv8 for disease identification and Retrieval Augmented Generation (RAG) for context-aware diagnosis. Focused on addressing the challenges of diseases affecting the coffee production sector in Karnataka, The system integrates sophisticated object detection techniques with language models to address the inherent constraints associated with Large Language Models (LLMs). Our methodology not only tackles the issue of hallucinations in LLMs, but also introduces dynamic disease identification and remediation strategies. Real-time monitoring, collaborative dataset expansion, and organizational involvement ensure the system's adaptability in diverse agricultural settings. The effect of the suggested system extends beyond automation, aiming to secure food supplies, protect livelihoods, and promote eco-friendly farming practices. By facilitating precise disease identification, the system contributes to sustainable and environmentally conscious agriculture, reducing reliance on pesticides. Looking to the future, the project envisions continuous development in RAG-integrated object detection systems, emphasizing scalability, reliability, and usability. This research strives to be a beacon for positive change in agriculture, aligning with global efforts toward sustainable and technologically enhanced food production. © 2024 IEEE.","GPT-3.5; LLM; NLP; Object Detection; Precision Agriculture; RAG; YOLOv8","Agricultural robots; Diagnosis; Farms; Food supply; Object recognition; Precision agriculture; Sustainable development; Agriculture systems; Context-Aware; GPT-3.5; Language model; Large language model; Leaf disease; Objects detection; Precision Agriculture; Retrieval augmented generation; YOLOv8; Object detection","","Institute of Electrical and Electronics Engineers Inc.","English","Conference paper","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85196065003"
"Dai M.; Yuan C.; Nie X.","Dai, Muyun (57220207006); Yuan, Chun (59171000500); Nie, Xiaomei (57212575750)","57220207006; 59171000500; 57212575750","Managing the Personality of NPCs with Your Interactions: A Game Design System Based on Large Language Models","2024","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","14730 LNCS","","","247","259","12","0","10.1007/978-3-031-60692-2_17","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195853220&doi=10.1007%2f978-3-031-60692-2_17&partnerID=40&md5=fe4e588e4bfe74dd7d253b19995000bd","Tsinghua University, Shenzhen, China","Dai M., Tsinghua University, Shenzhen, China; Yuan C., Tsinghua University, Shenzhen, China; Nie X., Tsinghua University, Shenzhen, China","How to create a Non-player character (NPC) that has its own personality and also consistent with the intention of game designers is a problem to be discussed. This study is aim to design a system for designers to create NPCs quickly and easily that can accept open input of player and make a variety of reasonable feedback adaptively in the game based on the dynamic interactions of player. The system comprises two essential components: an adaptive personality model manager and a drama mechanism manager based on retrieval augmented generation. In our experiment, a role-playing game is designed using this system, and corresponding user research is conducted to verify its effectiveness. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.","Design tools/technologies; Development methodology; Interactive System; LLMs; NPC design","Character designs; Design tool; Design tool/technology; Development methodology; Game design; Interactive system; LLM; Non-player character; Non-player character design; Tool technology; Game design","Fang X.","Springer Science and Business Media Deutschland GmbH","English","Conference paper","Final","","Scopus","2-s2.0-85195853220"
"Azov G.; Pelc T.; Alon A.F.; Kamhi G.","Azov, Guy (59144594300); Pelc, Tatiana (59144638500); Alon, Adi Fledel (59144683700); Kamhi, Gila (22733906700)","59144594300; 59144638500; 59144683700; 22733906700","Self-Improving Customer Review Response Generation Based on LLMs","2024","7th Workshop on e-Commerce and NLP, ECNLP 2024 at LREC-COLING 2024 - Workshop Proceedings","","","","40","57","17","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195201023&partnerID=40&md5=63ba02e0ad0093aa5a3faef155d74300","Intel Corporation","Azov G., Intel Corporation; Pelc T., Intel Corporation; Alon A.F., Intel Corporation; Kamhi G., Intel Corporation","Previous studies have demonstrated that proactive interaction with user reviews has a positive impact on the perception of app users and encourages them to submit revised ratings. Nevertheless, developers encounter challenges in managing a high volume of reviews, particularly in the case of popular apps with a substantial influx of daily reviews. Consequently, there is a demand for automated solutions aimed at streamlining the process of responding to user reviews. To address this, we have developed a new system for generating automatic responses by leveraging user-contributed documents with the help of retrieval-augmented generation (RAG) and advanced Large Language Models (LLMs). Our solution, named SCRABLE, represents an adaptive customer review response automation that enhances itself with self-optimizing prompts and a judging mechanism based on LLMs. Additionally, we introduce an automatic scoring mechanism that mimics the role of a human evaluator to assess the quality of responses generated in customer review domains. Extensive experiments and analyses conducted on real-world datasets reveal that our method is effective in producing high-quality responses, yielding improvement of more than 8.5% compared to the baseline. Further validation through manual examination of the generated responses underscores the efficacy our proposed system. © 2024 ELRA Language Resource Association.","LLM-as-a-Judge; Prompt Optimization; Review Response Generation; Self Improving System","Customer review; Improving systems; Language model; Large language model-as-a-judge; Optimisations; Prompt optimization; Response generation; Review response generation; Self improving system; User reviews; Sales","Malmasi S.; Fetahu B.; Ueffing N.; Rokhlenko O.; Agichtein E.; Guy I.","European Language Resources Association (ELRA)","English","Conference paper","Final","","Scopus","2-s2.0-85195201023"
"Dixit T.; Paranjape B.; Hajishirzi H.; Zettlemoyer L.","Dixit, Tanay (57275259400); Paranjape, Bhargavi (57220344217); Hajishirzi, Hannaneh (23008126600); Zettlemoyer, Luke (57204370628)","57275259400; 57220344217; 23008126600; 57204370628","CORE: A Retrieve-then-Edit Framework for Counterfactual Data Generation","2022","Findings of the Association for Computational Linguistics: EMNLP 2022","","","","2964","2984","20","10","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149904020&partnerID=40&md5=d69654f7bc97eb5c3a17d15bc011d857","Indian Institute of Technology, Madras, India; Paul G. Allen School of Computer Science & Engineering, University of Washington, United States; Allen Institute of Artificial Intelligence, Seattle, United States; Meta AI","Dixit T., Indian Institute of Technology, Madras, India; Paranjape B., Paul G. Allen School of Computer Science & Engineering, University of Washington, United States; Hajishirzi H., Paul G. Allen School of Computer Science & Engineering, University of Washington, United States, Allen Institute of Artificial Intelligence, Seattle, United States; Zettlemoyer L., Paul G. Allen School of Computer Science & Engineering, University of Washington, United States, Meta AI","Counterfactual data augmentation (CDA) - i.e., adding minimally perturbed inputs during training - helps reduce model reliance on spurious correlations and improves generalization to out-of-distribution (OOD) data. Prior work on generating counterfactuals only considered restricted classes of perturbations, limiting their effectiveness. We present COunterfactual Generation via Retrieval and Editing (CORE), a retrieval-augmented generation framework for creating diverse counterfactual perturbations for CDA. For each training example, CORE first performs a dense retrieval over a task-related unlabeled text corpus using a learned bi-encoder and extracts relevant counterfactual excerpts. CORE then incorporates these into prompts to a large language model with few-shot learning capabilities, for counterfactual editing. Conditioning language model edits on naturally occurring data results in diverse perturbations. Experiments on natural language inference and sentiment analysis benchmarks show that CORE counterfactuals are more effective at improving generalization to OOD data compared to other DA approaches. We also show that the CORE retrieval framework can be used to encourage diversity in manually authored perturbations. © 2022 Association for Computational Linguistics.","","Computational linguistics; Counterfactuals; Data augmentation; Data generation; Generalisation; Language model; Learning capabilities; Natural languages; Naturally occurring; Text corpora; Training example; Sentiment analysis","Goldberg Y.; Kozareva Z.; Zhang Y.","Association for Computational Linguistics (ACL)","English","Conference paper","Final","","Scopus","2-s2.0-85149904020"
"Pitkäranta T.; Pitkäranta L.","Pitkäranta, Tapio (6506623750); Pitkäranta, Leena (59139133000)","6506623750; 59139133000","Bridging Human and AI Decision-Making with LLMs: The RAGADA Approach","2024","International Conference on Enterprise Information Systems, ICEIS - Proceedings","1","","","812","819","7","0","10.5220/0012705000003690","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193974262&doi=10.5220%2f0012705000003690&partnerID=40&md5=f86e2091bda79749950dfc9ba51b513e","Department of Computer Science and Engineering, Aalto University, Finland; Department of Industrial Engineering and Management, Aalto University, Finland","Pitkäranta T., Department of Computer Science and Engineering, Aalto University, Finland; Pitkäranta L., Department of Industrial Engineering and Management, Aalto University, Finland","The Retrieval Augmented Generation Algorithmic Decision Alignment (RAGADA) architecture is an advancement in AI-augmented decision-making for corporate environments. This paper discusses RAGADA’s innovative architecture that merges RAG and Multi-Agent System (MAS) with sophisticated business algorithms and dynamic interfaces, enhancing natural language interaction between AI systems and users. This fusion extends AI’s reach, facilitating adaptable decision-making tools for leaders, in line with evolving business strategies and ethical standards. Experimental validation of RAGADA within the banking sector, involving diverse stakeholder groups ranging from customers to business and ethical managers, confirms its effectiveness. The system adeptly translates natural language inquiries into actionable insights, thereby improving the user experience and decision-making transparency. This validation underscores RAGADA’s potential to transform stakeholder engagement and demonstrates a leap in utilizing AI for strategic and ethical business management. Copyright © 2024 by SCITEPRESS – Science and Technology Publications, Lda.","IR Information Retrieval; LLM Large Language Models; Multi-Agent Systems (MAS); RAG: Retrieval Augmented Generation; RAGADA: Retrieval Augmented Generation Algorithmic Decision Alignment","Decision making; Information retrieval; Philosophical aspects; Search engines; Algorithmics; Corporate environment; Decisions makings; IR information retrieval; Language model; LLM large language model; Multi-agent system; RAG: retrieval augmented generation; Retrieval augmented generation algorithmic decision alignment: retrieval augmented generation algorithmic decision alignment; Multi agent systems","Filipe J.; Smialek M.; Brodsky A.; Hammoudi S.","Science and Technology Publications, Lda","English","Conference paper","Final","All Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85193974262"
"Ranade P.; Joshi A.","Ranade, Priyanka (57205677723); Joshi, Anupam (7402452908)","57205677723; 7402452908","FABULA: Intelligence Report Generation Using Retrieval-Augmented Narrative Construction","2023","Proceedings of the 2023 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining, ASONAM 2023","","","","603","610","7","3","10.1145/3625007.3627505","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190626299&doi=10.1145%2f3625007.3627505&partnerID=40&md5=efc58e57f7452acfa42d51965d4f766f","University of Maryland, Baltimore County, Baltimore, MD, United States","Ranade P., University of Maryland, Baltimore County, Baltimore, MD, United States; Joshi A., University of Maryland, Baltimore County, Baltimore, MD, United States","Narrative construction is the process of representing disparate event information into a logical plot structure that models an end to end story. Intelligence analysis is an example of a domain that can benefit tremendously from narrative construction techniques, particularly in aiding analysts during the largely manual and costly process of synthesizing event information into comprehensive intelligence reports. Manual intelligence report generation is often prone to challenges such as integrating dynamic event information, writing fine-grained queries, and closing information gaps. This motivates the development of a system that retrieves and represents critical aspects of events in a form that aids in automatic generation of intelligence reports.We introduce a Retrieval Augmented Generation (RAG) approach to augment prompting of an autoregressive decoder by retrieving structured information asserted in a knowledge graph to generate targeted information based on a narrative plot model. We apply our approach to the problem of neural intelligence report generation and introduce FABULA, framework to augment intelligence analysis workflows using RAG. An analyst can use FABULA to query an Event Plot Graph (EPG) to retrieve relevant event plot points, which can be used to augment prompting of a Large Language Model (LLM) during intelligence report generation. Our evaluation studies show that the plot points included in the generated intelligence reports have high semantic relevance, high coherency, and low data redundancy. © 2023 ACM.","knowledge graphs; large language models; narratives; retrieval augmented generation","Computational linguistics; Semantics; Construction technique; Dynamic events; End to end; Intelligence analysis; Knowledge graphs; Language model; Large language model; Narrative; Report generation; Retrieval augmented generation; Knowledge graph","Aditya Prakash B.; Wang D.; Weninger T.","Association for Computing Machinery, Inc","English","Conference paper","Final","All Open Access; Bronze Open Access","Scopus","2-s2.0-85190626299"
"Huang D.; Wang Z.","Huang, Donghao (59068051800); Wang, Zhaoxia (55719794000)","59068051800; 55719794000","Evaluation of Orca 2 Against Other LLMs for Retrieval Augmented Generation","2024","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","14658 LNAI","","","3","19","16","0","10.1007/978-981-97-2650-9_1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192372028&doi=10.1007%2f978-981-97-2650-9_1&partnerID=40&md5=ba0557997890bca01f37f4fe55f26ef3","School of Computing and Information Systems, Singapore Management University, 80 Stamford Rd, Singapore, 178902, Singapore","Huang D., School of Computing and Information Systems, Singapore Management University, 80 Stamford Rd, Singapore, 178902, Singapore; Wang Z., School of Computing and Information Systems, Singapore Management University, 80 Stamford Rd, Singapore, 178902, Singapore","This study presents a comprehensive evaluation of Microsoft Research’s Orca 2, a small yet potent language model, in the context of Retrieval Augmented Generation (RAG). The research involved comparing Orca 2 with other significant models such as Llama-2, GPT-3.5-Turbo, and GPT-4, particularly focusing on its application in RAG. Key metrics, included faithfulness, answer relevance, overall score, and inference speed, were assessed. Experiments conducted on high-specification PCs revealed Orca 2’s exceptional performance in generating high quality responses and its efficiency on consumer-grade GPUs, underscoring its potential for scalable RAG applications. This study highlights the pivotal role of smaller, efficient models like Orca 2 in the advancement of conversational AI and their implications for various IT infrastructures. The source codes and datasets of this paper are accessible here (https://github.com/inflaton/Evaluation-of-Orca-2-for-RAG.). © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2024.","Generated Pre-trained Transformer (GPT); Large Language Model (LLM); Model Comparison; Question Answering; Retrieval Augmented Generation (RAG)","Computational linguistics; 2-generated; Comprehensive evaluation; Generated pre-trained transformer; ITS applications; Language model; Large language model; Microsoft researches; Models comparisons; Question Answering; Retrieval augmented generation; Program processors","Wang Z.; Tan C.W.","Springer Science and Business Media Deutschland GmbH","English","Conference paper","Final","","Scopus","2-s2.0-85192372028"
"Cheng X.; Luo D.; Chen X.; Liu L.; Zhao D.; Yan R.","Cheng, Xin (57887848600); Luo, Di (58260275300); Chen, Xiuying (57211747485); Liu, Lemao (55272241500); Zhao, Dongyan (55387416000); Yan, Rui (36723202000)","57887848600; 58260275300; 57211747485; 55272241500; 55387416000; 36723202000","Lift Yourself Up: Retrieval-augmented Text Generation with Self-Memory","2023","Advances in Neural Information Processing Systems","36","","","43780","43799","19","3","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205561550&partnerID=40&md5=f01f9f055070db2780dc35daed6a4fbd","Peking University, China; Remin University of China, China; KAUST, Saudi Arabia; Tencent AI Lab, China","Cheng X., Peking University, China; Luo D., Remin University of China, China; Chen X., KAUST, Saudi Arabia; Liu L., Tencent AI Lab, China; Zhao D., Peking University, China; Yan R., Remin University of China, China","With direct access to human-written reference as memory, retrieval-augmented generation has achieved much progress in a wide range of text generation tasks. Since better memory would typically prompt better generation (we define this as primal problem). The traditional approach for memory retrieval involves selecting memory that exhibits the highest similarity to the input. However, this method is constrained by the quality of the fixed corpus from which memory is retrieved. In this paper, by exploring the duality of the primal problem: better generation also prompts better memory, we propose a novel framework, Selfmem, which addresses this limitation by iteratively employing a retrieval-augmented generator to create an unbounded memory pool and using a memory selector to choose one output as memory for the subsequent generation round. This enables the model to leverage its own output, referred to as self-memory, for improved generation. We evaluate the effectiveness of Selfmem on three distinct text generation tasks: neural machine translation, abstractive text summarization, and dialogue generation, under two generation paradigms: fine-tuned small model and few-shot LLM. Our approach achieves state-of-the-art results in four directions in JRC-Acquis translation dataset, 50.3 ROUGE-1 in XSum, and 62.9 ROUGE-1 in BigPatent, demonstrating the potential of self-memory in enhancing retrieval-augmented generation models. Furthermore, we conduct thorough analyses of each component in the Selfmem framework to identify current system bottlenecks and provide insights for future research. © 2023 Neural information processing systems foundation. All rights reserved.","","Dialogue generations; Machine translations; Memory pool; Memory retrieval; Primal problem; Text generations; Text Summarisation; Traditional approaches; Traditional approachs; Unbounded memory; Neural machine translation","Oh A.; Neumann T.; Globerson A.; Saenko K.; Hardt M.; Levine S.","Neural information processing systems foundation","English","Conference paper","Final","","Scopus","2-s2.0-85205561550"
"Gamage G.; Mills N.; De Silva D.; Manic M.; Moraliyage H.; Jennings A.; Alahakoon D.","Gamage, Gihan (57206903785); Mills, Nishan (57204273605); De Silva, Daswin (55242193900); Manic, Milos (6603474732); Moraliyage, Harsha (57220061394); Jennings, Andrew (57226406642); Alahakoon, Damminda (6602546111)","57206903785; 57204273605; 55242193900; 6603474732; 57220061394; 57226406642; 6602546111","Multi-Agent RAG Chatbot Architecture for Decision Support in Net-Zero Emission Energy Systems","2024","Proceedings of the IEEE International Conference on Industrial Technology","","","","","","","0","10.1109/ICIT58233.2024.10540920","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195804931&doi=10.1109%2fICIT58233.2024.10540920&partnerID=40&md5=bfa5893b72ab08785b386773881d2b9c","La Trobe University, Centre For Data Analytics And Cognition, Melbourne, Australia; Virginia Commonwealth University, Department Of Computer Science, Richmond, United States","Gamage G., La Trobe University, Centre For Data Analytics And Cognition, Melbourne, Australia; Mills N., La Trobe University, Centre For Data Analytics And Cognition, Melbourne, Australia; De Silva D., La Trobe University, Centre For Data Analytics And Cognition, Melbourne, Australia; Manic M., Virginia Commonwealth University, Department Of Computer Science, Richmond, United States; Moraliyage H., La Trobe University, Centre For Data Analytics And Cognition, Melbourne, Australia; Jennings A., La Trobe University, Centre For Data Analytics And Cognition, Melbourne, Australia; Alahakoon D., La Trobe University, Centre For Data Analytics And Cognition, Melbourne, Australia","Modern energy platforms are increasingly leveraging Artificial Intelligence (AI) for effective decision-making and efficient operations. This has led to the development of expansive data spaces that comprise both structured and unstructured energy data in various modalities. Conversational agents with the most recent advancements in Large Language Models (LLM) are primed to facilitate the efficient retrieval of this diverse information for decision support. In this paper, we propose a multi-agent chatbot architecture for decision support in net-zero emissions energy systems, leveraging LLMs and Retrieval-Augmented Generation (RAG). This architecture consists of a Chatbot User Interface (UI), an advanced Natural Language Understanding (NLU) module for precise entity and intent recognition, a robust Chatbot Core with four specialized agents: Observer, Knowledge Retriever, Behavior Analyzer, and Visualizer and Response Construction Module. These components work together to address diverse decision support needs in energy environments, specifically for net zero carbon emissions initiatives that need to consider diverse parameters and large volumes of data. We showcase the chatbot's successful integration and evaluation for decision support in the net-zero emissions energy system of a large tertiary education institution.  © 2024 IEEE.","AI Agents; Chatbots; Generative AI; Microgrid; Multi Agent Architecture; Net Zero Emissions; Retrieval-Augmented Generation","Air pollution; Architecture; Decision making; Decision support systems; Multi agent systems; Artificial intelligence agent; Chatbots; Decision supports; Generative artificial intelligence; Microgrid; Multiagent architecture; Net zero emission; Retrieval-augmented generation; Zero emission; Zero-emission energy systems; User interfaces","","Institute of Electrical and Electronics Engineers Inc.","English","Conference paper","Final","","Scopus","2-s2.0-85195804931"
"Mishra K.; Soliman T.; Ramakrishna A.; Kumar A.; Galstyan A.","Mishra, Kshitij (59095557300); Soliman, Tamer (58729151500); Ramakrishna, Anil (55938669100); Kumar, Anoop (57883632100); Galstyan, Aram (7003679856)","59095557300; 58729151500; 55938669100; 57883632100; 7003679856","Correcting Language Model Outputs by Editing Salient Layers","2024","EACL 2024 - 18th Conference of the European Chapter of the Association for Computational Linguistics, Findings of EACL 2024","","","","1295","1305","10","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188747578&partnerID=40&md5=7e3732dfa1498b77d1495ba5f3422c56","Indian Institute of Technology, India; Amazon Generative AI Center; Amazon AGI Foundations","Mishra K., Indian Institute of Technology, India; Soliman T., Amazon Generative AI Center; Ramakrishna A., Amazon AGI Foundations; Kumar A., Amazon AGI Foundations; Galstyan A., Amazon AGI Foundations","Large language models can accumulate incorrect or outdated knowledge as the real world evolves. Compared to typical solutions such as retraining, retrieval augmented generation, model editing offers an effective yet low cost solution to address this issue. However, existing model editing algorithms employ manual selection of edit layers, which requires prior domain knowledge or expensive architecture-specific empirical layer selection methods, such as causal tracing. In this work, we propose SaLEM (Salient Layers Editing Model), an efficient solution for data driven layer selection for the model editing task. Our solution utilizes layer-wise saliency maps for layer selection, and matches the accuracy of prior approaches but with only 1/3 of their edits, enabling efficient updates to the parametric knowledge in large language models. © 2024 Association for Computational Linguistics.","","Domain Knowledge; Image segmentation; Data driven; Domain knowledge; Language model; Layer-wise; Low-cost solution; Model outputs; Real-world; Saliency map; Selection methods; Computational linguistics","Graham Y.; Purver M.; Purver M.","Association for Computational Linguistics (ACL)","English","Conference paper","Final","","Scopus","2-s2.0-85188747578"
"Zhang X.; He P.; Deb T.; Yang G.; Liu X.; Hu Z.; Mao T.","Zhang, Xuefei (58788799900); He, Peiyang (58787493800); Deb, Tomal (57218220446); Yang, Guang (57453659600); Liu, Xuefeng (58787493900); Hu, Ziqing (58954566800); Mao, Tianyi (58788435100)","58788799900; 58787493800; 57218220446; 57453659600; 58787493900; 58954566800; 58788435100","Topic Knowledge Based Controlled Generation for Long Documents Using Retrieval-Based Language Models","2023","Frontiers in Artificial Intelligence and Applications","378","","","762","769","7","0","10.3233/FAIA231087","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181117382&doi=10.3233%2fFAIA231087&partnerID=40&md5=8c53272818327647b321fcc436c9070e","Amazon, Shenzhen, China","Zhang X., Amazon, Shenzhen, China; He P., Amazon, Shenzhen, China; Deb T., Amazon, Shenzhen, China; Yang G., Amazon, Shenzhen, China; Liu X., Amazon, Shenzhen, China; Hu Z., Amazon, Shenzhen, China; Mao T., Amazon, Shenzhen, China","Current LLM summarization systems Produce broad overviews which are disconnected from people specific interests and expectations. Basically, people preferences (topics) can be expressed by a collection of semantic keywords. Previous work exploit these keywords as extra input to generate summary. That requires additional human annotations. To tackle these constraints, we propose a novel framework, Topic Knowledge based Controlled Generation (TKCG), to control generated summaries through a set of topic keywords that are extracted automatically from source documents. First, as large language models (LLMs) are limited by context window length, we need to split the documents into small pieces like chapters acccording to the document format, as one chapter is a semantically complete section. Secondly we extract some topic keywords from source documents with a transformer-based model. These topic keywords are used to retrieve the chapters that are related to the topic. We then input the combination of topic keywords and chapters as prompts into LLM to get conditional summaries. We also demonstrate the effectiveness of TKCG on two standard datasets, MACSum and arXiv.  © 2023 The authors and IOS Press.","LLM; RAG; text generation; word embedding","Computational linguistics; Data mining; Knowledge based systems; Natural language processing systems; 'current; Embeddings; Human annotations; Knowledge based; Language model; Large language model; RAG; Summarization systems; Text generations; Word embedding; Semantics","Tallon-Ballesteros A.J.; Beltran-Barba R.","IOS Press BV","English","Conference paper","Final","All Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85181117382"
"Fujita M.; Onaga T.; Kano Y.","Fujita, Masaki (58183638000); Onaga, Takaaki (58184480200); Kano, Yoshinobu (35336718500)","58183638000; 58184480200; 35336718500","LLM Tuning and Interpretable CoT: KIS Team in COLIEE 2024","2024","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","14741 LNAI","","","140","155","15","0","10.1007/978-981-97-3076-6_10","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195261197&doi=10.1007%2f978-981-97-3076-6_10&partnerID=40&md5=08c7bacff4689067d399686a13418012","Shizuoka University, Johoku, 3-5-1, Chuo-ku, Shizuoka, Hamamatsu-shi, 432-8011, Japan","Fujita M., Shizuoka University, Johoku, 3-5-1, Chuo-ku, Shizuoka, Hamamatsu-shi, 432-8011, Japan; Onaga T., Shizuoka University, Johoku, 3-5-1, Chuo-ku, Shizuoka, Hamamatsu-shi, 432-8011, Japan; Kano Y., Shizuoka University, Johoku, 3-5-1, Chuo-ku, Shizuoka, Hamamatsu-shi, 432-8011, Japan","Focusing on the recently advanced Large Language Models (LLMs), we studied two key areas: LLM tuning and Chain-of-Thought (CoT) interpretability, which are crucial in legal tasks. Regarding LLM tuning, we conducted experiments comparing multiple models, a variety of techniques including prompt engineering, and the presence or absence of fine-tune, thereby identifying the most effective settings. Additionally, we proposed new methods to overcome the shortcomings of models during fine-tune, leading to improved accuracy. In terms of CoT interpretability, we introduced a format that facilitates guiding the CoT process, enabling the identification of which parts of the reasoning process significantly influence the inference results. Furthermore, we demonstrated that fine-tune enables any model to produce outputs in this format, and this approach can clearly define the differences in reasoning capabilities among various models. Using implication reasoning tasks in the civil law section of the judicial examination as a subject, we achieved enhanced task performance with large-scale language models. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2024.","Chain-of-Thought; COLIEE; GPT-4; Large Language Models; Legal Bar Exam; Legal Information; LLM; Question Answering; Retrieval Augmented Generation","Chain-of-thought; COLIEE; GPT-4; Language model; Large language model; Legal bar exam; Legal information; Question Answering; Retrieval augmented generation; Computational linguistics","Suzumura T.; Bono M.","Springer Science and Business Media Deutschland GmbH","English","Conference paper","Final","","Scopus","2-s2.0-85195261197"
"Earley S.","Earley, Seth (26039103100)","26039103100","What executives need to know about knowledge management, large language models and generative AI","2023","Applied Marketing Analytics","9","3","","215","229","14","5","10.69554/yqbv7690","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180239029&doi=10.69554%2fyqbv7690&partnerID=40&md5=d8a00e75bceac24d70a390977a9965d8","CEO, Earley Information Science, United States; Earley Information Science, 63 Old East Street, Carlisle, 01741, MA, United States","Earley S., CEO, Earley Information Science, United States, Earley Information Science, 63 Old East Street, Carlisle, 01741, MA, United States","This paper discusses the opportunities and risks presented by large language models (LLMs), which power the popular and widely adopted Chat-GPT types of applications. The potential benefits include support for enhancing the customer journey and efficient management of an ever-increasing volume of information for employees. Risks include hallucinations (made up answers by generative AI that are not factually correct), exposure of corporate intellectual property (IP) to training models, lack of traceability and audit trails and misalignment with brand guidelines. The approach to handling risk described in this paper is retrieval-augmented generation (RAG), which references corporate knowledge and data sources in order to identify precise answers and retrieve exactly what users want. The paper also outlines the need for a knowledge architecture which enables enriched embeddings into vector databases which retain the context of intelligently componentised content. Using RAG requires knowledge hygiene and metadata models, and the paper discusses an experiment in which results were measured with and without the knowledge architecture. The improvement was significant: 53 per cent of questions were answered correctly without the model versus 83 per cent with the model. The use of RAG virtually eliminated hallucinations, secured corporate IP and provided traceability and an audit trail. © 2023, Henry Stewart Publications. All rights reserved.","ChatGPT; generative AI; KM; knowledge architecture; knowledge management; knowledge models; large language models; LLM challenges; LLM solutions; LLMs; metadata models; RAG; retrieval augmented generation","","","Henry Stewart Publications","English","Article","Final","","Scopus","2-s2.0-85180239029"
"Mosser L.; Aursand P.; Brakstad K.S.; Lehre C.; Myhre-Bakkevig J.","Mosser, L. (59004766000); Aursand, P. (57219411537); Brakstad, K.S. (57190070551); Lehre, C. (59004766100); Myhre-Bakkevig, J. (59004984000)","59004766000; 57219411537; 57190070551; 59004766100; 59004984000","Exploration Robot Chat: Uncovering Decades of Exploration Knowledge and Data with Conversational Large Language Models","2024","Society of Petroleum Engineers - SPE Norway Subsurface Conference, BERG 2024","","","","","","","0","10.2118/218439-MS","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191450907&doi=10.2118%2f218439-MS&partnerID=40&md5=0203be98fdd2ef92458973df55cfe555","AkerBP ASA, Norway; AkerBP ASA, Sopra Steria, Norway","Mosser L., AkerBP ASA, Norway; Aursand P., AkerBP ASA, Norway; Brakstad K.S., AkerBP ASA, Norway; Lehre C., AkerBP ASA, Sopra Steria, Norway; Myhre-Bakkevig J., AkerBP ASA, Norway","Hydrocarbon exploration and carbon capture and storage (CCS) evaluation are inherently multi-disciplinary tasks that require the integration of knowledge from multiple datatypes set in a historical and geological context. The diverse nature of subsurface data is often represented by a combination of direct and indirect measurements, interpretations and observations documented in multi-dimensional datasets as images, and written reports. The fidelity of these images and reports can have an enormous variety, and different qualities leading to a challenging situation where explorationists need to determine the value of a source of information while combining these sources across large spatiotemporal contexts. Modern search engines today can not only search through document text but also images. These capabilities have improved our ability to find well-known concepts based on short phrases, or keywords, combined with significant metadata. While these types of search engines have certainly benefited practitioners, the challenge of combining information from multiple data-sources, data modalities and languages remains an open problem. With the advent of conversational large language model (LLM) systems such as ChatGPT (Achiam et al. 2023) that provide coherent textual information and are informed by their training data, have become a reality. While ChatGPT certainly has taken many industries and their disciplines by storm, the tool is not without its shortcomings. For industry applications, in many cases the information necessary to provide answers will be highly proprietary, not shared with third parties and not part of the training data of the popular LLMs. Furthermore, due to their probabilistic nature LLMs suffer from so-called hallucinations, where the model provides a confident answer based on the user provided input but is non-factual and often non-sensical. To answer a given user-query with factuality it is important to provide relevant information as context to the LLMs. Lewis et al. (2020) proposes combining two systems: An information retrieval system that provide relevant information to answer a given question or to solve a specific task, and a second system being an LLM that is supplemented with the retrieved information as context to answer the user's question. This pattern of so-called retrieval-augmented generation (RAG) has become highly popular in the last year due to the strong conversational capabilities of systems like ChatGPT, accessible developer APIs for interfacing with LLMs, open-source software to orchestrate RAG-systems, as well as the rapid development of open-source LLMs (Touvron et al. 2023). Moreover, since the RAG pattern does not require fine-tuning or re-training a language model, it remains one of the most accessible ways to tailor LLMs to proprietary knowledge bases. © 2024 Society of Petroleum Engineers - SPE Norway Subsurface Conference, BERG 2024. All rights reserved.","","Computational linguistics; Digital storage; Open source software; Open systems; Petroleum prospecting; Query processing; Datatypes; Direct and indirect measurements; Exploration data; Exploration knowledge; Exploration robots; Hydrocarbon exploration; Integration of knowledge; Language model; Subsurface data; Training data; Search engines","","Society of Petroleum Engineers","English","Conference paper","Final","","Scopus","2-s2.0-85191450907"
"Painter J.L.; Mahaux O.; Vanini M.; Kara V.; Roshan C.; Karwowski M.; Chalamalasetti V.R.; Bate A.","Painter, Jeffery L. (55356702000); Mahaux, Olivia (37120438900); Vanini, Marco (59239890500); Kara, Vijay (57766316900); Roshan, Christie (59240153500); Karwowski, Marcin (59239533300); Chalamalasetti, Venkateswara Rao (59214061500); Bate, Andrew (7003390785)","55356702000; 37120438900; 59239890500; 57766316900; 59240153500; 59239533300; 59214061500; 7003390785","Enhancing Drug Safety Documentation Search Capabilities with Large Language Models: A User-Centric Approach","2023","Proceedings - 2023 International Conference on Computational Science and Computational Intelligence, CSCI 2023","","","","49","56","7","1","10.1109/CSCI62032.2023.00015","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198183632&doi=10.1109%2fCSCI62032.2023.00015&partnerID=40&md5=f2bb0e41cec9cc03464bce253071682c","Gsk, Durham, NC, United States; Gsk, Wavre, Belgium; Gsk, London, United Kingdom; Gsk, Poznan, Poland","Painter J.L., Gsk, Durham, NC, United States; Mahaux O., Gsk, Wavre, Belgium; Vanini M., Gsk, Wavre, Belgium; Kara V., Gsk, London, United Kingdom; Roshan C., Gsk, London, United Kingdom; Karwowski M., Gsk, Poznan, Poland; Chalamalasetti V.R., Gsk, Durham, NC, United States; Bate A., Gsk, London, United Kingdom","Integrating Large Language Models (LLMs) to enhance complex business document retrieval represents an emerging field known as retrieval-augmented generation (RAG). In highly regulated domains like drug safety (pharmacovigilance), its application has remained largely unexplored. This technology brings numerous advantages, including expedited staff on-boarding, enhanced comprehension of contextual queries, and swift information retrieval through natural language inquiries, surpassing conventional keyword searches. This study delves into various operational tasks, such as locating regulatory process guidance, navigating intricate scenarios for advice, and ensuring the LLM's competence in recognizing uncertainties to prevent misinformation. LLMs empower users to engage with documentation using natural language, markedly improving search efficiency. The case study underscores LLM's effectiveness in delivering prompt guidance within pharmacovigilance and adverse event processing and reporting, offering a user-centric solution that streamlines the search for intricate business documentation. © 2023 IEEE.","drug safety; large language models; LLM; pharmacovigilance; retrieval-augmented generation","Computational linguistics; Drug products; Drug safety; Language model; Large language model; Natural languages; Pharmacovigilance; Retrieval-augmented generation; Search capabilities; User-centric; Information retrieval","","Institute of Electrical and Electronics Engineers Inc.","English","Conference paper","Final","","Scopus","2-s2.0-85198183632"
"Li Z.; Zhang H.; Zhang J.","Li, Zizhong (58553325500); Zhang, Haopeng (57221295408); Zhang, Jiawei (55954167400)","58553325500; 57221295408; 55954167400","Unveiling the Magic: Investigating Attention Distillation in Retrieval-Augmented Generation","2024","Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL 2024","2","","","745","754","9","0","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197752410&partnerID=40&md5=a608f4b6e702f0e3bf92afffbeaedc87","IFM Lab, University of California, Davis, United States","Li Z., IFM Lab, University of California, Davis, United States; Zhang H., IFM Lab, University of California, Davis, United States; Zhang J., IFM Lab, University of California, Davis, United States","Retrieval-augmented generation framework addresses the limitations of large language models by enabling real-time knowledge updates for more accurate answers. An efficient way in the training phase of retrieval-augmented models is attention distillation, which uses attention scores as supervision signals instead of manually annotated query-document pairs. Despite its growing popularity, the detailed mechanisms behind the success of attention distillation remain unexplored, particularly the specific patterns it leverages to benefit training. In this paper, we address this gap by conducting a comprehensive investigation of attention distillation workflow and identifying key factors influencing the learning performance of retrieval-augmented language models. We further propose several insightful indicators for optimizing models’ training methods and avoiding ineffective training. © 2024 Association for Computational Linguistics.","","Computational linguistics; Information retrieval; Key factors; Knowledge update; Language model; Learning performance; Model training; Optimizing models; Query documents; Real- time; Training phasis; Work-flows; Distillation","","Association for Computational Linguistics (ACL)","English","Conference paper","Final","","Scopus","2-s2.0-85197752410"
"Zhou Q.; Liu C.; Duan Y.; Sun K.; Li Y.; Kan H.; Gu Z.; Shu J.; Hu J.","Zhou, Qingqing (58069709800); Liu, Can (57800463800); Duan, Yuchen (58070177600); Sun, Kaijie (58941681200); Li, Yu (59154764000); Kan, Hongxing (16233306900); Gu, Zongyun (55899034300); Shu, Jianhua (57218872111); Hu, Jili (57221832288)","58069709800; 57800463800; 58070177600; 58941681200; 59154764000; 16233306900; 55899034300; 57218872111; 57221832288","GastroBot: a Chinese gastrointestinal disease chatbot based on the retrieval-augmented generation","2024","Frontiers in Medicine","11","","1392555","","","","0","10.3389/fmed.2024.1392555","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195095833&doi=10.3389%2ffmed.2024.1392555&partnerID=40&md5=a8ef3438268e91f70a1eb431a6323c52","School of Medical Information Engineering, Anhui University of Chinese Medicine, Hefei, China; Center for Xin’an Medicine and Modernization of Traditional Chinese Medicine of IHM, Anhui University of Chinese Medicine, Hefei, China","Zhou Q., School of Medical Information Engineering, Anhui University of Chinese Medicine, Hefei, China; Liu C., School of Medical Information Engineering, Anhui University of Chinese Medicine, Hefei, China; Duan Y., School of Medical Information Engineering, Anhui University of Chinese Medicine, Hefei, China; Sun K., School of Medical Information Engineering, Anhui University of Chinese Medicine, Hefei, China; Li Y., School of Medical Information Engineering, Anhui University of Chinese Medicine, Hefei, China; Kan H., School of Medical Information Engineering, Anhui University of Chinese Medicine, Hefei, China, Center for Xin’an Medicine and Modernization of Traditional Chinese Medicine of IHM, Anhui University of Chinese Medicine, Hefei, China; Gu Z., School of Medical Information Engineering, Anhui University of Chinese Medicine, Hefei, China; Shu J., School of Medical Information Engineering, Anhui University of Chinese Medicine, Hefei, China; Hu J., School of Medical Information Engineering, Anhui University of Chinese Medicine, Hefei, China, Center for Xin’an Medicine and Modernization of Traditional Chinese Medicine of IHM, Anhui University of Chinese Medicine, Hefei, China","Introduction: Large Language Models (LLMs) play a crucial role in clinical information processing, showcasing robust generalization across diverse language tasks. However, existing LLMs, despite their significance, lack optimization for clinical applications, presenting challenges in terms of illusions and interpretability. The Retrieval-Augmented Generation (RAG) model addresses these issues by providing sources for answer generation, thereby reducing errors. This study explores the application of RAG technology in clinical gastroenterology to enhance knowledge generation on gastrointestinal diseases. Methods: We fine-tuned the embedding model using a corpus consisting of 25 guidelines on gastrointestinal diseases. The fine-tuned model exhibited an 18% improvement in hit rate compared to its base model, gte-base-zh. Moreover, it outperformed OpenAI’s Embedding model by 20%. Employing the RAG framework with the llama-index, we developed a Chinese gastroenterology chatbot named “GastroBot,” which significantly improves answer accuracy and contextual relevance, minimizing errors and the risk of disseminating misleading information. Results: When evaluating GastroBot using the RAGAS framework, we observed a context recall rate of 95%. The faithfulness to the source, stands at 93.73%. The relevance of answers exhibits a strong correlation, reaching 92.28%. These findings highlight the effectiveness of GastroBot in providing accurate and contextually relevant information about gastrointestinal diseases. During manual assessment of GastroBot, in comparison with other models, our GastroBot model delivers a substantial amount of valuable knowledge while ensuring the completeness and consistency of the results. Discussion: Research findings suggest that incorporating the RAG method into clinical gastroenterology can enhance the accuracy and reliability of large language models. Serving as a practical implementation of this method, GastroBot has demonstrated significant enhancements in contextual comprehension and response quality. Continued exploration and refinement of the model are poised to drive forward clinical information processing and decision support in the gastroenterology field. Copyright © 2024 Zhou, Liu, Duan, Sun, Li, Kan, Gu, Shu and Hu.","chatbot; embedding model; gastrointestinal disease; GPT; large language models; natural language process; question-answering; retrieval-augmented generation","Article; Chinese (language); comparative study; conceptual framework; decision support system; gastrointestinal disease; information processing; information retrieval; large language model; practice guideline; reliability","","Frontiers Media SA","English","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85195095833"
"Loevenich J.F.; Adler E.; Mercier R.; Velazquez A.; Lopes R.R.F.","Loevenich, Johannes F. (57220783158); Adler, Erik (59168104300); Mercier, Remi (59168360200); Velazquez, Alexander (57190585368); Lopes, Roberto Rigolin F. (57200253245)","57220783158; 59168104300; 59168360200; 57190585368; 57200253245","Design of an Autonomous Cyber Defence Agent using Hybrid AI models","2024","2024 International Conference on Military Communication and Information Systems, ICMCIS 2024","","","","","","","0","10.1109/ICMCIS61231.2024.10540988","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195693813&doi=10.1109%2fICMCIS61231.2024.10540988&partnerID=40&md5=dc233935a69f2aeaf6141b8b4057d5e2","Secure Communications & Information (SIX), Thales Deutschland, Ditzingen, Germany; University of Osnabrück, Department of Mathematics/Computer Science, Osnabrück, Germany; Medical Informatics, Heilbronn University of Applied Sciences, Heilbronn, Germany; Computer Sciences and Networks (INFRES), Télécom Paris, Paris, France; Information Technology Division, U.S. Naval Research Laboratory, Washington, DC, United States","Loevenich J.F., Secure Communications & Information (SIX), Thales Deutschland, Ditzingen, Germany, University of Osnabrück, Department of Mathematics/Computer Science, Osnabrück, Germany; Adler E., Secure Communications & Information (SIX), Thales Deutschland, Ditzingen, Germany, Medical Informatics, Heilbronn University of Applied Sciences, Heilbronn, Germany; Mercier R., Secure Communications & Information (SIX), Thales Deutschland, Ditzingen, Germany, Computer Sciences and Networks (INFRES), Télécom Paris, Paris, France; Velazquez A., Information Technology Division, U.S. Naval Research Laboratory, Washington, DC, United States; Lopes R.R.F., Secure Communications & Information (SIX), Thales Deutschland, Ditzingen, Germany","This paper extends the design of an autonomous cyber defence (ACD) agent to monitor and actuate within a protected core network segment. The goal is to take advantage of recent developments in AI models to define a hybrid architecture that combines deep reinforcement learning (DRL), large language models (LLMs), and rule-based models. The motivation comes from the fact that modern network segments within colored clouds are using software-defined controllers with the means to host ACD agents and other cybersecurity tools implementing hybrid AI models. For example, our ACD agent uses a DRL model and the chatbot uses an LLM to create an interface with human cybersecurity experts. The ACD agent was evaluated against two red agent strategies in a gym environment using a set of actions to defend services in the network (monitor, analyse, decoy, remove, and restore). Our chatbot was developed using retrieval augmented generation and a prompting agent to augment a pre-trained LLM with data from cybersecurity knowledge graphs. We performed a comparative analysis between a baseline implementation and our chatbot using generation/retrieval metrics. The results suggest that both ACD agent and chatbot can potentially enhance the defence of critical networks connected to untrusted infrastructure.  © 2024 IEEE.","Autonomous Cyber Defence; Cybersecurity; Deep Reinforcement Learning; Large Language Model","Autonomous agents; Computational linguistics; Cybersecurity; Deep learning; Learning systems; Autonomous cybe defense; Chatbots; Core networks; Cyber security; Cyber-defense; Deep reinforcement learning; Language model; Large language model; Network segment; Reinforcement learnings; Reinforcement learning","","Institute of Electrical and Electronics Engineers Inc.","English","Conference paper","Final","","Scopus","2-s2.0-85195693813"
"Bianchini F.; Calamo M.; De Luzi F.; Macrì M.; Mecella M.","Bianchini, Filippo (57734178100); Calamo, Marco (58399768500); De Luzi, Francesca (57279785300); Macrì, Mattia (58455038200); Mecella, Massimo (6602717537)","57734178100; 58399768500; 57279785300; 58455038200; 6602717537","Enhancing Complex Linguistic Tasks Resolution Through Fine-Tuning LLMs, RAG and Knowledge Graphs (Short Paper)","2024","Lecture Notes in Business Information Processing","521","","","147","155","8","0","10.1007/978-3-031-61003-5_13","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196186653&doi=10.1007%2f978-3-031-61003-5_13&partnerID=40&md5=40e449f918b271da33d8903866e114ad","Dipartimento Ingegneria informatica, automatica e gestionale Antonio Ruberti, Sapienza Università di Roma, Rome, Italy","Bianchini F., Dipartimento Ingegneria informatica, automatica e gestionale Antonio Ruberti, Sapienza Università di Roma, Rome, Italy; Calamo M., Dipartimento Ingegneria informatica, automatica e gestionale Antonio Ruberti, Sapienza Università di Roma, Rome, Italy; De Luzi F., Dipartimento Ingegneria informatica, automatica e gestionale Antonio Ruberti, Sapienza Università di Roma, Rome, Italy; Macrì M., Dipartimento Ingegneria informatica, automatica e gestionale Antonio Ruberti, Sapienza Università di Roma, Rome, Italy; Mecella M., Dipartimento Ingegneria informatica, automatica e gestionale Antonio Ruberti, Sapienza Università di Roma, Rome, Italy","Given the synergy between Large Language Models (LLMs) and Knowledge Graphs (KGs), we introduce a pipeline to tackle complex linguistic tasks, which we are experimenting in the legal domain. While LLMs offer unprecedented generative capabilities, their reliance on sub-symbolic processing can lead to fallacious outcomes. Our methodology introduces an advanced Retrieval Augmented Generation (RAG) pipeline, enriched with two KGs and optimized LLMs, promising to enhance the resolution of complex linguistic tasks. Through KG construction based on prompt engineering techniques and iterative fine-tuning, we transcend the limitations of conventional LLMs. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.","Complex linguistic tasks; Knowledge Graphs; Large Language Models","Computational linguistics; Knowledge graph; Pipelines; Complex linguistic task; Engineering techniques; Fine tuning; Graph construction; Knowledge graphs; Language model; Large language model; Legal domains; Sub-symbolic; Symbolic processing; Iterative methods","Almeida J.P.A.; Di Ciccio C.; Kalloniatis C.","Springer Science and Business Media Deutschland GmbH","English","Conference paper","Final","","Scopus","2-s2.0-85196186653"
"Sanna L.; Bellan P.; Magnolini S.; Segala M.; Haez S.G.; Consolandi M.; Dragoni M.","Sanna, Leonardo (59265215200); Bellan, Patrizio (57204825247); Magnolini, Simone (56530696900); Segala, Marina (59156410800); Haez, Saba Ghanbari (59156154700); Consolandi, Monica (57216831165); Dragoni, Mauro (19638448200)","59265215200; 57204825247; 56530696900; 59156410800; 59156154700; 57216831165; 19638448200","Building Certified Medical Chatbots: Overcoming Unstructured Data Limitations with Modular RAG","2024","1st Workshop on Patient-Oriented Language Processing, CL4Health 2024 at LREC-COLING 2024 - Workshop Proceedings","","","","124","130","6","1","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195167642&partnerID=40&md5=5d5eb12234401bd299f3d100c7dba24f","Fondazione Bruno Kessler, Trento, Italy; Free University of Bozen, Bozen, Italy","Sanna L., Fondazione Bruno Kessler, Trento, Italy; Bellan P., Fondazione Bruno Kessler, Trento, Italy; Magnolini S., Fondazione Bruno Kessler, Trento, Italy; Segala M., Fondazione Bruno Kessler, Trento, Italy; Haez S.G., Fondazione Bruno Kessler, Trento, Italy, Free University of Bozen, Bozen, Italy; Consolandi M., Fondazione Bruno Kessler, Trento, Italy; Dragoni M., Fondazione Bruno Kessler, Trento, Italy","Creating a certified conversational agent poses several issues. The need to manage fine-grained information delivery and the necessity to provide reliable medical information requires a notable effort, especially in dataset preparation. In this paper, we investigate the challenges of building a certified medical chatbot in Italian that provides information about pregnancy and early childhood. We show some negative initial results regarding the possibility of creating a certified conversational agent within the RASA framework starting from unstructured data. Finally, we propose a modular RAG model to implement a Large Language Model in a certified context, overcoming data limitations and enabling data collection on actual conversations. © 2024 ELRA Language Resource Association: CC BY-NC 4.0.","Conversational Agent; Digital Health; Retrieval-Augmented Generation","Chatbots; Conversational agents; Data limitations; Digital health; Fine grained; Information delivery; Medical information; Modulars; Retrieval-augmented generation; Unstructured data","Demner-Fushman D.; Ananiadou S.; Thompson P.; Ondov B.","European Language Resources Association (ELRA)","English","Conference paper","Final","","Scopus","2-s2.0-85195167642"
"Yang H.; Zhang M.; Wei D.","Yang, Hao (57208745952); Zhang, Min (57282022500); Wei, Daimeng (57219324919)","57208745952; 57282022500; 57219324919","SRAG: Speech Retrieval Augmented Generation for Spoken Language Understanding","2023","6th International Seminar on Research of Information Technology and Intelligent Systems, ISRITI 2023 - Proceeding","","","","279","283","4","0","10.1109/ISRITI60336.2023.10467285","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190064828&doi=10.1109%2fISRITI60336.2023.10467285&partnerID=40&md5=6d8089f8905a8bbca06801381b6155e3","Huawei Technologies CO., LTD, 2012 Labs, China","Yang H., Huawei Technologies CO., LTD, 2012 Labs, China; Zhang M., Huawei Technologies CO., LTD, 2012 Labs, China; Wei D., Huawei Technologies CO., LTD, 2012 Labs, China","Retrieval augmented generation (RAG) has shown promise for enhancing natural language understanding (NLU) capabilities of large language models (LLMs) by retrieving relevant knowledge as prompts. Extending RAG to spoken language understanding (SLU) represents an important research direction. This paper proposes a RAG approach for improving SLU. First, the encoder of a pretrained automatic speech recognition model is utilized for speech retrieval over the training set. The corresponding texts and intent labels are then formulated as prompts to guide the SLU decoder. Furthermore, a prompt attention mechanism is introduced to strengthen the attention between generation and prompts. Experiments demonstrate that the proposed speech RAG approach substantially outperforms conventional end-to-end and cascaded SLU models in intent prediction from speech. This highlights the efficacy of leveraging retrieval-based prompting to incorporate external knowledge for advancing SLU. © 2023 IEEE.","Large Language Models; Retrieval Augmented Generation; Spoken Language Understanding","Computational linguistics; Knowledge management; Speech communication; Attention mechanisms; Automatic speech recognition; Language model; Large language model; Natural language understanding; Recognition models; Retrieval augmented generation; Speech retrieval; Spoken language understanding; Training sets; Speech recognition","","Institute of Electrical and Electronics Engineers Inc.","English","Conference paper","Final","","Scopus","2-s2.0-85190064828"
"Afzal M.; Li R.Y.M.; Shoaib M.; Ayyub M.F.; Tagliabue L.C.; Bilal M.; Ghafoor H.; Manta O.","Afzal, Muhammad (58585048900); Li, Rita Yi Man (35189135600); Shoaib, Muhammad (57213458638); Ayyub, Muhammad Faisal (58765217300); Tagliabue, Lavinia Chiara (18042749100); Bilal, Muhammad (57209092366); Ghafoor, Habiba (57219230938); Manta, Otilia (56968091500)","58585048900; 35189135600; 57213458638; 58765217300; 18042749100; 57209092366; 57219230938; 56968091500","Delving into the Digital Twin Developments and Applications in the Construction Industry: A PRISMA Approach","2023","Sustainability (Switzerland)","15","23","16436","","","","6","10.3390/su152316436","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185718782&doi=10.3390%2fsu152316436&partnerID=40&md5=328286cc0ac7f25791b4759ba6240685","Department of Architecture, Built Environment and Construction Engineering (DABC), Politecnico di Milano, Milano, 20133, Italy; Sustainable Real Estate Research Center, Department of Economics and Finance, Hong Kong Shue Yan University, North Point, 999077, Hong Kong; Department of Civil, Chemical, Environmental and Material Engineering—DICAM, Alma Mater Studiorum, University of Bologna, Bologna, 40126, Italy; Department of Computer Science, University of Turin, Turin, 10149, Italy; Department of Construction Engineering and Management, National University of Science and Technology (NUST), Islamabad, 44000, Pakistan; Descon Engineering Limited, Kasur Road Sufiabad, Lahore, 54760, Pakistan; Romanian Academy, Center for Financial and Monetary Research, Victor Slăvescu, Bucharest, 050711, Romania; Research Department, Romanian American University, Bucharest, 012101, Romania","Afzal M., Department of Architecture, Built Environment and Construction Engineering (DABC), Politecnico di Milano, Milano, 20133, Italy; Li R.Y.M., Sustainable Real Estate Research Center, Department of Economics and Finance, Hong Kong Shue Yan University, North Point, 999077, Hong Kong; Shoaib M., Department of Architecture, Built Environment and Construction Engineering (DABC), Politecnico di Milano, Milano, 20133, Italy; Ayyub M.F., Department of Civil, Chemical, Environmental and Material Engineering—DICAM, Alma Mater Studiorum, University of Bologna, Bologna, 40126, Italy; Tagliabue L.C., Department of Computer Science, University of Turin, Turin, 10149, Italy; Bilal M., Department of Construction Engineering and Management, National University of Science and Technology (NUST), Islamabad, 44000, Pakistan; Ghafoor H., Descon Engineering Limited, Kasur Road Sufiabad, Lahore, 54760, Pakistan; Manta O., Romanian Academy, Center for Financial and Monetary Research, Victor Slăvescu, Bucharest, 050711, Romania, Research Department, Romanian American University, Bucharest, 012101, Romania","Construction 4.0 is witnessing exponential growth in digital twin (DT) technology developments and applications, revolutionizing the adoption of building information modelling (BIM) and other emerging technologies used throughout the built environment lifecycle. BIM provides technologies, procedures, and data schemas representing building components and systems. At the same time, the DT enhances this with real-time data for integrating cyber-physical systems, enabling live asset monitoring and better decision making. Despite being in the early stages of development, DT applications have rapidly progressed in the AEC sector, resulting in a diverse literature landscape due to the various technologies and parameters involved in fully developing the DT technology. The intricate complexities inherent in digital twin advancements have confused professionals and researchers. This confusion arises from the nuanced distinctions between the two technologies, i.e., BIM and DT, causing a convergence that hinders realizing their potential. To address this confusion and lead to a swift development of DT technology, this study provides a holistic review of the existing research focusing on the critical components responsible for developing the applications of DT technology in the construction industry. It highlights five crucial elements: technologies, maturity levels, data layers, enablers, and functionalities. Additionally, it identifies research gaps and proposes future avenues for streamlined DT developments and applications in the AEC sector. Future researchers and practitioners can target data integrity, integration and transmission, bi-directional interoperability, non-technical factors, and data security to achieve mature digital twin applications for AEC practices. This study highlights the growing significance of DTs in construction and provides a foundation for further advancements in this field to harness its potential to transform built environment practices. It also pinpoints the latest developments in AI, namely the large language model (LLM) and retrieval-augmented generation (RAG)’s implications for DT education, policies, and the construction industry’s practices. © 2023 by the authors.","bi-directional interoperability; building information modelling; construction 4.0; digital transformation; digital twin; generative AI; PRISMA; sustainability","building; building construction; construction industry; foundation; future prospect; sustainability","","Multidisciplinary Digital Publishing Institute (MDPI)","English","Review","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85185718782"
"Zhang Z.; Zhang X.; Ren Y.; Shi S.; Han M.; Wu Y.; Lai R.; Cao Z.","Zhang, Zhebin (58781814900); Zhang, Xinyu (57224828442); Ren, Yuanhang (58675171400); Shi, Saijiang (58782913700); Han, Meng (58314426400); Wu, Yongkang (57274773500); Lai, Ruofei (57857551200); Cao, Zhao (57224829459)","58781814900; 57224828442; 58675171400; 58782913700; 58314426400; 57274773500; 57857551200; 57224829459","IAG: Induction-Augmented Generation Framework for Answering Reasoning Questions","2023","EMNLP 2023 - 2023 Conference on Empirical Methods in Natural Language Processing, Proceedings","","","","1","14","13","5","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184824245&partnerID=40&md5=03d9a4ab24ed2677f8ace99aaafb0772","Huawei Poisson Lab, China","Zhang Z., Huawei Poisson Lab, China; Zhang X., Huawei Poisson Lab, China; Ren Y., Huawei Poisson Lab, China; Shi S., Huawei Poisson Lab, China; Han M., Huawei Poisson Lab, China; Wu Y., Huawei Poisson Lab, China; Lai R., Huawei Poisson Lab, China; Cao Z., Huawei Poisson Lab, China","Retrieval-Augmented Generation (RAG), by incorporating external knowledge with parametric memory of language models, has become the state-of-the-art architecture for open-domain QA tasks. However, common knowledge bases are inherently constrained by limited coverage and noisy information, making retrieval-based approaches inadequate to answer implicit reasoning questions. In this paper, we propose an Induction-Augmented Generation (IAG) framework that utilizes inductive knowledge along with the retrieved documents for implicit reasoning. We leverage large language models (LLMs) for deriving such knowledge via a novel prompting method based on inductive reasoning patterns. On top of this, we implement two versions of IAG named IAG-GPT and IAG-Student, respectively. IAG-GPT directly utilizes the knowledge generated by GPT-3 for answer prediction, while IAG-Student gets rid of dependencies on GPT service at inference time by incorporating a student inductor model. The inductor is firstly trained via knowledge distillation and further optimized by back-propagating the generator feedback via differentiable beam scores. Experimental results show that IAG outperforms RAG baselines as well as ChatGPT on two Open-Domain QA tasks. Notably, our best models have won the first place in the official leaderboards of CSQA2.0 (since Nov 1, 2022) and StrategyQA (since Jan 8, 2023). ©2023 Association for Computational Linguistics.","","Computational linguistics; Distillation; Information retrieval; Knowledge management; Best model; Common knowledge; External knowledge; Inductive reasoning; Inductor modeling; Language model; Reasoning patterns; Retrieved documents; State of the art; Students","Bouamor H.; Pino J.; Bali K.","Association for Computational Linguistics (ACL)","English","Conference paper","Final","","Scopus","2-s2.0-85184824245"
"Rorseth J.; Godfrey P.; Golab L.; Srivastava D.; Szlichta J.","Rorseth, Joel (57204246939); Godfrey, Parke (7005052485); Golab, Lukasz (8224502200); Srivastava, Divesh (58161615400); Szlichta, Jaroslaw (37082075800)","57204246939; 7005052485; 8224502200; 58161615400; 37082075800","RAGE Against the Machine: Retrieval-Augmented LLM Explanations","2024","Proceedings - International Conference on Data Engineering","","","","5469","5472","3","2","10.1109/ICDE60146.2024.00430","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197244218&doi=10.1109%2fICDE60146.2024.00430&partnerID=40&md5=416828fe8eb5817973cdab7776a62a63","University of Waterloo, Canada; York University, Canada; AT&T Chief Data Office","Rorseth J., University of Waterloo, Canada; Godfrey P., York University, Canada; Golab L., University of Waterloo, Canada; Srivastava D., AT&T Chief Data Office; Szlichta J., York University, Canada","This paper demonstrates RAGE, an interactive tool for explaining Large Language Models (LLMs) augmented with retrieval capabilities; i.e., able to query external sources and pull relevant information into their input context. Our explanations are counterfactual in the sense that they identify parts of the input context that, when removed, change the answer to the question posed to the LLM. RAGE includes pruning methods to navigate the vast space of possible explanations, allowing users to view the provenance of the produced answers.  © 2024 IEEE.","Explainable AI; Large Language Models; Retrieval-Augmented Generation","Counterfactuals; Explainable AI; External sources; Interactive tool; Language model; Large language model; Pruning methods; Retrieval-augmented generation; Computational linguistics","","IEEE Computer Society","English","Conference paper","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85197244218"
